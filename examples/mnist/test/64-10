I0425 15:39:09.030145 12937 caffe.cpp:184] Using GPUs 0
I0425 15:39:09.321681 12937 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 5000
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/test/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/test/lenet_train_test.prototxt"
I0425 15:39:09.321825 12937 solver.cpp:91] Creating training net from net file: examples/mnist/test/lenet_train_test.prototxt
I0425 15:39:09.322209 12937 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0425 15:39:09.322229 12937 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0425 15:39:09.322310 12937 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0425 15:39:09.322396 12937 layer_factory.hpp:77] Creating layer mnist
I0425 15:39:09.322984 12937 net.cpp:106] Creating Layer mnist
I0425 15:39:09.322999 12937 net.cpp:411] mnist -> data
I0425 15:39:09.323031 12937 net.cpp:411] mnist -> label
I0425 15:39:09.324666 12942 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_train_lmdb
I0425 15:39:09.332370 12937 data_layer.cpp:41] output data size: 64,1,28,28
I0425 15:39:09.333314 12937 net.cpp:150] Setting up mnist
I0425 15:39:09.333336 12937 net.cpp:157] Top shape: 64 1 28 28 (50176)
I0425 15:39:09.333343 12937 net.cpp:157] Top shape: 64 (64)
I0425 15:39:09.333346 12937 net.cpp:165] Memory required for data: 200960
I0425 15:39:09.333356 12937 layer_factory.hpp:77] Creating layer conv1
I0425 15:39:09.333395 12937 net.cpp:106] Creating Layer conv1
I0425 15:39:09.333402 12937 net.cpp:454] conv1 <- data
I0425 15:39:09.333418 12937 net.cpp:411] conv1 -> conv1
I0425 15:39:09.461387 12937 net.cpp:150] Setting up conv1
I0425 15:39:09.461416 12937 net.cpp:157] Top shape: 64 20 24 24 (737280)
I0425 15:39:09.461421 12937 net.cpp:165] Memory required for data: 3150080
I0425 15:39:09.461439 12937 layer_factory.hpp:77] Creating layer pool1
I0425 15:39:09.461450 12937 net.cpp:106] Creating Layer pool1
I0425 15:39:09.461455 12937 net.cpp:454] pool1 <- conv1
I0425 15:39:09.461462 12937 net.cpp:411] pool1 -> pool1
I0425 15:39:09.462070 12937 net.cpp:150] Setting up pool1
I0425 15:39:09.462083 12937 net.cpp:157] Top shape: 64 20 12 12 (184320)
I0425 15:39:09.462087 12937 net.cpp:165] Memory required for data: 3887360
I0425 15:39:09.462091 12937 layer_factory.hpp:77] Creating layer conv2
I0425 15:39:09.462100 12937 net.cpp:106] Creating Layer conv2
I0425 15:39:09.462105 12937 net.cpp:454] conv2 <- pool1
I0425 15:39:09.462110 12937 net.cpp:411] conv2 -> conv2
I0425 15:39:09.464157 12937 net.cpp:150] Setting up conv2
I0425 15:39:09.464172 12937 net.cpp:157] Top shape: 64 50 8 8 (204800)
I0425 15:39:09.464176 12937 net.cpp:165] Memory required for data: 4706560
I0425 15:39:09.464184 12937 layer_factory.hpp:77] Creating layer pool2
I0425 15:39:09.464191 12937 net.cpp:106] Creating Layer pool2
I0425 15:39:09.464195 12937 net.cpp:454] pool2 <- conv2
I0425 15:39:09.464200 12937 net.cpp:411] pool2 -> pool2
I0425 15:39:09.464771 12937 net.cpp:150] Setting up pool2
I0425 15:39:09.464784 12937 net.cpp:157] Top shape: 64 50 4 4 (51200)
I0425 15:39:09.464787 12937 net.cpp:165] Memory required for data: 4911360
I0425 15:39:09.464792 12937 layer_factory.hpp:77] Creating layer ip1
I0425 15:39:09.464798 12937 net.cpp:106] Creating Layer ip1
I0425 15:39:09.464802 12937 net.cpp:454] ip1 <- pool2
I0425 15:39:09.464807 12937 net.cpp:411] ip1 -> ip1
I0425 15:39:09.465191 12937 net.cpp:150] Setting up ip1
I0425 15:39:09.465201 12937 net.cpp:157] Top shape: 64 64 (4096)
I0425 15:39:09.465204 12937 net.cpp:165] Memory required for data: 4927744
I0425 15:39:09.465211 12937 layer_factory.hpp:77] Creating layer relu1
I0425 15:39:09.465217 12937 net.cpp:106] Creating Layer relu1
I0425 15:39:09.465221 12937 net.cpp:454] relu1 <- ip1
I0425 15:39:09.465225 12937 net.cpp:397] relu1 -> ip1 (in-place)
I0425 15:39:09.465764 12937 net.cpp:150] Setting up relu1
I0425 15:39:09.465776 12937 net.cpp:157] Top shape: 64 64 (4096)
I0425 15:39:09.465780 12937 net.cpp:165] Memory required for data: 4944128
I0425 15:39:09.465782 12937 layer_factory.hpp:77] Creating layer ip2
I0425 15:39:09.465790 12937 net.cpp:106] Creating Layer ip2
I0425 15:39:09.465792 12937 net.cpp:454] ip2 <- ip1
I0425 15:39:09.465797 12937 net.cpp:411] ip2 -> ip2
I0425 15:39:09.465886 12937 net.cpp:150] Setting up ip2
I0425 15:39:09.465893 12937 net.cpp:157] Top shape: 64 10 (640)
I0425 15:39:09.465896 12937 net.cpp:165] Memory required for data: 4946688
I0425 15:39:09.465903 12937 layer_factory.hpp:77] Creating layer loss
I0425 15:39:09.465915 12937 net.cpp:106] Creating Layer loss
I0425 15:39:09.465919 12937 net.cpp:454] loss <- ip2
I0425 15:39:09.465922 12937 net.cpp:454] loss <- label
I0425 15:39:09.465929 12937 net.cpp:411] loss -> loss
I0425 15:39:09.465939 12937 layer_factory.hpp:77] Creating layer loss
I0425 15:39:09.466560 12937 net.cpp:150] Setting up loss
I0425 15:39:09.466574 12937 net.cpp:157] Top shape: (1)
I0425 15:39:09.466578 12937 net.cpp:160]     with loss weight 1
I0425 15:39:09.466593 12937 net.cpp:165] Memory required for data: 4946692
I0425 15:39:09.466595 12937 net.cpp:226] loss needs backward computation.
I0425 15:39:09.466598 12937 net.cpp:226] ip2 needs backward computation.
I0425 15:39:09.466601 12937 net.cpp:226] relu1 needs backward computation.
I0425 15:39:09.466604 12937 net.cpp:226] ip1 needs backward computation.
I0425 15:39:09.466606 12937 net.cpp:226] pool2 needs backward computation.
I0425 15:39:09.466609 12937 net.cpp:226] conv2 needs backward computation.
I0425 15:39:09.466612 12937 net.cpp:226] pool1 needs backward computation.
I0425 15:39:09.466615 12937 net.cpp:226] conv1 needs backward computation.
I0425 15:39:09.466619 12937 net.cpp:228] mnist does not need backward computation.
I0425 15:39:09.466621 12937 net.cpp:270] This network produces output loss
I0425 15:39:09.466629 12937 net.cpp:283] Network initialization done.
I0425 15:39:09.466924 12937 solver.cpp:181] Creating test net (#0) specified by net file: examples/mnist/test/lenet_train_test.prototxt
I0425 15:39:09.466949 12937 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0425 15:39:09.467044 12937 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0425 15:39:09.467113 12937 layer_factory.hpp:77] Creating layer mnist
I0425 15:39:09.467214 12937 net.cpp:106] Creating Layer mnist
I0425 15:39:09.467234 12937 net.cpp:411] mnist -> data
I0425 15:39:09.467243 12937 net.cpp:411] mnist -> label
I0425 15:39:09.468739 12944 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_test_lmdb
I0425 15:39:09.468860 12937 data_layer.cpp:41] output data size: 100,1,28,28
I0425 15:39:09.469799 12937 net.cpp:150] Setting up mnist
I0425 15:39:09.469812 12937 net.cpp:157] Top shape: 100 1 28 28 (78400)
I0425 15:39:09.469817 12937 net.cpp:157] Top shape: 100 (100)
I0425 15:39:09.469820 12937 net.cpp:165] Memory required for data: 314000
I0425 15:39:09.469823 12937 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0425 15:39:09.469844 12937 net.cpp:106] Creating Layer label_mnist_1_split
I0425 15:39:09.469851 12937 net.cpp:454] label_mnist_1_split <- label
I0425 15:39:09.469859 12937 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_0
I0425 15:39:09.469871 12937 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_1
I0425 15:39:09.469987 12937 net.cpp:150] Setting up label_mnist_1_split
I0425 15:39:09.469998 12937 net.cpp:157] Top shape: 100 (100)
I0425 15:39:09.470002 12937 net.cpp:157] Top shape: 100 (100)
I0425 15:39:09.470006 12937 net.cpp:165] Memory required for data: 314800
I0425 15:39:09.470011 12937 layer_factory.hpp:77] Creating layer conv1
I0425 15:39:09.470026 12937 net.cpp:106] Creating Layer conv1
I0425 15:39:09.470032 12937 net.cpp:454] conv1 <- data
I0425 15:39:09.470041 12937 net.cpp:411] conv1 -> conv1
I0425 15:39:09.472365 12937 net.cpp:150] Setting up conv1
I0425 15:39:09.472380 12937 net.cpp:157] Top shape: 100 20 24 24 (1152000)
I0425 15:39:09.472384 12937 net.cpp:165] Memory required for data: 4922800
I0425 15:39:09.472393 12937 layer_factory.hpp:77] Creating layer pool1
I0425 15:39:09.472398 12937 net.cpp:106] Creating Layer pool1
I0425 15:39:09.472417 12937 net.cpp:454] pool1 <- conv1
I0425 15:39:09.472430 12937 net.cpp:411] pool1 -> pool1
I0425 15:39:09.473233 12937 net.cpp:150] Setting up pool1
I0425 15:39:09.473249 12937 net.cpp:157] Top shape: 100 20 12 12 (288000)
I0425 15:39:09.473259 12937 net.cpp:165] Memory required for data: 6074800
I0425 15:39:09.473268 12937 layer_factory.hpp:77] Creating layer conv2
I0425 15:39:09.473289 12937 net.cpp:106] Creating Layer conv2
I0425 15:39:09.473306 12937 net.cpp:454] conv2 <- pool1
I0425 15:39:09.473318 12937 net.cpp:411] conv2 -> conv2
I0425 15:39:09.475661 12937 net.cpp:150] Setting up conv2
I0425 15:39:09.475675 12937 net.cpp:157] Top shape: 100 50 8 8 (320000)
I0425 15:39:09.475679 12937 net.cpp:165] Memory required for data: 7354800
I0425 15:39:09.475692 12937 layer_factory.hpp:77] Creating layer pool2
I0425 15:39:09.475699 12937 net.cpp:106] Creating Layer pool2
I0425 15:39:09.475705 12937 net.cpp:454] pool2 <- conv2
I0425 15:39:09.475710 12937 net.cpp:411] pool2 -> pool2
I0425 15:39:09.476455 12937 net.cpp:150] Setting up pool2
I0425 15:39:09.476477 12937 net.cpp:157] Top shape: 100 50 4 4 (80000)
I0425 15:39:09.476481 12937 net.cpp:165] Memory required for data: 7674800
I0425 15:39:09.476485 12937 layer_factory.hpp:77] Creating layer ip1
I0425 15:39:09.476497 12937 net.cpp:106] Creating Layer ip1
I0425 15:39:09.476508 12937 net.cpp:454] ip1 <- pool2
I0425 15:39:09.476532 12937 net.cpp:411] ip1 -> ip1
I0425 15:39:09.477365 12937 net.cpp:150] Setting up ip1
I0425 15:39:09.477386 12937 net.cpp:157] Top shape: 100 64 (6400)
I0425 15:39:09.477394 12937 net.cpp:165] Memory required for data: 7700400
I0425 15:39:09.477402 12937 layer_factory.hpp:77] Creating layer relu1
I0425 15:39:09.477409 12937 net.cpp:106] Creating Layer relu1
I0425 15:39:09.477416 12937 net.cpp:454] relu1 <- ip1
I0425 15:39:09.477427 12937 net.cpp:397] relu1 -> ip1 (in-place)
I0425 15:39:09.478070 12937 net.cpp:150] Setting up relu1
I0425 15:39:09.478087 12937 net.cpp:157] Top shape: 100 64 (6400)
I0425 15:39:09.478108 12937 net.cpp:165] Memory required for data: 7726000
I0425 15:39:09.478116 12937 layer_factory.hpp:77] Creating layer ip2
I0425 15:39:09.478129 12937 net.cpp:106] Creating Layer ip2
I0425 15:39:09.478132 12937 net.cpp:454] ip2 <- ip1
I0425 15:39:09.478140 12937 net.cpp:411] ip2 -> ip2
I0425 15:39:09.478248 12937 net.cpp:150] Setting up ip2
I0425 15:39:09.478260 12937 net.cpp:157] Top shape: 100 10 (1000)
I0425 15:39:09.478266 12937 net.cpp:165] Memory required for data: 7730000
I0425 15:39:09.478277 12937 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0425 15:39:09.478282 12937 net.cpp:106] Creating Layer ip2_ip2_0_split
I0425 15:39:09.478286 12937 net.cpp:454] ip2_ip2_0_split <- ip2
I0425 15:39:09.478291 12937 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0425 15:39:09.478307 12937 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0425 15:39:09.478343 12937 net.cpp:150] Setting up ip2_ip2_0_split
I0425 15:39:09.478351 12937 net.cpp:157] Top shape: 100 10 (1000)
I0425 15:39:09.478361 12937 net.cpp:157] Top shape: 100 10 (1000)
I0425 15:39:09.478364 12937 net.cpp:165] Memory required for data: 7738000
I0425 15:39:09.478368 12937 layer_factory.hpp:77] Creating layer accuracy
I0425 15:39:09.478374 12937 net.cpp:106] Creating Layer accuracy
I0425 15:39:09.478377 12937 net.cpp:454] accuracy <- ip2_ip2_0_split_0
I0425 15:39:09.478380 12937 net.cpp:454] accuracy <- label_mnist_1_split_0
I0425 15:39:09.478385 12937 net.cpp:411] accuracy -> accuracy
I0425 15:39:09.478392 12937 net.cpp:150] Setting up accuracy
I0425 15:39:09.478406 12937 net.cpp:157] Top shape: (1)
I0425 15:39:09.478410 12937 net.cpp:165] Memory required for data: 7738004
I0425 15:39:09.478421 12937 layer_factory.hpp:77] Creating layer loss
I0425 15:39:09.478428 12937 net.cpp:106] Creating Layer loss
I0425 15:39:09.478436 12937 net.cpp:454] loss <- ip2_ip2_0_split_1
I0425 15:39:09.478440 12937 net.cpp:454] loss <- label_mnist_1_split_1
I0425 15:39:09.478444 12937 net.cpp:411] loss -> loss
I0425 15:39:09.478451 12937 layer_factory.hpp:77] Creating layer loss
I0425 15:39:09.479217 12937 net.cpp:150] Setting up loss
I0425 15:39:09.479230 12937 net.cpp:157] Top shape: (1)
I0425 15:39:09.479233 12937 net.cpp:160]     with loss weight 1
I0425 15:39:09.479240 12937 net.cpp:165] Memory required for data: 7738008
I0425 15:39:09.479243 12937 net.cpp:226] loss needs backward computation.
I0425 15:39:09.479248 12937 net.cpp:228] accuracy does not need backward computation.
I0425 15:39:09.479250 12937 net.cpp:226] ip2_ip2_0_split needs backward computation.
I0425 15:39:09.479254 12937 net.cpp:226] ip2 needs backward computation.
I0425 15:39:09.479256 12937 net.cpp:226] relu1 needs backward computation.
I0425 15:39:09.479259 12937 net.cpp:226] ip1 needs backward computation.
I0425 15:39:09.479261 12937 net.cpp:226] pool2 needs backward computation.
I0425 15:39:09.479264 12937 net.cpp:226] conv2 needs backward computation.
I0425 15:39:09.479267 12937 net.cpp:226] pool1 needs backward computation.
I0425 15:39:09.479270 12937 net.cpp:226] conv1 needs backward computation.
I0425 15:39:09.479275 12937 net.cpp:228] label_mnist_1_split does not need backward computation.
I0425 15:39:09.479279 12937 net.cpp:228] mnist does not need backward computation.
I0425 15:39:09.479281 12937 net.cpp:270] This network produces output accuracy
I0425 15:39:09.479285 12937 net.cpp:270] This network produces output loss
I0425 15:39:09.479295 12937 net.cpp:283] Network initialization done.
I0425 15:39:09.479341 12937 solver.cpp:60] Solver scaffolding done.
I0425 15:39:09.479578 12937 caffe.cpp:212] Starting Optimization
I0425 15:39:09.479584 12937 solver.cpp:288] Solving LeNet
I0425 15:39:09.479588 12937 solver.cpp:289] Learning Rate Policy: inv
I0425 15:39:09.479859 12937 solver.cpp:341] Iteration 0, Testing net (#0)
I0425 15:39:09.485781 12937 blocking_queue.cpp:50] Data layer prefetch queue empty
I0425 15:39:09.582319 12937 solver.cpp:409]     Test net output #0: accuracy = 0.0895
I0425 15:39:09.582356 12937 solver.cpp:409]     Test net output #1: loss = 2.40433 (* 1 = 2.40433 loss)
I0425 15:39:09.584285 12937 solver.cpp:237] Iteration 0, loss = 2.40729
I0425 15:39:09.584306 12937 solver.cpp:253]     Train net output #0: loss = 2.40729 (* 1 = 2.40729 loss)
I0425 15:39:09.584318 12937 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0425 15:39:09.746526 12937 solver.cpp:237] Iteration 100, loss = 0.24545
I0425 15:39:09.746554 12937 solver.cpp:253]     Train net output #0: loss = 0.24545 (* 1 = 0.24545 loss)
I0425 15:39:09.746561 12937 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0425 15:39:09.899101 12937 solver.cpp:237] Iteration 200, loss = 0.159319
I0425 15:39:09.899158 12937 solver.cpp:253]     Train net output #0: loss = 0.159319 (* 1 = 0.159319 loss)
I0425 15:39:09.899174 12937 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0425 15:39:10.048415 12937 solver.cpp:237] Iteration 300, loss = 0.206301
I0425 15:39:10.048450 12937 solver.cpp:253]     Train net output #0: loss = 0.206301 (* 1 = 0.206301 loss)
I0425 15:39:10.048459 12937 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0425 15:39:10.192713 12937 solver.cpp:237] Iteration 400, loss = 0.0830832
I0425 15:39:10.192739 12937 solver.cpp:253]     Train net output #0: loss = 0.0830832 (* 1 = 0.0830832 loss)
I0425 15:39:10.192744 12937 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0425 15:39:10.339522 12937 solver.cpp:237] Iteration 500, loss = 0.131562
I0425 15:39:10.339547 12937 solver.cpp:253]     Train net output #0: loss = 0.131562 (* 1 = 0.131562 loss)
I0425 15:39:10.339553 12937 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0425 15:39:10.485980 12937 solver.cpp:237] Iteration 600, loss = 0.101071
I0425 15:39:10.486006 12937 solver.cpp:253]     Train net output #0: loss = 0.101071 (* 1 = 0.101071 loss)
I0425 15:39:10.486012 12937 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0425 15:39:10.630851 12937 solver.cpp:237] Iteration 700, loss = 0.173988
I0425 15:39:10.630877 12937 solver.cpp:253]     Train net output #0: loss = 0.173988 (* 1 = 0.173988 loss)
I0425 15:39:10.630882 12937 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0425 15:39:10.777348 12937 solver.cpp:237] Iteration 800, loss = 0.237911
I0425 15:39:10.777371 12937 solver.cpp:253]     Train net output #0: loss = 0.237911 (* 1 = 0.237911 loss)
I0425 15:39:10.777377 12937 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0425 15:39:10.925688 12937 solver.cpp:237] Iteration 900, loss = 0.149675
I0425 15:39:10.925729 12937 solver.cpp:253]     Train net output #0: loss = 0.149675 (* 1 = 0.149675 loss)
I0425 15:39:10.925741 12937 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0425 15:39:11.073715 12937 solver.cpp:237] Iteration 1000, loss = 0.144947
I0425 15:39:11.073745 12937 solver.cpp:253]     Train net output #0: loss = 0.144947 (* 1 = 0.144947 loss)
I0425 15:39:11.073752 12937 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0425 15:39:11.220336 12937 solver.cpp:237] Iteration 1100, loss = 0.00722291
I0425 15:39:11.220360 12937 solver.cpp:253]     Train net output #0: loss = 0.00722285 (* 1 = 0.00722285 loss)
I0425 15:39:11.220366 12937 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0425 15:39:11.367272 12937 solver.cpp:237] Iteration 1200, loss = 0.0163552
I0425 15:39:11.367296 12937 solver.cpp:253]     Train net output #0: loss = 0.0163552 (* 1 = 0.0163552 loss)
I0425 15:39:11.367302 12937 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0425 15:39:11.516705 12937 solver.cpp:237] Iteration 1300, loss = 0.0254893
I0425 15:39:11.516742 12937 solver.cpp:253]     Train net output #0: loss = 0.0254892 (* 1 = 0.0254892 loss)
I0425 15:39:11.516752 12937 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0425 15:39:11.663337 12937 solver.cpp:237] Iteration 1400, loss = 0.00587706
I0425 15:39:11.663362 12937 solver.cpp:253]     Train net output #0: loss = 0.00587697 (* 1 = 0.00587697 loss)
I0425 15:39:11.663367 12937 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0425 15:39:11.809434 12937 solver.cpp:237] Iteration 1500, loss = 0.0708902
I0425 15:39:11.809458 12937 solver.cpp:253]     Train net output #0: loss = 0.0708901 (* 1 = 0.0708901 loss)
I0425 15:39:11.809464 12937 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0425 15:39:11.954563 12937 solver.cpp:237] Iteration 1600, loss = 0.165444
I0425 15:39:11.954586 12937 solver.cpp:253]     Train net output #0: loss = 0.165444 (* 1 = 0.165444 loss)
I0425 15:39:11.954592 12937 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0425 15:39:12.101275 12937 solver.cpp:237] Iteration 1700, loss = 0.0344139
I0425 15:39:12.101300 12937 solver.cpp:253]     Train net output #0: loss = 0.0344138 (* 1 = 0.0344138 loss)
I0425 15:39:12.101306 12937 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0425 15:39:12.246281 12937 solver.cpp:237] Iteration 1800, loss = 0.0165822
I0425 15:39:12.246306 12937 solver.cpp:253]     Train net output #0: loss = 0.0165821 (* 1 = 0.0165821 loss)
I0425 15:39:12.246312 12937 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0425 15:39:12.393208 12937 solver.cpp:237] Iteration 1900, loss = 0.128271
I0425 15:39:12.393237 12937 solver.cpp:253]     Train net output #0: loss = 0.12827 (* 1 = 0.12827 loss)
I0425 15:39:12.393244 12937 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0425 15:39:12.539193 12937 solver.cpp:237] Iteration 2000, loss = 0.0158136
I0425 15:39:12.539214 12937 solver.cpp:253]     Train net output #0: loss = 0.0158135 (* 1 = 0.0158135 loss)
I0425 15:39:12.539221 12937 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0425 15:39:12.685888 12937 solver.cpp:237] Iteration 2100, loss = 0.00574427
I0425 15:39:12.685909 12937 solver.cpp:253]     Train net output #0: loss = 0.00574413 (* 1 = 0.00574413 loss)
I0425 15:39:12.685914 12937 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0425 15:39:12.832278 12937 solver.cpp:237] Iteration 2200, loss = 0.0241803
I0425 15:39:12.832300 12937 solver.cpp:253]     Train net output #0: loss = 0.0241801 (* 1 = 0.0241801 loss)
I0425 15:39:12.832306 12937 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0425 15:39:12.978386 12937 solver.cpp:237] Iteration 2300, loss = 0.102019
I0425 15:39:12.978409 12937 solver.cpp:253]     Train net output #0: loss = 0.102019 (* 1 = 0.102019 loss)
I0425 15:39:12.978433 12937 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0425 15:39:13.124929 12937 solver.cpp:237] Iteration 2400, loss = 0.0109336
I0425 15:39:13.124949 12937 solver.cpp:253]     Train net output #0: loss = 0.0109334 (* 1 = 0.0109334 loss)
I0425 15:39:13.124954 12937 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0425 15:39:13.271680 12937 solver.cpp:237] Iteration 2500, loss = 0.0382135
I0425 15:39:13.271702 12937 solver.cpp:253]     Train net output #0: loss = 0.0382133 (* 1 = 0.0382133 loss)
I0425 15:39:13.271706 12937 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0425 15:39:13.417794 12937 solver.cpp:237] Iteration 2600, loss = 0.0578766
I0425 15:39:13.417814 12937 solver.cpp:253]     Train net output #0: loss = 0.0578764 (* 1 = 0.0578764 loss)
I0425 15:39:13.417820 12937 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0425 15:39:13.564260 12937 solver.cpp:237] Iteration 2700, loss = 0.0799852
I0425 15:39:13.564280 12937 solver.cpp:253]     Train net output #0: loss = 0.079985 (* 1 = 0.079985 loss)
I0425 15:39:13.564285 12937 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0425 15:39:13.710186 12937 solver.cpp:237] Iteration 2800, loss = 0.00356873
I0425 15:39:13.710206 12937 solver.cpp:253]     Train net output #0: loss = 0.00356855 (* 1 = 0.00356855 loss)
I0425 15:39:13.710212 12937 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0425 15:39:13.857383 12937 solver.cpp:237] Iteration 2900, loss = 0.0529105
I0425 15:39:13.857403 12937 solver.cpp:253]     Train net output #0: loss = 0.0529103 (* 1 = 0.0529103 loss)
I0425 15:39:13.857408 12937 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0425 15:39:14.002686 12937 solver.cpp:237] Iteration 3000, loss = 0.00929417
I0425 15:39:14.002708 12937 solver.cpp:253]     Train net output #0: loss = 0.00929399 (* 1 = 0.00929399 loss)
I0425 15:39:14.002714 12937 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0425 15:39:14.148653 12937 solver.cpp:237] Iteration 3100, loss = 0.00523859
I0425 15:39:14.148680 12937 solver.cpp:253]     Train net output #0: loss = 0.00523844 (* 1 = 0.00523844 loss)
I0425 15:39:14.148686 12937 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0425 15:39:14.294744 12937 solver.cpp:237] Iteration 3200, loss = 0.00872643
I0425 15:39:14.294769 12937 solver.cpp:253]     Train net output #0: loss = 0.00872625 (* 1 = 0.00872625 loss)
I0425 15:39:14.294773 12937 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0425 15:39:14.442201 12937 solver.cpp:237] Iteration 3300, loss = 0.0397288
I0425 15:39:14.442224 12937 solver.cpp:253]     Train net output #0: loss = 0.0397286 (* 1 = 0.0397286 loss)
I0425 15:39:14.442230 12937 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0425 15:39:14.588650 12937 solver.cpp:237] Iteration 3400, loss = 0.0154537
I0425 15:39:14.588672 12937 solver.cpp:253]     Train net output #0: loss = 0.0154535 (* 1 = 0.0154535 loss)
I0425 15:39:14.588677 12937 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0425 15:39:14.734989 12937 solver.cpp:237] Iteration 3500, loss = 0.00707823
I0425 15:39:14.735011 12937 solver.cpp:253]     Train net output #0: loss = 0.00707805 (* 1 = 0.00707805 loss)
I0425 15:39:14.735018 12937 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0425 15:39:14.880570 12937 solver.cpp:237] Iteration 3600, loss = 0.0404804
I0425 15:39:14.880594 12937 solver.cpp:253]     Train net output #0: loss = 0.0404802 (* 1 = 0.0404802 loss)
I0425 15:39:14.880599 12937 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0425 15:39:15.026866 12937 solver.cpp:237] Iteration 3700, loss = 0.0492061
I0425 15:39:15.026890 12937 solver.cpp:253]     Train net output #0: loss = 0.049206 (* 1 = 0.049206 loss)
I0425 15:39:15.026895 12937 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0425 15:39:15.172960 12937 solver.cpp:237] Iteration 3800, loss = 0.0212087
I0425 15:39:15.172981 12937 solver.cpp:253]     Train net output #0: loss = 0.0212086 (* 1 = 0.0212086 loss)
I0425 15:39:15.173012 12937 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0425 15:39:15.319317 12937 solver.cpp:237] Iteration 3900, loss = 0.0563577
I0425 15:39:15.319339 12937 solver.cpp:253]     Train net output #0: loss = 0.0563576 (* 1 = 0.0563576 loss)
I0425 15:39:15.319344 12937 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0425 15:39:15.466224 12937 solver.cpp:237] Iteration 4000, loss = 0.0183601
I0425 15:39:15.466248 12937 solver.cpp:253]     Train net output #0: loss = 0.0183599 (* 1 = 0.0183599 loss)
I0425 15:39:15.466253 12937 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0425 15:39:15.612637 12937 solver.cpp:237] Iteration 4100, loss = 0.0308576
I0425 15:39:15.612660 12937 solver.cpp:253]     Train net output #0: loss = 0.0308574 (* 1 = 0.0308574 loss)
I0425 15:39:15.612665 12937 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0425 15:39:15.759148 12937 solver.cpp:237] Iteration 4200, loss = 0.0144007
I0425 15:39:15.759173 12937 solver.cpp:253]     Train net output #0: loss = 0.0144005 (* 1 = 0.0144005 loss)
I0425 15:39:15.759178 12937 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0425 15:39:15.905684 12937 solver.cpp:237] Iteration 4300, loss = 0.0588345
I0425 15:39:15.905707 12937 solver.cpp:253]     Train net output #0: loss = 0.0588343 (* 1 = 0.0588343 loss)
I0425 15:39:15.905714 12937 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0425 15:39:16.052731 12937 solver.cpp:237] Iteration 4400, loss = 0.0117878
I0425 15:39:16.052753 12937 solver.cpp:253]     Train net output #0: loss = 0.0117876 (* 1 = 0.0117876 loss)
I0425 15:39:16.052758 12937 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0425 15:39:16.198642 12937 solver.cpp:237] Iteration 4500, loss = 0.0061641
I0425 15:39:16.198664 12937 solver.cpp:253]     Train net output #0: loss = 0.00616395 (* 1 = 0.00616395 loss)
I0425 15:39:16.198670 12937 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0425 15:39:16.345260 12937 solver.cpp:237] Iteration 4600, loss = 0.0200009
I0425 15:39:16.345283 12937 solver.cpp:253]     Train net output #0: loss = 0.0200008 (* 1 = 0.0200008 loss)
I0425 15:39:16.345289 12937 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0425 15:39:16.491763 12937 solver.cpp:237] Iteration 4700, loss = 0.0146928
I0425 15:39:16.491786 12937 solver.cpp:253]     Train net output #0: loss = 0.0146927 (* 1 = 0.0146927 loss)
I0425 15:39:16.491792 12937 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0425 15:39:16.638103 12937 solver.cpp:237] Iteration 4800, loss = 0.0163712
I0425 15:39:16.638125 12937 solver.cpp:253]     Train net output #0: loss = 0.0163711 (* 1 = 0.0163711 loss)
I0425 15:39:16.638131 12937 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0425 15:39:16.784003 12937 solver.cpp:237] Iteration 4900, loss = 0.00626826
I0425 15:39:16.784024 12937 solver.cpp:253]     Train net output #0: loss = 0.00626809 (* 1 = 0.00626809 loss)
I0425 15:39:16.784029 12937 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0425 15:39:16.928618 12937 solver.cpp:459] Snapshotting to binary proto file examples/mnist/test/lenet_iter_5000.caffemodel
I0425 15:39:16.931087 12937 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/test/lenet_iter_5000.solverstate
I0425 15:39:16.931578 12937 solver.cpp:341] Iteration 5000, Testing net (#0)
I0425 15:39:17.013597 12937 solver.cpp:409]     Test net output #0: accuracy = 0.9887
I0425 15:39:17.013629 12937 solver.cpp:409]     Test net output #1: loss = 0.0337344 (* 1 = 0.0337344 loss)
I0425 15:39:17.014400 12937 solver.cpp:237] Iteration 5000, loss = 0.0673237
I0425 15:39:17.014422 12937 solver.cpp:253]     Train net output #0: loss = 0.0673236 (* 1 = 0.0673236 loss)
I0425 15:39:17.014435 12937 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0425 15:39:17.160682 12937 solver.cpp:237] Iteration 5100, loss = 0.0254377
I0425 15:39:17.160703 12937 solver.cpp:253]     Train net output #0: loss = 0.0254376 (* 1 = 0.0254376 loss)
I0425 15:39:17.160708 12937 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0425 15:39:17.307683 12937 solver.cpp:237] Iteration 5200, loss = 0.0141119
I0425 15:39:17.307725 12937 solver.cpp:253]     Train net output #0: loss = 0.0141118 (* 1 = 0.0141118 loss)
I0425 15:39:17.307732 12937 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0425 15:39:17.454718 12937 solver.cpp:237] Iteration 5300, loss = 0.00296403
I0425 15:39:17.454741 12937 solver.cpp:253]     Train net output #0: loss = 0.00296392 (* 1 = 0.00296392 loss)
I0425 15:39:17.454746 12937 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0425 15:39:17.600966 12937 solver.cpp:237] Iteration 5400, loss = 0.0113816
I0425 15:39:17.600987 12937 solver.cpp:253]     Train net output #0: loss = 0.0113814 (* 1 = 0.0113814 loss)
I0425 15:39:17.600993 12937 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0425 15:39:17.747117 12937 solver.cpp:237] Iteration 5500, loss = 0.00535842
I0425 15:39:17.747138 12937 solver.cpp:253]     Train net output #0: loss = 0.00535829 (* 1 = 0.00535829 loss)
I0425 15:39:17.747143 12937 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0425 15:39:17.893579 12937 solver.cpp:237] Iteration 5600, loss = 0.00104149
I0425 15:39:17.893599 12937 solver.cpp:253]     Train net output #0: loss = 0.00104135 (* 1 = 0.00104135 loss)
I0425 15:39:17.893604 12937 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0425 15:39:18.040823 12937 solver.cpp:237] Iteration 5700, loss = 0.00501578
I0425 15:39:18.040844 12937 solver.cpp:253]     Train net output #0: loss = 0.00501566 (* 1 = 0.00501566 loss)
I0425 15:39:18.040850 12937 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0425 15:39:18.186421 12937 solver.cpp:237] Iteration 5800, loss = 0.0597509
I0425 15:39:18.186441 12937 solver.cpp:253]     Train net output #0: loss = 0.0597508 (* 1 = 0.0597508 loss)
I0425 15:39:18.186447 12937 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0425 15:39:18.331316 12937 solver.cpp:237] Iteration 5900, loss = 0.0116305
I0425 15:39:18.331336 12937 solver.cpp:253]     Train net output #0: loss = 0.0116304 (* 1 = 0.0116304 loss)
I0425 15:39:18.331342 12937 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0425 15:39:18.476908 12937 solver.cpp:237] Iteration 6000, loss = 0.00479084
I0425 15:39:18.476928 12937 solver.cpp:253]     Train net output #0: loss = 0.00479074 (* 1 = 0.00479074 loss)
I0425 15:39:18.476948 12937 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0425 15:39:18.623219 12937 solver.cpp:237] Iteration 6100, loss = 0.00359761
I0425 15:39:18.623239 12937 solver.cpp:253]     Train net output #0: loss = 0.00359753 (* 1 = 0.00359753 loss)
I0425 15:39:18.623245 12937 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0425 15:39:18.768515 12937 solver.cpp:237] Iteration 6200, loss = 0.0096595
I0425 15:39:18.768539 12937 solver.cpp:253]     Train net output #0: loss = 0.00965943 (* 1 = 0.00965943 loss)
I0425 15:39:18.768545 12937 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0425 15:39:18.913729 12937 solver.cpp:237] Iteration 6300, loss = 0.0076937
I0425 15:39:18.913753 12937 solver.cpp:253]     Train net output #0: loss = 0.00769362 (* 1 = 0.00769362 loss)
I0425 15:39:18.913758 12937 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0425 15:39:19.061019 12937 solver.cpp:237] Iteration 6400, loss = 0.0174166
I0425 15:39:19.061040 12937 solver.cpp:253]     Train net output #0: loss = 0.0174165 (* 1 = 0.0174165 loss)
I0425 15:39:19.061046 12937 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0425 15:39:19.207595 12937 solver.cpp:237] Iteration 6500, loss = 0.0171336
I0425 15:39:19.207618 12937 solver.cpp:253]     Train net output #0: loss = 0.0171335 (* 1 = 0.0171335 loss)
I0425 15:39:19.207628 12937 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0425 15:39:19.355294 12937 solver.cpp:237] Iteration 6600, loss = 0.053218
I0425 15:39:19.355330 12937 solver.cpp:253]     Train net output #0: loss = 0.0532179 (* 1 = 0.0532179 loss)
I0425 15:39:19.355341 12937 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0425 15:39:19.502924 12937 solver.cpp:237] Iteration 6700, loss = 0.00740113
I0425 15:39:19.502953 12937 solver.cpp:253]     Train net output #0: loss = 0.00740105 (* 1 = 0.00740105 loss)
I0425 15:39:19.502985 12937 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0425 15:39:19.649525 12937 solver.cpp:237] Iteration 6800, loss = 0.0023847
I0425 15:39:19.649550 12937 solver.cpp:253]     Train net output #0: loss = 0.00238461 (* 1 = 0.00238461 loss)
I0425 15:39:19.649564 12937 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0425 15:39:19.796622 12937 solver.cpp:237] Iteration 6900, loss = 0.00695535
I0425 15:39:19.796645 12937 solver.cpp:253]     Train net output #0: loss = 0.00695526 (* 1 = 0.00695526 loss)
I0425 15:39:19.796651 12937 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0425 15:39:19.942807 12937 solver.cpp:237] Iteration 7000, loss = 0.010558
I0425 15:39:19.942834 12937 solver.cpp:253]     Train net output #0: loss = 0.0105579 (* 1 = 0.0105579 loss)
I0425 15:39:19.942841 12937 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0425 15:39:20.089231 12937 solver.cpp:237] Iteration 7100, loss = 0.0155647
I0425 15:39:20.089257 12937 solver.cpp:253]     Train net output #0: loss = 0.0155646 (* 1 = 0.0155646 loss)
I0425 15:39:20.089262 12937 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0425 15:39:20.235798 12937 solver.cpp:237] Iteration 7200, loss = 0.00752036
I0425 15:39:20.235823 12937 solver.cpp:253]     Train net output #0: loss = 0.00752026 (* 1 = 0.00752026 loss)
I0425 15:39:20.235829 12937 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0425 15:39:20.382669 12937 solver.cpp:237] Iteration 7300, loss = 0.0224859
I0425 15:39:20.382695 12937 solver.cpp:253]     Train net output #0: loss = 0.0224858 (* 1 = 0.0224858 loss)
I0425 15:39:20.382701 12937 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0425 15:39:20.531476 12937 solver.cpp:237] Iteration 7400, loss = 0.0108619
I0425 15:39:20.531515 12937 solver.cpp:253]     Train net output #0: loss = 0.0108618 (* 1 = 0.0108618 loss)
I0425 15:39:20.531527 12937 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0425 15:39:20.682013 12937 solver.cpp:237] Iteration 7500, loss = 0.00688176
I0425 15:39:20.682040 12937 solver.cpp:253]     Train net output #0: loss = 0.00688168 (* 1 = 0.00688168 loss)
I0425 15:39:20.682047 12937 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0425 15:39:20.829483 12937 solver.cpp:237] Iteration 7600, loss = 0.0101509
I0425 15:39:20.829509 12937 solver.cpp:253]     Train net output #0: loss = 0.0101508 (* 1 = 0.0101508 loss)
I0425 15:39:20.829514 12937 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0425 15:39:20.976141 12937 solver.cpp:237] Iteration 7700, loss = 0.0571693
I0425 15:39:20.976166 12937 solver.cpp:253]     Train net output #0: loss = 0.0571691 (* 1 = 0.0571691 loss)
I0425 15:39:20.976171 12937 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0425 15:39:21.122154 12937 solver.cpp:237] Iteration 7800, loss = 0.00570166
I0425 15:39:21.122177 12937 solver.cpp:253]     Train net output #0: loss = 0.00570155 (* 1 = 0.00570155 loss)
I0425 15:39:21.122182 12937 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0425 15:39:21.268196 12937 solver.cpp:237] Iteration 7900, loss = 0.00566689
I0425 15:39:21.268218 12937 solver.cpp:253]     Train net output #0: loss = 0.00566677 (* 1 = 0.00566677 loss)
I0425 15:39:21.268223 12937 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0425 15:39:21.414575 12937 solver.cpp:237] Iteration 8000, loss = 0.0153049
I0425 15:39:21.414598 12937 solver.cpp:253]     Train net output #0: loss = 0.0153048 (* 1 = 0.0153048 loss)
I0425 15:39:21.414604 12937 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0425 15:39:21.561244 12937 solver.cpp:237] Iteration 8100, loss = 0.0389931
I0425 15:39:21.561266 12937 solver.cpp:253]     Train net output #0: loss = 0.038993 (* 1 = 0.038993 loss)
I0425 15:39:21.561272 12937 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0425 15:39:21.707640 12937 solver.cpp:237] Iteration 8200, loss = 0.00438518
I0425 15:39:21.707660 12937 solver.cpp:253]     Train net output #0: loss = 0.00438506 (* 1 = 0.00438506 loss)
I0425 15:39:21.707666 12937 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0425 15:39:21.853564 12937 solver.cpp:237] Iteration 8300, loss = 0.0409344
I0425 15:39:21.853588 12937 solver.cpp:253]     Train net output #0: loss = 0.0409342 (* 1 = 0.0409342 loss)
I0425 15:39:21.853595 12937 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0425 15:39:21.999502 12937 solver.cpp:237] Iteration 8400, loss = 0.0158525
I0425 15:39:21.999524 12937 solver.cpp:253]     Train net output #0: loss = 0.0158523 (* 1 = 0.0158523 loss)
I0425 15:39:21.999529 12937 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0425 15:39:22.146116 12937 solver.cpp:237] Iteration 8500, loss = 0.011124
I0425 15:39:22.146139 12937 solver.cpp:253]     Train net output #0: loss = 0.0111239 (* 1 = 0.0111239 loss)
I0425 15:39:22.146145 12937 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0425 15:39:22.292078 12937 solver.cpp:237] Iteration 8600, loss = 0.000742814
I0425 15:39:22.292101 12937 solver.cpp:253]     Train net output #0: loss = 0.000742701 (* 1 = 0.000742701 loss)
I0425 15:39:22.292107 12937 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0425 15:39:22.438295 12937 solver.cpp:237] Iteration 8700, loss = 0.00550423
I0425 15:39:22.438318 12937 solver.cpp:253]     Train net output #0: loss = 0.00550412 (* 1 = 0.00550412 loss)
I0425 15:39:22.438323 12937 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0425 15:39:22.584465 12937 solver.cpp:237] Iteration 8800, loss = 0.00135737
I0425 15:39:22.584486 12937 solver.cpp:253]     Train net output #0: loss = 0.00135725 (* 1 = 0.00135725 loss)
I0425 15:39:22.584492 12937 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0425 15:39:22.729990 12937 solver.cpp:237] Iteration 8900, loss = 0.000794247
I0425 15:39:22.730012 12937 solver.cpp:253]     Train net output #0: loss = 0.000794126 (* 1 = 0.000794126 loss)
I0425 15:39:22.730017 12937 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0425 15:39:22.876791 12937 solver.cpp:237] Iteration 9000, loss = 0.0218396
I0425 15:39:22.876813 12937 solver.cpp:253]     Train net output #0: loss = 0.0218395 (* 1 = 0.0218395 loss)
I0425 15:39:22.876819 12937 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0425 15:39:23.023296 12937 solver.cpp:237] Iteration 9100, loss = 0.0188153
I0425 15:39:23.023320 12937 solver.cpp:253]     Train net output #0: loss = 0.0188152 (* 1 = 0.0188152 loss)
I0425 15:39:23.023326 12937 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0425 15:39:23.169420 12937 solver.cpp:237] Iteration 9200, loss = 0.00695076
I0425 15:39:23.169441 12937 solver.cpp:253]     Train net output #0: loss = 0.00695064 (* 1 = 0.00695064 loss)
I0425 15:39:23.169447 12937 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0425 15:39:23.315541 12937 solver.cpp:237] Iteration 9300, loss = 0.0088569
I0425 15:39:23.315562 12937 solver.cpp:253]     Train net output #0: loss = 0.00885679 (* 1 = 0.00885679 loss)
I0425 15:39:23.315567 12937 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0425 15:39:23.461819 12937 solver.cpp:237] Iteration 9400, loss = 0.0483996
I0425 15:39:23.461839 12937 solver.cpp:253]     Train net output #0: loss = 0.0483995 (* 1 = 0.0483995 loss)
I0425 15:39:23.461845 12937 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0425 15:39:23.607287 12937 solver.cpp:237] Iteration 9500, loss = 0.00311257
I0425 15:39:23.607307 12937 solver.cpp:253]     Train net output #0: loss = 0.00311247 (* 1 = 0.00311247 loss)
I0425 15:39:23.607313 12937 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0425 15:39:23.754199 12937 solver.cpp:237] Iteration 9600, loss = 0.00131888
I0425 15:39:23.754220 12937 solver.cpp:253]     Train net output #0: loss = 0.00131879 (* 1 = 0.00131879 loss)
I0425 15:39:23.754225 12937 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0425 15:39:23.900663 12937 solver.cpp:237] Iteration 9700, loss = 0.00322938
I0425 15:39:23.900686 12937 solver.cpp:253]     Train net output #0: loss = 0.00322927 (* 1 = 0.00322927 loss)
I0425 15:39:23.900696 12937 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0425 15:39:24.045881 12937 solver.cpp:237] Iteration 9800, loss = 0.018146
I0425 15:39:24.045920 12937 solver.cpp:253]     Train net output #0: loss = 0.0181459 (* 1 = 0.0181459 loss)
I0425 15:39:24.045928 12937 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0425 15:39:24.191138 12937 solver.cpp:237] Iteration 9900, loss = 0.00455038
I0425 15:39:24.191190 12937 solver.cpp:253]     Train net output #0: loss = 0.00455027 (* 1 = 0.00455027 loss)
I0425 15:39:24.191205 12937 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0425 15:39:24.339710 12937 solver.cpp:459] Snapshotting to binary proto file examples/mnist/test/lenet_iter_10000.caffemodel
I0425 15:39:24.341653 12937 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/test/lenet_iter_10000.solverstate
I0425 15:39:24.342315 12937 solver.cpp:341] Iteration 10000, Testing net (#0)
I0425 15:39:24.412574 12937 solver.cpp:409]     Test net output #0: accuracy = 0.99
I0425 15:39:24.412601 12937 solver.cpp:409]     Test net output #1: loss = 0.0310037 (* 1 = 0.0310037 loss)
I0425 15:39:24.413295 12937 solver.cpp:237] Iteration 10000, loss = 0.00399823
I0425 15:39:24.413312 12937 solver.cpp:253]     Train net output #0: loss = 0.00399811 (* 1 = 0.00399811 loss)
I0425 15:39:24.413321 12937 sgd_solver.cpp:106] Iteration 10000, lr = 0.00594604
I0425 15:39:24.559248 12937 solver.cpp:237] Iteration 10100, loss = 0.0161911
I0425 15:39:24.559270 12937 solver.cpp:253]     Train net output #0: loss = 0.016191 (* 1 = 0.016191 loss)
I0425 15:39:24.559276 12937 sgd_solver.cpp:106] Iteration 10100, lr = 0.00592384
I0425 15:39:24.704416 12937 solver.cpp:237] Iteration 10200, loss = 0.020812
I0425 15:39:24.704439 12937 solver.cpp:253]     Train net output #0: loss = 0.0208119 (* 1 = 0.0208119 loss)
I0425 15:39:24.704445 12937 sgd_solver.cpp:106] Iteration 10200, lr = 0.00590183
I0425 15:39:24.849506 12937 solver.cpp:237] Iteration 10300, loss = 0.000750872
I0425 15:39:24.849534 12937 solver.cpp:253]     Train net output #0: loss = 0.000750749 (* 1 = 0.000750749 loss)
I0425 15:39:24.849540 12937 sgd_solver.cpp:106] Iteration 10300, lr = 0.00588001
I0425 15:39:24.995316 12937 solver.cpp:237] Iteration 10400, loss = 0.0137085
I0425 15:39:24.995339 12937 solver.cpp:253]     Train net output #0: loss = 0.0137083 (* 1 = 0.0137083 loss)
I0425 15:39:24.995345 12937 sgd_solver.cpp:106] Iteration 10400, lr = 0.00585838
I0425 15:39:25.139628 12937 solver.cpp:237] Iteration 10500, loss = 0.00360587
I0425 15:39:25.139650 12937 solver.cpp:253]     Train net output #0: loss = 0.00360574 (* 1 = 0.00360574 loss)
I0425 15:39:25.139657 12937 sgd_solver.cpp:106] Iteration 10500, lr = 0.00583693
I0425 15:39:25.283572 12937 solver.cpp:237] Iteration 10600, loss = 0.00474901
I0425 15:39:25.283594 12937 solver.cpp:253]     Train net output #0: loss = 0.00474889 (* 1 = 0.00474889 loss)
I0425 15:39:25.283599 12937 sgd_solver.cpp:106] Iteration 10600, lr = 0.00581567
I0425 15:39:25.427814 12937 solver.cpp:237] Iteration 10700, loss = 0.00504898
I0425 15:39:25.427835 12937 solver.cpp:253]     Train net output #0: loss = 0.00504886 (* 1 = 0.00504886 loss)
I0425 15:39:25.427840 12937 sgd_solver.cpp:106] Iteration 10700, lr = 0.00579458
I0425 15:39:25.572707 12937 solver.cpp:237] Iteration 10800, loss = 0.00290006
I0425 15:39:25.572728 12937 solver.cpp:253]     Train net output #0: loss = 0.00289994 (* 1 = 0.00289994 loss)
I0425 15:39:25.572734 12937 sgd_solver.cpp:106] Iteration 10800, lr = 0.00577368
I0425 15:39:25.717176 12937 solver.cpp:237] Iteration 10900, loss = 0.00439927
I0425 15:39:25.717198 12937 solver.cpp:253]     Train net output #0: loss = 0.00439915 (* 1 = 0.00439915 loss)
I0425 15:39:25.717203 12937 sgd_solver.cpp:106] Iteration 10900, lr = 0.00575295
I0425 15:39:25.862128 12937 solver.cpp:237] Iteration 11000, loss = 0.00226197
I0425 15:39:25.862149 12937 solver.cpp:253]     Train net output #0: loss = 0.00226185 (* 1 = 0.00226185 loss)
I0425 15:39:25.862154 12937 sgd_solver.cpp:106] Iteration 11000, lr = 0.00573239
I0425 15:39:26.006727 12937 solver.cpp:237] Iteration 11100, loss = 0.0122113
I0425 15:39:26.006772 12937 solver.cpp:253]     Train net output #0: loss = 0.0122112 (* 1 = 0.0122112 loss)
I0425 15:39:26.006778 12937 sgd_solver.cpp:106] Iteration 11100, lr = 0.005712
I0425 15:39:26.152243 12937 solver.cpp:237] Iteration 11200, loss = 0.0120783
I0425 15:39:26.152266 12937 solver.cpp:253]     Train net output #0: loss = 0.0120782 (* 1 = 0.0120782 loss)
I0425 15:39:26.152271 12937 sgd_solver.cpp:106] Iteration 11200, lr = 0.00569178
I0425 15:39:26.296445 12937 solver.cpp:237] Iteration 11300, loss = 0.00375805
I0425 15:39:26.296465 12937 solver.cpp:253]     Train net output #0: loss = 0.00375793 (* 1 = 0.00375793 loss)
I0425 15:39:26.296471 12937 sgd_solver.cpp:106] Iteration 11300, lr = 0.00567173
I0425 15:39:26.441479 12937 solver.cpp:237] Iteration 11400, loss = 0.0093103
I0425 15:39:26.441499 12937 solver.cpp:253]     Train net output #0: loss = 0.00931019 (* 1 = 0.00931019 loss)
I0425 15:39:26.441505 12937 sgd_solver.cpp:106] Iteration 11400, lr = 0.00565184
I0425 15:39:26.586302 12937 solver.cpp:237] Iteration 11500, loss = 0.00535063
I0425 15:39:26.586321 12937 solver.cpp:253]     Train net output #0: loss = 0.00535052 (* 1 = 0.00535052 loss)
I0425 15:39:26.586326 12937 sgd_solver.cpp:106] Iteration 11500, lr = 0.00563211
I0425 15:39:26.731926 12937 solver.cpp:237] Iteration 11600, loss = 0.00865125
I0425 15:39:26.731947 12937 solver.cpp:253]     Train net output #0: loss = 0.00865114 (* 1 = 0.00865114 loss)
I0425 15:39:26.731952 12937 sgd_solver.cpp:106] Iteration 11600, lr = 0.00561254
I0425 15:39:26.877257 12937 solver.cpp:237] Iteration 11700, loss = 0.00226632
I0425 15:39:26.877279 12937 solver.cpp:253]     Train net output #0: loss = 0.00226621 (* 1 = 0.00226621 loss)
I0425 15:39:26.877284 12937 sgd_solver.cpp:106] Iteration 11700, lr = 0.00559313
I0425 15:39:27.022210 12937 solver.cpp:237] Iteration 11800, loss = 0.0200755
I0425 15:39:27.022231 12937 solver.cpp:253]     Train net output #0: loss = 0.0200754 (* 1 = 0.0200754 loss)
I0425 15:39:27.022236 12937 sgd_solver.cpp:106] Iteration 11800, lr = 0.00557388
I0425 15:39:27.167532 12937 solver.cpp:237] Iteration 11900, loss = 0.00625001
I0425 15:39:27.167552 12937 solver.cpp:253]     Train net output #0: loss = 0.00624989 (* 1 = 0.00624989 loss)
I0425 15:39:27.167558 12937 sgd_solver.cpp:106] Iteration 11900, lr = 0.00555478
I0425 15:39:27.311336 12937 solver.cpp:237] Iteration 12000, loss = 0.0020385
I0425 15:39:27.311355 12937 solver.cpp:253]     Train net output #0: loss = 0.00203838 (* 1 = 0.00203838 loss)
I0425 15:39:27.311360 12937 sgd_solver.cpp:106] Iteration 12000, lr = 0.00553583
I0425 15:39:27.455884 12937 solver.cpp:237] Iteration 12100, loss = 0.0120269
I0425 15:39:27.455905 12937 solver.cpp:253]     Train net output #0: loss = 0.0120268 (* 1 = 0.0120268 loss)
I0425 15:39:27.455910 12937 sgd_solver.cpp:106] Iteration 12100, lr = 0.00551704
I0425 15:39:27.600499 12937 solver.cpp:237] Iteration 12200, loss = 0.00141107
I0425 15:39:27.600519 12937 solver.cpp:253]     Train net output #0: loss = 0.00141096 (* 1 = 0.00141096 loss)
I0425 15:39:27.600525 12937 sgd_solver.cpp:106] Iteration 12200, lr = 0.00549839
I0425 15:39:27.745760 12937 solver.cpp:237] Iteration 12300, loss = 0.00767332
I0425 15:39:27.745780 12937 solver.cpp:253]     Train net output #0: loss = 0.0076732 (* 1 = 0.0076732 loss)
I0425 15:39:27.745786 12937 sgd_solver.cpp:106] Iteration 12300, lr = 0.00547988
I0425 15:39:27.890664 12937 solver.cpp:237] Iteration 12400, loss = 0.00349246
I0425 15:39:27.890687 12937 solver.cpp:253]     Train net output #0: loss = 0.00349235 (* 1 = 0.00349235 loss)
I0425 15:39:27.890693 12937 sgd_solver.cpp:106] Iteration 12400, lr = 0.00546153
I0425 15:39:28.035982 12937 solver.cpp:237] Iteration 12500, loss = 0.0198572
I0425 15:39:28.036003 12937 solver.cpp:253]     Train net output #0: loss = 0.0198571 (* 1 = 0.0198571 loss)
I0425 15:39:28.036008 12937 sgd_solver.cpp:106] Iteration 12500, lr = 0.00544331
I0425 15:39:28.180984 12937 solver.cpp:237] Iteration 12600, loss = 0.0149309
I0425 15:39:28.181004 12937 solver.cpp:253]     Train net output #0: loss = 0.0149308 (* 1 = 0.0149308 loss)
I0425 15:39:28.181030 12937 sgd_solver.cpp:106] Iteration 12600, lr = 0.00542524
I0425 15:39:28.325554 12937 solver.cpp:237] Iteration 12700, loss = 0.00856205
I0425 15:39:28.325574 12937 solver.cpp:253]     Train net output #0: loss = 0.00856193 (* 1 = 0.00856193 loss)
I0425 15:39:28.325579 12937 sgd_solver.cpp:106] Iteration 12700, lr = 0.0054073
I0425 15:39:28.470131 12937 solver.cpp:237] Iteration 12800, loss = 0.00118474
I0425 15:39:28.470151 12937 solver.cpp:253]     Train net output #0: loss = 0.00118462 (* 1 = 0.00118462 loss)
I0425 15:39:28.470157 12937 sgd_solver.cpp:106] Iteration 12800, lr = 0.0053895
I0425 15:39:28.614708 12937 solver.cpp:237] Iteration 12900, loss = 0.00472446
I0425 15:39:28.614729 12937 solver.cpp:253]     Train net output #0: loss = 0.00472433 (* 1 = 0.00472433 loss)
I0425 15:39:28.614734 12937 sgd_solver.cpp:106] Iteration 12900, lr = 0.00537184
I0425 15:39:28.763072 12937 solver.cpp:237] Iteration 13000, loss = 0.00248415
I0425 15:39:28.763108 12937 solver.cpp:253]     Train net output #0: loss = 0.00248402 (* 1 = 0.00248402 loss)
I0425 15:39:28.763118 12937 sgd_solver.cpp:106] Iteration 13000, lr = 0.00535432
I0425 15:39:28.912871 12937 solver.cpp:237] Iteration 13100, loss = 0.000289356
I0425 15:39:28.912909 12937 solver.cpp:253]     Train net output #0: loss = 0.00028923 (* 1 = 0.00028923 loss)
I0425 15:39:28.912917 12937 sgd_solver.cpp:106] Iteration 13100, lr = 0.00533692
I0425 15:39:29.059231 12937 solver.cpp:237] Iteration 13200, loss = 0.000959264
I0425 15:39:29.059254 12937 solver.cpp:253]     Train net output #0: loss = 0.000959121 (* 1 = 0.000959121 loss)
I0425 15:39:29.059260 12937 sgd_solver.cpp:106] Iteration 13200, lr = 0.00531966
I0425 15:39:29.202325 12937 solver.cpp:237] Iteration 13300, loss = 0.0119672
I0425 15:39:29.202347 12937 solver.cpp:253]     Train net output #0: loss = 0.011967 (* 1 = 0.011967 loss)
I0425 15:39:29.202353 12937 sgd_solver.cpp:106] Iteration 13300, lr = 0.00530253
I0425 15:39:29.345085 12937 solver.cpp:237] Iteration 13400, loss = 0.00617188
I0425 15:39:29.345106 12937 solver.cpp:253]     Train net output #0: loss = 0.00617173 (* 1 = 0.00617173 loss)
I0425 15:39:29.345113 12937 sgd_solver.cpp:106] Iteration 13400, lr = 0.00528552
I0425 15:39:29.488404 12937 solver.cpp:237] Iteration 13500, loss = 0.00298021
I0425 15:39:29.488425 12937 solver.cpp:253]     Train net output #0: loss = 0.00298007 (* 1 = 0.00298007 loss)
I0425 15:39:29.488431 12937 sgd_solver.cpp:106] Iteration 13500, lr = 0.00526865
I0425 15:39:29.631844 12937 solver.cpp:237] Iteration 13600, loss = 0.000945537
I0425 15:39:29.631867 12937 solver.cpp:253]     Train net output #0: loss = 0.000945387 (* 1 = 0.000945387 loss)
I0425 15:39:29.631873 12937 sgd_solver.cpp:106] Iteration 13600, lr = 0.00525189
I0425 15:39:29.777667 12937 solver.cpp:237] Iteration 13700, loss = 0.00553544
I0425 15:39:29.777688 12937 solver.cpp:253]     Train net output #0: loss = 0.00553529 (* 1 = 0.00553529 loss)
I0425 15:39:29.777693 12937 sgd_solver.cpp:106] Iteration 13700, lr = 0.00523527
I0425 15:39:29.923820 12937 solver.cpp:237] Iteration 13800, loss = 0.00356566
I0425 15:39:29.923858 12937 solver.cpp:253]     Train net output #0: loss = 0.0035655 (* 1 = 0.0035655 loss)
I0425 15:39:29.923871 12937 sgd_solver.cpp:106] Iteration 13800, lr = 0.00521876
I0425 15:39:30.073324 12937 solver.cpp:237] Iteration 13900, loss = 0.00743592
I0425 15:39:30.073351 12937 solver.cpp:253]     Train net output #0: loss = 0.00743576 (* 1 = 0.00743576 loss)
I0425 15:39:30.073359 12937 sgd_solver.cpp:106] Iteration 13900, lr = 0.00520237
I0425 15:39:30.219768 12937 solver.cpp:237] Iteration 14000, loss = 0.00411478
I0425 15:39:30.219791 12937 solver.cpp:253]     Train net output #0: loss = 0.00411462 (* 1 = 0.00411462 loss)
I0425 15:39:30.219797 12937 sgd_solver.cpp:106] Iteration 14000, lr = 0.00518611
I0425 15:39:30.365499 12937 solver.cpp:237] Iteration 14100, loss = 0.032665
I0425 15:39:30.365522 12937 solver.cpp:253]     Train net output #0: loss = 0.0326649 (* 1 = 0.0326649 loss)
I0425 15:39:30.365552 12937 sgd_solver.cpp:106] Iteration 14100, lr = 0.00516996
I0425 15:39:30.510097 12937 solver.cpp:237] Iteration 14200, loss = 0.00483828
I0425 15:39:30.510119 12937 solver.cpp:253]     Train net output #0: loss = 0.00483813 (* 1 = 0.00483813 loss)
I0425 15:39:30.510124 12937 sgd_solver.cpp:106] Iteration 14200, lr = 0.00515393
I0425 15:39:30.656976 12937 solver.cpp:237] Iteration 14300, loss = 0.00303231
I0425 15:39:30.656998 12937 solver.cpp:253]     Train net output #0: loss = 0.00303216 (* 1 = 0.00303216 loss)
I0425 15:39:30.657004 12937 sgd_solver.cpp:106] Iteration 14300, lr = 0.00513801
I0425 15:39:30.803786 12937 solver.cpp:237] Iteration 14400, loss = 0.00377527
I0425 15:39:30.803812 12937 solver.cpp:253]     Train net output #0: loss = 0.00377512 (* 1 = 0.00377512 loss)
I0425 15:39:30.803818 12937 sgd_solver.cpp:106] Iteration 14400, lr = 0.00512221
I0425 15:39:30.950170 12937 solver.cpp:237] Iteration 14500, loss = 0.00286621
I0425 15:39:30.950193 12937 solver.cpp:253]     Train net output #0: loss = 0.00286607 (* 1 = 0.00286607 loss)
I0425 15:39:30.950199 12937 sgd_solver.cpp:106] Iteration 14500, lr = 0.00510653
I0425 15:39:31.095911 12937 solver.cpp:237] Iteration 14600, loss = 0.0086966
I0425 15:39:31.095934 12937 solver.cpp:253]     Train net output #0: loss = 0.00869646 (* 1 = 0.00869646 loss)
I0425 15:39:31.095940 12937 sgd_solver.cpp:106] Iteration 14600, lr = 0.00509095
I0425 15:39:31.240510 12937 solver.cpp:237] Iteration 14700, loss = 0.00358615
I0425 15:39:31.240531 12937 solver.cpp:253]     Train net output #0: loss = 0.003586 (* 1 = 0.003586 loss)
I0425 15:39:31.240536 12937 sgd_solver.cpp:106] Iteration 14700, lr = 0.00507548
I0425 15:39:31.385977 12937 solver.cpp:237] Iteration 14800, loss = 0.0139029
I0425 15:39:31.385998 12937 solver.cpp:253]     Train net output #0: loss = 0.0139028 (* 1 = 0.0139028 loss)
I0425 15:39:31.386003 12937 sgd_solver.cpp:106] Iteration 14800, lr = 0.00506012
I0425 15:39:31.530443 12937 solver.cpp:237] Iteration 14900, loss = 0.00509119
I0425 15:39:31.530464 12937 solver.cpp:253]     Train net output #0: loss = 0.00509103 (* 1 = 0.00509103 loss)
I0425 15:39:31.530469 12937 sgd_solver.cpp:106] Iteration 14900, lr = 0.00504488
I0425 15:39:31.673848 12937 solver.cpp:459] Snapshotting to binary proto file examples/mnist/test/lenet_iter_15000.caffemodel
I0425 15:39:31.675467 12937 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/test/lenet_iter_15000.solverstate
I0425 15:39:31.675933 12937 solver.cpp:341] Iteration 15000, Testing net (#0)
I0425 15:39:31.757516 12937 solver.cpp:409]     Test net output #0: accuracy = 0.9893
I0425 15:39:31.757550 12937 solver.cpp:409]     Test net output #1: loss = 0.0335627 (* 1 = 0.0335627 loss)
I0425 15:39:31.758324 12937 solver.cpp:237] Iteration 15000, loss = 0.00491741
I0425 15:39:31.758347 12937 solver.cpp:253]     Train net output #0: loss = 0.00491725 (* 1 = 0.00491725 loss)
I0425 15:39:31.758358 12937 sgd_solver.cpp:106] Iteration 15000, lr = 0.00502973
I0425 15:39:31.898821 12937 solver.cpp:237] Iteration 15100, loss = 0.00506766
I0425 15:39:31.898844 12937 solver.cpp:253]     Train net output #0: loss = 0.00506751 (* 1 = 0.00506751 loss)
I0425 15:39:31.898849 12937 sgd_solver.cpp:106] Iteration 15100, lr = 0.0050147
I0425 15:39:32.039978 12937 solver.cpp:237] Iteration 15200, loss = 0.0149475
I0425 15:39:32.040001 12937 solver.cpp:253]     Train net output #0: loss = 0.0149473 (* 1 = 0.0149473 loss)
I0425 15:39:32.040007 12937 sgd_solver.cpp:106] Iteration 15200, lr = 0.00499976
I0425 15:39:32.179764 12937 solver.cpp:237] Iteration 15300, loss = 0.00209498
I0425 15:39:32.179787 12937 solver.cpp:253]     Train net output #0: loss = 0.00209484 (* 1 = 0.00209484 loss)
I0425 15:39:32.179792 12937 sgd_solver.cpp:106] Iteration 15300, lr = 0.00498494
I0425 15:39:32.321434 12937 solver.cpp:237] Iteration 15400, loss = 0.00439865
I0425 15:39:32.321456 12937 solver.cpp:253]     Train net output #0: loss = 0.0043985 (* 1 = 0.0043985 loss)
I0425 15:39:32.321482 12937 sgd_solver.cpp:106] Iteration 15400, lr = 0.00497021
I0425 15:39:32.462137 12937 solver.cpp:237] Iteration 15500, loss = 0.00754315
I0425 15:39:32.462158 12937 solver.cpp:253]     Train net output #0: loss = 0.00754301 (* 1 = 0.00754301 loss)
I0425 15:39:32.462163 12937 sgd_solver.cpp:106] Iteration 15500, lr = 0.00495558
I0425 15:39:32.602378 12937 solver.cpp:237] Iteration 15600, loss = 0.00915414
I0425 15:39:32.602401 12937 solver.cpp:253]     Train net output #0: loss = 0.00915399 (* 1 = 0.00915399 loss)
I0425 15:39:32.602406 12937 sgd_solver.cpp:106] Iteration 15600, lr = 0.00494106
I0425 15:39:32.743463 12937 solver.cpp:237] Iteration 15700, loss = 0.00211026
I0425 15:39:32.743484 12937 solver.cpp:253]     Train net output #0: loss = 0.00211011 (* 1 = 0.00211011 loss)
I0425 15:39:32.743490 12937 sgd_solver.cpp:106] Iteration 15700, lr = 0.00492663
I0425 15:39:32.884277 12937 solver.cpp:237] Iteration 15800, loss = 0.0269087
I0425 15:39:32.884300 12937 solver.cpp:253]     Train net output #0: loss = 0.0269086 (* 1 = 0.0269086 loss)
I0425 15:39:32.884305 12937 sgd_solver.cpp:106] Iteration 15800, lr = 0.0049123
I0425 15:39:33.026473 12937 solver.cpp:237] Iteration 15900, loss = 0.00724302
I0425 15:39:33.026509 12937 solver.cpp:253]     Train net output #0: loss = 0.00724288 (* 1 = 0.00724288 loss)
I0425 15:39:33.026518 12937 sgd_solver.cpp:106] Iteration 15900, lr = 0.00489807
I0425 15:39:33.170989 12937 solver.cpp:237] Iteration 16000, loss = 0.00598188
I0425 15:39:33.171013 12937 solver.cpp:253]     Train net output #0: loss = 0.00598173 (* 1 = 0.00598173 loss)
I0425 15:39:33.171020 12937 sgd_solver.cpp:106] Iteration 16000, lr = 0.00488394
I0425 15:39:33.314602 12937 solver.cpp:237] Iteration 16100, loss = 0.000857726
I0425 15:39:33.314626 12937 solver.cpp:253]     Train net output #0: loss = 0.000857583 (* 1 = 0.000857583 loss)
I0425 15:39:33.314632 12937 sgd_solver.cpp:106] Iteration 16100, lr = 0.0048699
I0425 15:39:33.457973 12937 solver.cpp:237] Iteration 16200, loss = 0.00287745
I0425 15:39:33.457996 12937 solver.cpp:253]     Train net output #0: loss = 0.00287731 (* 1 = 0.00287731 loss)
I0425 15:39:33.458003 12937 sgd_solver.cpp:106] Iteration 16200, lr = 0.00485595
I0425 15:39:33.600826 12937 solver.cpp:237] Iteration 16300, loss = 0.0012396
I0425 15:39:33.600850 12937 solver.cpp:253]     Train net output #0: loss = 0.00123945 (* 1 = 0.00123945 loss)
I0425 15:39:33.600857 12937 sgd_solver.cpp:106] Iteration 16300, lr = 0.00484209
I0425 15:39:33.744319 12937 solver.cpp:237] Iteration 16400, loss = 0.000631471
I0425 15:39:33.744343 12937 solver.cpp:253]     Train net output #0: loss = 0.000631324 (* 1 = 0.000631324 loss)
I0425 15:39:33.744349 12937 sgd_solver.cpp:106] Iteration 16400, lr = 0.00482833
I0425 15:39:33.887771 12937 solver.cpp:237] Iteration 16500, loss = 0.0139818
I0425 15:39:33.887804 12937 solver.cpp:253]     Train net output #0: loss = 0.0139816 (* 1 = 0.0139816 loss)
I0425 15:39:33.887812 12937 sgd_solver.cpp:106] Iteration 16500, lr = 0.00481466
I0425 15:39:34.029108 12937 solver.cpp:237] Iteration 16600, loss = 0.00919146
I0425 15:39:34.029130 12937 solver.cpp:253]     Train net output #0: loss = 0.00919132 (* 1 = 0.00919132 loss)
I0425 15:39:34.029135 12937 sgd_solver.cpp:106] Iteration 16600, lr = 0.00480108
I0425 15:39:34.169651 12937 solver.cpp:237] Iteration 16700, loss = 0.0049962
I0425 15:39:34.169672 12937 solver.cpp:253]     Train net output #0: loss = 0.00499606 (* 1 = 0.00499606 loss)
I0425 15:39:34.169679 12937 sgd_solver.cpp:106] Iteration 16700, lr = 0.00478759
I0425 15:39:34.310818 12937 solver.cpp:237] Iteration 16800, loss = 0.00581838
I0425 15:39:34.310839 12937 solver.cpp:253]     Train net output #0: loss = 0.00581824 (* 1 = 0.00581824 loss)
I0425 15:39:34.310848 12937 sgd_solver.cpp:106] Iteration 16800, lr = 0.00477418
I0425 15:39:34.451722 12937 solver.cpp:237] Iteration 16900, loss = 0.0121769
I0425 15:39:34.451743 12937 solver.cpp:253]     Train net output #0: loss = 0.0121768 (* 1 = 0.0121768 loss)
I0425 15:39:34.451748 12937 sgd_solver.cpp:106] Iteration 16900, lr = 0.00476086
I0425 15:39:34.592214 12937 solver.cpp:237] Iteration 17000, loss = 0.00245717
I0425 15:39:34.592237 12937 solver.cpp:253]     Train net output #0: loss = 0.00245702 (* 1 = 0.00245702 loss)
I0425 15:39:34.592243 12937 sgd_solver.cpp:106] Iteration 17000, lr = 0.00474763
I0425 15:39:34.732666 12937 solver.cpp:237] Iteration 17100, loss = 0.00242217
I0425 15:39:34.732687 12937 solver.cpp:253]     Train net output #0: loss = 0.00242203 (* 1 = 0.00242203 loss)
I0425 15:39:34.732692 12937 sgd_solver.cpp:106] Iteration 17100, lr = 0.00473449
I0425 15:39:34.872853 12937 solver.cpp:237] Iteration 17200, loss = 0.00191473
I0425 15:39:34.872880 12937 solver.cpp:253]     Train net output #0: loss = 0.00191459 (* 1 = 0.00191459 loss)
I0425 15:39:34.872886 12937 sgd_solver.cpp:106] Iteration 17200, lr = 0.00472143
I0425 15:39:35.013679 12937 solver.cpp:237] Iteration 17300, loss = 0.00876911
I0425 15:39:35.013702 12937 solver.cpp:253]     Train net output #0: loss = 0.00876896 (* 1 = 0.00876896 loss)
I0425 15:39:35.013708 12937 sgd_solver.cpp:106] Iteration 17300, lr = 0.00470845
I0425 15:39:35.153991 12937 solver.cpp:237] Iteration 17400, loss = 0.00368239
I0425 15:39:35.154012 12937 solver.cpp:253]     Train net output #0: loss = 0.00368224 (* 1 = 0.00368224 loss)
I0425 15:39:35.154017 12937 sgd_solver.cpp:106] Iteration 17400, lr = 0.00469556
I0425 15:39:35.294410 12937 solver.cpp:237] Iteration 17500, loss = 0.00300652
I0425 15:39:35.294432 12937 solver.cpp:253]     Train net output #0: loss = 0.00300637 (* 1 = 0.00300637 loss)
I0425 15:39:35.294437 12937 sgd_solver.cpp:106] Iteration 17500, lr = 0.00468274
I0425 15:39:35.435257 12937 solver.cpp:237] Iteration 17600, loss = 0.0133104
I0425 15:39:35.435279 12937 solver.cpp:253]     Train net output #0: loss = 0.0133103 (* 1 = 0.0133103 loss)
I0425 15:39:35.435284 12937 sgd_solver.cpp:106] Iteration 17600, lr = 0.00467001
I0425 15:39:35.576398 12937 solver.cpp:237] Iteration 17700, loss = 0.0102252
I0425 15:39:35.576418 12937 solver.cpp:253]     Train net output #0: loss = 0.0102251 (* 1 = 0.0102251 loss)
I0425 15:39:35.576424 12937 sgd_solver.cpp:106] Iteration 17700, lr = 0.00465736
I0425 15:39:35.716758 12937 solver.cpp:237] Iteration 17800, loss = 0.000235826
I0425 15:39:35.716778 12937 solver.cpp:253]     Train net output #0: loss = 0.000235673 (* 1 = 0.000235673 loss)
I0425 15:39:35.716784 12937 sgd_solver.cpp:106] Iteration 17800, lr = 0.00464479
I0425 15:39:35.857123 12937 solver.cpp:237] Iteration 17900, loss = 0.0076627
I0425 15:39:35.857144 12937 solver.cpp:253]     Train net output #0: loss = 0.00766254 (* 1 = 0.00766254 loss)
I0425 15:39:35.857149 12937 sgd_solver.cpp:106] Iteration 17900, lr = 0.0046323
I0425 15:39:35.997522 12937 solver.cpp:237] Iteration 18000, loss = 0.00479925
I0425 15:39:35.997545 12937 solver.cpp:253]     Train net output #0: loss = 0.0047991 (* 1 = 0.0047991 loss)
I0425 15:39:35.997550 12937 sgd_solver.cpp:106] Iteration 18000, lr = 0.00461989
I0425 15:39:36.138509 12937 solver.cpp:237] Iteration 18100, loss = 0.00317348
I0425 15:39:36.138532 12937 solver.cpp:253]     Train net output #0: loss = 0.00317333 (* 1 = 0.00317333 loss)
I0425 15:39:36.138546 12937 sgd_solver.cpp:106] Iteration 18100, lr = 0.00460755
I0425 15:39:36.279485 12937 solver.cpp:237] Iteration 18200, loss = 0.00368699
I0425 15:39:36.279506 12937 solver.cpp:253]     Train net output #0: loss = 0.00368684 (* 1 = 0.00368684 loss)
I0425 15:39:36.279512 12937 sgd_solver.cpp:106] Iteration 18200, lr = 0.00459529
I0425 15:39:36.420228 12937 solver.cpp:237] Iteration 18300, loss = 0.0021252
I0425 15:39:36.420249 12937 solver.cpp:253]     Train net output #0: loss = 0.00212504 (* 1 = 0.00212504 loss)
I0425 15:39:36.420254 12937 sgd_solver.cpp:106] Iteration 18300, lr = 0.00458311
I0425 15:39:36.561015 12937 solver.cpp:237] Iteration 18400, loss = 0.00256972
I0425 15:39:36.561038 12937 solver.cpp:253]     Train net output #0: loss = 0.00256956 (* 1 = 0.00256956 loss)
I0425 15:39:36.561043 12937 sgd_solver.cpp:106] Iteration 18400, lr = 0.004571
I0425 15:39:36.701709 12937 solver.cpp:237] Iteration 18500, loss = 0.00187318
I0425 15:39:36.701733 12937 solver.cpp:253]     Train net output #0: loss = 0.00187302 (* 1 = 0.00187302 loss)
I0425 15:39:36.701740 12937 sgd_solver.cpp:106] Iteration 18500, lr = 0.00455897
I0425 15:39:36.842701 12937 solver.cpp:237] Iteration 18600, loss = 0.00986605
I0425 15:39:36.842727 12937 solver.cpp:253]     Train net output #0: loss = 0.0098659 (* 1 = 0.0098659 loss)
I0425 15:39:36.842732 12937 sgd_solver.cpp:106] Iteration 18600, lr = 0.00454701
I0425 15:39:36.984170 12937 solver.cpp:237] Iteration 18700, loss = 0.0087813
I0425 15:39:36.984194 12937 solver.cpp:253]     Train net output #0: loss = 0.00878115 (* 1 = 0.00878115 loss)
I0425 15:39:36.984201 12937 sgd_solver.cpp:106] Iteration 18700, lr = 0.00453512
I0425 15:39:37.124876 12937 solver.cpp:237] Iteration 18800, loss = 0.00385233
I0425 15:39:37.124907 12937 solver.cpp:253]     Train net output #0: loss = 0.00385218 (* 1 = 0.00385218 loss)
I0425 15:39:37.124913 12937 sgd_solver.cpp:106] Iteration 18800, lr = 0.0045233
I0425 15:39:37.265295 12937 solver.cpp:237] Iteration 18900, loss = 0.00839686
I0425 15:39:37.265316 12937 solver.cpp:253]     Train net output #0: loss = 0.00839671 (* 1 = 0.00839671 loss)
I0425 15:39:37.265323 12937 sgd_solver.cpp:106] Iteration 18900, lr = 0.00451156
I0425 15:39:37.406612 12937 solver.cpp:237] Iteration 19000, loss = 0.00408889
I0425 15:39:37.406632 12937 solver.cpp:253]     Train net output #0: loss = 0.00408874 (* 1 = 0.00408874 loss)
I0425 15:39:37.406641 12937 sgd_solver.cpp:106] Iteration 19000, lr = 0.00449989
I0425 15:39:37.548225 12937 solver.cpp:237] Iteration 19100, loss = 0.00564431
I0425 15:39:37.548246 12937 solver.cpp:253]     Train net output #0: loss = 0.00564416 (* 1 = 0.00564416 loss)
I0425 15:39:37.548255 12937 sgd_solver.cpp:106] Iteration 19100, lr = 0.00448828
I0425 15:39:37.689075 12937 solver.cpp:237] Iteration 19200, loss = 0.00181683
I0425 15:39:37.689097 12937 solver.cpp:253]     Train net output #0: loss = 0.00181669 (* 1 = 0.00181669 loss)
I0425 15:39:37.689110 12937 sgd_solver.cpp:106] Iteration 19200, lr = 0.00447675
I0425 15:39:37.829370 12937 solver.cpp:237] Iteration 19300, loss = 0.0130071
I0425 15:39:37.829392 12937 solver.cpp:253]     Train net output #0: loss = 0.013007 (* 1 = 0.013007 loss)
I0425 15:39:37.829407 12937 sgd_solver.cpp:106] Iteration 19300, lr = 0.00446529
I0425 15:39:37.972858 12937 solver.cpp:237] Iteration 19400, loss = 0.00529019
I0425 15:39:37.972914 12937 solver.cpp:253]     Train net output #0: loss = 0.00529005 (* 1 = 0.00529005 loss)
I0425 15:39:37.972929 12937 sgd_solver.cpp:106] Iteration 19400, lr = 0.00445389
I0425 15:39:38.119212 12937 solver.cpp:237] Iteration 19500, loss = 0.00210676
I0425 15:39:38.119240 12937 solver.cpp:253]     Train net output #0: loss = 0.00210663 (* 1 = 0.00210663 loss)
I0425 15:39:38.119247 12937 sgd_solver.cpp:106] Iteration 19500, lr = 0.00444256
I0425 15:39:38.262172 12937 solver.cpp:237] Iteration 19600, loss = 0.00868916
I0425 15:39:38.262195 12937 solver.cpp:253]     Train net output #0: loss = 0.00868902 (* 1 = 0.00868902 loss)
I0425 15:39:38.262202 12937 sgd_solver.cpp:106] Iteration 19600, lr = 0.0044313
I0425 15:39:38.403652 12937 solver.cpp:237] Iteration 19700, loss = 0.000880114
I0425 15:39:38.403676 12937 solver.cpp:253]     Train net output #0: loss = 0.000879962 (* 1 = 0.000879962 loss)
I0425 15:39:38.403682 12937 sgd_solver.cpp:106] Iteration 19700, lr = 0.00442011
I0425 15:39:38.545183 12937 solver.cpp:237] Iteration 19800, loss = 0.00598085
I0425 15:39:38.545207 12937 solver.cpp:253]     Train net output #0: loss = 0.0059807 (* 1 = 0.0059807 loss)
I0425 15:39:38.545212 12937 sgd_solver.cpp:106] Iteration 19800, lr = 0.00440898
I0425 15:39:38.686436 12937 solver.cpp:237] Iteration 19900, loss = 0.00206295
I0425 15:39:38.686460 12937 solver.cpp:253]     Train net output #0: loss = 0.0020628 (* 1 = 0.0020628 loss)
I0425 15:39:38.686466 12937 sgd_solver.cpp:106] Iteration 19900, lr = 0.00439791
I0425 15:39:38.826360 12937 solver.cpp:459] Snapshotting to binary proto file examples/mnist/test/lenet_iter_20000.caffemodel
I0425 15:39:38.827986 12937 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/test/lenet_iter_20000.solverstate
I0425 15:39:38.828482 12937 solver.cpp:341] Iteration 20000, Testing net (#0)
I0425 15:39:38.896811 12937 solver.cpp:409]     Test net output #0: accuracy = 0.9906
I0425 15:39:38.896841 12937 solver.cpp:409]     Test net output #1: loss = 0.0289861 (* 1 = 0.0289861 loss)
I0425 15:39:38.897550 12937 solver.cpp:237] Iteration 20000, loss = 0.013205
I0425 15:39:38.897568 12937 solver.cpp:253]     Train net output #0: loss = 0.0132048 (* 1 = 0.0132048 loss)
I0425 15:39:38.897577 12937 sgd_solver.cpp:106] Iteration 20000, lr = 0.00438691
I0425 15:39:39.038516 12937 solver.cpp:237] Iteration 20100, loss = 0.0145826
I0425 15:39:39.038633 12937 solver.cpp:253]     Train net output #0: loss = 0.0145824 (* 1 = 0.0145824 loss)
I0425 15:39:39.038641 12937 sgd_solver.cpp:106] Iteration 20100, lr = 0.00437598
I0425 15:39:39.178057 12937 solver.cpp:237] Iteration 20200, loss = 0.00770616
I0425 15:39:39.178077 12937 solver.cpp:253]     Train net output #0: loss = 0.00770601 (* 1 = 0.00770601 loss)
I0425 15:39:39.178083 12937 sgd_solver.cpp:106] Iteration 20200, lr = 0.00436511
I0425 15:39:39.318611 12937 solver.cpp:237] Iteration 20300, loss = 0.00169555
I0425 15:39:39.318631 12937 solver.cpp:253]     Train net output #0: loss = 0.00169539 (* 1 = 0.00169539 loss)
I0425 15:39:39.318642 12937 sgd_solver.cpp:106] Iteration 20300, lr = 0.0043543
I0425 15:39:39.458734 12937 solver.cpp:237] Iteration 20400, loss = 0.0050891
I0425 15:39:39.458756 12937 solver.cpp:253]     Train net output #0: loss = 0.00508894 (* 1 = 0.00508894 loss)
I0425 15:39:39.458762 12937 sgd_solver.cpp:106] Iteration 20400, lr = 0.00434355
I0425 15:39:39.598525 12937 solver.cpp:237] Iteration 20500, loss = 0.00171854
I0425 15:39:39.598546 12937 solver.cpp:253]     Train net output #0: loss = 0.00171838 (* 1 = 0.00171838 loss)
I0425 15:39:39.598551 12937 sgd_solver.cpp:106] Iteration 20500, lr = 0.00433286
I0425 15:39:39.738543 12937 solver.cpp:237] Iteration 20600, loss = 0.000277878
I0425 15:39:39.738564 12937 solver.cpp:253]     Train net output #0: loss = 0.000277719 (* 1 = 0.000277719 loss)
I0425 15:39:39.738570 12937 sgd_solver.cpp:106] Iteration 20600, lr = 0.00432224
I0425 15:39:39.878515 12937 solver.cpp:237] Iteration 20700, loss = 0.000585208
I0425 15:39:39.878540 12937 solver.cpp:253]     Train net output #0: loss = 0.000585049 (* 1 = 0.000585049 loss)
I0425 15:39:39.878545 12937 sgd_solver.cpp:106] Iteration 20700, lr = 0.00431168
I0425 15:39:40.018607 12937 solver.cpp:237] Iteration 20800, loss = 0.00813662
I0425 15:39:40.018631 12937 solver.cpp:253]     Train net output #0: loss = 0.00813646 (* 1 = 0.00813646 loss)
I0425 15:39:40.018646 12937 sgd_solver.cpp:106] Iteration 20800, lr = 0.00430117
I0425 15:39:40.158512 12937 solver.cpp:237] Iteration 20900, loss = 0.00486438
I0425 15:39:40.158535 12937 solver.cpp:253]     Train net output #0: loss = 0.00486421 (* 1 = 0.00486421 loss)
I0425 15:39:40.158541 12937 sgd_solver.cpp:106] Iteration 20900, lr = 0.00429073
I0425 15:39:40.299412 12937 solver.cpp:237] Iteration 21000, loss = 0.00302937
I0425 15:39:40.299435 12937 solver.cpp:253]     Train net output #0: loss = 0.00302921 (* 1 = 0.00302921 loss)
I0425 15:39:40.299442 12937 sgd_solver.cpp:106] Iteration 21000, lr = 0.00428034
I0425 15:39:40.439579 12937 solver.cpp:237] Iteration 21100, loss = 0.000764329
I0425 15:39:40.439601 12937 solver.cpp:253]     Train net output #0: loss = 0.000764167 (* 1 = 0.000764167 loss)
I0425 15:39:40.439609 12937 sgd_solver.cpp:106] Iteration 21100, lr = 0.00427002
I0425 15:39:40.579350 12937 solver.cpp:237] Iteration 21200, loss = 0.00399236
I0425 15:39:40.579371 12937 solver.cpp:253]     Train net output #0: loss = 0.0039922 (* 1 = 0.0039922 loss)
I0425 15:39:40.579378 12937 sgd_solver.cpp:106] Iteration 21200, lr = 0.00425975
I0425 15:39:40.720240 12937 solver.cpp:237] Iteration 21300, loss = 0.00288632
I0425 15:39:40.720263 12937 solver.cpp:253]     Train net output #0: loss = 0.00288616 (* 1 = 0.00288616 loss)
I0425 15:39:40.720268 12937 sgd_solver.cpp:106] Iteration 21300, lr = 0.00424954
I0425 15:39:40.860106 12937 solver.cpp:237] Iteration 21400, loss = 0.00566447
I0425 15:39:40.860127 12937 solver.cpp:253]     Train net output #0: loss = 0.00566431 (* 1 = 0.00566431 loss)
I0425 15:39:40.860132 12937 sgd_solver.cpp:106] Iteration 21400, lr = 0.00423938
I0425 15:39:40.999830 12937 solver.cpp:237] Iteration 21500, loss = 0.00327511
I0425 15:39:40.999852 12937 solver.cpp:253]     Train net output #0: loss = 0.00327494 (* 1 = 0.00327494 loss)
I0425 15:39:40.999858 12937 sgd_solver.cpp:106] Iteration 21500, lr = 0.00422929
I0425 15:39:41.139892 12937 solver.cpp:237] Iteration 21600, loss = 0.0166631
I0425 15:39:41.139914 12937 solver.cpp:253]     Train net output #0: loss = 0.0166629 (* 1 = 0.0166629 loss)
I0425 15:39:41.139938 12937 sgd_solver.cpp:106] Iteration 21600, lr = 0.00421924
I0425 15:39:41.280197 12937 solver.cpp:237] Iteration 21700, loss = 0.0041378
I0425 15:39:41.280217 12937 solver.cpp:253]     Train net output #0: loss = 0.00413764 (* 1 = 0.00413764 loss)
I0425 15:39:41.280222 12937 sgd_solver.cpp:106] Iteration 21700, lr = 0.00420926
I0425 15:39:41.419950 12937 solver.cpp:237] Iteration 21800, loss = 0.00281453
I0425 15:39:41.419970 12937 solver.cpp:253]     Train net output #0: loss = 0.00281437 (* 1 = 0.00281437 loss)
I0425 15:39:41.419975 12937 sgd_solver.cpp:106] Iteration 21800, lr = 0.00419933
I0425 15:39:41.560308 12937 solver.cpp:237] Iteration 21900, loss = 0.00261659
I0425 15:39:41.560330 12937 solver.cpp:253]     Train net output #0: loss = 0.00261643 (* 1 = 0.00261643 loss)
I0425 15:39:41.560338 12937 sgd_solver.cpp:106] Iteration 21900, lr = 0.00418945
I0425 15:39:41.700055 12937 solver.cpp:237] Iteration 22000, loss = 0.00215892
I0425 15:39:41.700078 12937 solver.cpp:253]     Train net output #0: loss = 0.00215875 (* 1 = 0.00215875 loss)
I0425 15:39:41.700084 12937 sgd_solver.cpp:106] Iteration 22000, lr = 0.00417963
I0425 15:39:41.841773 12937 solver.cpp:237] Iteration 22100, loss = 0.0072272
I0425 15:39:41.841825 12937 solver.cpp:253]     Train net output #0: loss = 0.00722704 (* 1 = 0.00722704 loss)
I0425 15:39:41.841847 12937 sgd_solver.cpp:106] Iteration 22100, lr = 0.00416986
I0425 15:39:41.987669 12937 solver.cpp:237] Iteration 22200, loss = 0.00275751
I0425 15:39:41.987704 12937 solver.cpp:253]     Train net output #0: loss = 0.00275734 (* 1 = 0.00275734 loss)
I0425 15:39:41.987711 12937 sgd_solver.cpp:106] Iteration 22200, lr = 0.00416014
I0425 15:39:42.130411 12937 solver.cpp:237] Iteration 22300, loss = 0.0120398
I0425 15:39:42.130436 12937 solver.cpp:253]     Train net output #0: loss = 0.0120396 (* 1 = 0.0120396 loss)
I0425 15:39:42.130444 12937 sgd_solver.cpp:106] Iteration 22300, lr = 0.00415048
I0425 15:39:42.271620 12937 solver.cpp:237] Iteration 22400, loss = 0.00430732
I0425 15:39:42.271644 12937 solver.cpp:253]     Train net output #0: loss = 0.00430715 (* 1 = 0.00430715 loss)
I0425 15:39:42.271651 12937 sgd_solver.cpp:106] Iteration 22400, lr = 0.00414087
I0425 15:39:42.412822 12937 solver.cpp:237] Iteration 22500, loss = 0.00263721
I0425 15:39:42.412844 12937 solver.cpp:253]     Train net output #0: loss = 0.00263704 (* 1 = 0.00263704 loss)
I0425 15:39:42.412850 12937 sgd_solver.cpp:106] Iteration 22500, lr = 0.00413131
I0425 15:39:42.553144 12937 solver.cpp:237] Iteration 22600, loss = 0.0047231
I0425 15:39:42.553167 12937 solver.cpp:253]     Train net output #0: loss = 0.00472293 (* 1 = 0.00472293 loss)
I0425 15:39:42.553174 12937 sgd_solver.cpp:106] Iteration 22600, lr = 0.0041218
I0425 15:39:42.694247 12937 solver.cpp:237] Iteration 22700, loss = 0.0105219
I0425 15:39:42.694269 12937 solver.cpp:253]     Train net output #0: loss = 0.0105217 (* 1 = 0.0105217 loss)
I0425 15:39:42.694275 12937 sgd_solver.cpp:106] Iteration 22700, lr = 0.00411234
I0425 15:39:42.835342 12937 solver.cpp:237] Iteration 22800, loss = 0.00241483
I0425 15:39:42.835372 12937 solver.cpp:253]     Train net output #0: loss = 0.00241465 (* 1 = 0.00241465 loss)
I0425 15:39:42.835378 12937 sgd_solver.cpp:106] Iteration 22800, lr = 0.00410293
I0425 15:39:42.976670 12937 solver.cpp:237] Iteration 22900, loss = 0.00350374
I0425 15:39:42.976696 12937 solver.cpp:253]     Train net output #0: loss = 0.00350357 (* 1 = 0.00350357 loss)
I0425 15:39:42.976702 12937 sgd_solver.cpp:106] Iteration 22900, lr = 0.00409358
I0425 15:39:43.117573 12937 solver.cpp:237] Iteration 23000, loss = 0.00547148
I0425 15:39:43.117595 12937 solver.cpp:253]     Train net output #0: loss = 0.0054713 (* 1 = 0.0054713 loss)
I0425 15:39:43.117601 12937 sgd_solver.cpp:106] Iteration 23000, lr = 0.00408427
I0425 15:39:43.258002 12937 solver.cpp:237] Iteration 23100, loss = 0.00617491
I0425 15:39:43.258024 12937 solver.cpp:253]     Train net output #0: loss = 0.00617474 (* 1 = 0.00617474 loss)
I0425 15:39:43.258051 12937 sgd_solver.cpp:106] Iteration 23100, lr = 0.00407501
I0425 15:39:43.399335 12937 solver.cpp:237] Iteration 23200, loss = 0.00218644
I0425 15:39:43.399379 12937 solver.cpp:253]     Train net output #0: loss = 0.00218628 (* 1 = 0.00218628 loss)
I0425 15:39:43.399394 12937 sgd_solver.cpp:106] Iteration 23200, lr = 0.0040658
I0425 15:39:43.548306 12937 solver.cpp:237] Iteration 23300, loss = 0.0193206
I0425 15:39:43.548336 12937 solver.cpp:253]     Train net output #0: loss = 0.0193205 (* 1 = 0.0193205 loss)
I0425 15:39:43.548343 12937 sgd_solver.cpp:106] Iteration 23300, lr = 0.00405664
I0425 15:39:43.693219 12937 solver.cpp:237] Iteration 23400, loss = 0.00525179
I0425 15:39:43.693244 12937 solver.cpp:253]     Train net output #0: loss = 0.00525162 (* 1 = 0.00525162 loss)
I0425 15:39:43.693250 12937 sgd_solver.cpp:106] Iteration 23400, lr = 0.00404753
I0425 15:39:43.836714 12937 solver.cpp:237] Iteration 23500, loss = 0.00484845
I0425 15:39:43.836740 12937 solver.cpp:253]     Train net output #0: loss = 0.00484828 (* 1 = 0.00484828 loss)
I0425 15:39:43.836745 12937 sgd_solver.cpp:106] Iteration 23500, lr = 0.00403847
I0425 15:39:43.980296 12937 solver.cpp:237] Iteration 23600, loss = 0.000764179
I0425 15:39:43.980324 12937 solver.cpp:253]     Train net output #0: loss = 0.000764014 (* 1 = 0.000764014 loss)
I0425 15:39:43.980329 12937 sgd_solver.cpp:106] Iteration 23600, lr = 0.00402945
I0425 15:39:44.124253 12937 solver.cpp:237] Iteration 23700, loss = 0.00164423
I0425 15:39:44.124277 12937 solver.cpp:253]     Train net output #0: loss = 0.00164406 (* 1 = 0.00164406 loss)
I0425 15:39:44.124284 12937 sgd_solver.cpp:106] Iteration 23700, lr = 0.00402048
I0425 15:39:44.268975 12937 solver.cpp:237] Iteration 23800, loss = 0.00133424
I0425 15:39:44.269001 12937 solver.cpp:253]     Train net output #0: loss = 0.00133407 (* 1 = 0.00133407 loss)
I0425 15:39:44.269007 12937 sgd_solver.cpp:106] Iteration 23800, lr = 0.00401155
I0425 15:39:44.413813 12937 solver.cpp:237] Iteration 23900, loss = 0.000709189
I0425 15:39:44.413836 12937 solver.cpp:253]     Train net output #0: loss = 0.000709022 (* 1 = 0.000709022 loss)
I0425 15:39:44.413842 12937 sgd_solver.cpp:106] Iteration 23900, lr = 0.00400267
I0425 15:39:44.557075 12937 solver.cpp:237] Iteration 24000, loss = 0.0106241
I0425 15:39:44.557096 12937 solver.cpp:253]     Train net output #0: loss = 0.0106239 (* 1 = 0.0106239 loss)
I0425 15:39:44.557102 12937 sgd_solver.cpp:106] Iteration 24000, lr = 0.00399384
I0425 15:39:44.699177 12937 solver.cpp:237] Iteration 24100, loss = 0.00729037
I0425 15:39:44.699198 12937 solver.cpp:253]     Train net output #0: loss = 0.00729021 (* 1 = 0.00729021 loss)
I0425 15:39:44.699203 12937 sgd_solver.cpp:106] Iteration 24100, lr = 0.00398505
I0425 15:39:44.841814 12937 solver.cpp:237] Iteration 24200, loss = 0.00499786
I0425 15:39:44.841835 12937 solver.cpp:253]     Train net output #0: loss = 0.0049977 (* 1 = 0.0049977 loss)
I0425 15:39:44.841840 12937 sgd_solver.cpp:106] Iteration 24200, lr = 0.00397631
I0425 15:39:44.983422 12937 solver.cpp:237] Iteration 24300, loss = 0.00491284
I0425 15:39:44.983445 12937 solver.cpp:253]     Train net output #0: loss = 0.00491268 (* 1 = 0.00491268 loss)
I0425 15:39:44.983451 12937 sgd_solver.cpp:106] Iteration 24300, lr = 0.00396761
I0425 15:39:45.123736 12937 solver.cpp:237] Iteration 24400, loss = 0.00788927
I0425 15:39:45.123759 12937 solver.cpp:253]     Train net output #0: loss = 0.00788911 (* 1 = 0.00788911 loss)
I0425 15:39:45.123764 12937 sgd_solver.cpp:106] Iteration 24400, lr = 0.00395896
I0425 15:39:45.263986 12937 solver.cpp:237] Iteration 24500, loss = 0.00237486
I0425 15:39:45.264008 12937 solver.cpp:253]     Train net output #0: loss = 0.0023747 (* 1 = 0.0023747 loss)
I0425 15:39:45.264014 12937 sgd_solver.cpp:106] Iteration 24500, lr = 0.00395035
I0425 15:39:45.405478 12937 solver.cpp:237] Iteration 24600, loss = 0.00261197
I0425 15:39:45.405505 12937 solver.cpp:253]     Train net output #0: loss = 0.00261181 (* 1 = 0.00261181 loss)
I0425 15:39:45.405529 12937 sgd_solver.cpp:106] Iteration 24600, lr = 0.00394178
I0425 15:39:45.547041 12937 solver.cpp:237] Iteration 24700, loss = 0.00140223
I0425 15:39:45.547062 12937 solver.cpp:253]     Train net output #0: loss = 0.00140207 (* 1 = 0.00140207 loss)
I0425 15:39:45.547067 12937 sgd_solver.cpp:106] Iteration 24700, lr = 0.00393326
I0425 15:39:45.687746 12937 solver.cpp:237] Iteration 24800, loss = 0.00765456
I0425 15:39:45.687767 12937 solver.cpp:253]     Train net output #0: loss = 0.00765441 (* 1 = 0.00765441 loss)
I0425 15:39:45.687772 12937 sgd_solver.cpp:106] Iteration 24800, lr = 0.00392478
I0425 15:39:45.828166 12937 solver.cpp:237] Iteration 24900, loss = 0.00337665
I0425 15:39:45.828191 12937 solver.cpp:253]     Train net output #0: loss = 0.00337649 (* 1 = 0.00337649 loss)
I0425 15:39:45.828197 12937 sgd_solver.cpp:106] Iteration 24900, lr = 0.00391634
I0425 15:39:45.971520 12937 solver.cpp:459] Snapshotting to binary proto file examples/mnist/test/lenet_iter_25000.caffemodel
I0425 15:39:45.973522 12937 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/test/lenet_iter_25000.solverstate
I0425 15:39:45.974370 12937 solver.cpp:341] Iteration 25000, Testing net (#0)
I0425 15:39:46.050696 12937 solver.cpp:409]     Test net output #0: accuracy = 0.9913
I0425 15:39:46.050731 12937 solver.cpp:409]     Test net output #1: loss = 0.0281594 (* 1 = 0.0281594 loss)
I0425 15:39:46.051462 12937 solver.cpp:237] Iteration 25000, loss = 0.0026642
I0425 15:39:46.051486 12937 solver.cpp:253]     Train net output #0: loss = 0.00266405 (* 1 = 0.00266405 loss)
I0425 15:39:46.051501 12937 sgd_solver.cpp:106] Iteration 25000, lr = 0.00390795
I0425 15:39:46.197373 12937 solver.cpp:237] Iteration 25100, loss = 0.0108345
I0425 15:39:46.197394 12937 solver.cpp:253]     Train net output #0: loss = 0.0108343 (* 1 = 0.0108343 loss)
I0425 15:39:46.197401 12937 sgd_solver.cpp:106] Iteration 25100, lr = 0.0038996
I0425 15:39:46.345049 12937 solver.cpp:237] Iteration 25200, loss = 0.00835956
I0425 15:39:46.345070 12937 solver.cpp:253]     Train net output #0: loss = 0.0083594 (* 1 = 0.0083594 loss)
I0425 15:39:46.345077 12937 sgd_solver.cpp:106] Iteration 25200, lr = 0.00389128
I0425 15:39:46.492741 12937 solver.cpp:237] Iteration 25300, loss = 0.000164942
I0425 15:39:46.492763 12937 solver.cpp:253]     Train net output #0: loss = 0.000164787 (* 1 = 0.000164787 loss)
I0425 15:39:46.492769 12937 sgd_solver.cpp:106] Iteration 25300, lr = 0.00388301
I0425 15:39:46.640359 12937 solver.cpp:237] Iteration 25400, loss = 0.00666739
I0425 15:39:46.640379 12937 solver.cpp:253]     Train net output #0: loss = 0.00666723 (* 1 = 0.00666723 loss)
I0425 15:39:46.640391 12937 sgd_solver.cpp:106] Iteration 25400, lr = 0.00387478
I0425 15:39:46.788203 12937 solver.cpp:237] Iteration 25500, loss = 0.00516101
I0425 15:39:46.788226 12937 solver.cpp:253]     Train net output #0: loss = 0.00516085 (* 1 = 0.00516085 loss)
I0425 15:39:46.788233 12937 sgd_solver.cpp:106] Iteration 25500, lr = 0.0038666
I0425 15:39:46.935910 12937 solver.cpp:237] Iteration 25600, loss = 0.00263837
I0425 15:39:46.935933 12937 solver.cpp:253]     Train net output #0: loss = 0.00263821 (* 1 = 0.00263821 loss)
I0425 15:39:46.935940 12937 sgd_solver.cpp:106] Iteration 25600, lr = 0.00385845
I0425 15:39:47.083811 12937 solver.cpp:237] Iteration 25700, loss = 0.00266688
I0425 15:39:47.083832 12937 solver.cpp:253]     Train net output #0: loss = 0.00266672 (* 1 = 0.00266672 loss)
I0425 15:39:47.083838 12937 sgd_solver.cpp:106] Iteration 25700, lr = 0.00385034
I0425 15:39:47.229912 12937 solver.cpp:237] Iteration 25800, loss = 0.00184177
I0425 15:39:47.229933 12937 solver.cpp:253]     Train net output #0: loss = 0.00184161 (* 1 = 0.00184161 loss)
I0425 15:39:47.229939 12937 sgd_solver.cpp:106] Iteration 25800, lr = 0.00384227
I0425 15:39:47.377450 12937 solver.cpp:237] Iteration 25900, loss = 0.00228989
I0425 15:39:47.377471 12937 solver.cpp:253]     Train net output #0: loss = 0.00228973 (* 1 = 0.00228973 loss)
I0425 15:39:47.377477 12937 sgd_solver.cpp:106] Iteration 25900, lr = 0.00383424
I0425 15:39:47.523769 12937 solver.cpp:237] Iteration 26000, loss = 0.00163205
I0425 15:39:47.523789 12937 solver.cpp:253]     Train net output #0: loss = 0.00163189 (* 1 = 0.00163189 loss)
I0425 15:39:47.523795 12937 sgd_solver.cpp:106] Iteration 26000, lr = 0.00382625
I0425 15:39:47.672385 12937 solver.cpp:237] Iteration 26100, loss = 0.0086169
I0425 15:39:47.672405 12937 solver.cpp:253]     Train net output #0: loss = 0.00861673 (* 1 = 0.00861673 loss)
I0425 15:39:47.672411 12937 sgd_solver.cpp:106] Iteration 26100, lr = 0.0038183
I0425 15:39:47.819751 12937 solver.cpp:237] Iteration 26200, loss = 0.00718383
I0425 15:39:47.819771 12937 solver.cpp:253]     Train net output #0: loss = 0.00718367 (* 1 = 0.00718367 loss)
I0425 15:39:47.819777 12937 sgd_solver.cpp:106] Iteration 26200, lr = 0.00381038
I0425 15:39:47.968652 12937 solver.cpp:237] Iteration 26300, loss = 0.00365975
I0425 15:39:47.968682 12937 solver.cpp:253]     Train net output #0: loss = 0.00365959 (* 1 = 0.00365959 loss)
I0425 15:39:47.968689 12937 sgd_solver.cpp:106] Iteration 26300, lr = 0.00380251
I0425 15:39:48.114200 12937 solver.cpp:237] Iteration 26400, loss = 0.00788262
I0425 15:39:48.114223 12937 solver.cpp:253]     Train net output #0: loss = 0.00788247 (* 1 = 0.00788247 loss)
I0425 15:39:48.114228 12937 sgd_solver.cpp:106] Iteration 26400, lr = 0.00379467
I0425 15:39:48.261562 12937 solver.cpp:237] Iteration 26500, loss = 0.00424846
I0425 15:39:48.261582 12937 solver.cpp:253]     Train net output #0: loss = 0.00424831 (* 1 = 0.00424831 loss)
I0425 15:39:48.261589 12937 sgd_solver.cpp:106] Iteration 26500, lr = 0.00378687
I0425 15:39:48.409198 12937 solver.cpp:237] Iteration 26600, loss = 0.00526682
I0425 15:39:48.409219 12937 solver.cpp:253]     Train net output #0: loss = 0.00526667 (* 1 = 0.00526667 loss)
I0425 15:39:48.409225 12937 sgd_solver.cpp:106] Iteration 26600, lr = 0.00377911
I0425 15:39:48.558779 12937 solver.cpp:237] Iteration 26700, loss = 0.00186451
I0425 15:39:48.558814 12937 solver.cpp:253]     Train net output #0: loss = 0.00186435 (* 1 = 0.00186435 loss)
I0425 15:39:48.558823 12937 sgd_solver.cpp:106] Iteration 26700, lr = 0.00377138
I0425 15:39:48.706841 12937 solver.cpp:237] Iteration 26800, loss = 0.0109369
I0425 15:39:48.706866 12937 solver.cpp:253]     Train net output #0: loss = 0.0109368 (* 1 = 0.0109368 loss)
I0425 15:39:48.706872 12937 sgd_solver.cpp:106] Iteration 26800, lr = 0.00376369
I0425 15:39:48.853330 12937 solver.cpp:237] Iteration 26900, loss = 0.0052942
I0425 15:39:48.853354 12937 solver.cpp:253]     Train net output #0: loss = 0.00529405 (* 1 = 0.00529405 loss)
I0425 15:39:48.853360 12937 sgd_solver.cpp:106] Iteration 26900, lr = 0.00375604
I0425 15:39:49.001467 12937 solver.cpp:237] Iteration 27000, loss = 0.00219715
I0425 15:39:49.001489 12937 solver.cpp:253]     Train net output #0: loss = 0.002197 (* 1 = 0.002197 loss)
I0425 15:39:49.001494 12937 sgd_solver.cpp:106] Iteration 27000, lr = 0.00374842
I0425 15:39:49.149469 12937 solver.cpp:237] Iteration 27100, loss = 0.00759272
I0425 15:39:49.149490 12937 solver.cpp:253]     Train net output #0: loss = 0.00759257 (* 1 = 0.00759257 loss)
I0425 15:39:49.149497 12937 sgd_solver.cpp:106] Iteration 27100, lr = 0.00374084
I0425 15:39:49.296927 12937 solver.cpp:237] Iteration 27200, loss = 0.000828754
I0425 15:39:49.296947 12937 solver.cpp:253]     Train net output #0: loss = 0.000828594 (* 1 = 0.000828594 loss)
I0425 15:39:49.296953 12937 sgd_solver.cpp:106] Iteration 27200, lr = 0.0037333
I0425 15:39:49.444175 12937 solver.cpp:237] Iteration 27300, loss = 0.00539659
I0425 15:39:49.444197 12937 solver.cpp:253]     Train net output #0: loss = 0.00539643 (* 1 = 0.00539643 loss)
I0425 15:39:49.444202 12937 sgd_solver.cpp:106] Iteration 27300, lr = 0.00372579
I0425 15:39:49.591491 12937 solver.cpp:237] Iteration 27400, loss = 0.00188984
I0425 15:39:49.591511 12937 solver.cpp:253]     Train net output #0: loss = 0.00188968 (* 1 = 0.00188968 loss)
I0425 15:39:49.591516 12937 sgd_solver.cpp:106] Iteration 27400, lr = 0.00371832
I0425 15:39:49.738996 12937 solver.cpp:237] Iteration 27500, loss = 0.0107901
I0425 15:39:49.739017 12937 solver.cpp:253]     Train net output #0: loss = 0.01079 (* 1 = 0.01079 loss)
I0425 15:39:49.739022 12937 sgd_solver.cpp:106] Iteration 27500, lr = 0.00371088
I0425 15:39:49.886634 12937 solver.cpp:237] Iteration 27600, loss = 0.0137669
I0425 15:39:49.886654 12937 solver.cpp:253]     Train net output #0: loss = 0.0137668 (* 1 = 0.0137668 loss)
I0425 15:39:49.886659 12937 sgd_solver.cpp:106] Iteration 27600, lr = 0.00370347
I0425 15:39:50.034437 12937 solver.cpp:237] Iteration 27700, loss = 0.00730407
I0425 15:39:50.034461 12937 solver.cpp:253]     Train net output #0: loss = 0.00730391 (* 1 = 0.00730391 loss)
I0425 15:39:50.034467 12937 sgd_solver.cpp:106] Iteration 27700, lr = 0.0036961
I0425 15:39:50.181762 12937 solver.cpp:237] Iteration 27800, loss = 0.00176345
I0425 15:39:50.181784 12937 solver.cpp:253]     Train net output #0: loss = 0.00176329 (* 1 = 0.00176329 loss)
I0425 15:39:50.181790 12937 sgd_solver.cpp:106] Iteration 27800, lr = 0.00368877
I0425 15:39:50.328979 12937 solver.cpp:237] Iteration 27900, loss = 0.00471753
I0425 15:39:50.329000 12937 solver.cpp:253]     Train net output #0: loss = 0.00471737 (* 1 = 0.00471737 loss)
I0425 15:39:50.329005 12937 sgd_solver.cpp:106] Iteration 27900, lr = 0.00368146
I0425 15:39:50.476212 12937 solver.cpp:237] Iteration 28000, loss = 0.00173396
I0425 15:39:50.476233 12937 solver.cpp:253]     Train net output #0: loss = 0.0017338 (* 1 = 0.0017338 loss)
I0425 15:39:50.476238 12937 sgd_solver.cpp:106] Iteration 28000, lr = 0.0036742
I0425 15:39:50.624027 12937 solver.cpp:237] Iteration 28100, loss = 0.000285251
I0425 15:39:50.624054 12937 solver.cpp:253]     Train net output #0: loss = 0.000285095 (* 1 = 0.000285095 loss)
I0425 15:39:50.624068 12937 sgd_solver.cpp:106] Iteration 28100, lr = 0.00366696
I0425 15:39:50.770936 12937 solver.cpp:237] Iteration 28200, loss = 0.000513804
I0425 15:39:50.770957 12937 solver.cpp:253]     Train net output #0: loss = 0.000513654 (* 1 = 0.000513654 loss)
I0425 15:39:50.770963 12937 sgd_solver.cpp:106] Iteration 28200, lr = 0.00365976
I0425 15:39:50.918947 12937 solver.cpp:237] Iteration 28300, loss = 0.00717837
I0425 15:39:50.918968 12937 solver.cpp:253]     Train net output #0: loss = 0.00717822 (* 1 = 0.00717822 loss)
I0425 15:39:50.918974 12937 sgd_solver.cpp:106] Iteration 28300, lr = 0.00365259
I0425 15:39:51.067035 12937 solver.cpp:237] Iteration 28400, loss = 0.00441818
I0425 15:39:51.067056 12937 solver.cpp:253]     Train net output #0: loss = 0.00441803 (* 1 = 0.00441803 loss)
I0425 15:39:51.067062 12937 sgd_solver.cpp:106] Iteration 28400, lr = 0.00364545
I0425 15:39:51.213347 12937 solver.cpp:237] Iteration 28500, loss = 0.00312177
I0425 15:39:51.213367 12937 solver.cpp:253]     Train net output #0: loss = 0.00312161 (* 1 = 0.00312161 loss)
I0425 15:39:51.213372 12937 sgd_solver.cpp:106] Iteration 28500, lr = 0.00363835
I0425 15:39:51.361196 12937 solver.cpp:237] Iteration 28600, loss = 0.000669246
I0425 15:39:51.361215 12937 solver.cpp:253]     Train net output #0: loss = 0.000669092 (* 1 = 0.000669092 loss)
I0425 15:39:51.361222 12937 sgd_solver.cpp:106] Iteration 28600, lr = 0.00363128
I0425 15:39:51.507860 12937 solver.cpp:237] Iteration 28700, loss = 0.00298387
I0425 15:39:51.507880 12937 solver.cpp:253]     Train net output #0: loss = 0.00298372 (* 1 = 0.00298372 loss)
I0425 15:39:51.507886 12937 sgd_solver.cpp:106] Iteration 28700, lr = 0.00362424
I0425 15:39:51.657177 12937 solver.cpp:237] Iteration 28800, loss = 0.00260213
I0425 15:39:51.657219 12937 solver.cpp:253]     Train net output #0: loss = 0.00260198 (* 1 = 0.00260198 loss)
I0425 15:39:51.657232 12937 sgd_solver.cpp:106] Iteration 28800, lr = 0.00361723
I0425 15:39:51.804756 12937 solver.cpp:237] Iteration 28900, loss = 0.00569608
I0425 15:39:51.804796 12937 solver.cpp:253]     Train net output #0: loss = 0.00569593 (* 1 = 0.00569593 loss)
I0425 15:39:51.804805 12937 sgd_solver.cpp:106] Iteration 28900, lr = 0.00361025
I0425 15:39:51.953057 12937 solver.cpp:237] Iteration 29000, loss = 0.00336535
I0425 15:39:51.953102 12937 solver.cpp:253]     Train net output #0: loss = 0.0033652 (* 1 = 0.0033652 loss)
I0425 15:39:51.953109 12937 sgd_solver.cpp:106] Iteration 29000, lr = 0.00360331
I0425 15:39:52.100160 12937 solver.cpp:237] Iteration 29100, loss = 0.0130987
I0425 15:39:52.100183 12937 solver.cpp:253]     Train net output #0: loss = 0.0130985 (* 1 = 0.0130985 loss)
I0425 15:39:52.100188 12937 sgd_solver.cpp:106] Iteration 29100, lr = 0.0035964
I0425 15:39:52.247462 12937 solver.cpp:237] Iteration 29200, loss = 0.00390092
I0425 15:39:52.247484 12937 solver.cpp:253]     Train net output #0: loss = 0.00390077 (* 1 = 0.00390077 loss)
I0425 15:39:52.247489 12937 sgd_solver.cpp:106] Iteration 29200, lr = 0.00358951
I0425 15:39:52.394701 12937 solver.cpp:237] Iteration 29300, loss = 0.00256446
I0425 15:39:52.394723 12937 solver.cpp:253]     Train net output #0: loss = 0.00256431 (* 1 = 0.00256431 loss)
I0425 15:39:52.394728 12937 sgd_solver.cpp:106] Iteration 29300, lr = 0.00358266
I0425 15:39:52.541649 12937 solver.cpp:237] Iteration 29400, loss = 0.00227972
I0425 15:39:52.541671 12937 solver.cpp:253]     Train net output #0: loss = 0.00227957 (* 1 = 0.00227957 loss)
I0425 15:39:52.541676 12937 sgd_solver.cpp:106] Iteration 29400, lr = 0.00357584
I0425 15:39:52.688648 12937 solver.cpp:237] Iteration 29500, loss = 0.00185781
I0425 15:39:52.688669 12937 solver.cpp:253]     Train net output #0: loss = 0.00185767 (* 1 = 0.00185767 loss)
I0425 15:39:52.688674 12937 sgd_solver.cpp:106] Iteration 29500, lr = 0.00356905
I0425 15:39:52.836030 12937 solver.cpp:237] Iteration 29600, loss = 0.00610438
I0425 15:39:52.836050 12937 solver.cpp:253]     Train net output #0: loss = 0.00610424 (* 1 = 0.00610424 loss)
I0425 15:39:52.836056 12937 sgd_solver.cpp:106] Iteration 29600, lr = 0.00356228
I0425 15:39:52.984272 12937 solver.cpp:237] Iteration 29700, loss = 0.00272492
I0425 15:39:52.984318 12937 solver.cpp:253]     Train net output #0: loss = 0.00272478 (* 1 = 0.00272478 loss)
I0425 15:39:52.984328 12937 sgd_solver.cpp:106] Iteration 29700, lr = 0.00355555
I0425 15:39:53.130254 12937 solver.cpp:237] Iteration 29800, loss = 0.0100446
I0425 15:39:53.130277 12937 solver.cpp:253]     Train net output #0: loss = 0.0100445 (* 1 = 0.0100445 loss)
I0425 15:39:53.130285 12937 sgd_solver.cpp:106] Iteration 29800, lr = 0.00354885
I0425 15:39:53.277848 12937 solver.cpp:237] Iteration 29900, loss = 0.00428899
I0425 15:39:53.277869 12937 solver.cpp:253]     Train net output #0: loss = 0.00428885 (* 1 = 0.00428885 loss)
I0425 15:39:53.277875 12937 sgd_solver.cpp:106] Iteration 29900, lr = 0.00354218
I0425 15:39:53.424247 12937 solver.cpp:459] Snapshotting to binary proto file examples/mnist/test/lenet_iter_30000.caffemodel
I0425 15:39:53.425926 12937 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/test/lenet_iter_30000.solverstate
I0425 15:39:53.426426 12937 solver.cpp:341] Iteration 30000, Testing net (#0)
I0425 15:39:53.514428 12937 solver.cpp:409]     Test net output #0: accuracy = 0.9897
I0425 15:39:53.514456 12937 solver.cpp:409]     Test net output #1: loss = 0.0307686 (* 1 = 0.0307686 loss)
I0425 15:39:53.515117 12937 solver.cpp:237] Iteration 30000, loss = 0.00220245
I0425 15:39:53.515141 12937 solver.cpp:253]     Train net output #0: loss = 0.00220232 (* 1 = 0.00220232 loss)
I0425 15:39:53.515149 12937 sgd_solver.cpp:106] Iteration 30000, lr = 0.00353553
I0425 15:39:53.662160 12937 solver.cpp:237] Iteration 30100, loss = 0.00425161
I0425 15:39:53.662185 12937 solver.cpp:253]     Train net output #0: loss = 0.00425148 (* 1 = 0.00425148 loss)
I0425 15:39:53.662194 12937 sgd_solver.cpp:106] Iteration 30100, lr = 0.00352892
I0425 15:39:53.809736 12937 solver.cpp:237] Iteration 30200, loss = 0.00946398
I0425 15:39:53.809757 12937 solver.cpp:253]     Train net output #0: loss = 0.00946384 (* 1 = 0.00946384 loss)
I0425 15:39:53.809763 12937 sgd_solver.cpp:106] Iteration 30200, lr = 0.00352233
I0425 15:39:53.958273 12937 solver.cpp:237] Iteration 30300, loss = 0.00262489
I0425 15:39:53.958319 12937 solver.cpp:253]     Train net output #0: loss = 0.00262476 (* 1 = 0.00262476 loss)
I0425 15:39:53.958328 12937 sgd_solver.cpp:106] Iteration 30300, lr = 0.00351578
I0425 15:39:54.104876 12937 solver.cpp:237] Iteration 30400, loss = 0.00313395
I0425 15:39:54.104904 12937 solver.cpp:253]     Train net output #0: loss = 0.00313381 (* 1 = 0.00313381 loss)
I0425 15:39:54.104912 12937 sgd_solver.cpp:106] Iteration 30400, lr = 0.00350925
I0425 15:39:54.250329 12937 solver.cpp:237] Iteration 30500, loss = 0.00493256
I0425 15:39:54.250349 12937 solver.cpp:253]     Train net output #0: loss = 0.00493242 (* 1 = 0.00493242 loss)
I0425 15:39:54.250355 12937 sgd_solver.cpp:106] Iteration 30500, lr = 0.00350275
I0425 15:39:54.398432 12937 solver.cpp:237] Iteration 30600, loss = 0.00524899
I0425 15:39:54.398452 12937 solver.cpp:253]     Train net output #0: loss = 0.00524886 (* 1 = 0.00524886 loss)
I0425 15:39:54.398457 12937 sgd_solver.cpp:106] Iteration 30600, lr = 0.00349627
I0425 15:39:54.546067 12937 solver.cpp:237] Iteration 30700, loss = 0.00223219
I0425 15:39:54.546088 12937 solver.cpp:253]     Train net output #0: loss = 0.00223205 (* 1 = 0.00223205 loss)
I0425 15:39:54.546093 12937 sgd_solver.cpp:106] Iteration 30700, lr = 0.00348983
I0425 15:39:54.692984 12937 solver.cpp:237] Iteration 30800, loss = 0.0150252
I0425 15:39:54.693004 12937 solver.cpp:253]     Train net output #0: loss = 0.015025 (* 1 = 0.015025 loss)
I0425 15:39:54.693011 12937 sgd_solver.cpp:106] Iteration 30800, lr = 0.00348341
I0425 15:39:54.839767 12937 solver.cpp:237] Iteration 30900, loss = 0.00494053
I0425 15:39:54.839792 12937 solver.cpp:253]     Train net output #0: loss = 0.0049404 (* 1 = 0.0049404 loss)
I0425 15:39:54.839797 12937 sgd_solver.cpp:106] Iteration 30900, lr = 0.00347702
I0425 15:39:54.987614 12937 solver.cpp:237] Iteration 31000, loss = 0.00454646
I0425 15:39:54.987638 12937 solver.cpp:253]     Train net output #0: loss = 0.00454632 (* 1 = 0.00454632 loss)
I0425 15:39:54.987643 12937 sgd_solver.cpp:106] Iteration 31000, lr = 0.00347066
I0425 15:39:55.135671 12937 solver.cpp:237] Iteration 31100, loss = 0.000758916
I0425 15:39:55.135694 12937 solver.cpp:253]     Train net output #0: loss = 0.000758775 (* 1 = 0.000758775 loss)
I0425 15:39:55.135699 12937 sgd_solver.cpp:106] Iteration 31100, lr = 0.00346433
I0425 15:39:55.283043 12937 solver.cpp:237] Iteration 31200, loss = 0.00138464
I0425 15:39:55.283066 12937 solver.cpp:253]     Train net output #0: loss = 0.0013845 (* 1 = 0.0013845 loss)
I0425 15:39:55.283071 12937 sgd_solver.cpp:106] Iteration 31200, lr = 0.00345802
I0425 15:39:55.430379 12937 solver.cpp:237] Iteration 31300, loss = 0.00131356
I0425 15:39:55.430402 12937 solver.cpp:253]     Train net output #0: loss = 0.00131342 (* 1 = 0.00131342 loss)
I0425 15:39:55.430408 12937 sgd_solver.cpp:106] Iteration 31300, lr = 0.00345174
I0425 15:39:55.577760 12937 solver.cpp:237] Iteration 31400, loss = 0.000848395
I0425 15:39:55.577783 12937 solver.cpp:253]     Train net output #0: loss = 0.000848253 (* 1 = 0.000848253 loss)
I0425 15:39:55.577788 12937 sgd_solver.cpp:106] Iteration 31400, lr = 0.00344548
I0425 15:39:55.725419 12937 solver.cpp:237] Iteration 31500, loss = 0.00995051
I0425 15:39:55.725447 12937 solver.cpp:253]     Train net output #0: loss = 0.00995037 (* 1 = 0.00995037 loss)
I0425 15:39:55.725452 12937 sgd_solver.cpp:106] Iteration 31500, lr = 0.00343925
I0425 15:39:55.873172 12937 solver.cpp:237] Iteration 31600, loss = 0.00675376
I0425 15:39:55.873193 12937 solver.cpp:253]     Train net output #0: loss = 0.00675362 (* 1 = 0.00675362 loss)
I0425 15:39:55.873199 12937 sgd_solver.cpp:106] Iteration 31600, lr = 0.00343305
I0425 15:39:56.021052 12937 solver.cpp:237] Iteration 31700, loss = 0.00455698
I0425 15:39:56.021078 12937 solver.cpp:253]     Train net output #0: loss = 0.00455684 (* 1 = 0.00455684 loss)
I0425 15:39:56.021085 12937 sgd_solver.cpp:106] Iteration 31700, lr = 0.00342687
I0425 15:39:56.167390 12937 solver.cpp:237] Iteration 31800, loss = 0.00427386
I0425 15:39:56.167413 12937 solver.cpp:253]     Train net output #0: loss = 0.00427372 (* 1 = 0.00427372 loss)
I0425 15:39:56.167440 12937 sgd_solver.cpp:106] Iteration 31800, lr = 0.00342072
I0425 15:39:56.314424 12937 solver.cpp:237] Iteration 31900, loss = 0.00744265
I0425 15:39:56.314445 12937 solver.cpp:253]     Train net output #0: loss = 0.00744251 (* 1 = 0.00744251 loss)
I0425 15:39:56.314451 12937 sgd_solver.cpp:106] Iteration 31900, lr = 0.0034146
I0425 15:39:56.461922 12937 solver.cpp:237] Iteration 32000, loss = 0.00229431
I0425 15:39:56.461943 12937 solver.cpp:253]     Train net output #0: loss = 0.00229417 (* 1 = 0.00229417 loss)
I0425 15:39:56.461948 12937 sgd_solver.cpp:106] Iteration 32000, lr = 0.0034085
I0425 15:39:56.608636 12937 solver.cpp:237] Iteration 32100, loss = 0.00257529
I0425 15:39:56.608659 12937 solver.cpp:253]     Train net output #0: loss = 0.00257515 (* 1 = 0.00257515 loss)
I0425 15:39:56.608664 12937 sgd_solver.cpp:106] Iteration 32100, lr = 0.00340242
I0425 15:39:56.755933 12937 solver.cpp:237] Iteration 32200, loss = 0.00129744
I0425 15:39:56.755954 12937 solver.cpp:253]     Train net output #0: loss = 0.0012973 (* 1 = 0.0012973 loss)
I0425 15:39:56.755959 12937 sgd_solver.cpp:106] Iteration 32200, lr = 0.00339637
I0425 15:39:56.904321 12937 solver.cpp:237] Iteration 32300, loss = 0.0081101
I0425 15:39:56.904345 12937 solver.cpp:253]     Train net output #0: loss = 0.00810996 (* 1 = 0.00810996 loss)
I0425 15:39:56.904351 12937 sgd_solver.cpp:106] Iteration 32300, lr = 0.00339035
I0425 15:39:57.053417 12937 solver.cpp:237] Iteration 32400, loss = 0.00329712
I0425 15:39:57.053437 12937 solver.cpp:253]     Train net output #0: loss = 0.00329698 (* 1 = 0.00329698 loss)
I0425 15:39:57.053442 12937 sgd_solver.cpp:106] Iteration 32400, lr = 0.00338435
I0425 15:39:57.202399 12937 solver.cpp:237] Iteration 32500, loss = 0.00283596
I0425 15:39:57.202417 12937 solver.cpp:253]     Train net output #0: loss = 0.00283582 (* 1 = 0.00283582 loss)
I0425 15:39:57.202424 12937 sgd_solver.cpp:106] Iteration 32500, lr = 0.00337838
I0425 15:39:57.351562 12937 solver.cpp:237] Iteration 32600, loss = 0.00992587
I0425 15:39:57.351582 12937 solver.cpp:253]     Train net output #0: loss = 0.00992574 (* 1 = 0.00992574 loss)
I0425 15:39:57.351588 12937 sgd_solver.cpp:106] Iteration 32600, lr = 0.00337243
I0425 15:39:57.500368 12937 solver.cpp:237] Iteration 32700, loss = 0.00795913
I0425 15:39:57.500391 12937 solver.cpp:253]     Train net output #0: loss = 0.007959 (* 1 = 0.007959 loss)
I0425 15:39:57.500396 12937 sgd_solver.cpp:106] Iteration 32700, lr = 0.0033665
I0425 15:39:57.646432 12937 solver.cpp:237] Iteration 32800, loss = 0.00015118
I0425 15:39:57.646452 12937 solver.cpp:253]     Train net output #0: loss = 0.000151045 (* 1 = 0.000151045 loss)
I0425 15:39:57.646457 12937 sgd_solver.cpp:106] Iteration 32800, lr = 0.0033606
I0425 15:39:57.793023 12937 solver.cpp:237] Iteration 32900, loss = 0.00618015
I0425 15:39:57.793046 12937 solver.cpp:253]     Train net output #0: loss = 0.00618002 (* 1 = 0.00618002 loss)
I0425 15:39:57.793052 12937 sgd_solver.cpp:106] Iteration 32900, lr = 0.00335473
I0425 15:39:57.940390 12937 solver.cpp:237] Iteration 33000, loss = 0.00481813
I0425 15:39:57.940412 12937 solver.cpp:253]     Train net output #0: loss = 0.004818 (* 1 = 0.004818 loss)
I0425 15:39:57.940417 12937 sgd_solver.cpp:106] Iteration 33000, lr = 0.00334887
I0425 15:39:58.087224 12937 solver.cpp:237] Iteration 33100, loss = 0.00286029
I0425 15:39:58.087245 12937 solver.cpp:253]     Train net output #0: loss = 0.00286015 (* 1 = 0.00286015 loss)
I0425 15:39:58.087251 12937 sgd_solver.cpp:106] Iteration 33100, lr = 0.00334304
I0425 15:39:58.235414 12937 solver.cpp:237] Iteration 33200, loss = 0.00238985
I0425 15:39:58.235438 12937 solver.cpp:253]     Train net output #0: loss = 0.00238972 (* 1 = 0.00238972 loss)
I0425 15:39:58.235447 12937 sgd_solver.cpp:106] Iteration 33200, lr = 0.00333724
I0425 15:39:58.382876 12937 solver.cpp:237] Iteration 33300, loss = 0.001753
I0425 15:39:58.382897 12937 solver.cpp:253]     Train net output #0: loss = 0.00175287 (* 1 = 0.00175287 loss)
I0425 15:39:58.382923 12937 sgd_solver.cpp:106] Iteration 33300, lr = 0.00333146
I0425 15:39:58.529371 12937 solver.cpp:237] Iteration 33400, loss = 0.00209207
I0425 15:39:58.529392 12937 solver.cpp:253]     Train net output #0: loss = 0.00209195 (* 1 = 0.00209195 loss)
I0425 15:39:58.529397 12937 sgd_solver.cpp:106] Iteration 33400, lr = 0.0033257
I0425 15:39:58.677120 12937 solver.cpp:237] Iteration 33500, loss = 0.00162017
I0425 15:39:58.677140 12937 solver.cpp:253]     Train net output #0: loss = 0.00162004 (* 1 = 0.00162004 loss)
I0425 15:39:58.677145 12937 sgd_solver.cpp:106] Iteration 33500, lr = 0.00331996
I0425 15:39:58.824158 12937 solver.cpp:237] Iteration 33600, loss = 0.00840136
I0425 15:39:58.824178 12937 solver.cpp:253]     Train net output #0: loss = 0.00840124 (* 1 = 0.00840124 loss)
I0425 15:39:58.824184 12937 sgd_solver.cpp:106] Iteration 33600, lr = 0.00331425
I0425 15:39:58.971982 12937 solver.cpp:237] Iteration 33700, loss = 0.00640607
I0425 15:39:58.972002 12937 solver.cpp:253]     Train net output #0: loss = 0.00640594 (* 1 = 0.00640594 loss)
I0425 15:39:58.972008 12937 sgd_solver.cpp:106] Iteration 33700, lr = 0.00330856
I0425 15:39:59.119458 12937 solver.cpp:237] Iteration 33800, loss = 0.00337001
I0425 15:39:59.119480 12937 solver.cpp:253]     Train net output #0: loss = 0.00336988 (* 1 = 0.00336988 loss)
I0425 15:39:59.119487 12937 sgd_solver.cpp:106] Iteration 33800, lr = 0.00330289
I0425 15:39:59.266767 12937 solver.cpp:237] Iteration 33900, loss = 0.00789012
I0425 15:39:59.266789 12937 solver.cpp:253]     Train net output #0: loss = 0.00788999 (* 1 = 0.00788999 loss)
I0425 15:39:59.266795 12937 sgd_solver.cpp:106] Iteration 33900, lr = 0.00329725
I0425 15:39:59.417084 12937 solver.cpp:237] Iteration 34000, loss = 0.00408632
I0425 15:39:59.417129 12937 solver.cpp:253]     Train net output #0: loss = 0.00408619 (* 1 = 0.00408619 loss)
I0425 15:39:59.417141 12937 sgd_solver.cpp:106] Iteration 34000, lr = 0.00329163
I0425 15:39:59.569533 12937 solver.cpp:237] Iteration 34100, loss = 0.00500727
I0425 15:39:59.569561 12937 solver.cpp:253]     Train net output #0: loss = 0.00500714 (* 1 = 0.00500714 loss)
I0425 15:39:59.569566 12937 sgd_solver.cpp:106] Iteration 34100, lr = 0.00328603
I0425 15:39:59.720177 12937 solver.cpp:237] Iteration 34200, loss = 0.00188905
I0425 15:39:59.720201 12937 solver.cpp:253]     Train net output #0: loss = 0.00188892 (* 1 = 0.00188892 loss)
I0425 15:39:59.720207 12937 sgd_solver.cpp:106] Iteration 34200, lr = 0.00328045
I0425 15:39:59.870270 12937 solver.cpp:237] Iteration 34300, loss = 0.01014
I0425 15:39:59.870293 12937 solver.cpp:253]     Train net output #0: loss = 0.0101399 (* 1 = 0.0101399 loss)
I0425 15:39:59.870301 12937 sgd_solver.cpp:106] Iteration 34300, lr = 0.00327489
I0425 15:40:00.021236 12937 solver.cpp:237] Iteration 34400, loss = 0.00558216
I0425 15:40:00.021261 12937 solver.cpp:253]     Train net output #0: loss = 0.00558202 (* 1 = 0.00558202 loss)
I0425 15:40:00.021267 12937 sgd_solver.cpp:106] Iteration 34400, lr = 0.00326936
I0425 15:40:00.170693 12937 solver.cpp:237] Iteration 34500, loss = 0.00219095
I0425 15:40:00.170718 12937 solver.cpp:253]     Train net output #0: loss = 0.00219081 (* 1 = 0.00219081 loss)
I0425 15:40:00.170724 12937 sgd_solver.cpp:106] Iteration 34500, lr = 0.00326385
I0425 15:40:00.318613 12937 solver.cpp:237] Iteration 34600, loss = 0.00654048
I0425 15:40:00.318634 12937 solver.cpp:253]     Train net output #0: loss = 0.00654035 (* 1 = 0.00654035 loss)
I0425 15:40:00.318639 12937 sgd_solver.cpp:106] Iteration 34600, lr = 0.00325836
I0425 15:40:00.464610 12937 solver.cpp:237] Iteration 34700, loss = 0.000868278
I0425 15:40:00.464630 12937 solver.cpp:253]     Train net output #0: loss = 0.000868146 (* 1 = 0.000868146 loss)
I0425 15:40:00.464637 12937 sgd_solver.cpp:106] Iteration 34700, lr = 0.00325289
I0425 15:40:00.610934 12937 solver.cpp:237] Iteration 34800, loss = 0.00543539
I0425 15:40:00.610954 12937 solver.cpp:253]     Train net output #0: loss = 0.00543526 (* 1 = 0.00543526 loss)
I0425 15:40:00.610980 12937 sgd_solver.cpp:106] Iteration 34800, lr = 0.00324744
I0425 15:40:00.759205 12937 solver.cpp:237] Iteration 34900, loss = 0.00203889
I0425 15:40:00.759227 12937 solver.cpp:253]     Train net output #0: loss = 0.00203876 (* 1 = 0.00203876 loss)
I0425 15:40:00.759234 12937 sgd_solver.cpp:106] Iteration 34900, lr = 0.00324202
I0425 15:40:00.903792 12937 solver.cpp:459] Snapshotting to binary proto file examples/mnist/test/lenet_iter_35000.caffemodel
I0425 15:40:00.905434 12937 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/test/lenet_iter_35000.solverstate
I0425 15:40:00.905899 12937 solver.cpp:341] Iteration 35000, Testing net (#0)
I0425 15:40:00.999462 12937 solver.cpp:409]     Test net output #0: accuracy = 0.9906
I0425 15:40:00.999493 12937 solver.cpp:409]     Test net output #1: loss = 0.0287246 (* 1 = 0.0287246 loss)
I0425 15:40:01.000149 12937 solver.cpp:237] Iteration 35000, loss = 0.00965371
I0425 15:40:01.000169 12937 solver.cpp:253]     Train net output #0: loss = 0.00965358 (* 1 = 0.00965358 loss)
I0425 15:40:01.000176 12937 sgd_solver.cpp:106] Iteration 35000, lr = 0.00323661
I0425 15:40:01.145817 12937 solver.cpp:237] Iteration 35100, loss = 0.0131968
I0425 15:40:01.145838 12937 solver.cpp:253]     Train net output #0: loss = 0.0131966 (* 1 = 0.0131966 loss)
I0425 15:40:01.145844 12937 sgd_solver.cpp:106] Iteration 35100, lr = 0.00323123
I0425 15:40:01.291863 12937 solver.cpp:237] Iteration 35200, loss = 0.00678563
I0425 15:40:01.291884 12937 solver.cpp:253]     Train net output #0: loss = 0.0067855 (* 1 = 0.0067855 loss)
I0425 15:40:01.291890 12937 sgd_solver.cpp:106] Iteration 35200, lr = 0.00322586
I0425 15:40:01.437876 12937 solver.cpp:237] Iteration 35300, loss = 0.00192785
I0425 15:40:01.437898 12937 solver.cpp:253]     Train net output #0: loss = 0.00192772 (* 1 = 0.00192772 loss)
I0425 15:40:01.437904 12937 sgd_solver.cpp:106] Iteration 35300, lr = 0.00322052
I0425 15:40:01.583969 12937 solver.cpp:237] Iteration 35400, loss = 0.00469564
I0425 15:40:01.583991 12937 solver.cpp:253]     Train net output #0: loss = 0.00469551 (* 1 = 0.00469551 loss)
I0425 15:40:01.583997 12937 sgd_solver.cpp:106] Iteration 35400, lr = 0.0032152
I0425 15:40:01.729506 12937 solver.cpp:237] Iteration 35500, loss = 0.00187657
I0425 15:40:01.729527 12937 solver.cpp:253]     Train net output #0: loss = 0.00187644 (* 1 = 0.00187644 loss)
I0425 15:40:01.729533 12937 sgd_solver.cpp:106] Iteration 35500, lr = 0.0032099
I0425 15:40:01.875686 12937 solver.cpp:237] Iteration 35600, loss = 0.000274632
I0425 15:40:01.875707 12937 solver.cpp:253]     Train net output #0: loss = 0.000274506 (* 1 = 0.000274506 loss)
I0425 15:40:01.875712 12937 sgd_solver.cpp:106] Iteration 35600, lr = 0.00320462
I0425 15:40:02.021234 12937 solver.cpp:237] Iteration 35700, loss = 0.000519656
I0425 15:40:02.021260 12937 solver.cpp:253]     Train net output #0: loss = 0.000519529 (* 1 = 0.000519529 loss)
I0425 15:40:02.021266 12937 sgd_solver.cpp:106] Iteration 35700, lr = 0.00319936
I0425 15:40:02.168329 12937 solver.cpp:237] Iteration 35800, loss = 0.00698142
I0425 15:40:02.168349 12937 solver.cpp:253]     Train net output #0: loss = 0.00698129 (* 1 = 0.00698129 loss)
I0425 15:40:02.168354 12937 sgd_solver.cpp:106] Iteration 35800, lr = 0.00319412
I0425 15:40:02.314517 12937 solver.cpp:237] Iteration 35900, loss = 0.00394069
I0425 15:40:02.314538 12937 solver.cpp:253]     Train net output #0: loss = 0.00394056 (* 1 = 0.00394056 loss)
I0425 15:40:02.314544 12937 sgd_solver.cpp:106] Iteration 35900, lr = 0.0031889
I0425 15:40:02.460708 12937 solver.cpp:237] Iteration 36000, loss = 0.00294401
I0425 15:40:02.460729 12937 solver.cpp:253]     Train net output #0: loss = 0.00294388 (* 1 = 0.00294388 loss)
I0425 15:40:02.460734 12937 sgd_solver.cpp:106] Iteration 36000, lr = 0.0031837
I0425 15:40:02.606259 12937 solver.cpp:237] Iteration 36100, loss = 0.000593585
I0425 15:40:02.606281 12937 solver.cpp:253]     Train net output #0: loss = 0.000593457 (* 1 = 0.000593457 loss)
I0425 15:40:02.606286 12937 sgd_solver.cpp:106] Iteration 36100, lr = 0.00317852
I0425 15:40:02.752563 12937 solver.cpp:237] Iteration 36200, loss = 0.00293364
I0425 15:40:02.752583 12937 solver.cpp:253]     Train net output #0: loss = 0.00293352 (* 1 = 0.00293352 loss)
I0425 15:40:02.752589 12937 sgd_solver.cpp:106] Iteration 36200, lr = 0.00317335
I0425 15:40:02.897794 12937 solver.cpp:237] Iteration 36300, loss = 0.00240469
I0425 15:40:02.897815 12937 solver.cpp:253]     Train net output #0: loss = 0.00240457 (* 1 = 0.00240457 loss)
I0425 15:40:02.897820 12937 sgd_solver.cpp:106] Iteration 36300, lr = 0.00316821
I0425 15:40:03.043269 12937 solver.cpp:237] Iteration 36400, loss = 0.00516108
I0425 15:40:03.043289 12937 solver.cpp:253]     Train net output #0: loss = 0.00516096 (* 1 = 0.00516096 loss)
I0425 15:40:03.043294 12937 sgd_solver.cpp:106] Iteration 36400, lr = 0.00316309
I0425 15:40:03.189504 12937 solver.cpp:237] Iteration 36500, loss = 0.00317364
I0425 15:40:03.189525 12937 solver.cpp:253]     Train net output #0: loss = 0.00317353 (* 1 = 0.00317353 loss)
I0425 15:40:03.189532 12937 sgd_solver.cpp:106] Iteration 36500, lr = 0.00315799
I0425 15:40:03.335161 12937 solver.cpp:237] Iteration 36600, loss = 0.0121119
I0425 15:40:03.335182 12937 solver.cpp:253]     Train net output #0: loss = 0.0121118 (* 1 = 0.0121118 loss)
I0425 15:40:03.335187 12937 sgd_solver.cpp:106] Iteration 36600, lr = 0.0031529
I0425 15:40:03.480788 12937 solver.cpp:237] Iteration 36700, loss = 0.00400328
I0425 15:40:03.480808 12937 solver.cpp:253]     Train net output #0: loss = 0.00400316 (* 1 = 0.00400316 loss)
I0425 15:40:03.480813 12937 sgd_solver.cpp:106] Iteration 36700, lr = 0.00314784
I0425 15:40:03.627197 12937 solver.cpp:237] Iteration 36800, loss = 0.00229287
I0425 15:40:03.627219 12937 solver.cpp:253]     Train net output #0: loss = 0.00229275 (* 1 = 0.00229275 loss)
I0425 15:40:03.627224 12937 sgd_solver.cpp:106] Iteration 36800, lr = 0.00314279
I0425 15:40:03.773202 12937 solver.cpp:237] Iteration 36900, loss = 0.00214086
I0425 15:40:03.773226 12937 solver.cpp:253]     Train net output #0: loss = 0.00214074 (* 1 = 0.00214074 loss)
I0425 15:40:03.773231 12937 sgd_solver.cpp:106] Iteration 36900, lr = 0.00313776
I0425 15:40:03.919953 12937 solver.cpp:237] Iteration 37000, loss = 0.00160782
I0425 15:40:03.919975 12937 solver.cpp:253]     Train net output #0: loss = 0.00160769 (* 1 = 0.00160769 loss)
I0425 15:40:03.919981 12937 sgd_solver.cpp:106] Iteration 37000, lr = 0.00313276
I0425 15:40:04.066359 12937 solver.cpp:237] Iteration 37100, loss = 0.00567876
I0425 15:40:04.066381 12937 solver.cpp:253]     Train net output #0: loss = 0.00567864 (* 1 = 0.00567864 loss)
I0425 15:40:04.066387 12937 sgd_solver.cpp:106] Iteration 37100, lr = 0.00312777
I0425 15:40:04.212797 12937 solver.cpp:237] Iteration 37200, loss = 0.00272402
I0425 15:40:04.212818 12937 solver.cpp:253]     Train net output #0: loss = 0.0027239 (* 1 = 0.0027239 loss)
I0425 15:40:04.212824 12937 sgd_solver.cpp:106] Iteration 37200, lr = 0.0031228
I0425 15:40:04.358778 12937 solver.cpp:237] Iteration 37300, loss = 0.00896025
I0425 15:40:04.358800 12937 solver.cpp:253]     Train net output #0: loss = 0.00896013 (* 1 = 0.00896013 loss)
I0425 15:40:04.358806 12937 sgd_solver.cpp:106] Iteration 37300, lr = 0.00311784
I0425 15:40:04.504647 12937 solver.cpp:237] Iteration 37400, loss = 0.00415798
I0425 15:40:04.504667 12937 solver.cpp:253]     Train net output #0: loss = 0.00415786 (* 1 = 0.00415786 loss)
I0425 15:40:04.504673 12937 sgd_solver.cpp:106] Iteration 37400, lr = 0.00311291
I0425 15:40:04.651396 12937 solver.cpp:237] Iteration 37500, loss = 0.0020336
I0425 15:40:04.651440 12937 solver.cpp:253]     Train net output #0: loss = 0.00203348 (* 1 = 0.00203348 loss)
I0425 15:40:04.651454 12937 sgd_solver.cpp:106] Iteration 37500, lr = 0.00310799
I0425 15:40:04.805785 12937 solver.cpp:237] Iteration 37600, loss = 0.00448151
I0425 15:40:04.805815 12937 solver.cpp:253]     Train net output #0: loss = 0.00448139 (* 1 = 0.00448139 loss)
I0425 15:40:04.805824 12937 sgd_solver.cpp:106] Iteration 37600, lr = 0.00310309
I0425 15:40:04.955551 12937 solver.cpp:237] Iteration 37700, loss = 0.00866602
I0425 15:40:04.955579 12937 solver.cpp:253]     Train net output #0: loss = 0.0086659 (* 1 = 0.0086659 loss)
I0425 15:40:04.955585 12937 sgd_solver.cpp:106] Iteration 37700, lr = 0.00309821
I0425 15:40:05.104728 12937 solver.cpp:237] Iteration 37800, loss = 0.00260022
I0425 15:40:05.104761 12937 solver.cpp:253]     Train net output #0: loss = 0.00260009 (* 1 = 0.00260009 loss)
I0425 15:40:05.104774 12937 sgd_solver.cpp:106] Iteration 37800, lr = 0.00309335
I0425 15:40:05.254726 12937 solver.cpp:237] Iteration 37900, loss = 0.00305398
I0425 15:40:05.254750 12937 solver.cpp:253]     Train net output #0: loss = 0.00305385 (* 1 = 0.00305385 loss)
I0425 15:40:05.254756 12937 sgd_solver.cpp:106] Iteration 37900, lr = 0.00308851
I0425 15:40:05.401593 12937 solver.cpp:237] Iteration 38000, loss = 0.00463639
I0425 15:40:05.401619 12937 solver.cpp:253]     Train net output #0: loss = 0.00463627 (* 1 = 0.00463627 loss)
I0425 15:40:05.401633 12937 sgd_solver.cpp:106] Iteration 38000, lr = 0.00308368
I0425 15:40:05.547351 12937 solver.cpp:237] Iteration 38100, loss = 0.00467329
I0425 15:40:05.547370 12937 solver.cpp:253]     Train net output #0: loss = 0.00467316 (* 1 = 0.00467316 loss)
I0425 15:40:05.547376 12937 sgd_solver.cpp:106] Iteration 38100, lr = 0.00307887
I0425 15:40:05.693840 12937 solver.cpp:237] Iteration 38200, loss = 0.00236809
I0425 15:40:05.693859 12937 solver.cpp:253]     Train net output #0: loss = 0.00236796 (* 1 = 0.00236796 loss)
I0425 15:40:05.693864 12937 sgd_solver.cpp:106] Iteration 38200, lr = 0.00307408
I0425 15:40:05.840881 12937 solver.cpp:237] Iteration 38300, loss = 0.013699
I0425 15:40:05.840906 12937 solver.cpp:253]     Train net output #0: loss = 0.0136989 (* 1 = 0.0136989 loss)
I0425 15:40:05.840914 12937 sgd_solver.cpp:106] Iteration 38300, lr = 0.0030693
I0425 15:40:05.986805 12937 solver.cpp:237] Iteration 38400, loss = 0.00483724
I0425 15:40:05.986824 12937 solver.cpp:253]     Train net output #0: loss = 0.00483711 (* 1 = 0.00483711 loss)
I0425 15:40:05.986830 12937 sgd_solver.cpp:106] Iteration 38400, lr = 0.00306454
I0425 15:40:06.132194 12937 solver.cpp:237] Iteration 38500, loss = 0.00463946
I0425 15:40:06.132213 12937 solver.cpp:253]     Train net output #0: loss = 0.00463933 (* 1 = 0.00463933 loss)
I0425 15:40:06.132218 12937 sgd_solver.cpp:106] Iteration 38500, lr = 0.0030598
I0425 15:40:06.277422 12937 solver.cpp:237] Iteration 38600, loss = 0.000725359
I0425 15:40:06.277443 12937 solver.cpp:253]     Train net output #0: loss = 0.00072523 (* 1 = 0.00072523 loss)
I0425 15:40:06.277448 12937 sgd_solver.cpp:106] Iteration 38600, lr = 0.00305508
I0425 15:40:06.423912 12937 solver.cpp:237] Iteration 38700, loss = 0.00128032
I0425 15:40:06.423933 12937 solver.cpp:253]     Train net output #0: loss = 0.00128019 (* 1 = 0.00128019 loss)
I0425 15:40:06.423939 12937 sgd_solver.cpp:106] Iteration 38700, lr = 0.00305038
I0425 15:40:06.569757 12937 solver.cpp:237] Iteration 38800, loss = 0.00131346
I0425 15:40:06.569777 12937 solver.cpp:253]     Train net output #0: loss = 0.00131333 (* 1 = 0.00131333 loss)
I0425 15:40:06.569782 12937 sgd_solver.cpp:106] Iteration 38800, lr = 0.00304569
I0425 15:40:06.715306 12937 solver.cpp:237] Iteration 38900, loss = 0.000869523
I0425 15:40:06.715325 12937 solver.cpp:253]     Train net output #0: loss = 0.000869392 (* 1 = 0.000869392 loss)
I0425 15:40:06.715330 12937 sgd_solver.cpp:106] Iteration 38900, lr = 0.00304101
I0425 15:40:06.860728 12937 solver.cpp:237] Iteration 39000, loss = 0.00941893
I0425 15:40:06.860751 12937 solver.cpp:253]     Train net output #0: loss = 0.0094188 (* 1 = 0.0094188 loss)
I0425 15:40:06.860756 12937 sgd_solver.cpp:106] Iteration 39000, lr = 0.00303636
I0425 15:40:07.006968 12937 solver.cpp:237] Iteration 39100, loss = 0.00675557
I0425 15:40:07.006989 12937 solver.cpp:253]     Train net output #0: loss = 0.00675543 (* 1 = 0.00675543 loss)
I0425 15:40:07.006995 12937 sgd_solver.cpp:106] Iteration 39100, lr = 0.00303172
I0425 15:40:07.153102 12937 solver.cpp:237] Iteration 39200, loss = 0.004262
I0425 15:40:07.153144 12937 solver.cpp:253]     Train net output #0: loss = 0.00426187 (* 1 = 0.00426187 loss)
I0425 15:40:07.153151 12937 sgd_solver.cpp:106] Iteration 39200, lr = 0.0030271
I0425 15:40:07.301458 12937 solver.cpp:237] Iteration 39300, loss = 0.00357789
I0425 15:40:07.301498 12937 solver.cpp:253]     Train net output #0: loss = 0.00357776 (* 1 = 0.00357776 loss)
I0425 15:40:07.301511 12937 sgd_solver.cpp:106] Iteration 39300, lr = 0.00302249
I0425 15:40:07.451736 12937 solver.cpp:237] Iteration 39400, loss = 0.0064068
I0425 15:40:07.451766 12937 solver.cpp:253]     Train net output #0: loss = 0.00640666 (* 1 = 0.00640666 loss)
I0425 15:40:07.451773 12937 sgd_solver.cpp:106] Iteration 39400, lr = 0.0030179
I0425 15:40:07.599372 12937 solver.cpp:237] Iteration 39500, loss = 0.00221194
I0425 15:40:07.599397 12937 solver.cpp:253]     Train net output #0: loss = 0.0022118 (* 1 = 0.0022118 loss)
I0425 15:40:07.599403 12937 sgd_solver.cpp:106] Iteration 39500, lr = 0.00301333
I0425 15:40:07.746199 12937 solver.cpp:237] Iteration 39600, loss = 0.00263006
I0425 15:40:07.746224 12937 solver.cpp:253]     Train net output #0: loss = 0.00262993 (* 1 = 0.00262993 loss)
I0425 15:40:07.746230 12937 sgd_solver.cpp:106] Iteration 39600, lr = 0.00300877
I0425 15:40:07.893110 12937 solver.cpp:237] Iteration 39700, loss = 0.00126849
I0425 15:40:07.893136 12937 solver.cpp:253]     Train net output #0: loss = 0.00126836 (* 1 = 0.00126836 loss)
I0425 15:40:07.893141 12937 sgd_solver.cpp:106] Iteration 39700, lr = 0.00300423
I0425 15:40:08.039355 12937 solver.cpp:237] Iteration 39800, loss = 0.00837465
I0425 15:40:08.039378 12937 solver.cpp:253]     Train net output #0: loss = 0.00837452 (* 1 = 0.00837452 loss)
I0425 15:40:08.039383 12937 sgd_solver.cpp:106] Iteration 39800, lr = 0.0029997
I0425 15:40:08.185390 12937 solver.cpp:237] Iteration 39900, loss = 0.00311224
I0425 15:40:08.185412 12937 solver.cpp:253]     Train net output #0: loss = 0.00311211 (* 1 = 0.00311211 loss)
I0425 15:40:08.185418 12937 sgd_solver.cpp:106] Iteration 39900, lr = 0.00299519
I0425 15:40:08.330163 12937 solver.cpp:459] Snapshotting to binary proto file examples/mnist/test/lenet_iter_40000.caffemodel
I0425 15:40:08.331753 12937 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/test/lenet_iter_40000.solverstate
I0425 15:40:08.332231 12937 solver.cpp:341] Iteration 40000, Testing net (#0)
I0425 15:40:08.401368 12937 solver.cpp:409]     Test net output #0: accuracy = 0.9912
I0425 15:40:08.401394 12937 solver.cpp:409]     Test net output #1: loss = 0.0277705 (* 1 = 0.0277705 loss)
I0425 15:40:08.402045 12937 solver.cpp:237] Iteration 40000, loss = 0.00269034
I0425 15:40:08.402065 12937 solver.cpp:253]     Train net output #0: loss = 0.00269021 (* 1 = 0.00269021 loss)
I0425 15:40:08.402072 12937 sgd_solver.cpp:106] Iteration 40000, lr = 0.0029907
I0425 15:40:08.543325 12937 solver.cpp:237] Iteration 40100, loss = 0.00920033
I0425 15:40:08.543346 12937 solver.cpp:253]     Train net output #0: loss = 0.0092002 (* 1 = 0.0092002 loss)
I0425 15:40:08.543352 12937 sgd_solver.cpp:106] Iteration 40100, lr = 0.00298622
I0425 15:40:08.684911 12937 solver.cpp:237] Iteration 40200, loss = 0.00757714
I0425 15:40:08.684932 12937 solver.cpp:253]     Train net output #0: loss = 0.00757701 (* 1 = 0.00757701 loss)
I0425 15:40:08.684937 12937 sgd_solver.cpp:106] Iteration 40200, lr = 0.00298176
I0425 15:40:08.826936 12937 solver.cpp:237] Iteration 40300, loss = 0.00013777
I0425 15:40:08.826956 12937 solver.cpp:253]     Train net output #0: loss = 0.000137635 (* 1 = 0.000137635 loss)
I0425 15:40:08.826962 12937 sgd_solver.cpp:106] Iteration 40300, lr = 0.00297731
I0425 15:40:08.973990 12937 solver.cpp:237] Iteration 40400, loss = 0.00615555
I0425 15:40:08.974031 12937 solver.cpp:253]     Train net output #0: loss = 0.00615541 (* 1 = 0.00615541 loss)
I0425 15:40:08.974042 12937 sgd_solver.cpp:106] Iteration 40400, lr = 0.00297288
I0425 15:40:09.119607 12937 solver.cpp:237] Iteration 40500, loss = 0.00497224
I0425 15:40:09.119746 12937 solver.cpp:253]     Train net output #0: loss = 0.00497211 (* 1 = 0.00497211 loss)
I0425 15:40:09.119756 12937 sgd_solver.cpp:106] Iteration 40500, lr = 0.00296846
I0425 15:40:09.268517 12937 solver.cpp:237] Iteration 40600, loss = 0.00274203
I0425 15:40:09.268546 12937 solver.cpp:253]     Train net output #0: loss = 0.00274189 (* 1 = 0.00274189 loss)
I0425 15:40:09.268558 12937 sgd_solver.cpp:106] Iteration 40600, lr = 0.00296406
I0425 15:40:09.410917 12937 solver.cpp:237] Iteration 40700, loss = 0.00218212
I0425 15:40:09.410939 12937 solver.cpp:253]     Train net output #0: loss = 0.00218199 (* 1 = 0.00218199 loss)
I0425 15:40:09.410949 12937 sgd_solver.cpp:106] Iteration 40700, lr = 0.00295968
I0425 15:40:09.551957 12937 solver.cpp:237] Iteration 40800, loss = 0.00177702
I0425 15:40:09.551980 12937 solver.cpp:253]     Train net output #0: loss = 0.00177688 (* 1 = 0.00177688 loss)
I0425 15:40:09.551990 12937 sgd_solver.cpp:106] Iteration 40800, lr = 0.0029553
I0425 15:40:09.693464 12937 solver.cpp:237] Iteration 40900, loss = 0.00197204
I0425 15:40:09.693487 12937 solver.cpp:253]     Train net output #0: loss = 0.0019719 (* 1 = 0.0019719 loss)
I0425 15:40:09.693497 12937 sgd_solver.cpp:106] Iteration 40900, lr = 0.00295095
I0425 15:40:09.835067 12937 solver.cpp:237] Iteration 41000, loss = 0.00157416
I0425 15:40:09.835095 12937 solver.cpp:253]     Train net output #0: loss = 0.00157402 (* 1 = 0.00157402 loss)
I0425 15:40:09.835104 12937 sgd_solver.cpp:106] Iteration 41000, lr = 0.00294661
I0425 15:40:09.976219 12937 solver.cpp:237] Iteration 41100, loss = 0.00813231
I0425 15:40:09.976240 12937 solver.cpp:253]     Train net output #0: loss = 0.00813217 (* 1 = 0.00813217 loss)
I0425 15:40:09.976249 12937 sgd_solver.cpp:106] Iteration 41100, lr = 0.00294228
I0425 15:40:10.117305 12937 solver.cpp:237] Iteration 41200, loss = 0.00594237
I0425 15:40:10.117326 12937 solver.cpp:253]     Train net output #0: loss = 0.00594223 (* 1 = 0.00594223 loss)
I0425 15:40:10.117336 12937 sgd_solver.cpp:106] Iteration 41200, lr = 0.00293797
I0425 15:40:10.259196 12937 solver.cpp:237] Iteration 41300, loss = 0.00314736
I0425 15:40:10.259219 12937 solver.cpp:253]     Train net output #0: loss = 0.00314722 (* 1 = 0.00314722 loss)
I0425 15:40:10.259228 12937 sgd_solver.cpp:106] Iteration 41300, lr = 0.00293367
I0425 15:40:10.401329 12937 solver.cpp:237] Iteration 41400, loss = 0.00741194
I0425 15:40:10.401352 12937 solver.cpp:253]     Train net output #0: loss = 0.00741181 (* 1 = 0.00741181 loss)
I0425 15:40:10.401361 12937 sgd_solver.cpp:106] Iteration 41400, lr = 0.00292939
I0425 15:40:10.542834 12937 solver.cpp:237] Iteration 41500, loss = 0.00408568
I0425 15:40:10.542857 12937 solver.cpp:253]     Train net output #0: loss = 0.00408554 (* 1 = 0.00408554 loss)
I0425 15:40:10.542866 12937 sgd_solver.cpp:106] Iteration 41500, lr = 0.00292513
I0425 15:40:10.684195 12937 solver.cpp:237] Iteration 41600, loss = 0.00441357
I0425 15:40:10.684216 12937 solver.cpp:253]     Train net output #0: loss = 0.00441343 (* 1 = 0.00441343 loss)
I0425 15:40:10.684226 12937 sgd_solver.cpp:106] Iteration 41600, lr = 0.00292087
I0425 15:40:10.825608 12937 solver.cpp:237] Iteration 41700, loss = 0.00189165
I0425 15:40:10.825631 12937 solver.cpp:253]     Train net output #0: loss = 0.00189152 (* 1 = 0.00189152 loss)
I0425 15:40:10.825640 12937 sgd_solver.cpp:106] Iteration 41700, lr = 0.00291664
I0425 15:40:10.966370 12937 solver.cpp:237] Iteration 41800, loss = 0.00958427
I0425 15:40:10.966395 12937 solver.cpp:253]     Train net output #0: loss = 0.00958414 (* 1 = 0.00958414 loss)
I0425 15:40:10.966404 12937 sgd_solver.cpp:106] Iteration 41800, lr = 0.00291241
I0425 15:40:11.107700 12937 solver.cpp:237] Iteration 41900, loss = 0.00586484
I0425 15:40:11.107723 12937 solver.cpp:253]     Train net output #0: loss = 0.00586471 (* 1 = 0.00586471 loss)
I0425 15:40:11.107733 12937 sgd_solver.cpp:106] Iteration 41900, lr = 0.0029082
I0425 15:40:11.249495 12937 solver.cpp:237] Iteration 42000, loss = 0.00236634
I0425 15:40:11.249516 12937 solver.cpp:253]     Train net output #0: loss = 0.00236621 (* 1 = 0.00236621 loss)
I0425 15:40:11.249548 12937 sgd_solver.cpp:106] Iteration 42000, lr = 0.00290401
I0425 15:40:11.390985 12937 solver.cpp:237] Iteration 42100, loss = 0.00631688
I0425 15:40:11.391006 12937 solver.cpp:253]     Train net output #0: loss = 0.00631674 (* 1 = 0.00631674 loss)
I0425 15:40:11.391016 12937 sgd_solver.cpp:106] Iteration 42100, lr = 0.00289982
I0425 15:40:11.532706 12937 solver.cpp:237] Iteration 42200, loss = 0.000929781
I0425 15:40:11.532732 12937 solver.cpp:253]     Train net output #0: loss = 0.000929644 (* 1 = 0.000929644 loss)
I0425 15:40:11.532742 12937 sgd_solver.cpp:106] Iteration 42200, lr = 0.00289566
I0425 15:40:11.673882 12937 solver.cpp:237] Iteration 42300, loss = 0.00547444
I0425 15:40:11.673904 12937 solver.cpp:253]     Train net output #0: loss = 0.0054743 (* 1 = 0.0054743 loss)
I0425 15:40:11.673913 12937 sgd_solver.cpp:106] Iteration 42300, lr = 0.0028915
I0425 15:40:11.815012 12937 solver.cpp:237] Iteration 42400, loss = 0.00182982
I0425 15:40:11.815037 12937 solver.cpp:253]     Train net output #0: loss = 0.00182969 (* 1 = 0.00182969 loss)
I0425 15:40:11.815047 12937 sgd_solver.cpp:106] Iteration 42400, lr = 0.00288736
I0425 15:40:11.957069 12937 solver.cpp:237] Iteration 42500, loss = 0.00918746
I0425 15:40:11.957093 12937 solver.cpp:253]     Train net output #0: loss = 0.00918732 (* 1 = 0.00918732 loss)
I0425 15:40:11.957101 12937 sgd_solver.cpp:106] Iteration 42500, lr = 0.00288324
I0425 15:40:12.098794 12937 solver.cpp:237] Iteration 42600, loss = 0.0126286
I0425 15:40:12.098816 12937 solver.cpp:253]     Train net output #0: loss = 0.0126285 (* 1 = 0.0126285 loss)
I0425 15:40:12.098825 12937 sgd_solver.cpp:106] Iteration 42600, lr = 0.00287913
I0425 15:40:12.240151 12937 solver.cpp:237] Iteration 42700, loss = 0.00655899
I0425 15:40:12.240175 12937 solver.cpp:253]     Train net output #0: loss = 0.00655886 (* 1 = 0.00655886 loss)
I0425 15:40:12.240183 12937 sgd_solver.cpp:106] Iteration 42700, lr = 0.00287503
I0425 15:40:12.381079 12937 solver.cpp:237] Iteration 42800, loss = 0.00192028
I0425 15:40:12.381103 12937 solver.cpp:253]     Train net output #0: loss = 0.00192014 (* 1 = 0.00192014 loss)
I0425 15:40:12.381113 12937 sgd_solver.cpp:106] Iteration 42800, lr = 0.00287094
I0425 15:40:12.522472 12937 solver.cpp:237] Iteration 42900, loss = 0.00467061
I0425 15:40:12.522495 12937 solver.cpp:253]     Train net output #0: loss = 0.00467048 (* 1 = 0.00467048 loss)
I0425 15:40:12.522503 12937 sgd_solver.cpp:106] Iteration 42900, lr = 0.00286687
I0425 15:40:12.663991 12937 solver.cpp:237] Iteration 43000, loss = 0.00193531
I0425 15:40:12.664013 12937 solver.cpp:253]     Train net output #0: loss = 0.00193517 (* 1 = 0.00193517 loss)
I0425 15:40:12.664022 12937 sgd_solver.cpp:106] Iteration 43000, lr = 0.00286281
I0425 15:40:12.805416 12937 solver.cpp:237] Iteration 43100, loss = 0.000292503
I0425 15:40:12.805443 12937 solver.cpp:253]     Train net output #0: loss = 0.000292372 (* 1 = 0.000292372 loss)
I0425 15:40:12.805450 12937 sgd_solver.cpp:106] Iteration 43100, lr = 0.00285877
I0425 15:40:12.946888 12937 solver.cpp:237] Iteration 43200, loss = 0.000543997
I0425 15:40:12.946913 12937 solver.cpp:253]     Train net output #0: loss = 0.000543867 (* 1 = 0.000543867 loss)
I0425 15:40:12.946929 12937 sgd_solver.cpp:106] Iteration 43200, lr = 0.00285474
I0425 15:40:13.088363 12937 solver.cpp:237] Iteration 43300, loss = 0.00676069
I0425 15:40:13.088385 12937 solver.cpp:253]     Train net output #0: loss = 0.00676056 (* 1 = 0.00676056 loss)
I0425 15:40:13.088394 12937 sgd_solver.cpp:106] Iteration 43300, lr = 0.00285072
I0425 15:40:13.229521 12937 solver.cpp:237] Iteration 43400, loss = 0.0037445
I0425 15:40:13.229544 12937 solver.cpp:253]     Train net output #0: loss = 0.00374437 (* 1 = 0.00374437 loss)
I0425 15:40:13.229557 12937 sgd_solver.cpp:106] Iteration 43400, lr = 0.00284672
I0425 15:40:13.371450 12937 solver.cpp:237] Iteration 43500, loss = 0.00292092
I0425 15:40:13.371472 12937 solver.cpp:253]     Train net output #0: loss = 0.00292079 (* 1 = 0.00292079 loss)
I0425 15:40:13.371508 12937 sgd_solver.cpp:106] Iteration 43500, lr = 0.00284272
I0425 15:40:13.512732 12937 solver.cpp:237] Iteration 43600, loss = 0.000586267
I0425 15:40:13.512753 12937 solver.cpp:253]     Train net output #0: loss = 0.000586134 (* 1 = 0.000586134 loss)
I0425 15:40:13.512764 12937 sgd_solver.cpp:106] Iteration 43600, lr = 0.00283875
I0425 15:40:13.654049 12937 solver.cpp:237] Iteration 43700, loss = 0.00277728
I0425 15:40:13.654070 12937 solver.cpp:253]     Train net output #0: loss = 0.00277715 (* 1 = 0.00277715 loss)
I0425 15:40:13.654079 12937 sgd_solver.cpp:106] Iteration 43700, lr = 0.00283478
I0425 15:40:13.795150 12937 solver.cpp:237] Iteration 43800, loss = 0.00230331
I0425 15:40:13.795172 12937 solver.cpp:253]     Train net output #0: loss = 0.00230318 (* 1 = 0.00230318 loss)
I0425 15:40:13.795186 12937 sgd_solver.cpp:106] Iteration 43800, lr = 0.00283083
I0425 15:40:13.937559 12937 solver.cpp:237] Iteration 43900, loss = 0.00513628
I0425 15:40:13.937583 12937 solver.cpp:253]     Train net output #0: loss = 0.00513615 (* 1 = 0.00513615 loss)
I0425 15:40:13.937592 12937 sgd_solver.cpp:106] Iteration 43900, lr = 0.00282689
I0425 15:40:14.078699 12937 solver.cpp:237] Iteration 44000, loss = 0.00314592
I0425 15:40:14.078722 12937 solver.cpp:253]     Train net output #0: loss = 0.00314579 (* 1 = 0.00314579 loss)
I0425 15:40:14.078732 12937 sgd_solver.cpp:106] Iteration 44000, lr = 0.00282296
I0425 15:40:14.219741 12937 solver.cpp:237] Iteration 44100, loss = 0.0108397
I0425 15:40:14.219763 12937 solver.cpp:253]     Train net output #0: loss = 0.0108396 (* 1 = 0.0108396 loss)
I0425 15:40:14.219772 12937 sgd_solver.cpp:106] Iteration 44100, lr = 0.00281905
I0425 15:40:14.361717 12937 solver.cpp:237] Iteration 44200, loss = 0.00389334
I0425 15:40:14.361738 12937 solver.cpp:253]     Train net output #0: loss = 0.00389321 (* 1 = 0.00389321 loss)
I0425 15:40:14.361747 12937 sgd_solver.cpp:106] Iteration 44200, lr = 0.00281514
I0425 15:40:14.503533 12937 solver.cpp:237] Iteration 44300, loss = 0.00192224
I0425 15:40:14.503554 12937 solver.cpp:253]     Train net output #0: loss = 0.00192211 (* 1 = 0.00192211 loss)
I0425 15:40:14.503563 12937 sgd_solver.cpp:106] Iteration 44300, lr = 0.00281125
I0425 15:40:14.644665 12937 solver.cpp:237] Iteration 44400, loss = 0.0020894
I0425 15:40:14.644687 12937 solver.cpp:253]     Train net output #0: loss = 0.00208928 (* 1 = 0.00208928 loss)
I0425 15:40:14.644697 12937 sgd_solver.cpp:106] Iteration 44400, lr = 0.00280738
I0425 15:40:14.786274 12937 solver.cpp:237] Iteration 44500, loss = 0.00151833
I0425 15:40:14.786296 12937 solver.cpp:253]     Train net output #0: loss = 0.0015182 (* 1 = 0.0015182 loss)
I0425 15:40:14.786305 12937 sgd_solver.cpp:106] Iteration 44500, lr = 0.00280351
I0425 15:40:14.927261 12937 solver.cpp:237] Iteration 44600, loss = 0.0053388
I0425 15:40:14.927284 12937 solver.cpp:253]     Train net output #0: loss = 0.00533867 (* 1 = 0.00533867 loss)
I0425 15:40:14.927294 12937 sgd_solver.cpp:106] Iteration 44600, lr = 0.00279966
I0425 15:40:15.069309 12937 solver.cpp:237] Iteration 44700, loss = 0.0027298
I0425 15:40:15.069331 12937 solver.cpp:253]     Train net output #0: loss = 0.00272967 (* 1 = 0.00272967 loss)
I0425 15:40:15.069340 12937 sgd_solver.cpp:106] Iteration 44700, lr = 0.00279582
I0425 15:40:15.210175 12937 solver.cpp:237] Iteration 44800, loss = 0.0080048
I0425 15:40:15.210197 12937 solver.cpp:253]     Train net output #0: loss = 0.00800466 (* 1 = 0.00800466 loss)
I0425 15:40:15.210206 12937 sgd_solver.cpp:106] Iteration 44800, lr = 0.00279199
I0425 15:40:15.351471 12937 solver.cpp:237] Iteration 44900, loss = 0.00399091
I0425 15:40:15.351495 12937 solver.cpp:253]     Train net output #0: loss = 0.00399078 (* 1 = 0.00399078 loss)
I0425 15:40:15.351502 12937 sgd_solver.cpp:106] Iteration 44900, lr = 0.00278818
I0425 15:40:15.494899 12937 solver.cpp:459] Snapshotting to binary proto file examples/mnist/test/lenet_iter_45000.caffemodel
I0425 15:40:15.497215 12937 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/test/lenet_iter_45000.solverstate
I0425 15:40:15.498339 12937 solver.cpp:341] Iteration 45000, Testing net (#0)
I0425 15:40:15.578189 12937 solver.cpp:409]     Test net output #0: accuracy = 0.99
I0425 15:40:15.578227 12937 solver.cpp:409]     Test net output #1: loss = 0.0298337 (* 1 = 0.0298337 loss)
I0425 15:40:15.578994 12937 solver.cpp:237] Iteration 45000, loss = 0.00193811
I0425 15:40:15.579017 12937 solver.cpp:253]     Train net output #0: loss = 0.00193798 (* 1 = 0.00193798 loss)
I0425 15:40:15.579028 12937 sgd_solver.cpp:106] Iteration 45000, lr = 0.00278438
I0425 15:40:15.722600 12937 solver.cpp:237] Iteration 45100, loss = 0.00426115
I0425 15:40:15.722627 12937 solver.cpp:253]     Train net output #0: loss = 0.00426102 (* 1 = 0.00426102 loss)
I0425 15:40:15.722633 12937 sgd_solver.cpp:106] Iteration 45100, lr = 0.00278059
I0425 15:40:15.865084 12937 solver.cpp:237] Iteration 45200, loss = 0.00825938
I0425 15:40:15.865111 12937 solver.cpp:253]     Train net output #0: loss = 0.00825925 (* 1 = 0.00825925 loss)
I0425 15:40:15.865118 12937 sgd_solver.cpp:106] Iteration 45200, lr = 0.00277681
I0425 15:40:16.006968 12937 solver.cpp:237] Iteration 45300, loss = 0.00261944
I0425 15:40:16.006992 12937 solver.cpp:253]     Train net output #0: loss = 0.00261931 (* 1 = 0.00261931 loss)
I0425 15:40:16.006999 12937 sgd_solver.cpp:106] Iteration 45300, lr = 0.00277304
I0425 15:40:16.149325 12937 solver.cpp:237] Iteration 45400, loss = 0.00295673
I0425 15:40:16.149358 12937 solver.cpp:253]     Train net output #0: loss = 0.0029566 (* 1 = 0.0029566 loss)
I0425 15:40:16.149374 12937 sgd_solver.cpp:106] Iteration 45400, lr = 0.00276929
I0425 15:40:16.291445 12937 solver.cpp:237] Iteration 45500, loss = 0.00436725
I0425 15:40:16.291468 12937 solver.cpp:253]     Train net output #0: loss = 0.00436712 (* 1 = 0.00436712 loss)
I0425 15:40:16.291474 12937 sgd_solver.cpp:106] Iteration 45500, lr = 0.00276554
I0425 15:40:16.433691 12937 solver.cpp:237] Iteration 45600, loss = 0.00467796
I0425 15:40:16.433714 12937 solver.cpp:253]     Train net output #0: loss = 0.00467783 (* 1 = 0.00467783 loss)
I0425 15:40:16.433720 12937 sgd_solver.cpp:106] Iteration 45600, lr = 0.00276181
I0425 15:40:16.575981 12937 solver.cpp:237] Iteration 45700, loss = 0.00248867
I0425 15:40:16.576004 12937 solver.cpp:253]     Train net output #0: loss = 0.00248854 (* 1 = 0.00248854 loss)
I0425 15:40:16.576009 12937 sgd_solver.cpp:106] Iteration 45700, lr = 0.00275809
I0425 15:40:16.716886 12937 solver.cpp:237] Iteration 45800, loss = 0.012615
I0425 15:40:16.716917 12937 solver.cpp:253]     Train net output #0: loss = 0.0126149 (* 1 = 0.0126149 loss)
I0425 15:40:16.716922 12937 sgd_solver.cpp:106] Iteration 45800, lr = 0.00275438
I0425 15:40:16.857538 12937 solver.cpp:237] Iteration 45900, loss = 0.00507068
I0425 15:40:16.857558 12937 solver.cpp:253]     Train net output #0: loss = 0.00507055 (* 1 = 0.00507055 loss)
I0425 15:40:16.857564 12937 sgd_solver.cpp:106] Iteration 45900, lr = 0.00275069
I0425 15:40:16.998903 12937 solver.cpp:237] Iteration 46000, loss = 0.00464114
I0425 15:40:16.998924 12937 solver.cpp:253]     Train net output #0: loss = 0.00464101 (* 1 = 0.00464101 loss)
I0425 15:40:16.998930 12937 sgd_solver.cpp:106] Iteration 46000, lr = 0.002747
I0425 15:40:17.139914 12937 solver.cpp:237] Iteration 46100, loss = 0.000690164
I0425 15:40:17.139936 12937 solver.cpp:253]     Train net output #0: loss = 0.000690036 (* 1 = 0.000690036 loss)
I0425 15:40:17.139941 12937 sgd_solver.cpp:106] Iteration 46100, lr = 0.00274333
I0425 15:40:17.281118 12937 solver.cpp:237] Iteration 46200, loss = 0.00125731
I0425 15:40:17.281139 12937 solver.cpp:253]     Train net output #0: loss = 0.00125719 (* 1 = 0.00125719 loss)
I0425 15:40:17.281146 12937 sgd_solver.cpp:106] Iteration 46200, lr = 0.00273967
I0425 15:40:17.422047 12937 solver.cpp:237] Iteration 46300, loss = 0.00130036
I0425 15:40:17.422071 12937 solver.cpp:253]     Train net output #0: loss = 0.00130023 (* 1 = 0.00130023 loss)
I0425 15:40:17.422076 12937 sgd_solver.cpp:106] Iteration 46300, lr = 0.00273602
I0425 15:40:17.563066 12937 solver.cpp:237] Iteration 46400, loss = 0.000926865
I0425 15:40:17.563086 12937 solver.cpp:253]     Train net output #0: loss = 0.00092674 (* 1 = 0.00092674 loss)
I0425 15:40:17.563092 12937 sgd_solver.cpp:106] Iteration 46400, lr = 0.00273238
I0425 15:40:17.704126 12937 solver.cpp:237] Iteration 46500, loss = 0.00889276
I0425 15:40:17.704149 12937 solver.cpp:253]     Train net output #0: loss = 0.00889264 (* 1 = 0.00889264 loss)
I0425 15:40:17.704154 12937 sgd_solver.cpp:106] Iteration 46500, lr = 0.00272875
I0425 15:40:17.845314 12937 solver.cpp:237] Iteration 46600, loss = 0.00665173
I0425 15:40:17.845337 12937 solver.cpp:253]     Train net output #0: loss = 0.00665161 (* 1 = 0.00665161 loss)
I0425 15:40:17.845343 12937 sgd_solver.cpp:106] Iteration 46600, lr = 0.00272513
I0425 15:40:17.986538 12937 solver.cpp:237] Iteration 46700, loss = 0.00405295
I0425 15:40:17.986560 12937 solver.cpp:253]     Train net output #0: loss = 0.00405283 (* 1 = 0.00405283 loss)
I0425 15:40:17.986565 12937 sgd_solver.cpp:106] Iteration 46700, lr = 0.00272153
I0425 15:40:18.127399 12937 solver.cpp:237] Iteration 46800, loss = 0.00321159
I0425 15:40:18.127421 12937 solver.cpp:253]     Train net output #0: loss = 0.00321147 (* 1 = 0.00321147 loss)
I0425 15:40:18.127427 12937 sgd_solver.cpp:106] Iteration 46800, lr = 0.00271793
I0425 15:40:18.268430 12937 solver.cpp:237] Iteration 46900, loss = 0.00630604
I0425 15:40:18.268453 12937 solver.cpp:253]     Train net output #0: loss = 0.00630591 (* 1 = 0.00630591 loss)
I0425 15:40:18.268458 12937 sgd_solver.cpp:106] Iteration 46900, lr = 0.00271435
I0425 15:40:18.410151 12937 solver.cpp:237] Iteration 47000, loss = 0.00214939
I0425 15:40:18.410176 12937 solver.cpp:253]     Train net output #0: loss = 0.00214926 (* 1 = 0.00214926 loss)
I0425 15:40:18.410181 12937 sgd_solver.cpp:106] Iteration 47000, lr = 0.00271078
I0425 15:40:18.551084 12937 solver.cpp:237] Iteration 47100, loss = 0.00253247
I0425 15:40:18.551105 12937 solver.cpp:253]     Train net output #0: loss = 0.00253234 (* 1 = 0.00253234 loss)
I0425 15:40:18.551110 12937 sgd_solver.cpp:106] Iteration 47100, lr = 0.00270722
I0425 15:40:18.694453 12937 solver.cpp:237] Iteration 47200, loss = 0.00128933
I0425 15:40:18.694480 12937 solver.cpp:253]     Train net output #0: loss = 0.00128921 (* 1 = 0.00128921 loss)
I0425 15:40:18.694489 12937 sgd_solver.cpp:106] Iteration 47200, lr = 0.00270367
I0425 15:40:18.840472 12937 solver.cpp:237] Iteration 47300, loss = 0.00855602
I0425 15:40:18.840528 12937 solver.cpp:253]     Train net output #0: loss = 0.0085559 (* 1 = 0.0085559 loss)
I0425 15:40:18.840544 12937 sgd_solver.cpp:106] Iteration 47300, lr = 0.00270013
I0425 15:40:18.987114 12937 solver.cpp:237] Iteration 47400, loss = 0.0032523
I0425 15:40:18.987143 12937 solver.cpp:253]     Train net output #0: loss = 0.00325217 (* 1 = 0.00325217 loss)
I0425 15:40:18.987152 12937 sgd_solver.cpp:106] Iteration 47400, lr = 0.0026966
I0425 15:40:19.130285 12937 solver.cpp:237] Iteration 47500, loss = 0.00268812
I0425 15:40:19.130309 12937 solver.cpp:253]     Train net output #0: loss = 0.002688 (* 1 = 0.002688 loss)
I0425 15:40:19.130316 12937 sgd_solver.cpp:106] Iteration 47500, lr = 0.00269308
I0425 15:40:19.272040 12937 solver.cpp:237] Iteration 47600, loss = 0.00894769
I0425 15:40:19.272065 12937 solver.cpp:253]     Train net output #0: loss = 0.00894756 (* 1 = 0.00894756 loss)
I0425 15:40:19.272073 12937 sgd_solver.cpp:106] Iteration 47600, lr = 0.00268957
I0425 15:40:19.414506 12937 solver.cpp:237] Iteration 47700, loss = 0.00741302
I0425 15:40:19.414531 12937 solver.cpp:253]     Train net output #0: loss = 0.0074129 (* 1 = 0.0074129 loss)
I0425 15:40:19.414537 12937 sgd_solver.cpp:106] Iteration 47700, lr = 0.00268607
I0425 15:40:19.565376 12937 solver.cpp:237] Iteration 47800, loss = 0.000136136
I0425 15:40:19.565419 12937 solver.cpp:253]     Train net output #0: loss = 0.000136007 (* 1 = 0.000136007 loss)
I0425 15:40:19.565430 12937 sgd_solver.cpp:106] Iteration 47800, lr = 0.00268259
I0425 15:40:19.710614 12937 solver.cpp:237] Iteration 47900, loss = 0.00608101
I0425 15:40:19.710640 12937 solver.cpp:253]     Train net output #0: loss = 0.00608088 (* 1 = 0.00608088 loss)
I0425 15:40:19.710646 12937 sgd_solver.cpp:106] Iteration 47900, lr = 0.00267911
I0425 15:40:19.852710 12937 solver.cpp:237] Iteration 48000, loss = 0.00472569
I0425 15:40:19.852735 12937 solver.cpp:253]     Train net output #0: loss = 0.00472556 (* 1 = 0.00472556 loss)
I0425 15:40:19.852741 12937 sgd_solver.cpp:106] Iteration 48000, lr = 0.00267565
I0425 15:40:19.994956 12937 solver.cpp:237] Iteration 48100, loss = 0.00268662
I0425 15:40:19.994982 12937 solver.cpp:253]     Train net output #0: loss = 0.0026865 (* 1 = 0.0026865 loss)
I0425 15:40:19.994987 12937 sgd_solver.cpp:106] Iteration 48100, lr = 0.00267219
I0425 15:40:20.137589 12937 solver.cpp:237] Iteration 48200, loss = 0.00208968
I0425 15:40:20.137614 12937 solver.cpp:253]     Train net output #0: loss = 0.00208955 (* 1 = 0.00208955 loss)
I0425 15:40:20.137619 12937 sgd_solver.cpp:106] Iteration 48200, lr = 0.00266875
I0425 15:40:20.279609 12937 solver.cpp:237] Iteration 48300, loss = 0.00181804
I0425 15:40:20.279633 12937 solver.cpp:253]     Train net output #0: loss = 0.00181791 (* 1 = 0.00181791 loss)
I0425 15:40:20.279640 12937 sgd_solver.cpp:106] Iteration 48300, lr = 0.00266532
I0425 15:40:20.422890 12937 solver.cpp:237] Iteration 48400, loss = 0.00185837
I0425 15:40:20.422916 12937 solver.cpp:253]     Train net output #0: loss = 0.00185824 (* 1 = 0.00185824 loss)
I0425 15:40:20.422922 12937 sgd_solver.cpp:106] Iteration 48400, lr = 0.00266189
I0425 15:40:20.565500 12937 solver.cpp:237] Iteration 48500, loss = 0.00152514
I0425 15:40:20.565522 12937 solver.cpp:253]     Train net output #0: loss = 0.00152501 (* 1 = 0.00152501 loss)
I0425 15:40:20.565528 12937 sgd_solver.cpp:106] Iteration 48500, lr = 0.00265848
I0425 15:40:20.706789 12937 solver.cpp:237] Iteration 48600, loss = 0.00772963
I0425 15:40:20.706810 12937 solver.cpp:253]     Train net output #0: loss = 0.0077295 (* 1 = 0.0077295 loss)
I0425 15:40:20.706815 12937 sgd_solver.cpp:106] Iteration 48600, lr = 0.00265507
I0425 15:40:20.848387 12937 solver.cpp:237] Iteration 48700, loss = 0.00579111
I0425 15:40:20.848409 12937 solver.cpp:253]     Train net output #0: loss = 0.00579098 (* 1 = 0.00579098 loss)
I0425 15:40:20.848414 12937 sgd_solver.cpp:106] Iteration 48700, lr = 0.00265168
I0425 15:40:20.989951 12937 solver.cpp:237] Iteration 48800, loss = 0.00290758
I0425 15:40:20.989974 12937 solver.cpp:253]     Train net output #0: loss = 0.00290745 (* 1 = 0.00290745 loss)
I0425 15:40:20.989980 12937 sgd_solver.cpp:106] Iteration 48800, lr = 0.0026483
I0425 15:40:21.133334 12937 solver.cpp:237] Iteration 48900, loss = 0.00723162
I0425 15:40:21.133358 12937 solver.cpp:253]     Train net output #0: loss = 0.00723149 (* 1 = 0.00723149 loss)
I0425 15:40:21.133364 12937 sgd_solver.cpp:106] Iteration 48900, lr = 0.00264493
I0425 15:40:21.277897 12937 solver.cpp:237] Iteration 49000, loss = 0.00420411
I0425 15:40:21.277920 12937 solver.cpp:253]     Train net output #0: loss = 0.00420398 (* 1 = 0.00420398 loss)
I0425 15:40:21.277926 12937 sgd_solver.cpp:106] Iteration 49000, lr = 0.00264156
I0425 15:40:21.422211 12937 solver.cpp:237] Iteration 49100, loss = 0.00411183
I0425 15:40:21.422235 12937 solver.cpp:253]     Train net output #0: loss = 0.0041117 (* 1 = 0.0041117 loss)
I0425 15:40:21.422240 12937 sgd_solver.cpp:106] Iteration 49100, lr = 0.00263821
I0425 15:40:21.563352 12937 solver.cpp:237] Iteration 49200, loss = 0.00192735
I0425 15:40:21.563374 12937 solver.cpp:253]     Train net output #0: loss = 0.00192722 (* 1 = 0.00192722 loss)
I0425 15:40:21.563380 12937 sgd_solver.cpp:106] Iteration 49200, lr = 0.00263487
I0425 15:40:21.705435 12937 solver.cpp:237] Iteration 49300, loss = 0.00966393
I0425 15:40:21.705456 12937 solver.cpp:253]     Train net output #0: loss = 0.00966379 (* 1 = 0.00966379 loss)
I0425 15:40:21.705461 12937 sgd_solver.cpp:106] Iteration 49300, lr = 0.00263153
I0425 15:40:21.847323 12937 solver.cpp:237] Iteration 49400, loss = 0.00594849
I0425 15:40:21.847376 12937 solver.cpp:253]     Train net output #0: loss = 0.00594836 (* 1 = 0.00594836 loss)
I0425 15:40:21.847389 12937 sgd_solver.cpp:106] Iteration 49400, lr = 0.00262821
I0425 15:40:21.989401 12937 solver.cpp:237] Iteration 49500, loss = 0.00232955
I0425 15:40:21.989423 12937 solver.cpp:253]     Train net output #0: loss = 0.00232942 (* 1 = 0.00232942 loss)
I0425 15:40:21.989428 12937 sgd_solver.cpp:106] Iteration 49500, lr = 0.0026249
I0425 15:40:22.139029 12937 solver.cpp:237] Iteration 49600, loss = 0.00627863
I0425 15:40:22.139062 12937 solver.cpp:253]     Train net output #0: loss = 0.0062785 (* 1 = 0.0062785 loss)
I0425 15:40:22.139071 12937 sgd_solver.cpp:106] Iteration 49600, lr = 0.00262159
I0425 15:40:22.284795 12937 solver.cpp:237] Iteration 49700, loss = 0.000941869
I0425 15:40:22.284818 12937 solver.cpp:253]     Train net output #0: loss = 0.000941739 (* 1 = 0.000941739 loss)
I0425 15:40:22.284824 12937 sgd_solver.cpp:106] Iteration 49700, lr = 0.0026183
I0425 15:40:22.427924 12937 solver.cpp:237] Iteration 49800, loss = 0.00534047
I0425 15:40:22.427947 12937 solver.cpp:253]     Train net output #0: loss = 0.00534034 (* 1 = 0.00534034 loss)
I0425 15:40:22.427953 12937 sgd_solver.cpp:106] Iteration 49800, lr = 0.00261501
I0425 15:40:22.570966 12937 solver.cpp:237] Iteration 49900, loss = 0.0018521
I0425 15:40:22.570988 12937 solver.cpp:253]     Train net output #0: loss = 0.00185197 (* 1 = 0.00185197 loss)
I0425 15:40:22.570993 12937 sgd_solver.cpp:106] Iteration 49900, lr = 0.00261174
I0425 15:40:22.712649 12937 solver.cpp:459] Snapshotting to binary proto file examples/mnist/test/lenet_iter_50000.caffemodel
I0425 15:40:22.714247 12937 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/test/lenet_iter_50000.solverstate
I0425 15:40:22.715250 12937 solver.cpp:321] Iteration 50000, loss = 0.00881612
I0425 15:40:22.715287 12937 solver.cpp:341] Iteration 50000, Testing net (#0)
I0425 15:40:22.802966 12937 solver.cpp:409]     Test net output #0: accuracy = 0.9909
I0425 15:40:22.803009 12937 solver.cpp:409]     Test net output #1: loss = 0.0285377 (* 1 = 0.0285377 loss)
I0425 15:40:22.803017 12937 solver.cpp:326] Optimization Done.
I0425 15:40:22.803025 12937 caffe.cpp:215] Optimization Done.
