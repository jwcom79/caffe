I0428 22:35:21.571177  2425 caffe.cpp:184] Using GPUs 0
I0428 22:35:21.833166  2425 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 5000
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
solver_mode: GPU
device_id: 0
net: "examples/mnist/test/lenet_train_test.prototxt"
I0428 22:35:21.833310  2425 solver.cpp:91] Creating training net from net file: examples/mnist/test/lenet_train_test.prototxt
I0428 22:35:21.833884  2425 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 22:35:21.833928  2425 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 22:35:21.834064  2425 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "pool1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0428 22:35:21.834673  2425 layer_factory.hpp:77] Creating layer mnist
I0428 22:35:21.835398  2425 net.cpp:106] Creating Layer mnist
I0428 22:35:21.835434  2425 net.cpp:411] mnist -> data
I0428 22:35:21.835489  2425 net.cpp:411] mnist -> label
I0428 22:35:21.836441  2430 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 22:35:21.845288  2425 data_layer.cpp:41] output data size: 64,1,28,28
I0428 22:35:21.850004  2425 net.cpp:150] Setting up mnist
I0428 22:35:21.850067  2425 net.cpp:157] Top shape: 64 1 28 28 (50176)
I0428 22:35:21.850086  2425 net.cpp:157] Top shape: 64 (64)
I0428 22:35:21.850101  2425 net.cpp:165] Memory required for data: 200960
I0428 22:35:21.850124  2425 layer_factory.hpp:77] Creating layer conv1
I0428 22:35:21.850160  2425 net.cpp:106] Creating Layer conv1
I0428 22:35:21.850178  2425 net.cpp:454] conv1 <- data
I0428 22:35:21.850200  2425 net.cpp:411] conv1 -> conv1
I0428 22:35:22.005390  2425 net.cpp:150] Setting up conv1
I0428 22:35:22.005471  2425 net.cpp:157] Top shape: 64 20 24 24 (737280)
I0428 22:35:22.005492  2425 net.cpp:165] Memory required for data: 3150080
I0428 22:35:22.005535  2425 layer_factory.hpp:77] Creating layer pool1
I0428 22:35:22.005573  2425 net.cpp:106] Creating Layer pool1
I0428 22:35:22.005609  2425 net.cpp:454] pool1 <- conv1
I0428 22:35:22.005651  2425 net.cpp:411] pool1 -> pool1
I0428 22:35:22.006433  2425 net.cpp:150] Setting up pool1
I0428 22:35:22.006469  2425 net.cpp:157] Top shape: 64 20 12 12 (184320)
I0428 22:35:22.006489  2425 net.cpp:165] Memory required for data: 3887360
I0428 22:35:22.006510  2425 layer_factory.hpp:77] Creating layer drop1
I0428 22:35:22.006537  2425 net.cpp:106] Creating Layer drop1
I0428 22:35:22.006559  2425 net.cpp:454] drop1 <- pool1
I0428 22:35:22.006583  2425 net.cpp:397] drop1 -> pool1 (in-place)
I0428 22:35:22.006641  2425 net.cpp:150] Setting up drop1
I0428 22:35:22.006669  2425 net.cpp:157] Top shape: 64 20 12 12 (184320)
I0428 22:35:22.006687  2425 net.cpp:165] Memory required for data: 4624640
I0428 22:35:22.006706  2425 layer_factory.hpp:77] Creating layer conv2
I0428 22:35:22.006736  2425 net.cpp:106] Creating Layer conv2
I0428 22:35:22.006757  2425 net.cpp:454] conv2 <- pool1
I0428 22:35:22.006780  2425 net.cpp:411] conv2 -> conv2
I0428 22:35:22.009507  2425 net.cpp:150] Setting up conv2
I0428 22:35:22.009557  2425 net.cpp:157] Top shape: 64 50 8 8 (204800)
I0428 22:35:22.009578  2425 net.cpp:165] Memory required for data: 5443840
I0428 22:35:22.009608  2425 layer_factory.hpp:77] Creating layer pool2
I0428 22:35:22.009634  2425 net.cpp:106] Creating Layer pool2
I0428 22:35:22.009656  2425 net.cpp:454] pool2 <- conv2
I0428 22:35:22.009682  2425 net.cpp:411] pool2 -> pool2
I0428 22:35:22.010443  2425 net.cpp:150] Setting up pool2
I0428 22:35:22.010479  2425 net.cpp:157] Top shape: 64 50 4 4 (51200)
I0428 22:35:22.010505  2425 net.cpp:165] Memory required for data: 5648640
I0428 22:35:22.010526  2425 layer_factory.hpp:77] Creating layer ip1
I0428 22:35:22.010551  2425 net.cpp:106] Creating Layer ip1
I0428 22:35:22.010572  2425 net.cpp:454] ip1 <- pool2
I0428 22:35:22.010598  2425 net.cpp:411] ip1 -> ip1
I0428 22:35:22.014333  2425 net.cpp:150] Setting up ip1
I0428 22:35:22.014400  2425 net.cpp:157] Top shape: 64 500 (32000)
I0428 22:35:22.014420  2425 net.cpp:165] Memory required for data: 5776640
I0428 22:35:22.014456  2425 layer_factory.hpp:77] Creating layer relu1
I0428 22:35:22.014487  2425 net.cpp:106] Creating Layer relu1
I0428 22:35:22.014509  2425 net.cpp:454] relu1 <- ip1
I0428 22:35:22.014533  2425 net.cpp:397] relu1 -> ip1 (in-place)
I0428 22:35:22.015321  2425 net.cpp:150] Setting up relu1
I0428 22:35:22.015355  2425 net.cpp:157] Top shape: 64 500 (32000)
I0428 22:35:22.015378  2425 net.cpp:165] Memory required for data: 5904640
I0428 22:35:22.015399  2425 layer_factory.hpp:77] Creating layer ip2
I0428 22:35:22.015429  2425 net.cpp:106] Creating Layer ip2
I0428 22:35:22.015451  2425 net.cpp:454] ip2 <- ip1
I0428 22:35:22.015475  2425 net.cpp:411] ip2 -> ip2
I0428 22:35:22.016141  2425 net.cpp:150] Setting up ip2
I0428 22:35:22.016178  2425 net.cpp:157] Top shape: 64 10 (640)
I0428 22:35:22.016201  2425 net.cpp:165] Memory required for data: 5907200
I0428 22:35:22.016227  2425 layer_factory.hpp:77] Creating layer loss
I0428 22:35:22.016253  2425 net.cpp:106] Creating Layer loss
I0428 22:35:22.016276  2425 net.cpp:454] loss <- ip2
I0428 22:35:22.016299  2425 net.cpp:454] loss <- label
I0428 22:35:22.016329  2425 net.cpp:411] loss -> loss
I0428 22:35:22.016373  2425 layer_factory.hpp:77] Creating layer loss
I0428 22:35:22.017220  2425 net.cpp:150] Setting up loss
I0428 22:35:22.017257  2425 net.cpp:157] Top shape: (1)
I0428 22:35:22.017280  2425 net.cpp:160]     with loss weight 1
I0428 22:35:22.017320  2425 net.cpp:165] Memory required for data: 5907204
I0428 22:35:22.017343  2425 net.cpp:226] loss needs backward computation.
I0428 22:35:22.017364  2425 net.cpp:226] ip2 needs backward computation.
I0428 22:35:22.017387  2425 net.cpp:226] relu1 needs backward computation.
I0428 22:35:22.017407  2425 net.cpp:226] ip1 needs backward computation.
I0428 22:35:22.017427  2425 net.cpp:226] pool2 needs backward computation.
I0428 22:35:22.017447  2425 net.cpp:226] conv2 needs backward computation.
I0428 22:35:22.017468  2425 net.cpp:226] drop1 needs backward computation.
I0428 22:35:22.017513  2425 net.cpp:226] pool1 needs backward computation.
I0428 22:35:22.017535  2425 net.cpp:226] conv1 needs backward computation.
I0428 22:35:22.017556  2425 net.cpp:228] mnist does not need backward computation.
I0428 22:35:22.017576  2425 net.cpp:270] This network produces output loss
I0428 22:35:22.017606  2425 net.cpp:283] Network initialization done.
I0428 22:35:22.018151  2425 solver.cpp:181] Creating test net (#0) specified by net file: examples/mnist/test/lenet_train_test.prototxt
I0428 22:35:22.018211  2425 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 22:35:22.018365  2425 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "pool1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0428 22:35:22.019011  2425 layer_factory.hpp:77] Creating layer mnist
I0428 22:35:22.019165  2425 net.cpp:106] Creating Layer mnist
I0428 22:35:22.019196  2425 net.cpp:411] mnist -> data
I0428 22:35:22.019227  2425 net.cpp:411] mnist -> label
I0428 22:35:22.020176  2432 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 22:35:22.025025  2425 data_layer.cpp:41] output data size: 100,1,28,28
I0428 22:35:22.026114  2425 net.cpp:150] Setting up mnist
I0428 22:35:22.026154  2425 net.cpp:157] Top shape: 100 1 28 28 (78400)
I0428 22:35:22.026180  2425 net.cpp:157] Top shape: 100 (100)
I0428 22:35:22.026201  2425 net.cpp:165] Memory required for data: 314000
I0428 22:35:22.026226  2425 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 22:35:22.026254  2425 net.cpp:106] Creating Layer label_mnist_1_split
I0428 22:35:22.026278  2425 net.cpp:454] label_mnist_1_split <- label
I0428 22:35:22.026304  2425 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_0
I0428 22:35:22.026335  2425 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_1
I0428 22:35:22.026402  2425 net.cpp:150] Setting up label_mnist_1_split
I0428 22:35:22.026440  2425 net.cpp:157] Top shape: 100 (100)
I0428 22:35:22.026475  2425 net.cpp:157] Top shape: 100 (100)
I0428 22:35:22.026496  2425 net.cpp:165] Memory required for data: 314800
I0428 22:35:22.026516  2425 layer_factory.hpp:77] Creating layer conv1
I0428 22:35:22.026546  2425 net.cpp:106] Creating Layer conv1
I0428 22:35:22.026567  2425 net.cpp:454] conv1 <- data
I0428 22:35:22.026594  2425 net.cpp:411] conv1 -> conv1
I0428 22:35:22.033143  2425 net.cpp:150] Setting up conv1
I0428 22:35:22.033193  2425 net.cpp:157] Top shape: 100 20 24 24 (1152000)
I0428 22:35:22.033217  2425 net.cpp:165] Memory required for data: 4922800
I0428 22:35:22.033252  2425 layer_factory.hpp:77] Creating layer pool1
I0428 22:35:22.033280  2425 net.cpp:106] Creating Layer pool1
I0428 22:35:22.033304  2425 net.cpp:454] pool1 <- conv1
I0428 22:35:22.033330  2425 net.cpp:411] pool1 -> pool1
I0428 22:35:22.034102  2425 net.cpp:150] Setting up pool1
I0428 22:35:22.034138  2425 net.cpp:157] Top shape: 100 20 12 12 (288000)
I0428 22:35:22.034162  2425 net.cpp:165] Memory required for data: 6074800
I0428 22:35:22.034183  2425 layer_factory.hpp:77] Creating layer drop1
I0428 22:35:22.034209  2425 net.cpp:106] Creating Layer drop1
I0428 22:35:22.034231  2425 net.cpp:454] drop1 <- pool1
I0428 22:35:22.034255  2425 net.cpp:397] drop1 -> pool1 (in-place)
I0428 22:35:22.034307  2425 net.cpp:150] Setting up drop1
I0428 22:35:22.034334  2425 net.cpp:157] Top shape: 100 20 12 12 (288000)
I0428 22:35:22.034355  2425 net.cpp:165] Memory required for data: 7226800
I0428 22:35:22.034375  2425 layer_factory.hpp:77] Creating layer conv2
I0428 22:35:22.034401  2425 net.cpp:106] Creating Layer conv2
I0428 22:35:22.034423  2425 net.cpp:454] conv2 <- pool1
I0428 22:35:22.034447  2425 net.cpp:411] conv2 -> conv2
I0428 22:35:22.037008  2425 net.cpp:150] Setting up conv2
I0428 22:35:22.037046  2425 net.cpp:157] Top shape: 100 50 8 8 (320000)
I0428 22:35:22.037070  2425 net.cpp:165] Memory required for data: 8506800
I0428 22:35:22.037099  2425 layer_factory.hpp:77] Creating layer pool2
I0428 22:35:22.037128  2425 net.cpp:106] Creating Layer pool2
I0428 22:35:22.037150  2425 net.cpp:454] pool2 <- conv2
I0428 22:35:22.037174  2425 net.cpp:411] pool2 -> pool2
I0428 22:35:22.038033  2425 net.cpp:150] Setting up pool2
I0428 22:35:22.038069  2425 net.cpp:157] Top shape: 100 50 4 4 (80000)
I0428 22:35:22.038092  2425 net.cpp:165] Memory required for data: 8826800
I0428 22:35:22.038115  2425 layer_factory.hpp:77] Creating layer ip1
I0428 22:35:22.038141  2425 net.cpp:106] Creating Layer ip1
I0428 22:35:22.038164  2425 net.cpp:454] ip1 <- pool2
I0428 22:35:22.038190  2425 net.cpp:411] ip1 -> ip1
I0428 22:35:22.041990  2425 net.cpp:150] Setting up ip1
I0428 22:35:22.042050  2425 net.cpp:157] Top shape: 100 500 (50000)
I0428 22:35:22.042073  2425 net.cpp:165] Memory required for data: 9026800
I0428 22:35:22.042106  2425 layer_factory.hpp:77] Creating layer relu1
I0428 22:35:22.042137  2425 net.cpp:106] Creating Layer relu1
I0428 22:35:22.042160  2425 net.cpp:454] relu1 <- ip1
I0428 22:35:22.042186  2425 net.cpp:397] relu1 -> ip1 (in-place)
I0428 22:35:22.042986  2425 net.cpp:150] Setting up relu1
I0428 22:35:22.043022  2425 net.cpp:157] Top shape: 100 500 (50000)
I0428 22:35:22.043045  2425 net.cpp:165] Memory required for data: 9226800
I0428 22:35:22.043067  2425 layer_factory.hpp:77] Creating layer ip2
I0428 22:35:22.043093  2425 net.cpp:106] Creating Layer ip2
I0428 22:35:22.043118  2425 net.cpp:454] ip2 <- ip1
I0428 22:35:22.043143  2425 net.cpp:411] ip2 -> ip2
I0428 22:35:22.043339  2425 net.cpp:150] Setting up ip2
I0428 22:35:22.043370  2425 net.cpp:157] Top shape: 100 10 (1000)
I0428 22:35:22.043390  2425 net.cpp:165] Memory required for data: 9230800
I0428 22:35:22.043416  2425 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0428 22:35:22.043439  2425 net.cpp:106] Creating Layer ip2_ip2_0_split
I0428 22:35:22.043462  2425 net.cpp:454] ip2_ip2_0_split <- ip2
I0428 22:35:22.043484  2425 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0428 22:35:22.043510  2425 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0428 22:35:22.043602  2425 net.cpp:150] Setting up ip2_ip2_0_split
I0428 22:35:22.043632  2425 net.cpp:157] Top shape: 100 10 (1000)
I0428 22:35:22.043654  2425 net.cpp:157] Top shape: 100 10 (1000)
I0428 22:35:22.043675  2425 net.cpp:165] Memory required for data: 9238800
I0428 22:35:22.043696  2425 layer_factory.hpp:77] Creating layer accuracy
I0428 22:35:22.043720  2425 net.cpp:106] Creating Layer accuracy
I0428 22:35:22.043742  2425 net.cpp:454] accuracy <- ip2_ip2_0_split_0
I0428 22:35:22.043763  2425 net.cpp:454] accuracy <- label_mnist_1_split_0
I0428 22:35:22.043787  2425 net.cpp:411] accuracy -> accuracy
I0428 22:35:22.043817  2425 net.cpp:150] Setting up accuracy
I0428 22:35:22.043841  2425 net.cpp:157] Top shape: (1)
I0428 22:35:22.043861  2425 net.cpp:165] Memory required for data: 9238804
I0428 22:35:22.043880  2425 layer_factory.hpp:77] Creating layer loss
I0428 22:35:22.043903  2425 net.cpp:106] Creating Layer loss
I0428 22:35:22.043923  2425 net.cpp:454] loss <- ip2_ip2_0_split_1
I0428 22:35:22.043946  2425 net.cpp:454] loss <- label_mnist_1_split_1
I0428 22:35:22.043967  2425 net.cpp:411] loss -> loss
I0428 22:35:22.043997  2425 layer_factory.hpp:77] Creating layer loss
I0428 22:35:22.044832  2425 net.cpp:150] Setting up loss
I0428 22:35:22.044868  2425 net.cpp:157] Top shape: (1)
I0428 22:35:22.044890  2425 net.cpp:160]     with loss weight 1
I0428 22:35:22.044935  2425 net.cpp:165] Memory required for data: 9238808
I0428 22:35:22.044957  2425 net.cpp:226] loss needs backward computation.
I0428 22:35:22.044980  2425 net.cpp:228] accuracy does not need backward computation.
I0428 22:35:22.045001  2425 net.cpp:226] ip2_ip2_0_split needs backward computation.
I0428 22:35:22.045022  2425 net.cpp:226] ip2 needs backward computation.
I0428 22:35:22.045042  2425 net.cpp:226] relu1 needs backward computation.
I0428 22:35:22.045061  2425 net.cpp:226] ip1 needs backward computation.
I0428 22:35:22.045081  2425 net.cpp:226] pool2 needs backward computation.
I0428 22:35:22.045100  2425 net.cpp:226] conv2 needs backward computation.
I0428 22:35:22.045120  2425 net.cpp:226] drop1 needs backward computation.
I0428 22:35:22.045140  2425 net.cpp:226] pool1 needs backward computation.
I0428 22:35:22.045159  2425 net.cpp:226] conv1 needs backward computation.
I0428 22:35:22.045179  2425 net.cpp:228] label_mnist_1_split does not need backward computation.
I0428 22:35:22.045199  2425 net.cpp:228] mnist does not need backward computation.
I0428 22:35:22.045219  2425 net.cpp:270] This network produces output accuracy
I0428 22:35:22.045239  2425 net.cpp:270] This network produces output loss
I0428 22:35:22.045267  2425 net.cpp:283] Network initialization done.
I0428 22:35:22.045368  2425 solver.cpp:60] Solver scaffolding done.
I0428 22:35:22.045732  2425 caffe.cpp:212] Starting Optimization
I0428 22:35:22.045763  2425 solver.cpp:288] Solving LeNet
I0428 22:35:22.045783  2425 solver.cpp:289] Learning Rate Policy: inv
I0428 22:35:22.046259  2425 solver.cpp:341] Iteration 0, Testing net (#0)
I0428 22:35:22.053668  2425 blocking_queue.cpp:50] Data layer prefetch queue empty
I0428 22:35:22.185084  2425 solver.cpp:409]     Test net output #0: accuracy = 0.1652
I0428 22:35:22.185179  2425 solver.cpp:409]     Test net output #1: loss = 2.30738 (* 1 = 2.30738 loss)
I0428 22:35:22.194141  2425 solver.cpp:237] Iteration 0, loss = 2.35711
I0428 22:35:22.194210  2425 solver.cpp:253]     Train net output #0: loss = 2.35711 (* 1 = 2.35711 loss)
I0428 22:35:22.194238  2425 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0428 22:35:22.438351  2425 solver.cpp:237] Iteration 100, loss = 0.304743
I0428 22:35:22.438439  2425 solver.cpp:253]     Train net output #0: loss = 0.304743 (* 1 = 0.304743 loss)
I0428 22:35:22.438467  2425 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0428 22:35:22.652297  2425 solver.cpp:237] Iteration 200, loss = 0.209727
I0428 22:35:22.652385  2425 solver.cpp:253]     Train net output #0: loss = 0.209727 (* 1 = 0.209727 loss)
I0428 22:35:22.652412  2425 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0428 22:35:22.863777  2425 solver.cpp:237] Iteration 300, loss = 0.175245
I0428 22:35:22.863857  2425 solver.cpp:253]     Train net output #0: loss = 0.175245 (* 1 = 0.175245 loss)
I0428 22:35:22.863879  2425 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0428 22:35:23.074076  2425 solver.cpp:237] Iteration 400, loss = 0.150592
I0428 22:35:23.074154  2425 solver.cpp:253]     Train net output #0: loss = 0.150592 (* 1 = 0.150592 loss)
I0428 22:35:23.074177  2425 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0428 22:35:23.280979  2425 solver.cpp:237] Iteration 500, loss = 0.170146
I0428 22:35:23.281067  2425 solver.cpp:253]     Train net output #0: loss = 0.170146 (* 1 = 0.170146 loss)
I0428 22:35:23.281095  2425 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0428 22:35:23.495818  2425 solver.cpp:237] Iteration 600, loss = 0.140641
I0428 22:35:23.495896  2425 solver.cpp:253]     Train net output #0: loss = 0.140641 (* 1 = 0.140641 loss)
I0428 22:35:23.495918  2425 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0428 22:35:23.703320  2425 solver.cpp:237] Iteration 700, loss = 0.172106
I0428 22:35:23.703408  2425 solver.cpp:253]     Train net output #0: loss = 0.172106 (* 1 = 0.172106 loss)
I0428 22:35:23.703434  2425 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0428 22:35:23.915753  2425 solver.cpp:237] Iteration 800, loss = 0.368222
I0428 22:35:23.915829  2425 solver.cpp:253]     Train net output #0: loss = 0.368222 (* 1 = 0.368222 loss)
I0428 22:35:23.915849  2425 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0428 22:35:24.126009  2425 solver.cpp:237] Iteration 900, loss = 0.149652
I0428 22:35:24.126099  2425 solver.cpp:253]     Train net output #0: loss = 0.149652 (* 1 = 0.149652 loss)
I0428 22:35:24.126123  2425 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0428 22:35:24.334295  2425 solver.cpp:237] Iteration 1000, loss = 0.110295
I0428 22:35:24.334370  2425 solver.cpp:253]     Train net output #0: loss = 0.110295 (* 1 = 0.110295 loss)
I0428 22:35:24.334389  2425 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0428 22:35:24.539304  2425 solver.cpp:237] Iteration 1100, loss = 0.0141834
I0428 22:35:24.539392  2425 solver.cpp:253]     Train net output #0: loss = 0.0141833 (* 1 = 0.0141833 loss)
I0428 22:35:24.539415  2425 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0428 22:35:24.760082  2425 solver.cpp:237] Iteration 1200, loss = 0.0351761
I0428 22:35:24.760160  2425 solver.cpp:253]     Train net output #0: loss = 0.035176 (* 1 = 0.035176 loss)
I0428 22:35:24.760182  2425 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0428 22:35:24.978260  2425 solver.cpp:237] Iteration 1300, loss = 0.0374732
I0428 22:35:24.978348  2425 solver.cpp:253]     Train net output #0: loss = 0.0374731 (* 1 = 0.0374731 loss)
I0428 22:35:24.978375  2425 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0428 22:35:25.193620  2425 solver.cpp:237] Iteration 1400, loss = 0.033399
I0428 22:35:25.193704  2425 solver.cpp:253]     Train net output #0: loss = 0.0333989 (* 1 = 0.0333989 loss)
I0428 22:35:25.193730  2425 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0428 22:35:25.416028  2425 solver.cpp:237] Iteration 1500, loss = 0.0795671
I0428 22:35:25.416106  2425 solver.cpp:253]     Train net output #0: loss = 0.079567 (* 1 = 0.079567 loss)
I0428 22:35:25.416128  2425 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0428 22:35:25.634004  2425 solver.cpp:237] Iteration 1600, loss = 0.147627
I0428 22:35:25.634093  2425 solver.cpp:253]     Train net output #0: loss = 0.147626 (* 1 = 0.147626 loss)
I0428 22:35:25.634117  2425 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0428 22:35:25.853370  2425 solver.cpp:237] Iteration 1700, loss = 0.098301
I0428 22:35:25.853458  2425 solver.cpp:253]     Train net output #0: loss = 0.098301 (* 1 = 0.098301 loss)
I0428 22:35:25.853483  2425 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0428 22:35:26.065608  2425 solver.cpp:237] Iteration 1800, loss = 0.0644881
I0428 22:35:26.065699  2425 solver.cpp:253]     Train net output #0: loss = 0.064488 (* 1 = 0.064488 loss)
I0428 22:35:26.065752  2425 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0428 22:35:26.277536  2425 solver.cpp:237] Iteration 1900, loss = 0.107614
I0428 22:35:26.277624  2425 solver.cpp:253]     Train net output #0: loss = 0.107614 (* 1 = 0.107614 loss)
I0428 22:35:26.277649  2425 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0428 22:35:26.494307  2425 solver.cpp:237] Iteration 2000, loss = 0.043726
I0428 22:35:26.494387  2425 solver.cpp:253]     Train net output #0: loss = 0.0437259 (* 1 = 0.0437259 loss)
I0428 22:35:26.494410  2425 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0428 22:35:26.701864  2425 solver.cpp:237] Iteration 2100, loss = 0.0412337
I0428 22:35:26.701956  2425 solver.cpp:253]     Train net output #0: loss = 0.0412336 (* 1 = 0.0412336 loss)
I0428 22:35:26.701984  2425 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0428 22:35:26.914988  2425 solver.cpp:237] Iteration 2200, loss = 0.0629053
I0428 22:35:26.915066  2425 solver.cpp:253]     Train net output #0: loss = 0.0629053 (* 1 = 0.0629053 loss)
I0428 22:35:26.915084  2425 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0428 22:35:27.153316  2425 solver.cpp:237] Iteration 2300, loss = 0.139152
I0428 22:35:27.153396  2425 solver.cpp:253]     Train net output #0: loss = 0.139152 (* 1 = 0.139152 loss)
I0428 22:35:27.153419  2425 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0428 22:35:27.390532  2425 solver.cpp:237] Iteration 2400, loss = 0.0219671
I0428 22:35:27.390692  2425 solver.cpp:253]     Train net output #0: loss = 0.021967 (* 1 = 0.021967 loss)
I0428 22:35:27.390754  2425 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0428 22:35:27.631089  2425 solver.cpp:237] Iteration 2500, loss = 0.0593224
I0428 22:35:27.631250  2425 solver.cpp:253]     Train net output #0: loss = 0.0593223 (* 1 = 0.0593223 loss)
I0428 22:35:27.631314  2425 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0428 22:35:27.859047  2425 solver.cpp:237] Iteration 2600, loss = 0.123961
I0428 22:35:27.859202  2425 solver.cpp:253]     Train net output #0: loss = 0.123961 (* 1 = 0.123961 loss)
I0428 22:35:27.859261  2425 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0428 22:35:28.097198  2425 solver.cpp:237] Iteration 2700, loss = 0.130406
I0428 22:35:28.097353  2425 solver.cpp:253]     Train net output #0: loss = 0.130406 (* 1 = 0.130406 loss)
I0428 22:35:28.097409  2425 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0428 22:35:28.312774  2425 solver.cpp:237] Iteration 2800, loss = 0.00786813
I0428 22:35:28.312852  2425 solver.cpp:253]     Train net output #0: loss = 0.00786802 (* 1 = 0.00786802 loss)
I0428 22:35:28.312873  2425 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0428 22:35:28.546972  2425 solver.cpp:237] Iteration 2900, loss = 0.0675904
I0428 22:35:28.547047  2425 solver.cpp:253]     Train net output #0: loss = 0.0675903 (* 1 = 0.0675903 loss)
I0428 22:35:28.547068  2425 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0428 22:35:28.779496  2425 solver.cpp:237] Iteration 3000, loss = 0.0420478
I0428 22:35:28.779574  2425 solver.cpp:253]     Train net output #0: loss = 0.0420477 (* 1 = 0.0420477 loss)
I0428 22:35:28.779597  2425 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0428 22:35:29.010937  2425 solver.cpp:237] Iteration 3100, loss = 0.0640723
I0428 22:35:29.011095  2425 solver.cpp:253]     Train net output #0: loss = 0.0640722 (* 1 = 0.0640722 loss)
I0428 22:35:29.011155  2425 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0428 22:35:29.225240  2425 solver.cpp:237] Iteration 3200, loss = 0.0402959
I0428 22:35:29.225402  2425 solver.cpp:253]     Train net output #0: loss = 0.0402958 (* 1 = 0.0402958 loss)
I0428 22:35:29.225463  2425 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0428 22:35:29.451031  2425 solver.cpp:237] Iteration 3300, loss = 0.0325909
I0428 22:35:29.451107  2425 solver.cpp:253]     Train net output #0: loss = 0.0325908 (* 1 = 0.0325908 loss)
I0428 22:35:29.451128  2425 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0428 22:35:29.684782  2425 solver.cpp:237] Iteration 3400, loss = 0.0486857
I0428 22:35:29.684880  2425 solver.cpp:253]     Train net output #0: loss = 0.0486856 (* 1 = 0.0486856 loss)
I0428 22:35:29.684906  2425 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0428 22:35:29.924374  2425 solver.cpp:237] Iteration 3500, loss = 0.0255235
I0428 22:35:29.924537  2425 solver.cpp:253]     Train net output #0: loss = 0.0255234 (* 1 = 0.0255234 loss)
I0428 22:35:29.924597  2425 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0428 22:35:30.147027  2425 solver.cpp:237] Iteration 3600, loss = 0.111823
I0428 22:35:30.147106  2425 solver.cpp:253]     Train net output #0: loss = 0.111823 (* 1 = 0.111823 loss)
I0428 22:35:30.147128  2425 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0428 22:35:30.379024  2425 solver.cpp:237] Iteration 3700, loss = 0.0379819
I0428 22:35:30.379103  2425 solver.cpp:253]     Train net output #0: loss = 0.0379818 (* 1 = 0.0379818 loss)
I0428 22:35:30.379124  2425 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0428 22:35:30.616420  2425 solver.cpp:237] Iteration 3800, loss = 0.00994086
I0428 22:35:30.616582  2425 solver.cpp:253]     Train net output #0: loss = 0.00994071 (* 1 = 0.00994071 loss)
I0428 22:35:30.616646  2425 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0428 22:35:30.853193  2425 solver.cpp:237] Iteration 3900, loss = 0.0348786
I0428 22:35:30.853353  2425 solver.cpp:253]     Train net output #0: loss = 0.0348785 (* 1 = 0.0348785 loss)
I0428 22:35:30.853417  2425 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0428 22:35:31.068287  2425 solver.cpp:237] Iteration 4000, loss = 0.0602337
I0428 22:35:31.068451  2425 solver.cpp:253]     Train net output #0: loss = 0.0602336 (* 1 = 0.0602336 loss)
I0428 22:35:31.068511  2425 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0428 22:35:31.304265  2425 solver.cpp:237] Iteration 4100, loss = 0.0395114
I0428 22:35:31.304421  2425 solver.cpp:253]     Train net output #0: loss = 0.0395113 (* 1 = 0.0395113 loss)
I0428 22:35:31.304478  2425 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0428 22:35:31.544348  2425 solver.cpp:237] Iteration 4200, loss = 0.0257673
I0428 22:35:31.544509  2425 solver.cpp:253]     Train net output #0: loss = 0.0257671 (* 1 = 0.0257671 loss)
I0428 22:35:31.544567  2425 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0428 22:35:31.786999  2425 solver.cpp:237] Iteration 4300, loss = 0.0793943
I0428 22:35:31.787081  2425 solver.cpp:253]     Train net output #0: loss = 0.0793942 (* 1 = 0.0793942 loss)
I0428 22:35:31.787102  2425 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0428 22:35:32.024487  2425 solver.cpp:237] Iteration 4400, loss = 0.0340872
I0428 22:35:32.024651  2425 solver.cpp:253]     Train net output #0: loss = 0.0340871 (* 1 = 0.0340871 loss)
I0428 22:35:32.024713  2425 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0428 22:35:32.255002  2425 solver.cpp:237] Iteration 4500, loss = 0.0541587
I0428 22:35:32.255077  2425 solver.cpp:253]     Train net output #0: loss = 0.0541586 (* 1 = 0.0541586 loss)
I0428 22:35:32.255100  2425 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0428 22:35:32.479624  2425 solver.cpp:237] Iteration 4600, loss = 0.0364074
I0428 22:35:32.479789  2425 solver.cpp:253]     Train net output #0: loss = 0.0364073 (* 1 = 0.0364073 loss)
I0428 22:35:32.479849  2425 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0428 22:35:32.707432  2425 solver.cpp:237] Iteration 4700, loss = 0.0523717
I0428 22:35:32.707593  2425 solver.cpp:253]     Train net output #0: loss = 0.0523716 (* 1 = 0.0523716 loss)
I0428 22:35:32.707654  2425 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0428 22:35:32.940361  2425 solver.cpp:237] Iteration 4800, loss = 0.0978837
I0428 22:35:32.940521  2425 solver.cpp:253]     Train net output #0: loss = 0.0978836 (* 1 = 0.0978836 loss)
I0428 22:35:32.940582  2425 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0428 22:35:33.174962  2425 solver.cpp:237] Iteration 4900, loss = 0.028189
I0428 22:35:33.175050  2425 solver.cpp:253]     Train net output #0: loss = 0.0281889 (* 1 = 0.0281889 loss)
I0428 22:35:33.175086  2425 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0428 22:35:33.404553  2425 solver.cpp:341] Iteration 5000, Testing net (#0)
I0428 22:35:33.539621  2425 solver.cpp:409]     Test net output #0: accuracy = 0.9882
I0428 22:35:33.539700  2425 solver.cpp:409]     Test net output #1: loss = 0.0350118 (* 1 = 0.0350118 loss)
I0428 22:35:33.541326  2425 solver.cpp:237] Iteration 5000, loss = 0.0740353
I0428 22:35:33.541467  2425 solver.cpp:253]     Train net output #0: loss = 0.0740352 (* 1 = 0.0740352 loss)
I0428 22:35:33.541522  2425 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0428 22:35:33.786105  2425 solver.cpp:237] Iteration 5100, loss = 0.111743
I0428 22:35:33.786185  2425 solver.cpp:253]     Train net output #0: loss = 0.111743 (* 1 = 0.111743 loss)
I0428 22:35:33.786207  2425 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0428 22:35:33.995741  2425 solver.cpp:237] Iteration 5200, loss = 0.0410202
I0428 22:35:33.995820  2425 solver.cpp:253]     Train net output #0: loss = 0.0410201 (* 1 = 0.0410201 loss)
I0428 22:35:33.995839  2425 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0428 22:35:34.195708  2425 solver.cpp:237] Iteration 5300, loss = 0.0428972
I0428 22:35:34.195785  2425 solver.cpp:253]     Train net output #0: loss = 0.0428971 (* 1 = 0.0428971 loss)
I0428 22:35:34.195807  2425 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0428 22:35:34.391767  2425 solver.cpp:237] Iteration 5400, loss = 0.0598668
I0428 22:35:34.391841  2425 solver.cpp:253]     Train net output #0: loss = 0.0598667 (* 1 = 0.0598667 loss)
I0428 22:35:34.391863  2425 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0428 22:35:34.564586  2425 solver.cpp:237] Iteration 5500, loss = 0.023593
I0428 22:35:34.564748  2425 solver.cpp:253]     Train net output #0: loss = 0.0235929 (* 1 = 0.0235929 loss)
I0428 22:35:34.564808  2425 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0428 22:35:34.734515  2425 solver.cpp:237] Iteration 5600, loss = 0.00837081
I0428 22:35:34.734676  2425 solver.cpp:253]     Train net output #0: loss = 0.00837074 (* 1 = 0.00837074 loss)
I0428 22:35:34.734737  2425 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0428 22:35:34.904053  2425 solver.cpp:237] Iteration 5700, loss = 0.00835101
I0428 22:35:34.904217  2425 solver.cpp:253]     Train net output #0: loss = 0.00835095 (* 1 = 0.00835095 loss)
I0428 22:35:34.904276  2425 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0428 22:35:35.073971  2425 solver.cpp:237] Iteration 5800, loss = 0.0490147
I0428 22:35:35.074127  2425 solver.cpp:253]     Train net output #0: loss = 0.0490146 (* 1 = 0.0490146 loss)
I0428 22:35:35.074187  2425 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0428 22:35:35.243763  2425 solver.cpp:237] Iteration 5900, loss = 0.0417645
I0428 22:35:35.243923  2425 solver.cpp:253]     Train net output #0: loss = 0.0417644 (* 1 = 0.0417644 loss)
I0428 22:35:35.243983  2425 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0428 22:35:35.413375  2425 solver.cpp:237] Iteration 6000, loss = 0.0161676
I0428 22:35:35.413534  2425 solver.cpp:253]     Train net output #0: loss = 0.0161675 (* 1 = 0.0161675 loss)
I0428 22:35:35.413592  2425 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0428 22:35:35.582741  2425 solver.cpp:237] Iteration 6100, loss = 0.0153659
I0428 22:35:35.582898  2425 solver.cpp:253]     Train net output #0: loss = 0.0153658 (* 1 = 0.0153658 loss)
I0428 22:35:35.582957  2425 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0428 22:35:35.753463  2425 solver.cpp:237] Iteration 6200, loss = 0.0263273
I0428 22:35:35.753623  2425 solver.cpp:253]     Train net output #0: loss = 0.0263272 (* 1 = 0.0263272 loss)
I0428 22:35:35.753682  2425 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0428 22:35:35.940150  2425 solver.cpp:237] Iteration 6300, loss = 0.0430337
I0428 22:35:35.940238  2425 solver.cpp:253]     Train net output #0: loss = 0.0430336 (* 1 = 0.0430336 loss)
I0428 22:35:35.940286  2425 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0428 22:35:36.160970  2425 solver.cpp:237] Iteration 6400, loss = 0.0478359
I0428 22:35:36.161056  2425 solver.cpp:253]     Train net output #0: loss = 0.0478358 (* 1 = 0.0478358 loss)
I0428 22:35:36.161080  2425 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0428 22:35:36.381865  2425 solver.cpp:237] Iteration 6500, loss = 0.0304203
I0428 22:35:36.381950  2425 solver.cpp:253]     Train net output #0: loss = 0.0304202 (* 1 = 0.0304202 loss)
I0428 22:35:36.381976  2425 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0428 22:35:36.600626  2425 solver.cpp:237] Iteration 6600, loss = 0.0168743
I0428 22:35:36.600703  2425 solver.cpp:253]     Train net output #0: loss = 0.0168742 (* 1 = 0.0168742 loss)
I0428 22:35:36.600726  2425 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0428 22:35:36.800611  2425 solver.cpp:237] Iteration 6700, loss = 0.0418544
I0428 22:35:36.800693  2425 solver.cpp:253]     Train net output #0: loss = 0.0418543 (* 1 = 0.0418543 loss)
I0428 22:35:36.800716  2425 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0428 22:35:37.012609  2425 solver.cpp:237] Iteration 6800, loss = 0.011317
I0428 22:35:37.012691  2425 solver.cpp:253]     Train net output #0: loss = 0.0113169 (* 1 = 0.0113169 loss)
I0428 22:35:37.012712  2425 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0428 22:35:37.221029  2425 solver.cpp:237] Iteration 6900, loss = 0.0489668
I0428 22:35:37.221117  2425 solver.cpp:253]     Train net output #0: loss = 0.0489666 (* 1 = 0.0489666 loss)
I0428 22:35:37.221143  2425 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0428 22:35:37.438978  2425 solver.cpp:237] Iteration 7000, loss = 0.0246146
I0428 22:35:37.439055  2425 solver.cpp:253]     Train net output #0: loss = 0.0246145 (* 1 = 0.0246145 loss)
I0428 22:35:37.439079  2425 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0428 22:35:37.636601  2425 solver.cpp:237] Iteration 7100, loss = 0.0367909
I0428 22:35:37.636679  2425 solver.cpp:253]     Train net output #0: loss = 0.0367907 (* 1 = 0.0367907 loss)
I0428 22:35:37.636703  2425 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0428 22:35:37.848875  2425 solver.cpp:237] Iteration 7200, loss = 0.0270976
I0428 22:35:37.848917  2425 solver.cpp:253]     Train net output #0: loss = 0.0270975 (* 1 = 0.0270975 loss)
I0428 22:35:37.848925  2425 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0428 22:35:38.068651  2425 solver.cpp:237] Iteration 7300, loss = 0.0685331
I0428 22:35:38.068727  2425 solver.cpp:253]     Train net output #0: loss = 0.068533 (* 1 = 0.068533 loss)
I0428 22:35:38.068747  2425 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0428 22:35:38.285701  2425 solver.cpp:237] Iteration 7400, loss = 0.0830491
I0428 22:35:38.285737  2425 solver.cpp:253]     Train net output #0: loss = 0.083049 (* 1 = 0.083049 loss)
I0428 22:35:38.285745  2425 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0428 22:35:38.497185  2425 solver.cpp:237] Iteration 7500, loss = 0.0108069
I0428 22:35:38.497273  2425 solver.cpp:253]     Train net output #0: loss = 0.0108068 (* 1 = 0.0108068 loss)
I0428 22:35:38.497299  2425 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0428 22:35:38.701159  2425 solver.cpp:237] Iteration 7600, loss = 0.0485386
I0428 22:35:38.701248  2425 solver.cpp:253]     Train net output #0: loss = 0.0485385 (* 1 = 0.0485385 loss)
I0428 22:35:38.701280  2425 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0428 22:35:38.934828  2425 solver.cpp:237] Iteration 7700, loss = 0.0668771
I0428 22:35:38.934864  2425 solver.cpp:253]     Train net output #0: loss = 0.066877 (* 1 = 0.066877 loss)
I0428 22:35:38.934873  2425 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0428 22:35:39.141201  2425 solver.cpp:237] Iteration 7800, loss = 0.0121631
I0428 22:35:39.141290  2425 solver.cpp:253]     Train net output #0: loss = 0.012163 (* 1 = 0.012163 loss)
I0428 22:35:39.141324  2425 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0428 22:35:39.362926  2425 solver.cpp:237] Iteration 7900, loss = 0.0408242
I0428 22:35:39.363030  2425 solver.cpp:253]     Train net output #0: loss = 0.0408241 (* 1 = 0.0408241 loss)
I0428 22:35:39.363052  2425 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0428 22:35:39.578876  2425 solver.cpp:237] Iteration 8000, loss = 0.0162679
I0428 22:35:39.578953  2425 solver.cpp:253]     Train net output #0: loss = 0.0162678 (* 1 = 0.0162678 loss)
I0428 22:35:39.578974  2425 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0428 22:35:39.794551  2425 solver.cpp:237] Iteration 8100, loss = 0.0254057
I0428 22:35:39.794713  2425 solver.cpp:253]     Train net output #0: loss = 0.0254056 (* 1 = 0.0254056 loss)
I0428 22:35:39.794771  2425 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0428 22:35:40.016891  2425 solver.cpp:237] Iteration 8200, loss = 0.0229038
I0428 22:35:40.017055  2425 solver.cpp:253]     Train net output #0: loss = 0.0229037 (* 1 = 0.0229037 loss)
I0428 22:35:40.017112  2425 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0428 22:35:40.224097  2425 solver.cpp:237] Iteration 8300, loss = 0.0453491
I0428 22:35:40.224130  2425 solver.cpp:253]     Train net output #0: loss = 0.045349 (* 1 = 0.045349 loss)
I0428 22:35:40.224139  2425 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0428 22:35:40.395859  2425 solver.cpp:237] Iteration 8400, loss = 0.0262044
I0428 22:35:40.395946  2425 solver.cpp:253]     Train net output #0: loss = 0.0262043 (* 1 = 0.0262043 loss)
I0428 22:35:40.395977  2425 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0428 22:35:40.567165  2425 solver.cpp:237] Iteration 8500, loss = 0.0757379
I0428 22:35:40.567253  2425 solver.cpp:253]     Train net output #0: loss = 0.0757378 (* 1 = 0.0757378 loss)
I0428 22:35:40.567278  2425 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0428 22:35:40.752118  2425 solver.cpp:237] Iteration 8600, loss = 0.00505653
I0428 22:35:40.752207  2425 solver.cpp:253]     Train net output #0: loss = 0.00505647 (* 1 = 0.00505647 loss)
I0428 22:35:40.752236  2425 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0428 22:35:40.923655  2425 solver.cpp:237] Iteration 8700, loss = 0.00539236
I0428 22:35:40.923740  2425 solver.cpp:253]     Train net output #0: loss = 0.00539232 (* 1 = 0.00539232 loss)
I0428 22:35:40.923771  2425 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0428 22:35:41.095120  2425 solver.cpp:237] Iteration 8800, loss = 0.0100202
I0428 22:35:41.095208  2425 solver.cpp:253]     Train net output #0: loss = 0.0100201 (* 1 = 0.0100201 loss)
I0428 22:35:41.095234  2425 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0428 22:35:41.266525  2425 solver.cpp:237] Iteration 8900, loss = 0.00471314
I0428 22:35:41.266612  2425 solver.cpp:253]     Train net output #0: loss = 0.00471313 (* 1 = 0.00471313 loss)
I0428 22:35:41.266644  2425 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0428 22:35:41.438197  2425 solver.cpp:237] Iteration 9000, loss = 0.0904016
I0428 22:35:41.438282  2425 solver.cpp:253]     Train net output #0: loss = 0.0904016 (* 1 = 0.0904016 loss)
I0428 22:35:41.438313  2425 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0428 22:35:41.609475  2425 solver.cpp:237] Iteration 9100, loss = 0.047507
I0428 22:35:41.609560  2425 solver.cpp:253]     Train net output #0: loss = 0.047507 (* 1 = 0.047507 loss)
I0428 22:35:41.609586  2425 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0428 22:35:41.781066  2425 solver.cpp:237] Iteration 9200, loss = 0.0518862
I0428 22:35:41.781152  2425 solver.cpp:253]     Train net output #0: loss = 0.0518862 (* 1 = 0.0518862 loss)
I0428 22:35:41.781183  2425 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0428 22:35:41.952110  2425 solver.cpp:237] Iteration 9300, loss = 0.0369222
I0428 22:35:41.952199  2425 solver.cpp:253]     Train net output #0: loss = 0.0369222 (* 1 = 0.0369222 loss)
I0428 22:35:41.952231  2425 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0428 22:35:42.123386  2425 solver.cpp:237] Iteration 9400, loss = 0.11149
I0428 22:35:42.123471  2425 solver.cpp:253]     Train net output #0: loss = 0.11149 (* 1 = 0.11149 loss)
I0428 22:35:42.123515  2425 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0428 22:35:42.294806  2425 solver.cpp:237] Iteration 9500, loss = 0.0261908
I0428 22:35:42.294890  2425 solver.cpp:253]     Train net output #0: loss = 0.0261908 (* 1 = 0.0261908 loss)
I0428 22:35:42.294922  2425 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0428 22:35:42.466112  2425 solver.cpp:237] Iteration 9600, loss = 0.00800798
I0428 22:35:42.466200  2425 solver.cpp:253]     Train net output #0: loss = 0.00800798 (* 1 = 0.00800798 loss)
I0428 22:35:42.466230  2425 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0428 22:35:42.638118  2425 solver.cpp:237] Iteration 9700, loss = 0.0237904
I0428 22:35:42.638201  2425 solver.cpp:253]     Train net output #0: loss = 0.0237904 (* 1 = 0.0237904 loss)
I0428 22:35:42.638227  2425 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0428 22:35:42.809516  2425 solver.cpp:237] Iteration 9800, loss = 0.0576696
I0428 22:35:42.809603  2425 solver.cpp:253]     Train net output #0: loss = 0.0576696 (* 1 = 0.0576696 loss)
I0428 22:35:42.809628  2425 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0428 22:35:43.002943  2425 solver.cpp:237] Iteration 9900, loss = 0.0370006
I0428 22:35:43.003032  2425 solver.cpp:253]     Train net output #0: loss = 0.0370006 (* 1 = 0.0370006 loss)
I0428 22:35:43.003059  2425 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0428 22:35:43.213349  2425 solver.cpp:341] Iteration 10000, Testing net (#0)
I0428 22:35:43.353986  2425 solver.cpp:409]     Test net output #0: accuracy = 0.9901
I0428 22:35:43.354038  2425 solver.cpp:409]     Test net output #1: loss = 0.0284088 (* 1 = 0.0284088 loss)
I0428 22:35:43.354849  2425 solver.cpp:237] Iteration 10000, loss = 0.0298509
I0428 22:35:43.354868  2425 solver.cpp:253]     Train net output #0: loss = 0.0298509 (* 1 = 0.0298509 loss)
I0428 22:35:43.354881  2425 sgd_solver.cpp:106] Iteration 10000, lr = 0.00594604
I0428 22:35:43.572928  2425 solver.cpp:237] Iteration 10100, loss = 0.0478617
I0428 22:35:43.573005  2425 solver.cpp:253]     Train net output #0: loss = 0.0478618 (* 1 = 0.0478618 loss)
I0428 22:35:43.573027  2425 sgd_solver.cpp:106] Iteration 10100, lr = 0.00592384
I0428 22:35:43.804934  2425 solver.cpp:237] Iteration 10200, loss = 0.0738219
I0428 22:35:43.805023  2425 solver.cpp:253]     Train net output #0: loss = 0.0738219 (* 1 = 0.0738219 loss)
I0428 22:35:43.805048  2425 sgd_solver.cpp:106] Iteration 10200, lr = 0.00590183
I0428 22:35:44.011430  2425 solver.cpp:237] Iteration 10300, loss = 0.00682715
I0428 22:35:44.011523  2425 solver.cpp:253]     Train net output #0: loss = 0.00682714 (* 1 = 0.00682714 loss)
I0428 22:35:44.011548  2425 sgd_solver.cpp:106] Iteration 10300, lr = 0.00588001
I0428 22:35:44.222062  2425 solver.cpp:237] Iteration 10400, loss = 0.0318512
I0428 22:35:44.222141  2425 solver.cpp:253]     Train net output #0: loss = 0.0318512 (* 1 = 0.0318512 loss)
I0428 22:35:44.222163  2425 sgd_solver.cpp:106] Iteration 10400, lr = 0.00585838
I0428 22:35:44.425178  2425 solver.cpp:237] Iteration 10500, loss = 0.0199984
I0428 22:35:44.425257  2425 solver.cpp:253]     Train net output #0: loss = 0.0199984 (* 1 = 0.0199984 loss)
I0428 22:35:44.425283  2425 sgd_solver.cpp:106] Iteration 10500, lr = 0.00583693
I0428 22:35:44.596210  2425 solver.cpp:237] Iteration 10600, loss = 0.0157262
I0428 22:35:44.596294  2425 solver.cpp:253]     Train net output #0: loss = 0.0157262 (* 1 = 0.0157262 loss)
I0428 22:35:44.596319  2425 sgd_solver.cpp:106] Iteration 10600, lr = 0.00581567
I0428 22:35:44.767822  2425 solver.cpp:237] Iteration 10700, loss = 0.0350115
I0428 22:35:44.767907  2425 solver.cpp:253]     Train net output #0: loss = 0.0350115 (* 1 = 0.0350115 loss)
I0428 22:35:44.767932  2425 sgd_solver.cpp:106] Iteration 10700, lr = 0.00579458
I0428 22:35:44.939043  2425 solver.cpp:237] Iteration 10800, loss = 0.0163592
I0428 22:35:44.939126  2425 solver.cpp:253]     Train net output #0: loss = 0.0163592 (* 1 = 0.0163592 loss)
I0428 22:35:44.939151  2425 sgd_solver.cpp:106] Iteration 10800, lr = 0.00577368
I0428 22:35:45.110213  2425 solver.cpp:237] Iteration 10900, loss = 0.0228552
I0428 22:35:45.110297  2425 solver.cpp:253]     Train net output #0: loss = 0.0228552 (* 1 = 0.0228552 loss)
I0428 22:35:45.110322  2425 sgd_solver.cpp:106] Iteration 10900, lr = 0.00575295
I0428 22:35:45.281224  2425 solver.cpp:237] Iteration 11000, loss = 0.0138324
I0428 22:35:45.281307  2425 solver.cpp:253]     Train net output #0: loss = 0.0138324 (* 1 = 0.0138324 loss)
I0428 22:35:45.281332  2425 sgd_solver.cpp:106] Iteration 11000, lr = 0.00573239
I0428 22:35:45.452329  2425 solver.cpp:237] Iteration 11100, loss = 0.0581136
I0428 22:35:45.452414  2425 solver.cpp:253]     Train net output #0: loss = 0.0581136 (* 1 = 0.0581136 loss)
I0428 22:35:45.452440  2425 sgd_solver.cpp:106] Iteration 11100, lr = 0.005712
I0428 22:35:45.623386  2425 solver.cpp:237] Iteration 11200, loss = 0.0819106
I0428 22:35:45.623468  2425 solver.cpp:253]     Train net output #0: loss = 0.0819106 (* 1 = 0.0819106 loss)
I0428 22:35:45.623493  2425 sgd_solver.cpp:106] Iteration 11200, lr = 0.00569178
I0428 22:35:45.794636  2425 solver.cpp:237] Iteration 11300, loss = 0.0162176
I0428 22:35:45.794720  2425 solver.cpp:253]     Train net output #0: loss = 0.0162175 (* 1 = 0.0162175 loss)
I0428 22:35:45.794746  2425 sgd_solver.cpp:106] Iteration 11300, lr = 0.00567173
I0428 22:35:45.965579  2425 solver.cpp:237] Iteration 11400, loss = 0.0322477
I0428 22:35:45.965663  2425 solver.cpp:253]     Train net output #0: loss = 0.0322477 (* 1 = 0.0322477 loss)
I0428 22:35:45.965688  2425 sgd_solver.cpp:106] Iteration 11400, lr = 0.00565184
I0428 22:35:46.136963  2425 solver.cpp:237] Iteration 11500, loss = 0.0232349
I0428 22:35:46.137048  2425 solver.cpp:253]     Train net output #0: loss = 0.0232349 (* 1 = 0.0232349 loss)
I0428 22:35:46.137074  2425 sgd_solver.cpp:106] Iteration 11500, lr = 0.00563211
I0428 22:35:46.307935  2425 solver.cpp:237] Iteration 11600, loss = 0.0131355
I0428 22:35:46.308020  2425 solver.cpp:253]     Train net output #0: loss = 0.0131355 (* 1 = 0.0131355 loss)
I0428 22:35:46.308045  2425 sgd_solver.cpp:106] Iteration 11600, lr = 0.00561254
I0428 22:35:46.479094  2425 solver.cpp:237] Iteration 11700, loss = 0.0274941
I0428 22:35:46.479176  2425 solver.cpp:253]     Train net output #0: loss = 0.0274941 (* 1 = 0.0274941 loss)
I0428 22:35:46.479202  2425 sgd_solver.cpp:106] Iteration 11700, lr = 0.00559313
I0428 22:35:46.650245  2425 solver.cpp:237] Iteration 11800, loss = 0.028703
I0428 22:35:46.650327  2425 solver.cpp:253]     Train net output #0: loss = 0.0287029 (* 1 = 0.0287029 loss)
I0428 22:35:46.650352  2425 sgd_solver.cpp:106] Iteration 11800, lr = 0.00557388
I0428 22:35:46.821048  2425 solver.cpp:237] Iteration 11900, loss = 0.018496
I0428 22:35:46.821131  2425 solver.cpp:253]     Train net output #0: loss = 0.018496 (* 1 = 0.018496 loss)
I0428 22:35:46.821156  2425 sgd_solver.cpp:106] Iteration 11900, lr = 0.00555478
I0428 22:35:46.992408  2425 solver.cpp:237] Iteration 12000, loss = 0.0105294
I0428 22:35:46.992497  2425 solver.cpp:253]     Train net output #0: loss = 0.0105293 (* 1 = 0.0105293 loss)
I0428 22:35:46.992523  2425 sgd_solver.cpp:106] Iteration 12000, lr = 0.00553583
I0428 22:35:47.163398  2425 solver.cpp:237] Iteration 12100, loss = 0.0236408
I0428 22:35:47.163482  2425 solver.cpp:253]     Train net output #0: loss = 0.0236407 (* 1 = 0.0236407 loss)
I0428 22:35:47.163507  2425 sgd_solver.cpp:106] Iteration 12100, lr = 0.00551704
I0428 22:35:47.334664  2425 solver.cpp:237] Iteration 12200, loss = 0.0132765
I0428 22:35:47.334744  2425 solver.cpp:253]     Train net output #0: loss = 0.0132764 (* 1 = 0.0132764 loss)
I0428 22:35:47.334770  2425 sgd_solver.cpp:106] Iteration 12200, lr = 0.00549839
I0428 22:35:47.505569  2425 solver.cpp:237] Iteration 12300, loss = 0.0453911
I0428 22:35:47.505652  2425 solver.cpp:253]     Train net output #0: loss = 0.0453911 (* 1 = 0.0453911 loss)
I0428 22:35:47.505677  2425 sgd_solver.cpp:106] Iteration 12300, lr = 0.00547988
I0428 22:35:47.676697  2425 solver.cpp:237] Iteration 12400, loss = 0.00505017
I0428 22:35:47.676807  2425 solver.cpp:253]     Train net output #0: loss = 0.00505014 (* 1 = 0.00505014 loss)
I0428 22:35:47.676833  2425 sgd_solver.cpp:106] Iteration 12400, lr = 0.00546153
I0428 22:35:47.847630  2425 solver.cpp:237] Iteration 12500, loss = 0.0365625
I0428 22:35:47.847713  2425 solver.cpp:253]     Train net output #0: loss = 0.0365625 (* 1 = 0.0365625 loss)
I0428 22:35:47.847738  2425 sgd_solver.cpp:106] Iteration 12500, lr = 0.00544331
I0428 22:35:48.018424  2425 solver.cpp:237] Iteration 12600, loss = 0.048822
I0428 22:35:48.018507  2425 solver.cpp:253]     Train net output #0: loss = 0.048822 (* 1 = 0.048822 loss)
I0428 22:35:48.018532  2425 sgd_solver.cpp:106] Iteration 12600, lr = 0.00542524
I0428 22:35:48.190043  2425 solver.cpp:237] Iteration 12700, loss = 0.0284807
I0428 22:35:48.190129  2425 solver.cpp:253]     Train net output #0: loss = 0.0284807 (* 1 = 0.0284807 loss)
I0428 22:35:48.190153  2425 sgd_solver.cpp:106] Iteration 12700, lr = 0.0054073
I0428 22:35:48.361362  2425 solver.cpp:237] Iteration 12800, loss = 0.00562103
I0428 22:35:48.361448  2425 solver.cpp:253]     Train net output #0: loss = 0.00562102 (* 1 = 0.00562102 loss)
I0428 22:35:48.361472  2425 sgd_solver.cpp:106] Iteration 12800, lr = 0.0053895
I0428 22:35:48.533077  2425 solver.cpp:237] Iteration 12900, loss = 0.0525672
I0428 22:35:48.533161  2425 solver.cpp:253]     Train net output #0: loss = 0.0525672 (* 1 = 0.0525672 loss)
I0428 22:35:48.533186  2425 sgd_solver.cpp:106] Iteration 12900, lr = 0.00537184
I0428 22:35:48.703794  2425 solver.cpp:237] Iteration 13000, loss = 0.0178344
I0428 22:35:48.703876  2425 solver.cpp:253]     Train net output #0: loss = 0.0178344 (* 1 = 0.0178344 loss)
I0428 22:35:48.703902  2425 sgd_solver.cpp:106] Iteration 13000, lr = 0.00535432
I0428 22:35:48.874999  2425 solver.cpp:237] Iteration 13100, loss = 0.00173353
I0428 22:35:48.875082  2425 solver.cpp:253]     Train net output #0: loss = 0.00173349 (* 1 = 0.00173349 loss)
I0428 22:35:48.875108  2425 sgd_solver.cpp:106] Iteration 13100, lr = 0.00533692
I0428 22:35:49.045516  2425 solver.cpp:237] Iteration 13200, loss = 0.0142307
I0428 22:35:49.045598  2425 solver.cpp:253]     Train net output #0: loss = 0.0142306 (* 1 = 0.0142306 loss)
I0428 22:35:49.045624  2425 sgd_solver.cpp:106] Iteration 13200, lr = 0.00531966
I0428 22:35:49.216766  2425 solver.cpp:237] Iteration 13300, loss = 0.0385843
I0428 22:35:49.216848  2425 solver.cpp:253]     Train net output #0: loss = 0.0385843 (* 1 = 0.0385843 loss)
I0428 22:35:49.216872  2425 sgd_solver.cpp:106] Iteration 13300, lr = 0.00530253
I0428 22:35:49.387840  2425 solver.cpp:237] Iteration 13400, loss = 0.0398851
I0428 22:35:49.387922  2425 solver.cpp:253]     Train net output #0: loss = 0.039885 (* 1 = 0.039885 loss)
I0428 22:35:49.387946  2425 sgd_solver.cpp:106] Iteration 13400, lr = 0.00528552
I0428 22:35:49.558959  2425 solver.cpp:237] Iteration 13500, loss = 0.0146272
I0428 22:35:49.559043  2425 solver.cpp:253]     Train net output #0: loss = 0.0146271 (* 1 = 0.0146271 loss)
I0428 22:35:49.559069  2425 sgd_solver.cpp:106] Iteration 13500, lr = 0.00526865
I0428 22:35:49.730355  2425 solver.cpp:237] Iteration 13600, loss = 0.0165148
I0428 22:35:49.730442  2425 solver.cpp:253]     Train net output #0: loss = 0.0165148 (* 1 = 0.0165148 loss)
I0428 22:35:49.730468  2425 sgd_solver.cpp:106] Iteration 13600, lr = 0.00525189
I0428 22:35:49.901371  2425 solver.cpp:237] Iteration 13700, loss = 0.0316164
I0428 22:35:49.901453  2425 solver.cpp:253]     Train net output #0: loss = 0.0316163 (* 1 = 0.0316163 loss)
I0428 22:35:49.901478  2425 sgd_solver.cpp:106] Iteration 13700, lr = 0.00523527
I0428 22:35:50.072137  2425 solver.cpp:237] Iteration 13800, loss = 0.0321413
I0428 22:35:50.072222  2425 solver.cpp:253]     Train net output #0: loss = 0.0321413 (* 1 = 0.0321413 loss)
I0428 22:35:50.072248  2425 sgd_solver.cpp:106] Iteration 13800, lr = 0.00521876
I0428 22:35:50.243063  2425 solver.cpp:237] Iteration 13900, loss = 0.0561826
I0428 22:35:50.243146  2425 solver.cpp:253]     Train net output #0: loss = 0.0561825 (* 1 = 0.0561825 loss)
I0428 22:35:50.243209  2425 sgd_solver.cpp:106] Iteration 13900, lr = 0.00520237
I0428 22:35:50.414201  2425 solver.cpp:237] Iteration 14000, loss = 0.0179849
I0428 22:35:50.414280  2425 solver.cpp:253]     Train net output #0: loss = 0.0179849 (* 1 = 0.0179849 loss)
I0428 22:35:50.414305  2425 sgd_solver.cpp:106] Iteration 14000, lr = 0.00518611
I0428 22:35:50.585440  2425 solver.cpp:237] Iteration 14100, loss = 0.0524473
I0428 22:35:50.585525  2425 solver.cpp:253]     Train net output #0: loss = 0.0524473 (* 1 = 0.0524473 loss)
I0428 22:35:50.585551  2425 sgd_solver.cpp:106] Iteration 14100, lr = 0.00516996
I0428 22:35:50.756722  2425 solver.cpp:237] Iteration 14200, loss = 0.060446
I0428 22:35:50.756806  2425 solver.cpp:253]     Train net output #0: loss = 0.0604459 (* 1 = 0.0604459 loss)
I0428 22:35:50.756831  2425 sgd_solver.cpp:106] Iteration 14200, lr = 0.00515393
I0428 22:35:50.927927  2425 solver.cpp:237] Iteration 14300, loss = 0.0204067
I0428 22:35:50.928011  2425 solver.cpp:253]     Train net output #0: loss = 0.0204067 (* 1 = 0.0204067 loss)
I0428 22:35:50.928036  2425 sgd_solver.cpp:106] Iteration 14300, lr = 0.00513801
I0428 22:35:51.098955  2425 solver.cpp:237] Iteration 14400, loss = 0.0180512
I0428 22:35:51.099040  2425 solver.cpp:253]     Train net output #0: loss = 0.0180512 (* 1 = 0.0180512 loss)
I0428 22:35:51.099064  2425 sgd_solver.cpp:106] Iteration 14400, lr = 0.00512221
I0428 22:35:51.270033  2425 solver.cpp:237] Iteration 14500, loss = 0.0165379
I0428 22:35:51.270117  2425 solver.cpp:253]     Train net output #0: loss = 0.0165378 (* 1 = 0.0165378 loss)
I0428 22:35:51.270143  2425 sgd_solver.cpp:106] Iteration 14500, lr = 0.00510653
I0428 22:35:51.441575  2425 solver.cpp:237] Iteration 14600, loss = 0.0560568
I0428 22:35:51.441655  2425 solver.cpp:253]     Train net output #0: loss = 0.0560567 (* 1 = 0.0560567 loss)
I0428 22:35:51.441679  2425 sgd_solver.cpp:106] Iteration 14600, lr = 0.00509095
I0428 22:35:51.612305  2425 solver.cpp:237] Iteration 14700, loss = 0.014435
I0428 22:35:51.623241  2425 solver.cpp:253]     Train net output #0: loss = 0.014435 (* 1 = 0.014435 loss)
I0428 22:35:51.623280  2425 sgd_solver.cpp:106] Iteration 14700, lr = 0.00507548
I0428 22:35:51.814306  2425 solver.cpp:237] Iteration 14800, loss = 0.0462182
I0428 22:35:51.814388  2425 solver.cpp:253]     Train net output #0: loss = 0.0462181 (* 1 = 0.0462181 loss)
I0428 22:35:51.814414  2425 sgd_solver.cpp:106] Iteration 14800, lr = 0.00506012
I0428 22:35:51.985350  2425 solver.cpp:237] Iteration 14900, loss = 0.0271351
I0428 22:35:51.985435  2425 solver.cpp:253]     Train net output #0: loss = 0.0271351 (* 1 = 0.0271351 loss)
I0428 22:35:51.985460  2425 sgd_solver.cpp:106] Iteration 14900, lr = 0.00504488
I0428 22:35:52.155082  2425 solver.cpp:341] Iteration 15000, Testing net (#0)
I0428 22:35:52.294299  2425 solver.cpp:409]     Test net output #0: accuracy = 0.9906
I0428 22:35:52.294371  2425 solver.cpp:409]     Test net output #1: loss = 0.0289897 (* 1 = 0.0289897 loss)
I0428 22:35:52.295729  2425 solver.cpp:237] Iteration 15000, loss = 0.0154368
I0428 22:35:52.295776  2425 solver.cpp:253]     Train net output #0: loss = 0.0154368 (* 1 = 0.0154368 loss)
I0428 22:35:52.295807  2425 sgd_solver.cpp:106] Iteration 15000, lr = 0.00502973
I0428 22:35:52.473109  2425 solver.cpp:237] Iteration 15100, loss = 0.0170538
I0428 22:35:52.473193  2425 solver.cpp:253]     Train net output #0: loss = 0.0170537 (* 1 = 0.0170537 loss)
I0428 22:35:52.473218  2425 sgd_solver.cpp:106] Iteration 15100, lr = 0.0050147
I0428 22:35:52.649857  2425 solver.cpp:237] Iteration 15200, loss = 0.0353721
I0428 22:35:52.649940  2425 solver.cpp:253]     Train net output #0: loss = 0.035372 (* 1 = 0.035372 loss)
I0428 22:35:52.649966  2425 sgd_solver.cpp:106] Iteration 15200, lr = 0.00499976
I0428 22:35:52.826694  2425 solver.cpp:237] Iteration 15300, loss = 0.00769076
I0428 22:35:52.826778  2425 solver.cpp:253]     Train net output #0: loss = 0.00769067 (* 1 = 0.00769067 loss)
I0428 22:35:52.826817  2425 sgd_solver.cpp:106] Iteration 15300, lr = 0.00498494
I0428 22:35:53.004221  2425 solver.cpp:237] Iteration 15400, loss = 0.0128804
I0428 22:35:53.004304  2425 solver.cpp:253]     Train net output #0: loss = 0.0128803 (* 1 = 0.0128803 loss)
I0428 22:35:53.004330  2425 sgd_solver.cpp:106] Iteration 15400, lr = 0.00497021
I0428 22:35:53.181437  2425 solver.cpp:237] Iteration 15500, loss = 0.029171
I0428 22:35:53.181521  2425 solver.cpp:253]     Train net output #0: loss = 0.0291709 (* 1 = 0.0291709 loss)
I0428 22:35:53.181546  2425 sgd_solver.cpp:106] Iteration 15500, lr = 0.00495558
I0428 22:35:53.358721  2425 solver.cpp:237] Iteration 15600, loss = 0.0228329
I0428 22:35:53.358803  2425 solver.cpp:253]     Train net output #0: loss = 0.0228328 (* 1 = 0.0228328 loss)
I0428 22:35:53.358829  2425 sgd_solver.cpp:106] Iteration 15600, lr = 0.00494106
I0428 22:35:53.535527  2425 solver.cpp:237] Iteration 15700, loss = 0.0270809
I0428 22:35:53.535611  2425 solver.cpp:253]     Train net output #0: loss = 0.0270808 (* 1 = 0.0270808 loss)
I0428 22:35:53.535636  2425 sgd_solver.cpp:106] Iteration 15700, lr = 0.00492663
I0428 22:35:53.713016  2425 solver.cpp:237] Iteration 15800, loss = 0.040871
I0428 22:35:53.713099  2425 solver.cpp:253]     Train net output #0: loss = 0.0408709 (* 1 = 0.0408709 loss)
I0428 22:35:53.713125  2425 sgd_solver.cpp:106] Iteration 15800, lr = 0.0049123
I0428 22:35:53.890159  2425 solver.cpp:237] Iteration 15900, loss = 0.0305685
I0428 22:35:53.890244  2425 solver.cpp:253]     Train net output #0: loss = 0.0305684 (* 1 = 0.0305684 loss)
I0428 22:35:53.890269  2425 sgd_solver.cpp:106] Iteration 15900, lr = 0.00489807
I0428 22:35:54.066962  2425 solver.cpp:237] Iteration 16000, loss = 0.0194561
I0428 22:35:54.067046  2425 solver.cpp:253]     Train net output #0: loss = 0.019456 (* 1 = 0.019456 loss)
I0428 22:35:54.067072  2425 sgd_solver.cpp:106] Iteration 16000, lr = 0.00488394
I0428 22:35:54.244174  2425 solver.cpp:237] Iteration 16100, loss = 0.0055419
I0428 22:35:54.244257  2425 solver.cpp:253]     Train net output #0: loss = 0.00554181 (* 1 = 0.00554181 loss)
I0428 22:35:54.244307  2425 sgd_solver.cpp:106] Iteration 16100, lr = 0.0048699
I0428 22:35:54.421241  2425 solver.cpp:237] Iteration 16200, loss = 0.00530093
I0428 22:35:54.421326  2425 solver.cpp:253]     Train net output #0: loss = 0.00530084 (* 1 = 0.00530084 loss)
I0428 22:35:54.421352  2425 sgd_solver.cpp:106] Iteration 16200, lr = 0.00485595
I0428 22:35:54.598130  2425 solver.cpp:237] Iteration 16300, loss = 0.00562815
I0428 22:35:54.598213  2425 solver.cpp:253]     Train net output #0: loss = 0.00562805 (* 1 = 0.00562805 loss)
I0428 22:35:54.598239  2425 sgd_solver.cpp:106] Iteration 16300, lr = 0.00484209
I0428 22:35:54.774778  2425 solver.cpp:237] Iteration 16400, loss = 0.0047184
I0428 22:35:54.774863  2425 solver.cpp:253]     Train net output #0: loss = 0.00471831 (* 1 = 0.00471831 loss)
I0428 22:35:54.774888  2425 sgd_solver.cpp:106] Iteration 16400, lr = 0.00482833
I0428 22:35:54.952025  2425 solver.cpp:237] Iteration 16500, loss = 0.0199803
I0428 22:35:54.952110  2425 solver.cpp:253]     Train net output #0: loss = 0.0199802 (* 1 = 0.0199802 loss)
I0428 22:35:54.952134  2425 sgd_solver.cpp:106] Iteration 16500, lr = 0.00481466
I0428 22:35:55.129216  2425 solver.cpp:237] Iteration 16600, loss = 0.017902
I0428 22:35:55.129302  2425 solver.cpp:253]     Train net output #0: loss = 0.0179019 (* 1 = 0.0179019 loss)
I0428 22:35:55.129326  2425 sgd_solver.cpp:106] Iteration 16600, lr = 0.00480108
I0428 22:35:55.306579  2425 solver.cpp:237] Iteration 16700, loss = 0.0392326
I0428 22:35:55.306661  2425 solver.cpp:253]     Train net output #0: loss = 0.0392326 (* 1 = 0.0392326 loss)
I0428 22:35:55.306687  2425 sgd_solver.cpp:106] Iteration 16700, lr = 0.00478759
I0428 22:35:55.488740  2425 solver.cpp:237] Iteration 16800, loss = 0.0165396
I0428 22:35:55.488828  2425 solver.cpp:253]     Train net output #0: loss = 0.0165395 (* 1 = 0.0165395 loss)
I0428 22:35:55.488854  2425 sgd_solver.cpp:106] Iteration 16800, lr = 0.00477418
I0428 22:35:55.671506  2425 solver.cpp:237] Iteration 16900, loss = 0.0488964
I0428 22:35:55.671591  2425 solver.cpp:253]     Train net output #0: loss = 0.0488963 (* 1 = 0.0488963 loss)
I0428 22:35:55.671617  2425 sgd_solver.cpp:106] Iteration 16900, lr = 0.00476086
I0428 22:35:55.854568  2425 solver.cpp:237] Iteration 17000, loss = 0.00982205
I0428 22:35:55.854653  2425 solver.cpp:253]     Train net output #0: loss = 0.00982198 (* 1 = 0.00982198 loss)
I0428 22:35:55.854678  2425 sgd_solver.cpp:106] Iteration 17000, lr = 0.00474763
I0428 22:35:56.037369  2425 solver.cpp:237] Iteration 17100, loss = 0.0137902
I0428 22:35:56.037456  2425 solver.cpp:253]     Train net output #0: loss = 0.0137902 (* 1 = 0.0137902 loss)
I0428 22:35:56.037482  2425 sgd_solver.cpp:106] Iteration 17100, lr = 0.00473449
I0428 22:35:56.220466  2425 solver.cpp:237] Iteration 17200, loss = 0.0114845
I0428 22:35:56.220551  2425 solver.cpp:253]     Train net output #0: loss = 0.0114844 (* 1 = 0.0114844 loss)
I0428 22:35:56.220576  2425 sgd_solver.cpp:106] Iteration 17200, lr = 0.00472143
I0428 22:35:56.403442  2425 solver.cpp:237] Iteration 17300, loss = 0.0879776
I0428 22:35:56.403528  2425 solver.cpp:253]     Train net output #0: loss = 0.0879775 (* 1 = 0.0879775 loss)
I0428 22:35:56.403553  2425 sgd_solver.cpp:106] Iteration 17300, lr = 0.00470845
I0428 22:35:56.587002  2425 solver.cpp:237] Iteration 17400, loss = 0.0237326
I0428 22:35:56.587086  2425 solver.cpp:253]     Train net output #0: loss = 0.0237325 (* 1 = 0.0237325 loss)
I0428 22:35:56.587111  2425 sgd_solver.cpp:106] Iteration 17400, lr = 0.00469556
I0428 22:35:56.770345  2425 solver.cpp:237] Iteration 17500, loss = 0.00877006
I0428 22:35:56.770431  2425 solver.cpp:253]     Train net output #0: loss = 0.00877001 (* 1 = 0.00877001 loss)
I0428 22:35:56.770457  2425 sgd_solver.cpp:106] Iteration 17500, lr = 0.00468274
I0428 22:35:56.953629  2425 solver.cpp:237] Iteration 17600, loss = 0.0430078
I0428 22:35:56.953714  2425 solver.cpp:253]     Train net output #0: loss = 0.0430078 (* 1 = 0.0430078 loss)
I0428 22:35:56.953739  2425 sgd_solver.cpp:106] Iteration 17600, lr = 0.00467001
I0428 22:35:57.136662  2425 solver.cpp:237] Iteration 17700, loss = 0.0333515
I0428 22:35:57.136746  2425 solver.cpp:253]     Train net output #0: loss = 0.0333514 (* 1 = 0.0333514 loss)
I0428 22:35:57.136771  2425 sgd_solver.cpp:106] Iteration 17700, lr = 0.00465736
I0428 22:35:57.319651  2425 solver.cpp:237] Iteration 17800, loss = 0.00258644
I0428 22:35:57.319738  2425 solver.cpp:253]     Train net output #0: loss = 0.0025864 (* 1 = 0.0025864 loss)
I0428 22:35:57.319766  2425 sgd_solver.cpp:106] Iteration 17800, lr = 0.00464479
I0428 22:35:57.502936  2425 solver.cpp:237] Iteration 17900, loss = 0.0200344
I0428 22:35:57.503021  2425 solver.cpp:253]     Train net output #0: loss = 0.0200344 (* 1 = 0.0200344 loss)
I0428 22:35:57.503047  2425 sgd_solver.cpp:106] Iteration 17900, lr = 0.0046323
I0428 22:35:57.692940  2425 solver.cpp:237] Iteration 18000, loss = 0.00694285
I0428 22:35:57.693029  2425 solver.cpp:253]     Train net output #0: loss = 0.00694281 (* 1 = 0.00694281 loss)
I0428 22:35:57.693054  2425 sgd_solver.cpp:106] Iteration 18000, lr = 0.00461989
I0428 22:35:57.869004  2425 solver.cpp:237] Iteration 18100, loss = 0.00794566
I0428 22:35:57.869089  2425 solver.cpp:253]     Train net output #0: loss = 0.00794561 (* 1 = 0.00794561 loss)
I0428 22:35:57.869114  2425 sgd_solver.cpp:106] Iteration 18100, lr = 0.00460755
I0428 22:35:58.046798  2425 solver.cpp:237] Iteration 18200, loss = 0.0119538
I0428 22:35:58.046882  2425 solver.cpp:253]     Train net output #0: loss = 0.0119538 (* 1 = 0.0119538 loss)
I0428 22:35:58.046908  2425 sgd_solver.cpp:106] Iteration 18200, lr = 0.00459529
I0428 22:35:58.224052  2425 solver.cpp:237] Iteration 18300, loss = 0.00473595
I0428 22:35:58.224134  2425 solver.cpp:253]     Train net output #0: loss = 0.0047359 (* 1 = 0.0047359 loss)
I0428 22:35:58.224159  2425 sgd_solver.cpp:106] Iteration 18300, lr = 0.00458311
I0428 22:35:58.401255  2425 solver.cpp:237] Iteration 18400, loss = 0.0142302
I0428 22:35:58.401350  2425 solver.cpp:253]     Train net output #0: loss = 0.0142301 (* 1 = 0.0142301 loss)
I0428 22:35:58.401379  2425 sgd_solver.cpp:106] Iteration 18400, lr = 0.004571
I0428 22:35:58.578171  2425 solver.cpp:237] Iteration 18500, loss = 0.0079312
I0428 22:35:58.578254  2425 solver.cpp:253]     Train net output #0: loss = 0.00793117 (* 1 = 0.00793117 loss)
I0428 22:35:58.578279  2425 sgd_solver.cpp:106] Iteration 18500, lr = 0.00455897
I0428 22:35:58.754914  2425 solver.cpp:237] Iteration 18600, loss = 0.0587716
I0428 22:35:58.754998  2425 solver.cpp:253]     Train net output #0: loss = 0.0587715 (* 1 = 0.0587715 loss)
I0428 22:35:58.755023  2425 sgd_solver.cpp:106] Iteration 18600, lr = 0.00454701
I0428 22:35:58.931641  2425 solver.cpp:237] Iteration 18700, loss = 0.0407639
I0428 22:35:58.931725  2425 solver.cpp:253]     Train net output #0: loss = 0.0407638 (* 1 = 0.0407638 loss)
I0428 22:35:58.931749  2425 sgd_solver.cpp:106] Iteration 18700, lr = 0.00453512
I0428 22:35:59.109392  2425 solver.cpp:237] Iteration 18800, loss = 0.00570251
I0428 22:35:59.109478  2425 solver.cpp:253]     Train net output #0: loss = 0.00570245 (* 1 = 0.00570245 loss)
I0428 22:35:59.109503  2425 sgd_solver.cpp:106] Iteration 18800, lr = 0.0045233
I0428 22:35:59.286401  2425 solver.cpp:237] Iteration 18900, loss = 0.0197301
I0428 22:35:59.286484  2425 solver.cpp:253]     Train net output #0: loss = 0.0197301 (* 1 = 0.0197301 loss)
I0428 22:35:59.286510  2425 sgd_solver.cpp:106] Iteration 18900, lr = 0.00451156
I0428 22:35:59.463510  2425 solver.cpp:237] Iteration 19000, loss = 0.0221273
I0428 22:35:59.463593  2425 solver.cpp:253]     Train net output #0: loss = 0.0221272 (* 1 = 0.0221272 loss)
I0428 22:35:59.463618  2425 sgd_solver.cpp:106] Iteration 19000, lr = 0.00449989
I0428 22:35:59.640240  2425 solver.cpp:237] Iteration 19100, loss = 0.039792
I0428 22:35:59.640326  2425 solver.cpp:253]     Train net output #0: loss = 0.0397919 (* 1 = 0.0397919 loss)
I0428 22:35:59.640350  2425 sgd_solver.cpp:106] Iteration 19100, lr = 0.00448828
I0428 22:35:59.817760  2425 solver.cpp:237] Iteration 19200, loss = 0.0113175
I0428 22:35:59.817864  2425 solver.cpp:253]     Train net output #0: loss = 0.0113174 (* 1 = 0.0113174 loss)
I0428 22:35:59.817889  2425 sgd_solver.cpp:106] Iteration 19200, lr = 0.00447675
I0428 22:35:59.995074  2425 solver.cpp:237] Iteration 19300, loss = 0.088595
I0428 22:35:59.995158  2425 solver.cpp:253]     Train net output #0: loss = 0.0885949 (* 1 = 0.0885949 loss)
I0428 22:35:59.995182  2425 sgd_solver.cpp:106] Iteration 19300, lr = 0.00446529
I0428 22:36:00.171612  2425 solver.cpp:237] Iteration 19400, loss = 0.0133864
I0428 22:36:00.171696  2425 solver.cpp:253]     Train net output #0: loss = 0.0133863 (* 1 = 0.0133863 loss)
I0428 22:36:00.171722  2425 sgd_solver.cpp:106] Iteration 19400, lr = 0.00445389
I0428 22:36:00.348150  2425 solver.cpp:237] Iteration 19500, loss = 0.0197228
I0428 22:36:00.348232  2425 solver.cpp:253]     Train net output #0: loss = 0.0197227 (* 1 = 0.0197227 loss)
I0428 22:36:00.348258  2425 sgd_solver.cpp:106] Iteration 19500, lr = 0.00444256
I0428 22:36:00.525204  2425 solver.cpp:237] Iteration 19600, loss = 0.0296978
I0428 22:36:00.525287  2425 solver.cpp:253]     Train net output #0: loss = 0.0296977 (* 1 = 0.0296977 loss)
I0428 22:36:00.525313  2425 sgd_solver.cpp:106] Iteration 19600, lr = 0.0044313
I0428 22:36:00.702467  2425 solver.cpp:237] Iteration 19700, loss = 0.0283955
I0428 22:36:00.702553  2425 solver.cpp:253]     Train net output #0: loss = 0.0283954 (* 1 = 0.0283954 loss)
I0428 22:36:00.702577  2425 sgd_solver.cpp:106] Iteration 19700, lr = 0.00442011
I0428 22:36:00.878960  2425 solver.cpp:237] Iteration 19800, loss = 0.0209566
I0428 22:36:00.879041  2425 solver.cpp:253]     Train net output #0: loss = 0.0209565 (* 1 = 0.0209565 loss)
I0428 22:36:00.879066  2425 sgd_solver.cpp:106] Iteration 19800, lr = 0.00440898
I0428 22:36:01.055923  2425 solver.cpp:237] Iteration 19900, loss = 0.020364
I0428 22:36:01.056005  2425 solver.cpp:253]     Train net output #0: loss = 0.0203639 (* 1 = 0.0203639 loss)
I0428 22:36:01.056043  2425 sgd_solver.cpp:106] Iteration 19900, lr = 0.00439791
I0428 22:36:01.231740  2425 solver.cpp:341] Iteration 20000, Testing net (#0)
I0428 22:36:01.318919  2425 solver.cpp:409]     Test net output #0: accuracy = 0.9916
I0428 22:36:01.319003  2425 solver.cpp:409]     Test net output #1: loss = 0.0264033 (* 1 = 0.0264033 loss)
I0428 22:36:01.319947  2425 solver.cpp:237] Iteration 20000, loss = 0.0452439
I0428 22:36:01.319988  2425 solver.cpp:253]     Train net output #0: loss = 0.0452439 (* 1 = 0.0452439 loss)
I0428 22:36:01.320031  2425 sgd_solver.cpp:106] Iteration 20000, lr = 0.00438691
I0428 22:36:01.497180  2425 solver.cpp:237] Iteration 20100, loss = 0.0397078
I0428 22:36:01.497221  2425 solver.cpp:253]     Train net output #0: loss = 0.0397077 (* 1 = 0.0397077 loss)
I0428 22:36:01.497231  2425 sgd_solver.cpp:106] Iteration 20100, lr = 0.00437598
I0428 22:36:01.673887  2425 solver.cpp:237] Iteration 20200, loss = 0.0190556
I0428 22:36:01.673969  2425 solver.cpp:253]     Train net output #0: loss = 0.0190556 (* 1 = 0.0190556 loss)
I0428 22:36:01.673993  2425 sgd_solver.cpp:106] Iteration 20200, lr = 0.00436511
I0428 22:36:01.850986  2425 solver.cpp:237] Iteration 20300, loss = 0.00894577
I0428 22:36:01.851027  2425 solver.cpp:253]     Train net output #0: loss = 0.0089457 (* 1 = 0.0089457 loss)
I0428 22:36:01.851035  2425 sgd_solver.cpp:106] Iteration 20300, lr = 0.0043543
I0428 22:36:02.028031  2425 solver.cpp:237] Iteration 20400, loss = 0.0433818
I0428 22:36:02.028072  2425 solver.cpp:253]     Train net output #0: loss = 0.0433817 (* 1 = 0.0433817 loss)
I0428 22:36:02.028081  2425 sgd_solver.cpp:106] Iteration 20400, lr = 0.00434355
I0428 22:36:02.205019  2425 solver.cpp:237] Iteration 20500, loss = 0.0145449
I0428 22:36:02.205101  2425 solver.cpp:253]     Train net output #0: loss = 0.0145449 (* 1 = 0.0145449 loss)
I0428 22:36:02.205127  2425 sgd_solver.cpp:106] Iteration 20500, lr = 0.00433286
I0428 22:36:02.381880  2425 solver.cpp:237] Iteration 20600, loss = 0.00271502
I0428 22:36:02.381922  2425 solver.cpp:253]     Train net output #0: loss = 0.00271495 (* 1 = 0.00271495 loss)
I0428 22:36:02.381969  2425 sgd_solver.cpp:106] Iteration 20600, lr = 0.00432224
I0428 22:36:02.558794  2425 solver.cpp:237] Iteration 20700, loss = 0.0106302
I0428 22:36:02.558836  2425 solver.cpp:253]     Train net output #0: loss = 0.0106301 (* 1 = 0.0106301 loss)
I0428 22:36:02.558846  2425 sgd_solver.cpp:106] Iteration 20700, lr = 0.00431168
I0428 22:36:02.735889  2425 solver.cpp:237] Iteration 20800, loss = 0.0333395
I0428 22:36:02.735975  2425 solver.cpp:253]     Train net output #0: loss = 0.0333394 (* 1 = 0.0333394 loss)
I0428 22:36:02.736001  2425 sgd_solver.cpp:106] Iteration 20800, lr = 0.00430117
I0428 22:36:02.913395  2425 solver.cpp:237] Iteration 20900, loss = 0.0339402
I0428 22:36:02.913478  2425 solver.cpp:253]     Train net output #0: loss = 0.0339401 (* 1 = 0.0339401 loss)
I0428 22:36:02.913504  2425 sgd_solver.cpp:106] Iteration 20900, lr = 0.00429073
I0428 22:36:03.090735  2425 solver.cpp:237] Iteration 21000, loss = 0.014912
I0428 22:36:03.090818  2425 solver.cpp:253]     Train net output #0: loss = 0.0149119 (* 1 = 0.0149119 loss)
I0428 22:36:03.090844  2425 sgd_solver.cpp:106] Iteration 21000, lr = 0.00428034
I0428 22:36:03.268621  2425 solver.cpp:237] Iteration 21100, loss = 0.00505875
I0428 22:36:03.268705  2425 solver.cpp:253]     Train net output #0: loss = 0.00505869 (* 1 = 0.00505869 loss)
I0428 22:36:03.268730  2425 sgd_solver.cpp:106] Iteration 21100, lr = 0.00427002
I0428 22:36:03.446162  2425 solver.cpp:237] Iteration 21200, loss = 0.020483
I0428 22:36:03.446247  2425 solver.cpp:253]     Train net output #0: loss = 0.020483 (* 1 = 0.020483 loss)
I0428 22:36:03.446272  2425 sgd_solver.cpp:106] Iteration 21200, lr = 0.00425975
I0428 22:36:03.623828  2425 solver.cpp:237] Iteration 21300, loss = 0.0526626
I0428 22:36:03.623913  2425 solver.cpp:253]     Train net output #0: loss = 0.0526626 (* 1 = 0.0526626 loss)
I0428 22:36:03.623937  2425 sgd_solver.cpp:106] Iteration 21300, lr = 0.00424954
I0428 22:36:03.801448  2425 solver.cpp:237] Iteration 21400, loss = 0.0202868
I0428 22:36:03.801532  2425 solver.cpp:253]     Train net output #0: loss = 0.0202868 (* 1 = 0.0202868 loss)
I0428 22:36:03.801558  2425 sgd_solver.cpp:106] Iteration 21400, lr = 0.00423938
I0428 22:36:03.979708  2425 solver.cpp:237] Iteration 21500, loss = 0.0167904
I0428 22:36:03.979789  2425 solver.cpp:253]     Train net output #0: loss = 0.0167903 (* 1 = 0.0167903 loss)
I0428 22:36:03.979815  2425 sgd_solver.cpp:106] Iteration 21500, lr = 0.00422929
I0428 22:36:04.158823  2425 solver.cpp:237] Iteration 21600, loss = 0.0280839
I0428 22:36:04.158865  2425 solver.cpp:253]     Train net output #0: loss = 0.0280838 (* 1 = 0.0280838 loss)
I0428 22:36:04.158874  2425 sgd_solver.cpp:106] Iteration 21600, lr = 0.00421924
I0428 22:36:04.337234  2425 solver.cpp:237] Iteration 21700, loss = 0.0281813
I0428 22:36:04.337271  2425 solver.cpp:253]     Train net output #0: loss = 0.0281812 (* 1 = 0.0281812 loss)
I0428 22:36:04.337281  2425 sgd_solver.cpp:106] Iteration 21700, lr = 0.00420926
I0428 22:36:04.517415  2425 solver.cpp:237] Iteration 21800, loss = 0.00744913
I0428 22:36:04.517585  2425 solver.cpp:253]     Train net output #0: loss = 0.00744906 (* 1 = 0.00744906 loss)
I0428 22:36:04.517648  2425 sgd_solver.cpp:106] Iteration 21800, lr = 0.00419933
I0428 22:36:04.695374  2425 solver.cpp:237] Iteration 21900, loss = 0.0136109
I0428 22:36:04.695547  2425 solver.cpp:253]     Train net output #0: loss = 0.0136108 (* 1 = 0.0136108 loss)
I0428 22:36:04.695610  2425 sgd_solver.cpp:106] Iteration 21900, lr = 0.00418945
I0428 22:36:04.873608  2425 solver.cpp:237] Iteration 22000, loss = 0.0160774
I0428 22:36:04.873780  2425 solver.cpp:253]     Train net output #0: loss = 0.0160774 (* 1 = 0.0160774 loss)
I0428 22:36:04.873842  2425 sgd_solver.cpp:106] Iteration 22000, lr = 0.00417963
I0428 22:36:05.051801  2425 solver.cpp:237] Iteration 22100, loss = 0.0787228
I0428 22:36:05.051967  2425 solver.cpp:253]     Train net output #0: loss = 0.0787227 (* 1 = 0.0787227 loss)
I0428 22:36:05.052048  2425 sgd_solver.cpp:106] Iteration 22100, lr = 0.00416986
I0428 22:36:05.229465  2425 solver.cpp:237] Iteration 22200, loss = 0.0084049
I0428 22:36:05.229635  2425 solver.cpp:253]     Train net output #0: loss = 0.00840483 (* 1 = 0.00840483 loss)
I0428 22:36:05.229702  2425 sgd_solver.cpp:106] Iteration 22200, lr = 0.00416014
I0428 22:36:05.410745  2425 solver.cpp:237] Iteration 22300, loss = 0.0499506
I0428 22:36:05.410920  2425 solver.cpp:253]     Train net output #0: loss = 0.0499506 (* 1 = 0.0499506 loss)
I0428 22:36:05.410984  2425 sgd_solver.cpp:106] Iteration 22300, lr = 0.00415048
I0428 22:36:05.620424  2425 solver.cpp:237] Iteration 22400, loss = 0.0516439
I0428 22:36:05.620504  2425 solver.cpp:253]     Train net output #0: loss = 0.0516439 (* 1 = 0.0516439 loss)
I0428 22:36:05.620527  2425 sgd_solver.cpp:106] Iteration 22400, lr = 0.00414087
I0428 22:36:05.811538  2425 solver.cpp:237] Iteration 22500, loss = 0.00784421
I0428 22:36:05.811700  2425 solver.cpp:253]     Train net output #0: loss = 0.00784416 (* 1 = 0.00784416 loss)
I0428 22:36:05.811758  2425 sgd_solver.cpp:106] Iteration 22500, lr = 0.00413131
I0428 22:36:05.992717  2425 solver.cpp:237] Iteration 22600, loss = 0.042172
I0428 22:36:05.992879  2425 solver.cpp:253]     Train net output #0: loss = 0.0421719 (* 1 = 0.0421719 loss)
I0428 22:36:05.992946  2425 sgd_solver.cpp:106] Iteration 22600, lr = 0.0041218
I0428 22:36:06.177166  2425 solver.cpp:237] Iteration 22700, loss = 0.0271451
I0428 22:36:06.177326  2425 solver.cpp:253]     Train net output #0: loss = 0.027145 (* 1 = 0.027145 loss)
I0428 22:36:06.177386  2425 sgd_solver.cpp:106] Iteration 22700, lr = 0.00411234
I0428 22:36:06.363040  2425 solver.cpp:237] Iteration 22800, loss = 0.00496795
I0428 22:36:06.363203  2425 solver.cpp:253]     Train net output #0: loss = 0.00496788 (* 1 = 0.00496788 loss)
I0428 22:36:06.363260  2425 sgd_solver.cpp:106] Iteration 22800, lr = 0.00410293
I0428 22:36:06.549626  2425 solver.cpp:237] Iteration 22900, loss = 0.0244881
I0428 22:36:06.549785  2425 solver.cpp:253]     Train net output #0: loss = 0.024488 (* 1 = 0.024488 loss)
I0428 22:36:06.549845  2425 sgd_solver.cpp:106] Iteration 22900, lr = 0.00409358
I0428 22:36:06.737483  2425 solver.cpp:237] Iteration 23000, loss = 0.0211835
I0428 22:36:06.737637  2425 solver.cpp:253]     Train net output #0: loss = 0.0211834 (* 1 = 0.0211834 loss)
I0428 22:36:06.737694  2425 sgd_solver.cpp:106] Iteration 23000, lr = 0.00408427
I0428 22:36:06.926661  2425 solver.cpp:237] Iteration 23100, loss = 0.0126392
I0428 22:36:06.926820  2425 solver.cpp:253]     Train net output #0: loss = 0.0126391 (* 1 = 0.0126391 loss)
I0428 22:36:06.926879  2425 sgd_solver.cpp:106] Iteration 23100, lr = 0.00407501
I0428 22:36:07.118407  2425 solver.cpp:237] Iteration 23200, loss = 0.016468
I0428 22:36:07.118562  2425 solver.cpp:253]     Train net output #0: loss = 0.0164679 (* 1 = 0.0164679 loss)
I0428 22:36:07.118623  2425 sgd_solver.cpp:106] Iteration 23200, lr = 0.0040658
I0428 22:36:07.311388  2425 solver.cpp:237] Iteration 23300, loss = 0.0672781
I0428 22:36:07.311549  2425 solver.cpp:253]     Train net output #0: loss = 0.0672781 (* 1 = 0.0672781 loss)
I0428 22:36:07.311609  2425 sgd_solver.cpp:106] Iteration 23300, lr = 0.00405664
I0428 22:36:07.505287  2425 solver.cpp:237] Iteration 23400, loss = 0.0223029
I0428 22:36:07.505452  2425 solver.cpp:253]     Train net output #0: loss = 0.0223028 (* 1 = 0.0223028 loss)
I0428 22:36:07.505514  2425 sgd_solver.cpp:106] Iteration 23400, lr = 0.00404753
I0428 22:36:07.699508  2425 solver.cpp:237] Iteration 23500, loss = 0.0337061
I0428 22:36:07.699667  2425 solver.cpp:253]     Train net output #0: loss = 0.033706 (* 1 = 0.033706 loss)
I0428 22:36:07.699723  2425 sgd_solver.cpp:106] Iteration 23500, lr = 0.00403847
I0428 22:36:07.893527  2425 solver.cpp:237] Iteration 23600, loss = 0.00348999
I0428 22:36:07.893682  2425 solver.cpp:253]     Train net output #0: loss = 0.00348992 (* 1 = 0.00348992 loss)
I0428 22:36:07.893736  2425 sgd_solver.cpp:106] Iteration 23600, lr = 0.00402945
I0428 22:36:08.087398  2425 solver.cpp:237] Iteration 23700, loss = 0.00608267
I0428 22:36:08.087553  2425 solver.cpp:253]     Train net output #0: loss = 0.00608259 (* 1 = 0.00608259 loss)
I0428 22:36:08.087611  2425 sgd_solver.cpp:106] Iteration 23700, lr = 0.00402048
I0428 22:36:08.281975  2425 solver.cpp:237] Iteration 23800, loss = 0.0112822
I0428 22:36:08.282135  2425 solver.cpp:253]     Train net output #0: loss = 0.0112821 (* 1 = 0.0112821 loss)
I0428 22:36:08.282194  2425 sgd_solver.cpp:106] Iteration 23800, lr = 0.00401155
I0428 22:36:08.475642  2425 solver.cpp:237] Iteration 23900, loss = 0.00738654
I0428 22:36:08.475800  2425 solver.cpp:253]     Train net output #0: loss = 0.00738645 (* 1 = 0.00738645 loss)
I0428 22:36:08.475860  2425 sgd_solver.cpp:106] Iteration 23900, lr = 0.00400267
I0428 22:36:08.672175  2425 solver.cpp:237] Iteration 24000, loss = 0.0418581
I0428 22:36:08.672332  2425 solver.cpp:253]     Train net output #0: loss = 0.041858 (* 1 = 0.041858 loss)
I0428 22:36:08.672389  2425 sgd_solver.cpp:106] Iteration 24000, lr = 0.00399384
I0428 22:36:08.868214  2425 solver.cpp:237] Iteration 24100, loss = 0.0228449
I0428 22:36:08.868371  2425 solver.cpp:253]     Train net output #0: loss = 0.0228448 (* 1 = 0.0228448 loss)
I0428 22:36:08.868430  2425 sgd_solver.cpp:106] Iteration 24100, lr = 0.00398505
I0428 22:36:09.064084  2425 solver.cpp:237] Iteration 24200, loss = 0.0594303
I0428 22:36:09.064241  2425 solver.cpp:253]     Train net output #0: loss = 0.0594302 (* 1 = 0.0594302 loss)
I0428 22:36:09.064297  2425 sgd_solver.cpp:106] Iteration 24200, lr = 0.00397631
I0428 22:36:09.260181  2425 solver.cpp:237] Iteration 24300, loss = 0.0129103
I0428 22:36:09.260337  2425 solver.cpp:253]     Train net output #0: loss = 0.0129103 (* 1 = 0.0129103 loss)
I0428 22:36:09.260397  2425 sgd_solver.cpp:106] Iteration 24300, lr = 0.00396761
I0428 22:36:09.456025  2425 solver.cpp:237] Iteration 24400, loss = 0.0588539
I0428 22:36:09.456198  2425 solver.cpp:253]     Train net output #0: loss = 0.0588538 (* 1 = 0.0588538 loss)
I0428 22:36:09.456261  2425 sgd_solver.cpp:106] Iteration 24400, lr = 0.00395896
I0428 22:36:09.652281  2425 solver.cpp:237] Iteration 24500, loss = 0.00913558
I0428 22:36:09.652442  2425 solver.cpp:253]     Train net output #0: loss = 0.0091355 (* 1 = 0.0091355 loss)
I0428 22:36:09.652500  2425 sgd_solver.cpp:106] Iteration 24500, lr = 0.00395035
I0428 22:36:09.848498  2425 solver.cpp:237] Iteration 24600, loss = 0.0216706
I0428 22:36:09.848657  2425 solver.cpp:253]     Train net output #0: loss = 0.0216705 (* 1 = 0.0216705 loss)
I0428 22:36:09.848716  2425 sgd_solver.cpp:106] Iteration 24600, lr = 0.00394178
I0428 22:36:10.044755  2425 solver.cpp:237] Iteration 24700, loss = 0.019877
I0428 22:36:10.044921  2425 solver.cpp:253]     Train net output #0: loss = 0.0198769 (* 1 = 0.0198769 loss)
I0428 22:36:10.044984  2425 sgd_solver.cpp:106] Iteration 24700, lr = 0.00393326
I0428 22:36:10.241173  2425 solver.cpp:237] Iteration 24800, loss = 0.0260724
I0428 22:36:10.241323  2425 solver.cpp:253]     Train net output #0: loss = 0.0260723 (* 1 = 0.0260723 loss)
I0428 22:36:10.241379  2425 sgd_solver.cpp:106] Iteration 24800, lr = 0.00392478
I0428 22:36:10.437626  2425 solver.cpp:237] Iteration 24900, loss = 0.0153252
I0428 22:36:10.437783  2425 solver.cpp:253]     Train net output #0: loss = 0.0153251 (* 1 = 0.0153251 loss)
I0428 22:36:10.437841  2425 sgd_solver.cpp:106] Iteration 24900, lr = 0.00391634
I0428 22:36:10.632254  2425 solver.cpp:341] Iteration 25000, Testing net (#0)
I0428 22:36:10.729804  2425 solver.cpp:409]     Test net output #0: accuracy = 0.9909
I0428 22:36:10.729957  2425 solver.cpp:409]     Test net output #1: loss = 0.0270176 (* 1 = 0.0270176 loss)
I0428 22:36:10.731011  2425 solver.cpp:237] Iteration 25000, loss = 0.010525
I0428 22:36:10.731091  2425 solver.cpp:253]     Train net output #0: loss = 0.0105249 (* 1 = 0.0105249 loss)
I0428 22:36:10.731154  2425 sgd_solver.cpp:106] Iteration 25000, lr = 0.00390795
I0428 22:36:10.920378  2425 solver.cpp:237] Iteration 25100, loss = 0.0355733
I0428 22:36:10.920560  2425 solver.cpp:253]     Train net output #0: loss = 0.0355732 (* 1 = 0.0355732 loss)
I0428 22:36:10.920619  2425 sgd_solver.cpp:106] Iteration 25100, lr = 0.0038996
I0428 22:36:11.109992  2425 solver.cpp:237] Iteration 25200, loss = 0.065872
I0428 22:36:11.110136  2425 solver.cpp:253]     Train net output #0: loss = 0.0658719 (* 1 = 0.0658719 loss)
I0428 22:36:11.110195  2425 sgd_solver.cpp:106] Iteration 25200, lr = 0.00389128
I0428 22:36:11.298699  2425 solver.cpp:237] Iteration 25300, loss = 0.00312713
I0428 22:36:11.298854  2425 solver.cpp:253]     Train net output #0: loss = 0.00312702 (* 1 = 0.00312702 loss)
I0428 22:36:11.298910  2425 sgd_solver.cpp:106] Iteration 25300, lr = 0.00388301
I0428 22:36:11.488250  2425 solver.cpp:237] Iteration 25400, loss = 0.0240218
I0428 22:36:11.488410  2425 solver.cpp:253]     Train net output #0: loss = 0.0240217 (* 1 = 0.0240217 loss)
I0428 22:36:11.488471  2425 sgd_solver.cpp:106] Iteration 25400, lr = 0.00387478
I0428 22:36:11.677206  2425 solver.cpp:237] Iteration 25500, loss = 0.0109018
I0428 22:36:11.677361  2425 solver.cpp:253]     Train net output #0: loss = 0.0109017 (* 1 = 0.0109017 loss)
I0428 22:36:11.677419  2425 sgd_solver.cpp:106] Iteration 25500, lr = 0.0038666
I0428 22:36:11.866524  2425 solver.cpp:237] Iteration 25600, loss = 0.0215456
I0428 22:36:11.866679  2425 solver.cpp:253]     Train net output #0: loss = 0.0215455 (* 1 = 0.0215455 loss)
I0428 22:36:11.866737  2425 sgd_solver.cpp:106] Iteration 25600, lr = 0.00385845
I0428 22:36:12.056098  2425 solver.cpp:237] Iteration 25700, loss = 0.0161742
I0428 22:36:12.056259  2425 solver.cpp:253]     Train net output #0: loss = 0.0161742 (* 1 = 0.0161742 loss)
I0428 22:36:12.056316  2425 sgd_solver.cpp:106] Iteration 25700, lr = 0.00385034
I0428 22:36:12.246059  2425 solver.cpp:237] Iteration 25800, loss = 0.0145417
I0428 22:36:12.246212  2425 solver.cpp:253]     Train net output #0: loss = 0.0145417 (* 1 = 0.0145417 loss)
I0428 22:36:12.246285  2425 sgd_solver.cpp:106] Iteration 25800, lr = 0.00384227
I0428 22:36:12.435675  2425 solver.cpp:237] Iteration 25900, loss = 0.0149289
I0428 22:36:12.435835  2425 solver.cpp:253]     Train net output #0: loss = 0.0149288 (* 1 = 0.0149288 loss)
I0428 22:36:12.435894  2425 sgd_solver.cpp:106] Iteration 25900, lr = 0.00383424
I0428 22:36:12.624785  2425 solver.cpp:237] Iteration 26000, loss = 0.00643123
I0428 22:36:12.624963  2425 solver.cpp:253]     Train net output #0: loss = 0.00643113 (* 1 = 0.00643113 loss)
I0428 22:36:12.625025  2425 sgd_solver.cpp:106] Iteration 26000, lr = 0.00382625
I0428 22:36:12.813630  2425 solver.cpp:237] Iteration 26100, loss = 0.0282169
I0428 22:36:12.813666  2425 solver.cpp:253]     Train net output #0: loss = 0.0282168 (* 1 = 0.0282168 loss)
I0428 22:36:12.813675  2425 sgd_solver.cpp:106] Iteration 26100, lr = 0.0038183
I0428 22:36:13.003255  2425 solver.cpp:237] Iteration 26200, loss = 0.0597228
I0428 22:36:13.003417  2425 solver.cpp:253]     Train net output #0: loss = 0.0597227 (* 1 = 0.0597227 loss)
I0428 22:36:13.003478  2425 sgd_solver.cpp:106] Iteration 26200, lr = 0.00381038
I0428 22:36:13.192701  2425 solver.cpp:237] Iteration 26300, loss = 0.012516
I0428 22:36:13.192862  2425 solver.cpp:253]     Train net output #0: loss = 0.0125159 (* 1 = 0.0125159 loss)
I0428 22:36:13.192929  2425 sgd_solver.cpp:106] Iteration 26300, lr = 0.00380251
I0428 22:36:13.381937  2425 solver.cpp:237] Iteration 26400, loss = 0.0203962
I0428 22:36:13.382094  2425 solver.cpp:253]     Train net output #0: loss = 0.0203961 (* 1 = 0.0203961 loss)
I0428 22:36:13.382154  2425 sgd_solver.cpp:106] Iteration 26400, lr = 0.00379467
I0428 22:36:13.571620  2425 solver.cpp:237] Iteration 26500, loss = 0.0402442
I0428 22:36:13.571775  2425 solver.cpp:253]     Train net output #0: loss = 0.0402441 (* 1 = 0.0402441 loss)
I0428 22:36:13.571830  2425 sgd_solver.cpp:106] Iteration 26500, lr = 0.00378687
I0428 22:36:13.761577  2425 solver.cpp:237] Iteration 26600, loss = 0.0220128
I0428 22:36:13.761739  2425 solver.cpp:253]     Train net output #0: loss = 0.0220127 (* 1 = 0.0220127 loss)
I0428 22:36:13.761824  2425 sgd_solver.cpp:106] Iteration 26600, lr = 0.00377911
I0428 22:36:13.951462  2425 solver.cpp:237] Iteration 26700, loss = 0.0247722
I0428 22:36:13.951619  2425 solver.cpp:253]     Train net output #0: loss = 0.0247721 (* 1 = 0.0247721 loss)
I0428 22:36:13.951680  2425 sgd_solver.cpp:106] Iteration 26700, lr = 0.00377138
I0428 22:36:14.140591  2425 solver.cpp:237] Iteration 26800, loss = 0.0312593
I0428 22:36:14.140750  2425 solver.cpp:253]     Train net output #0: loss = 0.0312592 (* 1 = 0.0312592 loss)
I0428 22:36:14.140810  2425 sgd_solver.cpp:106] Iteration 26800, lr = 0.00376369
I0428 22:36:14.330206  2425 solver.cpp:237] Iteration 26900, loss = 0.0256423
I0428 22:36:14.330360  2425 solver.cpp:253]     Train net output #0: loss = 0.0256422 (* 1 = 0.0256422 loss)
I0428 22:36:14.330418  2425 sgd_solver.cpp:106] Iteration 26900, lr = 0.00375604
I0428 22:36:14.520100  2425 solver.cpp:237] Iteration 27000, loss = 0.0120078
I0428 22:36:14.520258  2425 solver.cpp:253]     Train net output #0: loss = 0.0120078 (* 1 = 0.0120078 loss)
I0428 22:36:14.520316  2425 sgd_solver.cpp:106] Iteration 27000, lr = 0.00374842
I0428 22:36:14.709796  2425 solver.cpp:237] Iteration 27100, loss = 0.0135533
I0428 22:36:14.709952  2425 solver.cpp:253]     Train net output #0: loss = 0.0135533 (* 1 = 0.0135533 loss)
I0428 22:36:14.710007  2425 sgd_solver.cpp:106] Iteration 27100, lr = 0.00374084
I0428 22:36:14.899049  2425 solver.cpp:237] Iteration 27200, loss = 0.0151066
I0428 22:36:14.899200  2425 solver.cpp:253]     Train net output #0: loss = 0.0151065 (* 1 = 0.0151065 loss)
I0428 22:36:14.899260  2425 sgd_solver.cpp:106] Iteration 27200, lr = 0.0037333
I0428 22:36:15.088973  2425 solver.cpp:237] Iteration 27300, loss = 0.0500582
I0428 22:36:15.089131  2425 solver.cpp:253]     Train net output #0: loss = 0.0500581 (* 1 = 0.0500581 loss)
I0428 22:36:15.089191  2425 sgd_solver.cpp:106] Iteration 27300, lr = 0.00372579
I0428 22:36:15.278687  2425 solver.cpp:237] Iteration 27400, loss = 0.0109356
I0428 22:36:15.278846  2425 solver.cpp:253]     Train net output #0: loss = 0.0109356 (* 1 = 0.0109356 loss)
I0428 22:36:15.278905  2425 sgd_solver.cpp:106] Iteration 27400, lr = 0.00371832
I0428 22:36:15.469039  2425 solver.cpp:237] Iteration 27500, loss = 0.0330189
I0428 22:36:15.469202  2425 solver.cpp:253]     Train net output #0: loss = 0.0330188 (* 1 = 0.0330188 loss)
I0428 22:36:15.469259  2425 sgd_solver.cpp:106] Iteration 27500, lr = 0.00371088
I0428 22:36:15.658136  2425 solver.cpp:237] Iteration 27600, loss = 0.0324272
I0428 22:36:15.658294  2425 solver.cpp:253]     Train net output #0: loss = 0.0324272 (* 1 = 0.0324272 loss)
I0428 22:36:15.658352  2425 sgd_solver.cpp:106] Iteration 27600, lr = 0.00370347
I0428 22:36:15.847661  2425 solver.cpp:237] Iteration 27700, loss = 0.0184231
I0428 22:36:15.847817  2425 solver.cpp:253]     Train net output #0: loss = 0.018423 (* 1 = 0.018423 loss)
I0428 22:36:15.847875  2425 sgd_solver.cpp:106] Iteration 27700, lr = 0.0036961
I0428 22:36:16.037019  2425 solver.cpp:237] Iteration 27800, loss = 0.011415
I0428 22:36:16.037174  2425 solver.cpp:253]     Train net output #0: loss = 0.0114149 (* 1 = 0.0114149 loss)
I0428 22:36:16.037235  2425 sgd_solver.cpp:106] Iteration 27800, lr = 0.00368877
I0428 22:36:16.226789  2425 solver.cpp:237] Iteration 27900, loss = 0.0393595
I0428 22:36:16.226948  2425 solver.cpp:253]     Train net output #0: loss = 0.0393594 (* 1 = 0.0393594 loss)
I0428 22:36:16.227008  2425 sgd_solver.cpp:106] Iteration 27900, lr = 0.00368146
I0428 22:36:16.446965  2425 solver.cpp:237] Iteration 28000, loss = 0.0141033
I0428 22:36:16.447116  2425 solver.cpp:253]     Train net output #0: loss = 0.0141032 (* 1 = 0.0141032 loss)
I0428 22:36:16.447172  2425 sgd_solver.cpp:106] Iteration 28000, lr = 0.0036742
I0428 22:36:16.642019  2425 solver.cpp:237] Iteration 28100, loss = 0.00318228
I0428 22:36:16.642180  2425 solver.cpp:253]     Train net output #0: loss = 0.00318222 (* 1 = 0.00318222 loss)
I0428 22:36:16.642238  2425 sgd_solver.cpp:106] Iteration 28100, lr = 0.00366696
I0428 22:36:16.831310  2425 solver.cpp:237] Iteration 28200, loss = 0.00831621
I0428 22:36:16.831470  2425 solver.cpp:253]     Train net output #0: loss = 0.00831615 (* 1 = 0.00831615 loss)
I0428 22:36:16.831527  2425 sgd_solver.cpp:106] Iteration 28200, lr = 0.00365976
I0428 22:36:17.051116  2425 solver.cpp:237] Iteration 28300, loss = 0.0300408
I0428 22:36:17.051203  2425 solver.cpp:253]     Train net output #0: loss = 0.0300408 (* 1 = 0.0300408 loss)
I0428 22:36:17.051228  2425 sgd_solver.cpp:106] Iteration 28300, lr = 0.00365259
I0428 22:36:17.291654  2425 solver.cpp:237] Iteration 28400, loss = 0.0247709
I0428 22:36:17.291733  2425 solver.cpp:253]     Train net output #0: loss = 0.0247709 (* 1 = 0.0247709 loss)
I0428 22:36:17.291754  2425 sgd_solver.cpp:106] Iteration 28400, lr = 0.00364545
I0428 22:36:17.533066  2425 solver.cpp:237] Iteration 28500, loss = 0.0161523
I0428 22:36:17.533144  2425 solver.cpp:253]     Train net output #0: loss = 0.0161523 (* 1 = 0.0161523 loss)
I0428 22:36:17.533165  2425 sgd_solver.cpp:106] Iteration 28500, lr = 0.00363835
I0428 22:36:17.775081  2425 solver.cpp:237] Iteration 28600, loss = 0.00890181
I0428 22:36:17.775159  2425 solver.cpp:253]     Train net output #0: loss = 0.00890176 (* 1 = 0.00890176 loss)
I0428 22:36:17.775178  2425 sgd_solver.cpp:106] Iteration 28600, lr = 0.00363128
I0428 22:36:18.008859  2425 solver.cpp:237] Iteration 28700, loss = 0.0202296
I0428 22:36:18.008946  2425 solver.cpp:253]     Train net output #0: loss = 0.0202296 (* 1 = 0.0202296 loss)
I0428 22:36:18.008970  2425 sgd_solver.cpp:106] Iteration 28700, lr = 0.00362424
I0428 22:36:18.210338  2425 solver.cpp:237] Iteration 28800, loss = 0.0235193
I0428 22:36:18.210429  2425 solver.cpp:253]     Train net output #0: loss = 0.0235193 (* 1 = 0.0235193 loss)
I0428 22:36:18.210454  2425 sgd_solver.cpp:106] Iteration 28800, lr = 0.00361723
I0428 22:36:18.438776  2425 solver.cpp:237] Iteration 28900, loss = 0.0331726
I0428 22:36:18.438876  2425 solver.cpp:253]     Train net output #0: loss = 0.0331725 (* 1 = 0.0331725 loss)
I0428 22:36:18.438905  2425 sgd_solver.cpp:106] Iteration 28900, lr = 0.00361025
I0428 22:36:18.661002  2425 solver.cpp:237] Iteration 29000, loss = 0.0204486
I0428 22:36:18.661082  2425 solver.cpp:253]     Train net output #0: loss = 0.0204485 (* 1 = 0.0204485 loss)
I0428 22:36:18.661103  2425 sgd_solver.cpp:106] Iteration 29000, lr = 0.00360331
I0428 22:36:18.895093  2425 solver.cpp:237] Iteration 29100, loss = 0.0361091
I0428 22:36:18.895170  2425 solver.cpp:253]     Train net output #0: loss = 0.0361091 (* 1 = 0.0361091 loss)
I0428 22:36:18.895192  2425 sgd_solver.cpp:106] Iteration 29100, lr = 0.0035964
I0428 22:36:19.126986  2425 solver.cpp:237] Iteration 29200, loss = 0.0549035
I0428 22:36:19.127075  2425 solver.cpp:253]     Train net output #0: loss = 0.0549034 (* 1 = 0.0549034 loss)
I0428 22:36:19.127101  2425 sgd_solver.cpp:106] Iteration 29200, lr = 0.00358951
I0428 22:36:19.348356  2425 solver.cpp:237] Iteration 29300, loss = 0.00787762
I0428 22:36:19.348402  2425 solver.cpp:253]     Train net output #0: loss = 0.00787758 (* 1 = 0.00787758 loss)
I0428 22:36:19.348410  2425 sgd_solver.cpp:106] Iteration 29300, lr = 0.00358266
I0428 22:36:19.592984  2425 solver.cpp:237] Iteration 29400, loss = 0.0143483
I0428 22:36:19.593067  2425 solver.cpp:253]     Train net output #0: loss = 0.0143482 (* 1 = 0.0143482 loss)
I0428 22:36:19.593091  2425 sgd_solver.cpp:106] Iteration 29400, lr = 0.00357584
I0428 22:36:19.827085  2425 solver.cpp:237] Iteration 29500, loss = 0.0052274
I0428 22:36:19.827165  2425 solver.cpp:253]     Train net output #0: loss = 0.00522737 (* 1 = 0.00522737 loss)
I0428 22:36:19.827188  2425 sgd_solver.cpp:106] Iteration 29500, lr = 0.00356905
I0428 22:36:20.069787  2425 solver.cpp:237] Iteration 29600, loss = 0.0172457
I0428 22:36:20.069883  2425 solver.cpp:253]     Train net output #0: loss = 0.0172457 (* 1 = 0.0172457 loss)
I0428 22:36:20.069912  2425 sgd_solver.cpp:106] Iteration 29600, lr = 0.00356228
I0428 22:36:20.305218  2425 solver.cpp:237] Iteration 29700, loss = 0.00909641
I0428 22:36:20.305307  2425 solver.cpp:253]     Train net output #0: loss = 0.00909638 (* 1 = 0.00909638 loss)
I0428 22:36:20.305333  2425 sgd_solver.cpp:106] Iteration 29700, lr = 0.00355555
I0428 22:36:20.547664  2425 solver.cpp:237] Iteration 29800, loss = 0.0355522
I0428 22:36:20.547744  2425 solver.cpp:253]     Train net output #0: loss = 0.0355522 (* 1 = 0.0355522 loss)
I0428 22:36:20.547767  2425 sgd_solver.cpp:106] Iteration 29800, lr = 0.00354885
I0428 22:36:20.789193  2425 solver.cpp:237] Iteration 29900, loss = 0.0241455
I0428 22:36:20.789279  2425 solver.cpp:253]     Train net output #0: loss = 0.0241455 (* 1 = 0.0241455 loss)
I0428 22:36:20.789304  2425 sgd_solver.cpp:106] Iteration 29900, lr = 0.00354218
I0428 22:36:21.021263  2425 solver.cpp:341] Iteration 30000, Testing net (#0)
I0428 22:36:21.178586  2425 solver.cpp:409]     Test net output #0: accuracy = 0.9906
I0428 22:36:21.178663  2425 solver.cpp:409]     Test net output #1: loss = 0.0277821 (* 1 = 0.0277821 loss)
I0428 22:36:21.179694  2425 solver.cpp:237] Iteration 30000, loss = 0.00997893
I0428 22:36:21.179730  2425 solver.cpp:253]     Train net output #0: loss = 0.00997891 (* 1 = 0.00997891 loss)
I0428 22:36:21.179750  2425 sgd_solver.cpp:106] Iteration 30000, lr = 0.00353553
I0428 22:36:21.467876  2425 solver.cpp:237] Iteration 30100, loss = 0.0334192
I0428 22:36:21.467967  2425 solver.cpp:253]     Train net output #0: loss = 0.0334192 (* 1 = 0.0334192 loss)
I0428 22:36:21.467993  2425 sgd_solver.cpp:106] Iteration 30100, lr = 0.00352892
I0428 22:36:21.699093  2425 solver.cpp:237] Iteration 30200, loss = 0.0786784
I0428 22:36:21.699296  2425 solver.cpp:253]     Train net output #0: loss = 0.0786783 (* 1 = 0.0786783 loss)
I0428 22:36:21.699318  2425 sgd_solver.cpp:106] Iteration 30200, lr = 0.00352233
I0428 22:36:21.949239  2425 solver.cpp:237] Iteration 30300, loss = 0.00631459
I0428 22:36:21.949332  2425 solver.cpp:253]     Train net output #0: loss = 0.00631456 (* 1 = 0.00631456 loss)
I0428 22:36:21.949373  2425 sgd_solver.cpp:106] Iteration 30300, lr = 0.00351578
I0428 22:36:22.169196  2425 solver.cpp:237] Iteration 30400, loss = 0.00936997
I0428 22:36:22.169287  2425 solver.cpp:253]     Train net output #0: loss = 0.00936993 (* 1 = 0.00936993 loss)
I0428 22:36:22.169312  2425 sgd_solver.cpp:106] Iteration 30400, lr = 0.00350925
I0428 22:36:22.411133  2425 solver.cpp:237] Iteration 30500, loss = 0.053542
I0428 22:36:22.411211  2425 solver.cpp:253]     Train net output #0: loss = 0.053542 (* 1 = 0.053542 loss)
I0428 22:36:22.411232  2425 sgd_solver.cpp:106] Iteration 30500, lr = 0.00350275
I0428 22:36:22.652737  2425 solver.cpp:237] Iteration 30600, loss = 0.0232906
I0428 22:36:22.652909  2425 solver.cpp:253]     Train net output #0: loss = 0.0232905 (* 1 = 0.0232905 loss)
I0428 22:36:22.652976  2425 sgd_solver.cpp:106] Iteration 30600, lr = 0.00349627
I0428 22:36:22.911089  2425 solver.cpp:237] Iteration 30700, loss = 0.0251608
I0428 22:36:22.911170  2425 solver.cpp:253]     Train net output #0: loss = 0.0251608 (* 1 = 0.0251608 loss)
I0428 22:36:22.911190  2425 sgd_solver.cpp:106] Iteration 30700, lr = 0.00348983
I0428 22:36:23.143141  2425 solver.cpp:237] Iteration 30800, loss = 0.0483683
I0428 22:36:23.143218  2425 solver.cpp:253]     Train net output #0: loss = 0.0483683 (* 1 = 0.0483683 loss)
I0428 22:36:23.143239  2425 sgd_solver.cpp:106] Iteration 30800, lr = 0.00348341
I0428 22:36:23.377300  2425 solver.cpp:237] Iteration 30900, loss = 0.0384435
I0428 22:36:23.377391  2425 solver.cpp:253]     Train net output #0: loss = 0.0384435 (* 1 = 0.0384435 loss)
I0428 22:36:23.377416  2425 sgd_solver.cpp:106] Iteration 30900, lr = 0.00347702
I0428 22:36:23.621033  2425 solver.cpp:237] Iteration 31000, loss = 0.0240889
I0428 22:36:23.621114  2425 solver.cpp:253]     Train net output #0: loss = 0.0240888 (* 1 = 0.0240888 loss)
I0428 22:36:23.621135  2425 sgd_solver.cpp:106] Iteration 31000, lr = 0.00347066
I0428 22:36:23.860699  2425 solver.cpp:237] Iteration 31100, loss = 0.00707611
I0428 22:36:23.860791  2425 solver.cpp:253]     Train net output #0: loss = 0.00707611 (* 1 = 0.00707611 loss)
I0428 22:36:23.860817  2425 sgd_solver.cpp:106] Iteration 31100, lr = 0.00346433
I0428 22:36:24.103970  2425 solver.cpp:237] Iteration 31200, loss = 0.0102962
I0428 22:36:24.104049  2425 solver.cpp:253]     Train net output #0: loss = 0.0102961 (* 1 = 0.0102961 loss)
I0428 22:36:24.104068  2425 sgd_solver.cpp:106] Iteration 31200, lr = 0.00345802
I0428 22:36:24.375141  2425 solver.cpp:237] Iteration 31300, loss = 0.00870777
I0428 22:36:24.375222  2425 solver.cpp:253]     Train net output #0: loss = 0.00870774 (* 1 = 0.00870774 loss)
I0428 22:36:24.375242  2425 sgd_solver.cpp:106] Iteration 31300, lr = 0.00345174
I0428 22:36:24.605013  2425 solver.cpp:237] Iteration 31400, loss = 0.00744107
I0428 22:36:24.605090  2425 solver.cpp:253]     Train net output #0: loss = 0.00744104 (* 1 = 0.00744104 loss)
I0428 22:36:24.605111  2425 sgd_solver.cpp:106] Iteration 31400, lr = 0.00344548
I0428 22:36:24.828980  2425 solver.cpp:237] Iteration 31500, loss = 0.0362896
I0428 22:36:24.829059  2425 solver.cpp:253]     Train net output #0: loss = 0.0362895 (* 1 = 0.0362895 loss)
I0428 22:36:24.829082  2425 sgd_solver.cpp:106] Iteration 31500, lr = 0.00343925
I0428 22:36:25.057235  2425 solver.cpp:237] Iteration 31600, loss = 0.0440562
I0428 22:36:25.057324  2425 solver.cpp:253]     Train net output #0: loss = 0.0440561 (* 1 = 0.0440561 loss)
I0428 22:36:25.057350  2425 sgd_solver.cpp:106] Iteration 31600, lr = 0.00343305
I0428 22:36:25.293007  2425 solver.cpp:237] Iteration 31700, loss = 0.0211326
I0428 22:36:25.293087  2425 solver.cpp:253]     Train net output #0: loss = 0.0211325 (* 1 = 0.0211325 loss)
I0428 22:36:25.293131  2425 sgd_solver.cpp:106] Iteration 31700, lr = 0.00342687
I0428 22:36:25.525204  2425 solver.cpp:237] Iteration 31800, loss = 0.0249818
I0428 22:36:25.525295  2425 solver.cpp:253]     Train net output #0: loss = 0.0249817 (* 1 = 0.0249817 loss)
I0428 22:36:25.525336  2425 sgd_solver.cpp:106] Iteration 31800, lr = 0.00342072
I0428 22:36:25.741209  2425 solver.cpp:237] Iteration 31900, loss = 0.0317855
I0428 22:36:25.741297  2425 solver.cpp:253]     Train net output #0: loss = 0.0317855 (* 1 = 0.0317855 loss)
I0428 22:36:25.741323  2425 sgd_solver.cpp:106] Iteration 31900, lr = 0.0034146
I0428 22:36:25.961206  2425 solver.cpp:237] Iteration 32000, loss = 0.0177644
I0428 22:36:25.961292  2425 solver.cpp:253]     Train net output #0: loss = 0.0177644 (* 1 = 0.0177644 loss)
I0428 22:36:25.961319  2425 sgd_solver.cpp:106] Iteration 32000, lr = 0.0034085
I0428 22:36:26.194876  2425 solver.cpp:237] Iteration 32100, loss = 0.0148991
I0428 22:36:26.194965  2425 solver.cpp:253]     Train net output #0: loss = 0.0148991 (* 1 = 0.0148991 loss)
I0428 22:36:26.194990  2425 sgd_solver.cpp:106] Iteration 32100, lr = 0.00340242
I0428 22:36:26.436991  2425 solver.cpp:237] Iteration 32200, loss = 0.0135099
I0428 22:36:26.437037  2425 solver.cpp:253]     Train net output #0: loss = 0.0135099 (* 1 = 0.0135099 loss)
I0428 22:36:26.437047  2425 sgd_solver.cpp:106] Iteration 32200, lr = 0.00339637
I0428 22:36:26.684980  2425 solver.cpp:237] Iteration 32300, loss = 0.0336832
I0428 22:36:26.685147  2425 solver.cpp:253]     Train net output #0: loss = 0.0336832 (* 1 = 0.0336832 loss)
I0428 22:36:26.685207  2425 sgd_solver.cpp:106] Iteration 32300, lr = 0.00339035
I0428 22:36:26.918987  2425 solver.cpp:237] Iteration 32400, loss = 0.009211
I0428 22:36:26.919070  2425 solver.cpp:253]     Train net output #0: loss = 0.00921098 (* 1 = 0.00921098 loss)
I0428 22:36:26.919092  2425 sgd_solver.cpp:106] Iteration 32400, lr = 0.00338435
I0428 22:36:27.128931  2425 solver.cpp:237] Iteration 32500, loss = 0.0121321
I0428 22:36:27.129019  2425 solver.cpp:253]     Train net output #0: loss = 0.0121321 (* 1 = 0.0121321 loss)
I0428 22:36:27.129043  2425 sgd_solver.cpp:106] Iteration 32500, lr = 0.00337838
I0428 22:36:27.360309  2425 solver.cpp:237] Iteration 32600, loss = 0.0679455
I0428 22:36:27.360388  2425 solver.cpp:253]     Train net output #0: loss = 0.0679455 (* 1 = 0.0679455 loss)
I0428 22:36:27.360412  2425 sgd_solver.cpp:106] Iteration 32600, lr = 0.00337243
I0428 22:36:27.593760  2425 solver.cpp:237] Iteration 32700, loss = 0.0572414
I0428 22:36:27.593922  2425 solver.cpp:253]     Train net output #0: loss = 0.0572414 (* 1 = 0.0572414 loss)
I0428 22:36:27.593983  2425 sgd_solver.cpp:106] Iteration 32700, lr = 0.0033665
I0428 22:36:27.816315  2425 solver.cpp:237] Iteration 32800, loss = 0.00366194
I0428 22:36:27.816398  2425 solver.cpp:253]     Train net output #0: loss = 0.0036619 (* 1 = 0.0036619 loss)
I0428 22:36:27.816421  2425 sgd_solver.cpp:106] Iteration 32800, lr = 0.0033606
I0428 22:36:28.038730  2425 solver.cpp:237] Iteration 32900, loss = 0.025391
I0428 22:36:28.038810  2425 solver.cpp:253]     Train net output #0: loss = 0.025391 (* 1 = 0.025391 loss)
I0428 22:36:28.038832  2425 sgd_solver.cpp:106] Iteration 32900, lr = 0.00335473
I0428 22:36:28.253036  2425 solver.cpp:237] Iteration 33000, loss = 0.0139943
I0428 22:36:28.253202  2425 solver.cpp:253]     Train net output #0: loss = 0.0139942 (* 1 = 0.0139942 loss)
I0428 22:36:28.253262  2425 sgd_solver.cpp:106] Iteration 33000, lr = 0.00334887
I0428 22:36:28.468544  2425 solver.cpp:237] Iteration 33100, loss = 0.0237696
I0428 22:36:28.468619  2425 solver.cpp:253]     Train net output #0: loss = 0.0237696 (* 1 = 0.0237696 loss)
I0428 22:36:28.468639  2425 sgd_solver.cpp:106] Iteration 33100, lr = 0.00334304
I0428 22:36:28.677026  2425 solver.cpp:237] Iteration 33200, loss = 0.0307335
I0428 22:36:28.677189  2425 solver.cpp:253]     Train net output #0: loss = 0.0307335 (* 1 = 0.0307335 loss)
I0428 22:36:28.677249  2425 sgd_solver.cpp:106] Iteration 33200, lr = 0.00333724
I0428 22:36:28.894749  2425 solver.cpp:237] Iteration 33300, loss = 0.0108329
I0428 22:36:28.894831  2425 solver.cpp:253]     Train net output #0: loss = 0.0108329 (* 1 = 0.0108329 loss)
I0428 22:36:28.894853  2425 sgd_solver.cpp:106] Iteration 33300, lr = 0.00333146
I0428 22:36:29.113004  2425 solver.cpp:237] Iteration 33400, loss = 0.0147098
I0428 22:36:29.113165  2425 solver.cpp:253]     Train net output #0: loss = 0.0147097 (* 1 = 0.0147097 loss)
I0428 22:36:29.113226  2425 sgd_solver.cpp:106] Iteration 33400, lr = 0.0033257
I0428 22:36:29.318415  2425 solver.cpp:237] Iteration 33500, loss = 0.00800105
I0428 22:36:29.318577  2425 solver.cpp:253]     Train net output #0: loss = 0.008001 (* 1 = 0.008001 loss)
I0428 22:36:29.318631  2425 sgd_solver.cpp:106] Iteration 33500, lr = 0.00331996
I0428 22:36:29.530450  2425 solver.cpp:237] Iteration 33600, loss = 0.0385657
I0428 22:36:29.530524  2425 solver.cpp:253]     Train net output #0: loss = 0.0385656 (* 1 = 0.0385656 loss)
I0428 22:36:29.530547  2425 sgd_solver.cpp:106] Iteration 33600, lr = 0.00331425
I0428 22:36:29.738723  2425 solver.cpp:237] Iteration 33700, loss = 0.0151233
I0428 22:36:29.738806  2425 solver.cpp:253]     Train net output #0: loss = 0.0151233 (* 1 = 0.0151233 loss)
I0428 22:36:29.738827  2425 sgd_solver.cpp:106] Iteration 33700, lr = 0.00330856
I0428 22:36:29.962388  2425 solver.cpp:237] Iteration 33800, loss = 0.0275017
I0428 22:36:29.962466  2425 solver.cpp:253]     Train net output #0: loss = 0.0275017 (* 1 = 0.0275017 loss)
I0428 22:36:29.962488  2425 sgd_solver.cpp:106] Iteration 33800, lr = 0.00330289
I0428 22:36:30.174468  2425 solver.cpp:237] Iteration 33900, loss = 0.024976
I0428 22:36:30.174547  2425 solver.cpp:253]     Train net output #0: loss = 0.0249759 (* 1 = 0.0249759 loss)
I0428 22:36:30.174571  2425 sgd_solver.cpp:106] Iteration 33900, lr = 0.00329725
I0428 22:36:30.384979  2425 solver.cpp:237] Iteration 34000, loss = 0.0335775
I0428 22:36:30.385141  2425 solver.cpp:253]     Train net output #0: loss = 0.0335775 (* 1 = 0.0335775 loss)
I0428 22:36:30.385203  2425 sgd_solver.cpp:106] Iteration 34000, lr = 0.00329163
I0428 22:36:30.601038  2425 solver.cpp:237] Iteration 34100, loss = 0.0283433
I0428 22:36:30.601203  2425 solver.cpp:253]     Train net output #0: loss = 0.0283432 (* 1 = 0.0283432 loss)
I0428 22:36:30.601264  2425 sgd_solver.cpp:106] Iteration 34100, lr = 0.00328603
I0428 22:36:30.812597  2425 solver.cpp:237] Iteration 34200, loss = 0.00965621
I0428 22:36:30.812674  2425 solver.cpp:253]     Train net output #0: loss = 0.00965619 (* 1 = 0.00965619 loss)
I0428 22:36:30.812692  2425 sgd_solver.cpp:106] Iteration 34200, lr = 0.00328045
I0428 22:36:31.014546  2425 solver.cpp:237] Iteration 34300, loss = 0.0257549
I0428 22:36:31.014704  2425 solver.cpp:253]     Train net output #0: loss = 0.0257549 (* 1 = 0.0257549 loss)
I0428 22:36:31.014765  2425 sgd_solver.cpp:106] Iteration 34300, lr = 0.00327489
I0428 22:36:31.232720  2425 solver.cpp:237] Iteration 34400, loss = 0.0227982
I0428 22:36:31.232800  2425 solver.cpp:253]     Train net output #0: loss = 0.0227982 (* 1 = 0.0227982 loss)
I0428 22:36:31.232822  2425 sgd_solver.cpp:106] Iteration 34400, lr = 0.00326936
I0428 22:36:31.446213  2425 solver.cpp:237] Iteration 34500, loss = 0.01133
I0428 22:36:31.446373  2425 solver.cpp:253]     Train net output #0: loss = 0.01133 (* 1 = 0.01133 loss)
I0428 22:36:31.446432  2425 sgd_solver.cpp:106] Iteration 34500, lr = 0.00326385
I0428 22:36:31.661011  2425 solver.cpp:237] Iteration 34600, loss = 0.0227071
I0428 22:36:31.661169  2425 solver.cpp:253]     Train net output #0: loss = 0.0227071 (* 1 = 0.0227071 loss)
I0428 22:36:31.661231  2425 sgd_solver.cpp:106] Iteration 34600, lr = 0.00325836
I0428 22:36:31.870837  2425 solver.cpp:237] Iteration 34700, loss = 0.0187611
I0428 22:36:31.870998  2425 solver.cpp:253]     Train net output #0: loss = 0.0187611 (* 1 = 0.0187611 loss)
I0428 22:36:31.871059  2425 sgd_solver.cpp:106] Iteration 34700, lr = 0.00325289
I0428 22:36:32.088732  2425 solver.cpp:237] Iteration 34800, loss = 0.0499884
I0428 22:36:32.088832  2425 solver.cpp:253]     Train net output #0: loss = 0.0499885 (* 1 = 0.0499885 loss)
I0428 22:36:32.088852  2425 sgd_solver.cpp:106] Iteration 34800, lr = 0.00324744
I0428 22:36:32.297091  2425 solver.cpp:237] Iteration 34900, loss = 0.00577871
I0428 22:36:32.297272  2425 solver.cpp:253]     Train net output #0: loss = 0.00577873 (* 1 = 0.00577873 loss)
I0428 22:36:32.297338  2425 sgd_solver.cpp:106] Iteration 34900, lr = 0.00324202
I0428 22:36:32.505328  2425 solver.cpp:341] Iteration 35000, Testing net (#0)
I0428 22:36:32.645913  2425 solver.cpp:409]     Test net output #0: accuracy = 0.9918
I0428 22:36:32.645992  2425 solver.cpp:409]     Test net output #1: loss = 0.0258339 (* 1 = 0.0258339 loss)
I0428 22:36:32.647047  2425 solver.cpp:237] Iteration 35000, loss = 0.0484273
I0428 22:36:32.647135  2425 solver.cpp:253]     Train net output #0: loss = 0.0484273 (* 1 = 0.0484273 loss)
I0428 22:36:32.647197  2425 sgd_solver.cpp:106] Iteration 35000, lr = 0.00323661
I0428 22:36:32.877643  2425 solver.cpp:237] Iteration 35100, loss = 0.0359702
I0428 22:36:32.877804  2425 solver.cpp:253]     Train net output #0: loss = 0.0359702 (* 1 = 0.0359702 loss)
I0428 22:36:32.877862  2425 sgd_solver.cpp:106] Iteration 35100, lr = 0.00323123
I0428 22:36:33.071240  2425 solver.cpp:237] Iteration 35200, loss = 0.0228021
I0428 22:36:33.071400  2425 solver.cpp:253]     Train net output #0: loss = 0.0228021 (* 1 = 0.0228021 loss)
I0428 22:36:33.071455  2425 sgd_solver.cpp:106] Iteration 35200, lr = 0.00322586
I0428 22:36:33.264478  2425 solver.cpp:237] Iteration 35300, loss = 0.0147552
I0428 22:36:33.264570  2425 solver.cpp:253]     Train net output #0: loss = 0.0147552 (* 1 = 0.0147552 loss)
I0428 22:36:33.264597  2425 sgd_solver.cpp:106] Iteration 35300, lr = 0.00322052
I0428 22:36:33.458961  2425 solver.cpp:237] Iteration 35400, loss = 0.0324519
I0428 22:36:33.459048  2425 solver.cpp:253]     Train net output #0: loss = 0.032452 (* 1 = 0.032452 loss)
I0428 22:36:33.459074  2425 sgd_solver.cpp:106] Iteration 35400, lr = 0.0032152
I0428 22:36:33.652765  2425 solver.cpp:237] Iteration 35500, loss = 0.0215411
I0428 22:36:33.652853  2425 solver.cpp:253]     Train net output #0: loss = 0.0215411 (* 1 = 0.0215411 loss)
I0428 22:36:33.652878  2425 sgd_solver.cpp:106] Iteration 35500, lr = 0.0032099
I0428 22:36:33.846881  2425 solver.cpp:237] Iteration 35600, loss = 0.00236393
I0428 22:36:33.846966  2425 solver.cpp:253]     Train net output #0: loss = 0.00236395 (* 1 = 0.00236395 loss)
I0428 22:36:33.846992  2425 sgd_solver.cpp:106] Iteration 35600, lr = 0.00320462
I0428 22:36:34.040241  2425 solver.cpp:237] Iteration 35700, loss = 0.013385
I0428 22:36:34.040333  2425 solver.cpp:253]     Train net output #0: loss = 0.013385 (* 1 = 0.013385 loss)
I0428 22:36:34.040359  2425 sgd_solver.cpp:106] Iteration 35700, lr = 0.00319936
I0428 22:36:34.233912  2425 solver.cpp:237] Iteration 35800, loss = 0.0426171
I0428 22:36:34.233999  2425 solver.cpp:253]     Train net output #0: loss = 0.0426171 (* 1 = 0.0426171 loss)
I0428 22:36:34.234025  2425 sgd_solver.cpp:106] Iteration 35800, lr = 0.00319412
I0428 22:36:34.427548  2425 solver.cpp:237] Iteration 35900, loss = 0.0261112
I0428 22:36:34.427634  2425 solver.cpp:253]     Train net output #0: loss = 0.0261113 (* 1 = 0.0261113 loss)
I0428 22:36:34.427660  2425 sgd_solver.cpp:106] Iteration 35900, lr = 0.0031889
I0428 22:36:34.620925  2425 solver.cpp:237] Iteration 36000, loss = 0.0142162
I0428 22:36:34.621013  2425 solver.cpp:253]     Train net output #0: loss = 0.0142162 (* 1 = 0.0142162 loss)
I0428 22:36:34.621039  2425 sgd_solver.cpp:106] Iteration 36000, lr = 0.0031837
I0428 22:36:34.814879  2425 solver.cpp:237] Iteration 36100, loss = 0.00933936
I0428 22:36:34.814973  2425 solver.cpp:253]     Train net output #0: loss = 0.0093394 (* 1 = 0.0093394 loss)
I0428 22:36:34.814999  2425 sgd_solver.cpp:106] Iteration 36100, lr = 0.00317852
I0428 22:36:35.007233  2425 solver.cpp:237] Iteration 36200, loss = 0.0234758
I0428 22:36:35.007323  2425 solver.cpp:253]     Train net output #0: loss = 0.0234758 (* 1 = 0.0234758 loss)
I0428 22:36:35.007375  2425 sgd_solver.cpp:106] Iteration 36200, lr = 0.00317335
I0428 22:36:35.199772  2425 solver.cpp:237] Iteration 36300, loss = 0.0182222
I0428 22:36:35.199810  2425 solver.cpp:253]     Train net output #0: loss = 0.0182223 (* 1 = 0.0182223 loss)
I0428 22:36:35.199820  2425 sgd_solver.cpp:106] Iteration 36300, lr = 0.00316821
I0428 22:36:35.392125  2425 solver.cpp:237] Iteration 36400, loss = 0.0350807
I0428 22:36:35.392163  2425 solver.cpp:253]     Train net output #0: loss = 0.0350808 (* 1 = 0.0350808 loss)
I0428 22:36:35.392173  2425 sgd_solver.cpp:106] Iteration 36400, lr = 0.00316309
I0428 22:36:35.584369  2425 solver.cpp:237] Iteration 36500, loss = 0.0134059
I0428 22:36:35.584405  2425 solver.cpp:253]     Train net output #0: loss = 0.0134059 (* 1 = 0.0134059 loss)
I0428 22:36:35.584414  2425 sgd_solver.cpp:106] Iteration 36500, lr = 0.00315799
I0428 22:36:35.779774  2425 solver.cpp:237] Iteration 36600, loss = 0.025128
I0428 22:36:35.779862  2425 solver.cpp:253]     Train net output #0: loss = 0.025128 (* 1 = 0.025128 loss)
I0428 22:36:35.779888  2425 sgd_solver.cpp:106] Iteration 36600, lr = 0.0031529
I0428 22:36:35.975338  2425 solver.cpp:237] Iteration 36700, loss = 0.0868045
I0428 22:36:35.975425  2425 solver.cpp:253]     Train net output #0: loss = 0.0868045 (* 1 = 0.0868045 loss)
I0428 22:36:35.975450  2425 sgd_solver.cpp:106] Iteration 36700, lr = 0.00314784
I0428 22:36:36.170842  2425 solver.cpp:237] Iteration 36800, loss = 0.013008
I0428 22:36:36.170927  2425 solver.cpp:253]     Train net output #0: loss = 0.0130081 (* 1 = 0.0130081 loss)
I0428 22:36:36.170951  2425 sgd_solver.cpp:106] Iteration 36800, lr = 0.00314279
I0428 22:36:36.365912  2425 solver.cpp:237] Iteration 36900, loss = 0.0138927
I0428 22:36:36.365999  2425 solver.cpp:253]     Train net output #0: loss = 0.0138927 (* 1 = 0.0138927 loss)
I0428 22:36:36.366024  2425 sgd_solver.cpp:106] Iteration 36900, lr = 0.00313776
I0428 22:36:36.561393  2425 solver.cpp:237] Iteration 37000, loss = 0.0114516
I0428 22:36:36.561480  2425 solver.cpp:253]     Train net output #0: loss = 0.0114517 (* 1 = 0.0114517 loss)
I0428 22:36:36.561506  2425 sgd_solver.cpp:106] Iteration 37000, lr = 0.00313276
I0428 22:36:36.756317  2425 solver.cpp:237] Iteration 37100, loss = 0.0405567
I0428 22:36:36.756353  2425 solver.cpp:253]     Train net output #0: loss = 0.0405567 (* 1 = 0.0405567 loss)
I0428 22:36:36.756362  2425 sgd_solver.cpp:106] Iteration 37100, lr = 0.00312777
I0428 22:36:36.951805  2425 solver.cpp:237] Iteration 37200, loss = 0.0127507
I0428 22:36:36.951894  2425 solver.cpp:253]     Train net output #0: loss = 0.0127507 (* 1 = 0.0127507 loss)
I0428 22:36:36.951920  2425 sgd_solver.cpp:106] Iteration 37200, lr = 0.0031228
I0428 22:36:37.147208  2425 solver.cpp:237] Iteration 37300, loss = 0.0560767
I0428 22:36:37.147294  2425 solver.cpp:253]     Train net output #0: loss = 0.0560767 (* 1 = 0.0560767 loss)
I0428 22:36:37.147320  2425 sgd_solver.cpp:106] Iteration 37300, lr = 0.00311784
I0428 22:36:37.342576  2425 solver.cpp:237] Iteration 37400, loss = 0.014968
I0428 22:36:37.342661  2425 solver.cpp:253]     Train net output #0: loss = 0.014968 (* 1 = 0.014968 loss)
I0428 22:36:37.342686  2425 sgd_solver.cpp:106] Iteration 37400, lr = 0.00311291
I0428 22:36:37.537791  2425 solver.cpp:237] Iteration 37500, loss = 0.0121682
I0428 22:36:37.537876  2425 solver.cpp:253]     Train net output #0: loss = 0.0121682 (* 1 = 0.0121682 loss)
I0428 22:36:37.537901  2425 sgd_solver.cpp:106] Iteration 37500, lr = 0.00310799
I0428 22:36:37.762626  2425 solver.cpp:237] Iteration 37600, loss = 0.0283365
I0428 22:36:37.762717  2425 solver.cpp:253]     Train net output #0: loss = 0.0283365 (* 1 = 0.0283365 loss)
I0428 22:36:37.762742  2425 sgd_solver.cpp:106] Iteration 37600, lr = 0.00310309
I0428 22:36:37.978909  2425 solver.cpp:237] Iteration 37700, loss = 0.0393527
I0428 22:36:37.978986  2425 solver.cpp:253]     Train net output #0: loss = 0.0393527 (* 1 = 0.0393527 loss)
I0428 22:36:37.979006  2425 sgd_solver.cpp:106] Iteration 37700, lr = 0.00309821
I0428 22:36:38.183919  2425 solver.cpp:237] Iteration 37800, loss = 0.00534134
I0428 22:36:38.184002  2425 solver.cpp:253]     Train net output #0: loss = 0.00534135 (* 1 = 0.00534135 loss)
I0428 22:36:38.184028  2425 sgd_solver.cpp:106] Iteration 37800, lr = 0.00309335
I0428 22:36:38.379062  2425 solver.cpp:237] Iteration 37900, loss = 0.0183946
I0428 22:36:38.379149  2425 solver.cpp:253]     Train net output #0: loss = 0.0183946 (* 1 = 0.0183946 loss)
I0428 22:36:38.379174  2425 sgd_solver.cpp:106] Iteration 37900, lr = 0.00308851
I0428 22:36:38.573669  2425 solver.cpp:237] Iteration 38000, loss = 0.0336359
I0428 22:36:38.573756  2425 solver.cpp:253]     Train net output #0: loss = 0.0336359 (* 1 = 0.0336359 loss)
I0428 22:36:38.573782  2425 sgd_solver.cpp:106] Iteration 38000, lr = 0.00308368
I0428 22:36:38.769173  2425 solver.cpp:237] Iteration 38100, loss = 0.029469
I0428 22:36:38.769260  2425 solver.cpp:253]     Train net output #0: loss = 0.029469 (* 1 = 0.029469 loss)
I0428 22:36:38.769285  2425 sgd_solver.cpp:106] Iteration 38100, lr = 0.00307887
I0428 22:36:38.964463  2425 solver.cpp:237] Iteration 38200, loss = 0.018777
I0428 22:36:38.964504  2425 solver.cpp:253]     Train net output #0: loss = 0.018777 (* 1 = 0.018777 loss)
I0428 22:36:38.964514  2425 sgd_solver.cpp:106] Iteration 38200, lr = 0.00307408
I0428 22:36:39.159595  2425 solver.cpp:237] Iteration 38300, loss = 0.0608761
I0428 22:36:39.159631  2425 solver.cpp:253]     Train net output #0: loss = 0.0608761 (* 1 = 0.0608761 loss)
I0428 22:36:39.159639  2425 sgd_solver.cpp:106] Iteration 38300, lr = 0.0030693
I0428 22:36:39.354864  2425 solver.cpp:237] Iteration 38400, loss = 0.0341723
I0428 22:36:39.354950  2425 solver.cpp:253]     Train net output #0: loss = 0.0341724 (* 1 = 0.0341724 loss)
I0428 22:36:39.354976  2425 sgd_solver.cpp:106] Iteration 38400, lr = 0.00306454
I0428 22:36:39.548496  2425 solver.cpp:237] Iteration 38500, loss = 0.0244117
I0428 22:36:39.548583  2425 solver.cpp:253]     Train net output #0: loss = 0.0244117 (* 1 = 0.0244117 loss)
I0428 22:36:39.548609  2425 sgd_solver.cpp:106] Iteration 38500, lr = 0.0030598
I0428 22:36:39.742983  2425 solver.cpp:237] Iteration 38600, loss = 0.00684399
I0428 22:36:39.743067  2425 solver.cpp:253]     Train net output #0: loss = 0.00684401 (* 1 = 0.00684401 loss)
I0428 22:36:39.743093  2425 sgd_solver.cpp:106] Iteration 38600, lr = 0.00305508
I0428 22:36:39.937629  2425 solver.cpp:237] Iteration 38700, loss = 0.00582414
I0428 22:36:39.937716  2425 solver.cpp:253]     Train net output #0: loss = 0.00582415 (* 1 = 0.00582415 loss)
I0428 22:36:39.937742  2425 sgd_solver.cpp:106] Iteration 38700, lr = 0.00305038
I0428 22:36:40.132789  2425 solver.cpp:237] Iteration 38800, loss = 0.00660494
I0428 22:36:40.132875  2425 solver.cpp:253]     Train net output #0: loss = 0.00660495 (* 1 = 0.00660495 loss)
I0428 22:36:40.132906  2425 sgd_solver.cpp:106] Iteration 38800, lr = 0.00304569
I0428 22:36:40.327359  2425 solver.cpp:237] Iteration 38900, loss = 0.00742703
I0428 22:36:40.327448  2425 solver.cpp:253]     Train net output #0: loss = 0.00742705 (* 1 = 0.00742705 loss)
I0428 22:36:40.327473  2425 sgd_solver.cpp:106] Iteration 38900, lr = 0.00304101
I0428 22:36:40.522317  2425 solver.cpp:237] Iteration 39000, loss = 0.0235374
I0428 22:36:40.522403  2425 solver.cpp:253]     Train net output #0: loss = 0.0235374 (* 1 = 0.0235374 loss)
I0428 22:36:40.522428  2425 sgd_solver.cpp:106] Iteration 39000, lr = 0.00303636
I0428 22:36:40.717463  2425 solver.cpp:237] Iteration 39100, loss = 0.0357561
I0428 22:36:40.717499  2425 solver.cpp:253]     Train net output #0: loss = 0.0357562 (* 1 = 0.0357562 loss)
I0428 22:36:40.717509  2425 sgd_solver.cpp:106] Iteration 39100, lr = 0.00303172
I0428 22:36:40.912797  2425 solver.cpp:237] Iteration 39200, loss = 0.0311499
I0428 22:36:40.912884  2425 solver.cpp:253]     Train net output #0: loss = 0.0311499 (* 1 = 0.0311499 loss)
I0428 22:36:40.912920  2425 sgd_solver.cpp:106] Iteration 39200, lr = 0.0030271
I0428 22:36:41.108052  2425 solver.cpp:237] Iteration 39300, loss = 0.0194595
I0428 22:36:41.108139  2425 solver.cpp:253]     Train net output #0: loss = 0.0194595 (* 1 = 0.0194595 loss)
I0428 22:36:41.108165  2425 sgd_solver.cpp:106] Iteration 39300, lr = 0.00302249
I0428 22:36:41.303647  2425 solver.cpp:237] Iteration 39400, loss = 0.03326
I0428 22:36:41.303735  2425 solver.cpp:253]     Train net output #0: loss = 0.03326 (* 1 = 0.03326 loss)
I0428 22:36:41.303761  2425 sgd_solver.cpp:106] Iteration 39400, lr = 0.0030179
I0428 22:36:41.499274  2425 solver.cpp:237] Iteration 39500, loss = 0.00825802
I0428 22:36:41.499361  2425 solver.cpp:253]     Train net output #0: loss = 0.00825801 (* 1 = 0.00825801 loss)
I0428 22:36:41.499387  2425 sgd_solver.cpp:106] Iteration 39500, lr = 0.00301333
I0428 22:36:41.693598  2425 solver.cpp:237] Iteration 39600, loss = 0.0245058
I0428 22:36:41.693634  2425 solver.cpp:253]     Train net output #0: loss = 0.0245058 (* 1 = 0.0245058 loss)
I0428 22:36:41.693642  2425 sgd_solver.cpp:106] Iteration 39600, lr = 0.00300877
I0428 22:36:41.888525  2425 solver.cpp:237] Iteration 39700, loss = 0.0221856
I0428 22:36:41.888613  2425 solver.cpp:253]     Train net output #0: loss = 0.0221856 (* 1 = 0.0221856 loss)
I0428 22:36:41.888639  2425 sgd_solver.cpp:106] Iteration 39700, lr = 0.00300423
I0428 22:36:42.083585  2425 solver.cpp:237] Iteration 39800, loss = 0.0463321
I0428 22:36:42.083673  2425 solver.cpp:253]     Train net output #0: loss = 0.0463321 (* 1 = 0.0463321 loss)
I0428 22:36:42.083698  2425 sgd_solver.cpp:106] Iteration 39800, lr = 0.0029997
I0428 22:36:42.278903  2425 solver.cpp:237] Iteration 39900, loss = 0.00776024
I0428 22:36:42.278990  2425 solver.cpp:253]     Train net output #0: loss = 0.00776023 (* 1 = 0.00776023 loss)
I0428 22:36:42.279014  2425 sgd_solver.cpp:106] Iteration 39900, lr = 0.00299519
I0428 22:36:42.472551  2425 solver.cpp:341] Iteration 40000, Testing net (#0)
I0428 22:36:42.614578  2425 solver.cpp:409]     Test net output #0: accuracy = 0.9914
I0428 22:36:42.614614  2425 solver.cpp:409]     Test net output #1: loss = 0.026989 (* 1 = 0.026989 loss)
I0428 22:36:42.615556  2425 solver.cpp:237] Iteration 40000, loss = 0.010653
I0428 22:36:42.615878  2425 solver.cpp:253]     Train net output #0: loss = 0.010653 (* 1 = 0.010653 loss)
I0428 22:36:42.615913  2425 sgd_solver.cpp:106] Iteration 40000, lr = 0.0029907
I0428 22:36:42.820282  2425 solver.cpp:237] Iteration 40100, loss = 0.0445546
I0428 22:36:42.820370  2425 solver.cpp:253]     Train net output #0: loss = 0.0445546 (* 1 = 0.0445546 loss)
I0428 22:36:42.820396  2425 sgd_solver.cpp:106] Iteration 40100, lr = 0.00298622
I0428 22:36:43.016772  2425 solver.cpp:237] Iteration 40200, loss = 0.117655
I0428 22:36:43.016921  2425 solver.cpp:253]     Train net output #0: loss = 0.117655 (* 1 = 0.117655 loss)
I0428 22:36:43.016934  2425 sgd_solver.cpp:106] Iteration 40200, lr = 0.00298176
I0428 22:36:43.212383  2425 solver.cpp:237] Iteration 40300, loss = 0.00452788
I0428 22:36:43.212469  2425 solver.cpp:253]     Train net output #0: loss = 0.00452787 (* 1 = 0.00452787 loss)
I0428 22:36:43.212496  2425 sgd_solver.cpp:106] Iteration 40300, lr = 0.00297731
I0428 22:36:43.407892  2425 solver.cpp:237] Iteration 40400, loss = 0.0497811
I0428 22:36:43.407979  2425 solver.cpp:253]     Train net output #0: loss = 0.049781 (* 1 = 0.049781 loss)
I0428 22:36:43.408004  2425 sgd_solver.cpp:106] Iteration 40400, lr = 0.00297288
I0428 22:36:43.602964  2425 solver.cpp:237] Iteration 40500, loss = 0.0114657
I0428 22:36:43.603049  2425 solver.cpp:253]     Train net output #0: loss = 0.0114657 (* 1 = 0.0114657 loss)
I0428 22:36:43.603075  2425 sgd_solver.cpp:106] Iteration 40500, lr = 0.00296846
I0428 22:36:43.798415  2425 solver.cpp:237] Iteration 40600, loss = 0.0116127
I0428 22:36:43.798451  2425 solver.cpp:253]     Train net output #0: loss = 0.0116126 (* 1 = 0.0116126 loss)
I0428 22:36:43.798460  2425 sgd_solver.cpp:106] Iteration 40600, lr = 0.00296406
I0428 22:36:43.993448  2425 solver.cpp:237] Iteration 40700, loss = 0.0132105
I0428 22:36:43.993535  2425 solver.cpp:253]     Train net output #0: loss = 0.0132105 (* 1 = 0.0132105 loss)
I0428 22:36:43.993584  2425 sgd_solver.cpp:106] Iteration 40700, lr = 0.00295968
I0428 22:36:44.188344  2425 solver.cpp:237] Iteration 40800, loss = 0.0068647
I0428 22:36:44.188428  2425 solver.cpp:253]     Train net output #0: loss = 0.00686465 (* 1 = 0.00686465 loss)
I0428 22:36:44.188467  2425 sgd_solver.cpp:106] Iteration 40800, lr = 0.0029553
I0428 22:36:44.383462  2425 solver.cpp:237] Iteration 40900, loss = 0.012013
I0428 22:36:44.383550  2425 solver.cpp:253]     Train net output #0: loss = 0.012013 (* 1 = 0.012013 loss)
I0428 22:36:44.383575  2425 sgd_solver.cpp:106] Iteration 40900, lr = 0.00295095
I0428 22:36:44.532954  2431 blocking_queue.cpp:50] Waiting for data
I0428 22:36:44.578429  2425 solver.cpp:237] Iteration 41000, loss = 0.00865461
I0428 22:36:44.578518  2425 solver.cpp:253]     Train net output #0: loss = 0.00865454 (* 1 = 0.00865454 loss)
I0428 22:36:44.578543  2425 sgd_solver.cpp:106] Iteration 41000, lr = 0.00294661
I0428 22:36:44.774273  2425 solver.cpp:237] Iteration 41100, loss = 0.0601258
I0428 22:36:44.774359  2425 solver.cpp:253]     Train net output #0: loss = 0.0601257 (* 1 = 0.0601257 loss)
I0428 22:36:44.774385  2425 sgd_solver.cpp:106] Iteration 41100, lr = 0.00294228
I0428 22:36:44.969743  2425 solver.cpp:237] Iteration 41200, loss = 0.0271597
I0428 22:36:44.969831  2425 solver.cpp:253]     Train net output #0: loss = 0.0271596 (* 1 = 0.0271596 loss)
I0428 22:36:44.969856  2425 sgd_solver.cpp:106] Iteration 41200, lr = 0.00293797
I0428 22:36:45.165845  2425 solver.cpp:237] Iteration 41300, loss = 0.0184618
I0428 22:36:45.165933  2425 solver.cpp:253]     Train net output #0: loss = 0.0184618 (* 1 = 0.0184618 loss)
I0428 22:36:45.165959  2425 sgd_solver.cpp:106] Iteration 41300, lr = 0.00293367
I0428 22:36:45.361243  2425 solver.cpp:237] Iteration 41400, loss = 0.0245944
I0428 22:36:45.361330  2425 solver.cpp:253]     Train net output #0: loss = 0.0245944 (* 1 = 0.0245944 loss)
I0428 22:36:45.361354  2425 sgd_solver.cpp:106] Iteration 41400, lr = 0.00292939
I0428 22:36:45.557098  2425 solver.cpp:237] Iteration 41500, loss = 0.0223867
I0428 22:36:45.557185  2425 solver.cpp:253]     Train net output #0: loss = 0.0223866 (* 1 = 0.0223866 loss)
I0428 22:36:45.557210  2425 sgd_solver.cpp:106] Iteration 41500, lr = 0.00292513
I0428 22:36:45.752085  2425 solver.cpp:237] Iteration 41600, loss = 0.0257476
I0428 22:36:45.752122  2425 solver.cpp:253]     Train net output #0: loss = 0.0257475 (* 1 = 0.0257475 loss)
I0428 22:36:45.752130  2425 sgd_solver.cpp:106] Iteration 41600, lr = 0.00292087
I0428 22:36:45.947849  2425 solver.cpp:237] Iteration 41700, loss = 0.0129138
I0428 22:36:45.947931  2425 solver.cpp:253]     Train net output #0: loss = 0.0129138 (* 1 = 0.0129138 loss)
I0428 22:36:45.947957  2425 sgd_solver.cpp:106] Iteration 41700, lr = 0.00291664
I0428 22:36:46.143611  2425 solver.cpp:237] Iteration 41800, loss = 0.0388514
I0428 22:36:46.143647  2425 solver.cpp:253]     Train net output #0: loss = 0.0388513 (* 1 = 0.0388513 loss)
I0428 22:36:46.143657  2425 sgd_solver.cpp:106] Iteration 41800, lr = 0.00291241
I0428 22:36:46.338910  2425 solver.cpp:237] Iteration 41900, loss = 0.022632
I0428 22:36:46.339000  2425 solver.cpp:253]     Train net output #0: loss = 0.022632 (* 1 = 0.022632 loss)
I0428 22:36:46.339026  2425 sgd_solver.cpp:106] Iteration 41900, lr = 0.0029082
I0428 22:36:46.535006  2425 solver.cpp:237] Iteration 42000, loss = 0.0136126
I0428 22:36:46.535094  2425 solver.cpp:253]     Train net output #0: loss = 0.0136126 (* 1 = 0.0136126 loss)
I0428 22:36:46.535118  2425 sgd_solver.cpp:106] Iteration 42000, lr = 0.00290401
I0428 22:36:46.730515  2425 solver.cpp:237] Iteration 42100, loss = 0.0270103
I0428 22:36:46.730602  2425 solver.cpp:253]     Train net output #0: loss = 0.0270102 (* 1 = 0.0270102 loss)
I0428 22:36:46.730626  2425 sgd_solver.cpp:106] Iteration 42100, lr = 0.00289982
I0428 22:36:46.925801  2425 solver.cpp:237] Iteration 42200, loss = 0.0374414
I0428 22:36:46.925837  2425 solver.cpp:253]     Train net output #0: loss = 0.0374413 (* 1 = 0.0374413 loss)
I0428 22:36:46.925876  2425 sgd_solver.cpp:106] Iteration 42200, lr = 0.00289566
I0428 22:36:47.121589  2425 solver.cpp:237] Iteration 42300, loss = 0.0285462
I0428 22:36:47.121624  2425 solver.cpp:253]     Train net output #0: loss = 0.0285461 (* 1 = 0.0285461 loss)
I0428 22:36:47.121634  2425 sgd_solver.cpp:106] Iteration 42300, lr = 0.0028915
I0428 22:36:47.317909  2425 solver.cpp:237] Iteration 42400, loss = 0.0144764
I0428 22:36:47.317997  2425 solver.cpp:253]     Train net output #0: loss = 0.0144763 (* 1 = 0.0144763 loss)
I0428 22:36:47.318023  2425 sgd_solver.cpp:106] Iteration 42400, lr = 0.00288736
I0428 22:36:47.514129  2425 solver.cpp:237] Iteration 42500, loss = 0.0551123
I0428 22:36:47.514215  2425 solver.cpp:253]     Train net output #0: loss = 0.0551122 (* 1 = 0.0551122 loss)
I0428 22:36:47.514241  2425 sgd_solver.cpp:106] Iteration 42500, lr = 0.00288324
I0428 22:36:47.709861  2425 solver.cpp:237] Iteration 42600, loss = 0.0337038
I0428 22:36:47.709946  2425 solver.cpp:253]     Train net output #0: loss = 0.0337038 (* 1 = 0.0337038 loss)
I0428 22:36:47.709972  2425 sgd_solver.cpp:106] Iteration 42600, lr = 0.00287913
I0428 22:36:47.905527  2425 solver.cpp:237] Iteration 42700, loss = 0.0309872
I0428 22:36:47.905616  2425 solver.cpp:253]     Train net output #0: loss = 0.0309871 (* 1 = 0.0309871 loss)
I0428 22:36:47.905642  2425 sgd_solver.cpp:106] Iteration 42700, lr = 0.00287503
I0428 22:36:48.101310  2425 solver.cpp:237] Iteration 42800, loss = 0.0102643
I0428 22:36:48.101454  2425 solver.cpp:253]     Train net output #0: loss = 0.0102643 (* 1 = 0.0102643 loss)
I0428 22:36:48.101467  2425 sgd_solver.cpp:106] Iteration 42800, lr = 0.00287094
I0428 22:36:48.343257  2425 solver.cpp:237] Iteration 42900, loss = 0.0458005
I0428 22:36:48.343344  2425 solver.cpp:253]     Train net output #0: loss = 0.0458005 (* 1 = 0.0458005 loss)
I0428 22:36:48.343370  2425 sgd_solver.cpp:106] Iteration 42900, lr = 0.00286687
I0428 22:36:48.539511  2425 solver.cpp:237] Iteration 43000, loss = 0.00884706
I0428 22:36:48.539595  2425 solver.cpp:253]     Train net output #0: loss = 0.00884701 (* 1 = 0.00884701 loss)
I0428 22:36:48.539619  2425 sgd_solver.cpp:106] Iteration 43000, lr = 0.00286281
I0428 22:36:48.735599  2425 solver.cpp:237] Iteration 43100, loss = 0.00454351
I0428 22:36:48.735683  2425 solver.cpp:253]     Train net output #0: loss = 0.00454346 (* 1 = 0.00454346 loss)
I0428 22:36:48.735708  2425 sgd_solver.cpp:106] Iteration 43100, lr = 0.00285877
I0428 22:36:48.932126  2425 solver.cpp:237] Iteration 43200, loss = 0.00787663
I0428 22:36:48.932214  2425 solver.cpp:253]     Train net output #0: loss = 0.0078766 (* 1 = 0.0078766 loss)
I0428 22:36:48.932240  2425 sgd_solver.cpp:106] Iteration 43200, lr = 0.00285474
I0428 22:36:49.126006  2425 solver.cpp:237] Iteration 43300, loss = 0.05336
I0428 22:36:49.126041  2425 solver.cpp:253]     Train net output #0: loss = 0.0533599 (* 1 = 0.0533599 loss)
I0428 22:36:49.126051  2425 sgd_solver.cpp:106] Iteration 43300, lr = 0.00285072
I0428 22:36:49.319831  2425 solver.cpp:237] Iteration 43400, loss = 0.0373245
I0428 22:36:49.319866  2425 solver.cpp:253]     Train net output #0: loss = 0.0373244 (* 1 = 0.0373244 loss)
I0428 22:36:49.319875  2425 sgd_solver.cpp:106] Iteration 43400, lr = 0.00284672
I0428 22:36:49.513888  2425 solver.cpp:237] Iteration 43500, loss = 0.01582
I0428 22:36:49.513923  2425 solver.cpp:253]     Train net output #0: loss = 0.0158199 (* 1 = 0.0158199 loss)
I0428 22:36:49.513932  2425 sgd_solver.cpp:106] Iteration 43500, lr = 0.00284272
I0428 22:36:49.707883  2425 solver.cpp:237] Iteration 43600, loss = 0.0113116
I0428 22:36:49.707921  2425 solver.cpp:253]     Train net output #0: loss = 0.0113116 (* 1 = 0.0113116 loss)
I0428 22:36:49.707929  2425 sgd_solver.cpp:106] Iteration 43600, lr = 0.00283875
I0428 22:36:49.902056  2425 solver.cpp:237] Iteration 43700, loss = 0.0309655
I0428 22:36:49.902091  2425 solver.cpp:253]     Train net output #0: loss = 0.0309655 (* 1 = 0.0309655 loss)
I0428 22:36:49.902130  2425 sgd_solver.cpp:106] Iteration 43700, lr = 0.00283478
I0428 22:36:50.096216  2425 solver.cpp:237] Iteration 43800, loss = 0.0349821
I0428 22:36:50.096252  2425 solver.cpp:253]     Train net output #0: loss = 0.034982 (* 1 = 0.034982 loss)
I0428 22:36:50.096261  2425 sgd_solver.cpp:106] Iteration 43800, lr = 0.00283083
I0428 22:36:50.289934  2425 solver.cpp:237] Iteration 43900, loss = 0.0304377
I0428 22:36:50.289969  2425 solver.cpp:253]     Train net output #0: loss = 0.0304377 (* 1 = 0.0304377 loss)
I0428 22:36:50.289978  2425 sgd_solver.cpp:106] Iteration 43900, lr = 0.00282689
I0428 22:36:50.483597  2425 solver.cpp:237] Iteration 44000, loss = 0.0173888
I0428 22:36:50.483631  2425 solver.cpp:253]     Train net output #0: loss = 0.0173888 (* 1 = 0.0173888 loss)
I0428 22:36:50.483640  2425 sgd_solver.cpp:106] Iteration 44000, lr = 0.00282296
I0428 22:36:50.677726  2425 solver.cpp:237] Iteration 44100, loss = 0.0442246
I0428 22:36:50.677760  2425 solver.cpp:253]     Train net output #0: loss = 0.0442246 (* 1 = 0.0442246 loss)
I0428 22:36:50.677769  2425 sgd_solver.cpp:106] Iteration 44100, lr = 0.00281905
I0428 22:36:50.871973  2425 solver.cpp:237] Iteration 44200, loss = 0.0281824
I0428 22:36:50.872009  2425 solver.cpp:253]     Train net output #0: loss = 0.0281824 (* 1 = 0.0281824 loss)
I0428 22:36:50.872017  2425 sgd_solver.cpp:106] Iteration 44200, lr = 0.00281514
I0428 22:36:51.065343  2425 solver.cpp:237] Iteration 44300, loss = 0.00685771
I0428 22:36:51.065376  2425 solver.cpp:253]     Train net output #0: loss = 0.00685768 (* 1 = 0.00685768 loss)
I0428 22:36:51.065385  2425 sgd_solver.cpp:106] Iteration 44300, lr = 0.00281125
I0428 22:36:51.259202  2425 solver.cpp:237] Iteration 44400, loss = 0.0187442
I0428 22:36:51.259238  2425 solver.cpp:253]     Train net output #0: loss = 0.0187441 (* 1 = 0.0187441 loss)
I0428 22:36:51.259246  2425 sgd_solver.cpp:106] Iteration 44400, lr = 0.00280738
I0428 22:36:51.453014  2425 solver.cpp:237] Iteration 44500, loss = 0.0298929
I0428 22:36:51.453049  2425 solver.cpp:253]     Train net output #0: loss = 0.0298929 (* 1 = 0.0298929 loss)
I0428 22:36:51.453058  2425 sgd_solver.cpp:106] Iteration 44500, lr = 0.00280351
I0428 22:36:51.647085  2425 solver.cpp:237] Iteration 44600, loss = 0.0301581
I0428 22:36:51.647121  2425 solver.cpp:253]     Train net output #0: loss = 0.0301581 (* 1 = 0.0301581 loss)
I0428 22:36:51.647130  2425 sgd_solver.cpp:106] Iteration 44600, lr = 0.00279966
I0428 22:36:51.841058  2425 solver.cpp:237] Iteration 44700, loss = 0.0247338
I0428 22:36:51.841192  2425 solver.cpp:253]     Train net output #0: loss = 0.0247337 (* 1 = 0.0247337 loss)
I0428 22:36:51.841203  2425 sgd_solver.cpp:106] Iteration 44700, lr = 0.00279582
I0428 22:36:52.035200  2425 solver.cpp:237] Iteration 44800, loss = 0.0684566
I0428 22:36:52.035238  2425 solver.cpp:253]     Train net output #0: loss = 0.0684566 (* 1 = 0.0684566 loss)
I0428 22:36:52.035246  2425 sgd_solver.cpp:106] Iteration 44800, lr = 0.00279199
I0428 22:36:52.228816  2425 solver.cpp:237] Iteration 44900, loss = 0.0461965
I0428 22:36:52.228853  2425 solver.cpp:253]     Train net output #0: loss = 0.0461964 (* 1 = 0.0461964 loss)
I0428 22:36:52.228862  2425 sgd_solver.cpp:106] Iteration 44900, lr = 0.00278818
I0428 22:36:52.421006  2425 solver.cpp:341] Iteration 45000, Testing net (#0)
I0428 22:36:52.539042  2425 solver.cpp:409]     Test net output #0: accuracy = 0.9915
I0428 22:36:52.539120  2425 solver.cpp:409]     Test net output #1: loss = 0.0270484 (* 1 = 0.0270484 loss)
I0428 22:36:52.540079  2425 solver.cpp:237] Iteration 45000, loss = 0.0166114
I0428 22:36:52.540127  2425 solver.cpp:253]     Train net output #0: loss = 0.0166114 (* 1 = 0.0166114 loss)
I0428 22:36:52.540153  2425 sgd_solver.cpp:106] Iteration 45000, lr = 0.00278438
I0428 22:36:52.782877  2425 solver.cpp:237] Iteration 45100, loss = 0.0389639
I0428 22:36:52.782966  2425 solver.cpp:253]     Train net output #0: loss = 0.0389639 (* 1 = 0.0389639 loss)
I0428 22:36:52.782992  2425 sgd_solver.cpp:106] Iteration 45100, lr = 0.00278059
I0428 22:36:52.970428  2425 solver.cpp:237] Iteration 45200, loss = 0.0587543
I0428 22:36:52.970517  2425 solver.cpp:253]     Train net output #0: loss = 0.0587543 (* 1 = 0.0587543 loss)
I0428 22:36:52.970542  2425 sgd_solver.cpp:106] Iteration 45200, lr = 0.00277681
I0428 22:36:53.157610  2425 solver.cpp:237] Iteration 45300, loss = 0.0114216
I0428 22:36:53.157753  2425 solver.cpp:253]     Train net output #0: loss = 0.0114216 (* 1 = 0.0114216 loss)
I0428 22:36:53.157766  2425 sgd_solver.cpp:106] Iteration 45300, lr = 0.00277304
I0428 22:36:53.344521  2425 solver.cpp:237] Iteration 45400, loss = 0.00921494
I0428 22:36:53.344558  2425 solver.cpp:253]     Train net output #0: loss = 0.00921495 (* 1 = 0.00921495 loss)
I0428 22:36:53.344566  2425 sgd_solver.cpp:106] Iteration 45400, lr = 0.00276929
I0428 22:36:53.531301  2425 solver.cpp:237] Iteration 45500, loss = 0.0346647
I0428 22:36:53.531334  2425 solver.cpp:253]     Train net output #0: loss = 0.0346647 (* 1 = 0.0346647 loss)
I0428 22:36:53.531343  2425 sgd_solver.cpp:106] Iteration 45500, lr = 0.00276554
I0428 22:36:53.718518  2425 solver.cpp:237] Iteration 45600, loss = 0.023392
I0428 22:36:53.718554  2425 solver.cpp:253]     Train net output #0: loss = 0.023392 (* 1 = 0.023392 loss)
I0428 22:36:53.718562  2425 sgd_solver.cpp:106] Iteration 45600, lr = 0.00276181
I0428 22:36:53.905830  2425 solver.cpp:237] Iteration 45700, loss = 0.0246371
I0428 22:36:53.905918  2425 solver.cpp:253]     Train net output #0: loss = 0.0246371 (* 1 = 0.0246371 loss)
I0428 22:36:53.905944  2425 sgd_solver.cpp:106] Iteration 45700, lr = 0.00275809
I0428 22:36:54.096426  2425 solver.cpp:237] Iteration 45800, loss = 0.0453355
I0428 22:36:54.096513  2425 solver.cpp:253]     Train net output #0: loss = 0.0453355 (* 1 = 0.0453355 loss)
I0428 22:36:54.096539  2425 sgd_solver.cpp:106] Iteration 45800, lr = 0.00275438
I0428 22:36:54.285897  2425 solver.cpp:237] Iteration 45900, loss = 0.0192514
I0428 22:36:54.285984  2425 solver.cpp:253]     Train net output #0: loss = 0.0192514 (* 1 = 0.0192514 loss)
I0428 22:36:54.286010  2425 sgd_solver.cpp:106] Iteration 45900, lr = 0.00275069
I0428 22:36:54.475971  2425 solver.cpp:237] Iteration 46000, loss = 0.0261038
I0428 22:36:54.476059  2425 solver.cpp:253]     Train net output #0: loss = 0.0261038 (* 1 = 0.0261038 loss)
I0428 22:36:54.476085  2425 sgd_solver.cpp:106] Iteration 46000, lr = 0.002747
I0428 22:36:54.666157  2425 solver.cpp:237] Iteration 46100, loss = 0.00733227
I0428 22:36:54.666245  2425 solver.cpp:253]     Train net output #0: loss = 0.00733227 (* 1 = 0.00733227 loss)
I0428 22:36:54.666301  2425 sgd_solver.cpp:106] Iteration 46100, lr = 0.00274333
I0428 22:36:54.855533  2425 solver.cpp:237] Iteration 46200, loss = 0.0123906
I0428 22:36:54.855621  2425 solver.cpp:253]     Train net output #0: loss = 0.0123906 (* 1 = 0.0123906 loss)
I0428 22:36:54.855646  2425 sgd_solver.cpp:106] Iteration 46200, lr = 0.00273967
I0428 22:36:55.044983  2425 solver.cpp:237] Iteration 46300, loss = 0.00868327
I0428 22:36:55.045073  2425 solver.cpp:253]     Train net output #0: loss = 0.00868326 (* 1 = 0.00868326 loss)
I0428 22:36:55.045097  2425 sgd_solver.cpp:106] Iteration 46300, lr = 0.00273602
I0428 22:36:55.234216  2425 solver.cpp:237] Iteration 46400, loss = 0.00652102
I0428 22:36:55.234302  2425 solver.cpp:253]     Train net output #0: loss = 0.00652103 (* 1 = 0.00652103 loss)
I0428 22:36:55.234328  2425 sgd_solver.cpp:106] Iteration 46400, lr = 0.00273238
I0428 22:36:55.423949  2425 solver.cpp:237] Iteration 46500, loss = 0.033607
I0428 22:36:55.424036  2425 solver.cpp:253]     Train net output #0: loss = 0.033607 (* 1 = 0.033607 loss)
I0428 22:36:55.424060  2425 sgd_solver.cpp:106] Iteration 46500, lr = 0.00272875
I0428 22:36:55.614092  2425 solver.cpp:237] Iteration 46600, loss = 0.0256104
I0428 22:36:55.614181  2425 solver.cpp:253]     Train net output #0: loss = 0.0256104 (* 1 = 0.0256104 loss)
I0428 22:36:55.614207  2425 sgd_solver.cpp:106] Iteration 46600, lr = 0.00272513
I0428 22:36:55.803164  2425 solver.cpp:237] Iteration 46700, loss = 0.0208363
I0428 22:36:55.803251  2425 solver.cpp:253]     Train net output #0: loss = 0.0208364 (* 1 = 0.0208364 loss)
I0428 22:36:55.803278  2425 sgd_solver.cpp:106] Iteration 46700, lr = 0.00272153
I0428 22:36:55.993505  2425 solver.cpp:237] Iteration 46800, loss = 0.0204178
I0428 22:36:55.993607  2425 solver.cpp:253]     Train net output #0: loss = 0.0204178 (* 1 = 0.0204178 loss)
I0428 22:36:55.993638  2425 sgd_solver.cpp:106] Iteration 46800, lr = 0.00271793
I0428 22:36:56.183759  2425 solver.cpp:237] Iteration 46900, loss = 0.0313451
I0428 22:36:56.183846  2425 solver.cpp:253]     Train net output #0: loss = 0.0313452 (* 1 = 0.0313452 loss)
I0428 22:36:56.183871  2425 sgd_solver.cpp:106] Iteration 46900, lr = 0.00271435
I0428 22:36:56.373570  2425 solver.cpp:237] Iteration 47000, loss = 0.0206288
I0428 22:36:56.373657  2425 solver.cpp:253]     Train net output #0: loss = 0.0206288 (* 1 = 0.0206288 loss)
I0428 22:36:56.373683  2425 sgd_solver.cpp:106] Iteration 47000, lr = 0.00271078
I0428 22:36:56.565750  2425 solver.cpp:237] Iteration 47100, loss = 0.0177983
I0428 22:36:56.565837  2425 solver.cpp:253]     Train net output #0: loss = 0.0177983 (* 1 = 0.0177983 loss)
I0428 22:36:56.565863  2425 sgd_solver.cpp:106] Iteration 47100, lr = 0.00270722
I0428 22:36:56.754561  2425 solver.cpp:237] Iteration 47200, loss = 0.0124537
I0428 22:36:56.754649  2425 solver.cpp:253]     Train net output #0: loss = 0.0124537 (* 1 = 0.0124537 loss)
I0428 22:36:56.754675  2425 sgd_solver.cpp:106] Iteration 47200, lr = 0.00270367
I0428 22:36:56.948909  2425 solver.cpp:237] Iteration 47300, loss = 0.0174669
I0428 22:36:56.948997  2425 solver.cpp:253]     Train net output #0: loss = 0.0174669 (* 1 = 0.0174669 loss)
I0428 22:36:56.949023  2425 sgd_solver.cpp:106] Iteration 47300, lr = 0.00270013
I0428 22:36:57.137394  2425 solver.cpp:237] Iteration 47400, loss = 0.0178775
I0428 22:36:57.137483  2425 solver.cpp:253]     Train net output #0: loss = 0.0178775 (* 1 = 0.0178775 loss)
I0428 22:36:57.137508  2425 sgd_solver.cpp:106] Iteration 47400, lr = 0.0026966
I0428 22:36:57.326177  2425 solver.cpp:237] Iteration 47500, loss = 0.0239059
I0428 22:36:57.326263  2425 solver.cpp:253]     Train net output #0: loss = 0.023906 (* 1 = 0.023906 loss)
I0428 22:36:57.326288  2425 sgd_solver.cpp:106] Iteration 47500, lr = 0.00269308
I0428 22:36:57.516222  2425 solver.cpp:237] Iteration 47600, loss = 0.0392999
I0428 22:36:57.516258  2425 solver.cpp:253]     Train net output #0: loss = 0.0393 (* 1 = 0.0393 loss)
I0428 22:36:57.516266  2425 sgd_solver.cpp:106] Iteration 47600, lr = 0.00268957
I0428 22:36:57.705072  2425 solver.cpp:237] Iteration 47700, loss = 0.0582673
I0428 22:36:57.705109  2425 solver.cpp:253]     Train net output #0: loss = 0.0582674 (* 1 = 0.0582674 loss)
I0428 22:36:57.705118  2425 sgd_solver.cpp:106] Iteration 47700, lr = 0.00268607
I0428 22:36:57.893290  2425 solver.cpp:237] Iteration 47800, loss = 0.00323647
I0428 22:36:57.893380  2425 solver.cpp:253]     Train net output #0: loss = 0.00323654 (* 1 = 0.00323654 loss)
I0428 22:36:57.893406  2425 sgd_solver.cpp:106] Iteration 47800, lr = 0.00268259
I0428 22:36:58.083835  2425 solver.cpp:237] Iteration 47900, loss = 0.0189181
I0428 22:36:58.083922  2425 solver.cpp:253]     Train net output #0: loss = 0.0189182 (* 1 = 0.0189182 loss)
I0428 22:36:58.083947  2425 sgd_solver.cpp:106] Iteration 47900, lr = 0.00267911
I0428 22:36:58.273618  2425 solver.cpp:237] Iteration 48000, loss = 0.0171214
I0428 22:36:58.273706  2425 solver.cpp:253]     Train net output #0: loss = 0.0171215 (* 1 = 0.0171215 loss)
I0428 22:36:58.273732  2425 sgd_solver.cpp:106] Iteration 48000, lr = 0.00267565
I0428 22:36:58.462381  2425 solver.cpp:237] Iteration 48100, loss = 0.0197847
I0428 22:36:58.462468  2425 solver.cpp:253]     Train net output #0: loss = 0.0197848 (* 1 = 0.0197848 loss)
I0428 22:36:58.462493  2425 sgd_solver.cpp:106] Iteration 48100, lr = 0.00267219
I0428 22:36:58.651844  2425 solver.cpp:237] Iteration 48200, loss = 0.0295314
I0428 22:36:58.651932  2425 solver.cpp:253]     Train net output #0: loss = 0.0295315 (* 1 = 0.0295315 loss)
I0428 22:36:58.651957  2425 sgd_solver.cpp:106] Iteration 48200, lr = 0.00266875
I0428 22:36:58.839355  2425 solver.cpp:237] Iteration 48300, loss = 0.0107463
I0428 22:36:58.839444  2425 solver.cpp:253]     Train net output #0: loss = 0.0107464 (* 1 = 0.0107464 loss)
I0428 22:36:58.839485  2425 sgd_solver.cpp:106] Iteration 48300, lr = 0.00266532
I0428 22:36:59.027295  2425 solver.cpp:237] Iteration 48400, loss = 0.0158289
I0428 22:36:59.027381  2425 solver.cpp:253]     Train net output #0: loss = 0.0158289 (* 1 = 0.0158289 loss)
I0428 22:36:59.027407  2425 sgd_solver.cpp:106] Iteration 48400, lr = 0.00266189
I0428 22:36:59.216068  2425 solver.cpp:237] Iteration 48500, loss = 0.00630035
I0428 22:36:59.216153  2425 solver.cpp:253]     Train net output #0: loss = 0.00630038 (* 1 = 0.00630038 loss)
I0428 22:36:59.216179  2425 sgd_solver.cpp:106] Iteration 48500, lr = 0.00265848
I0428 22:36:59.405347  2425 solver.cpp:237] Iteration 48600, loss = 0.0302699
I0428 22:36:59.405436  2425 solver.cpp:253]     Train net output #0: loss = 0.0302699 (* 1 = 0.0302699 loss)
I0428 22:36:59.405462  2425 sgd_solver.cpp:106] Iteration 48600, lr = 0.00265507
I0428 22:36:59.606477  2425 solver.cpp:237] Iteration 48700, loss = 0.0285363
I0428 22:36:59.606639  2425 solver.cpp:253]     Train net output #0: loss = 0.0285363 (* 1 = 0.0285363 loss)
I0428 22:36:59.606698  2425 sgd_solver.cpp:106] Iteration 48700, lr = 0.00265168
I0428 22:36:59.795764  2425 solver.cpp:237] Iteration 48800, loss = 0.0132145
I0428 22:36:59.795923  2425 solver.cpp:253]     Train net output #0: loss = 0.0132145 (* 1 = 0.0132145 loss)
I0428 22:36:59.795979  2425 sgd_solver.cpp:106] Iteration 48800, lr = 0.0026483
I0428 22:36:59.985471  2425 solver.cpp:237] Iteration 48900, loss = 0.0164412
I0428 22:36:59.985630  2425 solver.cpp:253]     Train net output #0: loss = 0.0164412 (* 1 = 0.0164412 loss)
I0428 22:36:59.985688  2425 sgd_solver.cpp:106] Iteration 48900, lr = 0.00264493
I0428 22:37:00.174748  2425 solver.cpp:237] Iteration 49000, loss = 0.0330086
I0428 22:37:00.174907  2425 solver.cpp:253]     Train net output #0: loss = 0.0330086 (* 1 = 0.0330086 loss)
I0428 22:37:00.174967  2425 sgd_solver.cpp:106] Iteration 49000, lr = 0.00264156
I0428 22:37:00.363798  2425 solver.cpp:237] Iteration 49100, loss = 0.0210595
I0428 22:37:00.363957  2425 solver.cpp:253]     Train net output #0: loss = 0.0210595 (* 1 = 0.0210595 loss)
I0428 22:37:00.364015  2425 sgd_solver.cpp:106] Iteration 49100, lr = 0.00263821
I0428 22:37:00.553052  2425 solver.cpp:237] Iteration 49200, loss = 0.00769435
I0428 22:37:00.553233  2425 solver.cpp:253]     Train net output #0: loss = 0.00769435 (* 1 = 0.00769435 loss)
I0428 22:37:00.553290  2425 sgd_solver.cpp:106] Iteration 49200, lr = 0.00263487
I0428 22:37:00.742234  2425 solver.cpp:237] Iteration 49300, loss = 0.0434646
I0428 22:37:00.742394  2425 solver.cpp:253]     Train net output #0: loss = 0.0434646 (* 1 = 0.0434646 loss)
I0428 22:37:00.742452  2425 sgd_solver.cpp:106] Iteration 49300, lr = 0.00263153
I0428 22:37:00.930739  2425 solver.cpp:237] Iteration 49400, loss = 0.0263179
I0428 22:37:00.930891  2425 solver.cpp:253]     Train net output #0: loss = 0.0263179 (* 1 = 0.0263179 loss)
I0428 22:37:00.930948  2425 sgd_solver.cpp:106] Iteration 49400, lr = 0.00262821
I0428 22:37:01.119554  2425 solver.cpp:237] Iteration 49500, loss = 0.0189311
I0428 22:37:01.119714  2425 solver.cpp:253]     Train net output #0: loss = 0.0189311 (* 1 = 0.0189311 loss)
I0428 22:37:01.119773  2425 sgd_solver.cpp:106] Iteration 49500, lr = 0.0026249
I0428 22:37:01.309041  2425 solver.cpp:237] Iteration 49600, loss = 0.0136431
I0428 22:37:01.309198  2425 solver.cpp:253]     Train net output #0: loss = 0.0136431 (* 1 = 0.0136431 loss)
I0428 22:37:01.309258  2425 sgd_solver.cpp:106] Iteration 49600, lr = 0.00262159
I0428 22:37:01.498179  2425 solver.cpp:237] Iteration 49700, loss = 0.0090582
I0428 22:37:01.498338  2425 solver.cpp:253]     Train net output #0: loss = 0.00905824 (* 1 = 0.00905824 loss)
I0428 22:37:01.498396  2425 sgd_solver.cpp:106] Iteration 49700, lr = 0.0026183
I0428 22:37:01.687567  2425 solver.cpp:237] Iteration 49800, loss = 0.0308698
I0428 22:37:01.687728  2425 solver.cpp:253]     Train net output #0: loss = 0.0308698 (* 1 = 0.0308698 loss)
I0428 22:37:01.687788  2425 sgd_solver.cpp:106] Iteration 49800, lr = 0.00261501
I0428 22:37:01.877059  2425 solver.cpp:237] Iteration 49900, loss = 0.00940132
I0428 22:37:01.877221  2425 solver.cpp:253]     Train net output #0: loss = 0.00940133 (* 1 = 0.00940133 loss)
I0428 22:37:01.877277  2425 sgd_solver.cpp:106] Iteration 49900, lr = 0.00261174
I0428 22:37:02.064442  2425 solver.cpp:459] Snapshotting to binary proto file _iter_50000.caffemodel
I0428 22:37:02.071115  2425 sgd_solver.cpp:269] Snapshotting solver state to binary proto file _iter_50000.solverstate
I0428 22:37:02.075219  2425 solver.cpp:321] Iteration 50000, loss = 0.0378906
I0428 22:37:02.075285  2425 solver.cpp:341] Iteration 50000, Testing net (#0)
I0428 22:37:02.189159  2425 solver.cpp:409]     Test net output #0: accuracy = 0.9915
I0428 22:37:02.189242  2425 solver.cpp:409]     Test net output #1: loss = 0.0267864 (* 1 = 0.0267864 loss)
I0428 22:37:02.189266  2425 solver.cpp:326] Optimization Done.
I0428 22:37:02.189286  2425 caffe.cpp:215] Optimization Done.
