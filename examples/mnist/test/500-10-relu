I0428 22:23:26.829658  2164 caffe.cpp:184] Using GPUs 0
I0428 22:23:27.090466  2164 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 5000
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
solver_mode: GPU
device_id: 0
net: "examples/mnist/test/lenet_train_test.prototxt"
I0428 22:23:27.090605  2164 solver.cpp:91] Creating training net from net file: examples/mnist/test/lenet_train_test.prototxt
I0428 22:23:27.091197  2164 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0428 22:23:27.091239  2164 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0428 22:23:27.091363  2164 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "relu2"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "relu2"
  bottom: "label"
  top: "loss"
}
I0428 22:23:27.091938  2164 layer_factory.hpp:77] Creating layer mnist
I0428 22:23:27.092650  2164 net.cpp:106] Creating Layer mnist
I0428 22:23:27.092695  2164 net.cpp:411] mnist -> data
I0428 22:23:27.092756  2164 net.cpp:411] mnist -> label
I0428 22:23:27.098004  2211 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_train_lmdb
I0428 22:23:27.106983  2164 data_layer.cpp:41] output data size: 64,1,28,28
I0428 22:23:27.109946  2164 net.cpp:150] Setting up mnist
I0428 22:23:27.109990  2164 net.cpp:157] Top shape: 64 1 28 28 (50176)
I0428 22:23:27.110008  2164 net.cpp:157] Top shape: 64 (64)
I0428 22:23:27.110020  2164 net.cpp:165] Memory required for data: 200960
I0428 22:23:27.110040  2164 layer_factory.hpp:77] Creating layer conv1
I0428 22:23:27.110075  2164 net.cpp:106] Creating Layer conv1
I0428 22:23:27.110092  2164 net.cpp:454] conv1 <- data
I0428 22:23:27.110115  2164 net.cpp:411] conv1 -> conv1
I0428 22:23:27.270103  2164 net.cpp:150] Setting up conv1
I0428 22:23:27.270177  2164 net.cpp:157] Top shape: 64 20 24 24 (737280)
I0428 22:23:27.270198  2164 net.cpp:165] Memory required for data: 3150080
I0428 22:23:27.270239  2164 layer_factory.hpp:77] Creating layer pool1
I0428 22:23:27.270274  2164 net.cpp:106] Creating Layer pool1
I0428 22:23:27.270298  2164 net.cpp:454] pool1 <- conv1
I0428 22:23:27.270334  2164 net.cpp:411] pool1 -> pool1
I0428 22:23:27.271129  2164 net.cpp:150] Setting up pool1
I0428 22:23:27.271165  2164 net.cpp:157] Top shape: 64 20 12 12 (184320)
I0428 22:23:27.271189  2164 net.cpp:165] Memory required for data: 3887360
I0428 22:23:27.271212  2164 layer_factory.hpp:77] Creating layer conv2
I0428 22:23:27.271244  2164 net.cpp:106] Creating Layer conv2
I0428 22:23:27.271266  2164 net.cpp:454] conv2 <- pool1
I0428 22:23:27.271292  2164 net.cpp:411] conv2 -> conv2
I0428 22:23:27.274025  2164 net.cpp:150] Setting up conv2
I0428 22:23:27.274086  2164 net.cpp:157] Top shape: 64 50 8 8 (204800)
I0428 22:23:27.274109  2164 net.cpp:165] Memory required for data: 4706560
I0428 22:23:27.274143  2164 layer_factory.hpp:77] Creating layer pool2
I0428 22:23:27.274174  2164 net.cpp:106] Creating Layer pool2
I0428 22:23:27.274197  2164 net.cpp:454] pool2 <- conv2
I0428 22:23:27.274222  2164 net.cpp:411] pool2 -> pool2
I0428 22:23:27.275007  2164 net.cpp:150] Setting up pool2
I0428 22:23:27.275043  2164 net.cpp:157] Top shape: 64 50 4 4 (51200)
I0428 22:23:27.275068  2164 net.cpp:165] Memory required for data: 4911360
I0428 22:23:27.275090  2164 layer_factory.hpp:77] Creating layer ip1
I0428 22:23:27.275117  2164 net.cpp:106] Creating Layer ip1
I0428 22:23:27.275140  2164 net.cpp:454] ip1 <- pool2
I0428 22:23:27.275166  2164 net.cpp:411] ip1 -> ip1
I0428 22:23:27.279134  2164 net.cpp:150] Setting up ip1
I0428 22:23:27.279211  2164 net.cpp:157] Top shape: 64 500 (32000)
I0428 22:23:27.279232  2164 net.cpp:165] Memory required for data: 5039360
I0428 22:23:27.279264  2164 layer_factory.hpp:77] Creating layer relu1
I0428 22:23:27.279295  2164 net.cpp:106] Creating Layer relu1
I0428 22:23:27.279317  2164 net.cpp:454] relu1 <- ip1
I0428 22:23:27.279342  2164 net.cpp:397] relu1 -> ip1 (in-place)
I0428 22:23:27.280244  2164 net.cpp:150] Setting up relu1
I0428 22:23:27.280284  2164 net.cpp:157] Top shape: 64 500 (32000)
I0428 22:23:27.280308  2164 net.cpp:165] Memory required for data: 5167360
I0428 22:23:27.280331  2164 layer_factory.hpp:77] Creating layer ip2
I0428 22:23:27.280359  2164 net.cpp:106] Creating Layer ip2
I0428 22:23:27.280380  2164 net.cpp:454] ip2 <- ip1
I0428 22:23:27.280407  2164 net.cpp:411] ip2 -> ip2
I0428 22:23:27.281142  2164 net.cpp:150] Setting up ip2
I0428 22:23:27.281184  2164 net.cpp:157] Top shape: 64 10 (640)
I0428 22:23:27.281208  2164 net.cpp:165] Memory required for data: 5169920
I0428 22:23:27.281237  2164 layer_factory.hpp:77] Creating layer relu2
I0428 22:23:27.281266  2164 net.cpp:106] Creating Layer relu2
I0428 22:23:27.281288  2164 net.cpp:454] relu2 <- ip2
I0428 22:23:27.281311  2164 net.cpp:411] relu2 -> relu2
I0428 22:23:27.282162  2164 net.cpp:150] Setting up relu2
I0428 22:23:27.282198  2164 net.cpp:157] Top shape: 64 10 (640)
I0428 22:23:27.282222  2164 net.cpp:165] Memory required for data: 5172480
I0428 22:23:27.282244  2164 layer_factory.hpp:77] Creating layer loss
I0428 22:23:27.282277  2164 net.cpp:106] Creating Layer loss
I0428 22:23:27.282301  2164 net.cpp:454] loss <- relu2
I0428 22:23:27.282323  2164 net.cpp:454] loss <- label
I0428 22:23:27.282352  2164 net.cpp:411] loss -> loss
I0428 22:23:27.282385  2164 layer_factory.hpp:77] Creating layer loss
I0428 22:23:27.283296  2164 net.cpp:150] Setting up loss
I0428 22:23:27.283334  2164 net.cpp:157] Top shape: (1)
I0428 22:23:27.283357  2164 net.cpp:160]     with loss weight 1
I0428 22:23:27.283395  2164 net.cpp:165] Memory required for data: 5172484
I0428 22:23:27.283416  2164 net.cpp:226] loss needs backward computation.
I0428 22:23:27.283437  2164 net.cpp:226] relu2 needs backward computation.
I0428 22:23:27.283457  2164 net.cpp:226] ip2 needs backward computation.
I0428 22:23:27.283478  2164 net.cpp:226] relu1 needs backward computation.
I0428 22:23:27.283499  2164 net.cpp:226] ip1 needs backward computation.
I0428 22:23:27.283519  2164 net.cpp:226] pool2 needs backward computation.
I0428 22:23:27.283538  2164 net.cpp:226] conv2 needs backward computation.
I0428 22:23:27.283558  2164 net.cpp:226] pool1 needs backward computation.
I0428 22:23:27.283598  2164 net.cpp:226] conv1 needs backward computation.
I0428 22:23:27.283622  2164 net.cpp:228] mnist does not need backward computation.
I0428 22:23:27.283643  2164 net.cpp:270] This network produces output loss
I0428 22:23:27.283676  2164 net.cpp:283] Network initialization done.
I0428 22:23:27.284209  2164 solver.cpp:181] Creating test net (#0) specified by net file: examples/mnist/test/lenet_train_test.prototxt
I0428 22:23:27.284268  2164 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0428 22:23:27.284421  2164 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "relu2"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "relu2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "relu2"
  bottom: "label"
  top: "loss"
}
I0428 22:23:27.285032  2164 layer_factory.hpp:77] Creating layer mnist
I0428 22:23:27.288928  2164 net.cpp:106] Creating Layer mnist
I0428 22:23:27.289006  2164 net.cpp:411] mnist -> data
I0428 22:23:27.289047  2164 net.cpp:411] mnist -> label
I0428 22:23:27.289996  2270 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_test_lmdb
I0428 22:23:27.290171  2164 data_layer.cpp:41] output data size: 100,1,28,28
I0428 22:23:27.291345  2164 net.cpp:150] Setting up mnist
I0428 22:23:27.291378  2164 net.cpp:157] Top shape: 100 1 28 28 (78400)
I0428 22:23:27.291393  2164 net.cpp:157] Top shape: 100 (100)
I0428 22:23:27.291404  2164 net.cpp:165] Memory required for data: 314000
I0428 22:23:27.291417  2164 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0428 22:23:27.291436  2164 net.cpp:106] Creating Layer label_mnist_1_split
I0428 22:23:27.291450  2164 net.cpp:454] label_mnist_1_split <- label
I0428 22:23:27.291466  2164 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_0
I0428 22:23:27.291486  2164 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_1
I0428 22:23:27.291543  2164 net.cpp:150] Setting up label_mnist_1_split
I0428 22:23:27.291563  2164 net.cpp:157] Top shape: 100 (100)
I0428 22:23:27.291574  2164 net.cpp:157] Top shape: 100 (100)
I0428 22:23:27.291594  2164 net.cpp:165] Memory required for data: 314800
I0428 22:23:27.291617  2164 layer_factory.hpp:77] Creating layer conv1
I0428 22:23:27.291640  2164 net.cpp:106] Creating Layer conv1
I0428 22:23:27.291653  2164 net.cpp:454] conv1 <- data
I0428 22:23:27.291667  2164 net.cpp:411] conv1 -> conv1
I0428 22:23:27.298001  2164 net.cpp:150] Setting up conv1
I0428 22:23:27.298069  2164 net.cpp:157] Top shape: 100 20 24 24 (1152000)
I0428 22:23:27.298089  2164 net.cpp:165] Memory required for data: 4922800
I0428 22:23:27.298125  2164 layer_factory.hpp:77] Creating layer pool1
I0428 22:23:27.298159  2164 net.cpp:106] Creating Layer pool1
I0428 22:23:27.298183  2164 net.cpp:454] pool1 <- conv1
I0428 22:23:27.298213  2164 net.cpp:411] pool1 -> pool1
I0428 22:23:27.299077  2164 net.cpp:150] Setting up pool1
I0428 22:23:27.299118  2164 net.cpp:157] Top shape: 100 20 12 12 (288000)
I0428 22:23:27.299144  2164 net.cpp:165] Memory required for data: 6074800
I0428 22:23:27.299166  2164 layer_factory.hpp:77] Creating layer conv2
I0428 22:23:27.299197  2164 net.cpp:106] Creating Layer conv2
I0428 22:23:27.299221  2164 net.cpp:454] conv2 <- pool1
I0428 22:23:27.299250  2164 net.cpp:411] conv2 -> conv2
I0428 22:23:27.302254  2164 net.cpp:150] Setting up conv2
I0428 22:23:27.302327  2164 net.cpp:157] Top shape: 100 50 8 8 (320000)
I0428 22:23:27.302348  2164 net.cpp:165] Memory required for data: 7354800
I0428 22:23:27.302382  2164 layer_factory.hpp:77] Creating layer pool2
I0428 22:23:27.302413  2164 net.cpp:106] Creating Layer pool2
I0428 22:23:27.302438  2164 net.cpp:454] pool2 <- conv2
I0428 22:23:27.302465  2164 net.cpp:411] pool2 -> pool2
I0428 22:23:27.303303  2164 net.cpp:150] Setting up pool2
I0428 22:23:27.303336  2164 net.cpp:157] Top shape: 100 50 4 4 (80000)
I0428 22:23:27.303360  2164 net.cpp:165] Memory required for data: 7674800
I0428 22:23:27.303383  2164 layer_factory.hpp:77] Creating layer ip1
I0428 22:23:27.303412  2164 net.cpp:106] Creating Layer ip1
I0428 22:23:27.303433  2164 net.cpp:454] ip1 <- pool2
I0428 22:23:27.303457  2164 net.cpp:411] ip1 -> ip1
I0428 22:23:27.307436  2164 net.cpp:150] Setting up ip1
I0428 22:23:27.307512  2164 net.cpp:157] Top shape: 100 500 (50000)
I0428 22:23:27.307533  2164 net.cpp:165] Memory required for data: 7874800
I0428 22:23:27.307564  2164 layer_factory.hpp:77] Creating layer relu1
I0428 22:23:27.307597  2164 net.cpp:106] Creating Layer relu1
I0428 22:23:27.307621  2164 net.cpp:454] relu1 <- ip1
I0428 22:23:27.307646  2164 net.cpp:397] relu1 -> ip1 (in-place)
I0428 22:23:27.308588  2164 net.cpp:150] Setting up relu1
I0428 22:23:27.308640  2164 net.cpp:157] Top shape: 100 500 (50000)
I0428 22:23:27.308663  2164 net.cpp:165] Memory required for data: 8074800
I0428 22:23:27.308687  2164 layer_factory.hpp:77] Creating layer ip2
I0428 22:23:27.308717  2164 net.cpp:106] Creating Layer ip2
I0428 22:23:27.308740  2164 net.cpp:454] ip2 <- ip1
I0428 22:23:27.308768  2164 net.cpp:411] ip2 -> ip2
I0428 22:23:27.308997  2164 net.cpp:150] Setting up ip2
I0428 22:23:27.309029  2164 net.cpp:157] Top shape: 100 10 (1000)
I0428 22:23:27.309051  2164 net.cpp:165] Memory required for data: 8078800
I0428 22:23:27.309078  2164 layer_factory.hpp:77] Creating layer relu2
I0428 22:23:27.309104  2164 net.cpp:106] Creating Layer relu2
I0428 22:23:27.309125  2164 net.cpp:454] relu2 <- ip2
I0428 22:23:27.309149  2164 net.cpp:411] relu2 -> relu2
I0428 22:23:27.310083  2164 net.cpp:150] Setting up relu2
I0428 22:23:27.310133  2164 net.cpp:157] Top shape: 100 10 (1000)
I0428 22:23:27.310158  2164 net.cpp:165] Memory required for data: 8082800
I0428 22:23:27.310180  2164 layer_factory.hpp:77] Creating layer relu2_relu2_0_split
I0428 22:23:27.310206  2164 net.cpp:106] Creating Layer relu2_relu2_0_split
I0428 22:23:27.310227  2164 net.cpp:454] relu2_relu2_0_split <- relu2
I0428 22:23:27.310256  2164 net.cpp:411] relu2_relu2_0_split -> relu2_relu2_0_split_0
I0428 22:23:27.310284  2164 net.cpp:411] relu2_relu2_0_split -> relu2_relu2_0_split_1
I0428 22:23:27.310354  2164 net.cpp:150] Setting up relu2_relu2_0_split
I0428 22:23:27.310392  2164 net.cpp:157] Top shape: 100 10 (1000)
I0428 22:23:27.310427  2164 net.cpp:157] Top shape: 100 10 (1000)
I0428 22:23:27.310447  2164 net.cpp:165] Memory required for data: 8090800
I0428 22:23:27.310467  2164 layer_factory.hpp:77] Creating layer accuracy
I0428 22:23:27.310494  2164 net.cpp:106] Creating Layer accuracy
I0428 22:23:27.310515  2164 net.cpp:454] accuracy <- relu2_relu2_0_split_0
I0428 22:23:27.310537  2164 net.cpp:454] accuracy <- label_mnist_1_split_0
I0428 22:23:27.310564  2164 net.cpp:411] accuracy -> accuracy
I0428 22:23:27.310592  2164 net.cpp:150] Setting up accuracy
I0428 22:23:27.310616  2164 net.cpp:157] Top shape: (1)
I0428 22:23:27.310636  2164 net.cpp:165] Memory required for data: 8090804
I0428 22:23:27.310655  2164 layer_factory.hpp:77] Creating layer loss
I0428 22:23:27.310680  2164 net.cpp:106] Creating Layer loss
I0428 22:23:27.310701  2164 net.cpp:454] loss <- relu2_relu2_0_split_1
I0428 22:23:27.310724  2164 net.cpp:454] loss <- label_mnist_1_split_1
I0428 22:23:27.310746  2164 net.cpp:411] loss -> loss
I0428 22:23:27.310775  2164 layer_factory.hpp:77] Creating layer loss
I0428 22:23:27.311784  2164 net.cpp:150] Setting up loss
I0428 22:23:27.311823  2164 net.cpp:157] Top shape: (1)
I0428 22:23:27.311846  2164 net.cpp:160]     with loss weight 1
I0428 22:23:27.311874  2164 net.cpp:165] Memory required for data: 8090808
I0428 22:23:27.311895  2164 net.cpp:226] loss needs backward computation.
I0428 22:23:27.311918  2164 net.cpp:228] accuracy does not need backward computation.
I0428 22:23:27.311939  2164 net.cpp:226] relu2_relu2_0_split needs backward computation.
I0428 22:23:27.311961  2164 net.cpp:226] relu2 needs backward computation.
I0428 22:23:27.311982  2164 net.cpp:226] ip2 needs backward computation.
I0428 22:23:27.312001  2164 net.cpp:226] relu1 needs backward computation.
I0428 22:23:27.312021  2164 net.cpp:226] ip1 needs backward computation.
I0428 22:23:27.312041  2164 net.cpp:226] pool2 needs backward computation.
I0428 22:23:27.312060  2164 net.cpp:226] conv2 needs backward computation.
I0428 22:23:27.312082  2164 net.cpp:226] pool1 needs backward computation.
I0428 22:23:27.312101  2164 net.cpp:226] conv1 needs backward computation.
I0428 22:23:27.312122  2164 net.cpp:228] label_mnist_1_split does not need backward computation.
I0428 22:23:27.312144  2164 net.cpp:228] mnist does not need backward computation.
I0428 22:23:27.312162  2164 net.cpp:270] This network produces output accuracy
I0428 22:23:27.312182  2164 net.cpp:270] This network produces output loss
I0428 22:23:27.312219  2164 net.cpp:283] Network initialization done.
I0428 22:23:27.312327  2164 solver.cpp:60] Solver scaffolding done.
I0428 22:23:27.312692  2164 caffe.cpp:212] Starting Optimization
I0428 22:23:27.312721  2164 solver.cpp:288] Solving LeNet
I0428 22:23:27.312741  2164 solver.cpp:289] Learning Rate Policy: inv
I0428 22:23:27.313282  2164 solver.cpp:341] Iteration 0, Testing net (#0)
I0428 22:23:27.327143  2164 blocking_queue.cpp:50] Data layer prefetch queue empty
I0428 22:23:27.455278  2164 solver.cpp:409]     Test net output #0: accuracy = 0.0979
I0428 22:23:27.455348  2164 solver.cpp:409]     Test net output #1: loss = 2.31113 (* 1 = 2.31113 loss)
I0428 22:23:27.461643  2164 solver.cpp:237] Iteration 0, loss = 2.30532
I0428 22:23:27.461709  2164 solver.cpp:253]     Train net output #0: loss = 2.30532 (* 1 = 2.30532 loss)
I0428 22:23:27.461740  2164 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0428 22:23:27.694351  2164 solver.cpp:237] Iteration 100, loss = 0.564902
I0428 22:23:27.694430  2164 solver.cpp:253]     Train net output #0: loss = 0.564902 (* 1 = 0.564902 loss)
I0428 22:23:27.694453  2164 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0428 22:23:27.900943  2164 solver.cpp:237] Iteration 200, loss = 0.407247
I0428 22:23:27.901033  2164 solver.cpp:253]     Train net output #0: loss = 0.407247 (* 1 = 0.407247 loss)
I0428 22:23:27.901062  2164 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0428 22:23:28.108965  2164 solver.cpp:237] Iteration 300, loss = 0.230007
I0428 22:23:28.109071  2164 solver.cpp:253]     Train net output #0: loss = 0.230007 (* 1 = 0.230007 loss)
I0428 22:23:28.109120  2164 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0428 22:23:28.321518  2164 solver.cpp:237] Iteration 400, loss = 0.0956244
I0428 22:23:28.321604  2164 solver.cpp:253]     Train net output #0: loss = 0.0956244 (* 1 = 0.0956244 loss)
I0428 22:23:28.321629  2164 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0428 22:23:28.521986  2164 solver.cpp:237] Iteration 500, loss = 0.124788
I0428 22:23:28.522070  2164 solver.cpp:253]     Train net output #0: loss = 0.124788 (* 1 = 0.124788 loss)
I0428 22:23:28.522094  2164 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0428 22:23:28.731181  2164 solver.cpp:237] Iteration 600, loss = 0.0841964
I0428 22:23:28.731268  2164 solver.cpp:253]     Train net output #0: loss = 0.0841964 (* 1 = 0.0841964 loss)
I0428 22:23:28.731292  2164 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0428 22:23:28.943737  2164 solver.cpp:237] Iteration 700, loss = 0.139671
I0428 22:23:28.943814  2164 solver.cpp:253]     Train net output #0: loss = 0.139671 (* 1 = 0.139671 loss)
I0428 22:23:28.943833  2164 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0428 22:23:29.151790  2164 solver.cpp:237] Iteration 800, loss = 0.222265
I0428 22:23:29.151865  2164 solver.cpp:253]     Train net output #0: loss = 0.222265 (* 1 = 0.222265 loss)
I0428 22:23:29.151883  2164 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0428 22:23:29.373492  2164 solver.cpp:237] Iteration 900, loss = 0.154644
I0428 22:23:29.373576  2164 solver.cpp:253]     Train net output #0: loss = 0.154644 (* 1 = 0.154644 loss)
I0428 22:23:29.373600  2164 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0428 22:23:29.585983  2164 solver.cpp:237] Iteration 1000, loss = 0.0693794
I0428 22:23:29.586066  2164 solver.cpp:253]     Train net output #0: loss = 0.0693794 (* 1 = 0.0693794 loss)
I0428 22:23:29.586089  2164 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0428 22:23:29.792490  2164 solver.cpp:237] Iteration 1100, loss = 0.013535
I0428 22:23:29.792580  2164 solver.cpp:253]     Train net output #0: loss = 0.013535 (* 1 = 0.013535 loss)
I0428 22:23:29.792609  2164 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0428 22:23:30.006901  2164 solver.cpp:237] Iteration 1200, loss = 0.0259873
I0428 22:23:30.006986  2164 solver.cpp:253]     Train net output #0: loss = 0.0259873 (* 1 = 0.0259873 loss)
I0428 22:23:30.007010  2164 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0428 22:23:30.229147  2164 solver.cpp:237] Iteration 1300, loss = 0.0188297
I0428 22:23:30.229218  2164 solver.cpp:253]     Train net output #0: loss = 0.0188296 (* 1 = 0.0188296 loss)
I0428 22:23:30.229238  2164 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0428 22:23:30.450054  2164 solver.cpp:237] Iteration 1400, loss = 0.0102755
I0428 22:23:30.450126  2164 solver.cpp:253]     Train net output #0: loss = 0.0102754 (* 1 = 0.0102754 loss)
I0428 22:23:30.450146  2164 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0428 22:23:30.655306  2164 solver.cpp:237] Iteration 1500, loss = 0.0856809
I0428 22:23:30.655390  2164 solver.cpp:253]     Train net output #0: loss = 0.0856809 (* 1 = 0.0856809 loss)
I0428 22:23:30.655414  2164 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0428 22:23:30.861352  2164 solver.cpp:237] Iteration 1600, loss = 0.105687
I0428 22:23:30.861439  2164 solver.cpp:253]     Train net output #0: loss = 0.105687 (* 1 = 0.105687 loss)
I0428 22:23:30.861464  2164 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0428 22:23:31.069978  2164 solver.cpp:237] Iteration 1700, loss = 0.0415087
I0428 22:23:31.070062  2164 solver.cpp:253]     Train net output #0: loss = 0.0415087 (* 1 = 0.0415087 loss)
I0428 22:23:31.070086  2164 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0428 22:23:31.285997  2164 solver.cpp:237] Iteration 1800, loss = 0.0294133
I0428 22:23:31.286082  2164 solver.cpp:253]     Train net output #0: loss = 0.0294133 (* 1 = 0.0294133 loss)
I0428 22:23:31.286118  2164 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0428 22:23:31.496922  2164 solver.cpp:237] Iteration 1900, loss = 0.123552
I0428 22:23:31.497005  2164 solver.cpp:253]     Train net output #0: loss = 0.123552 (* 1 = 0.123552 loss)
I0428 22:23:31.497030  2164 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0428 22:23:31.709718  2164 solver.cpp:237] Iteration 2000, loss = 0.0152471
I0428 22:23:31.709800  2164 solver.cpp:253]     Train net output #0: loss = 0.0152471 (* 1 = 0.0152471 loss)
I0428 22:23:31.709825  2164 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0428 22:23:31.928102  2164 solver.cpp:237] Iteration 2100, loss = 0.0154123
I0428 22:23:31.928177  2164 solver.cpp:253]     Train net output #0: loss = 0.0154122 (* 1 = 0.0154122 loss)
I0428 22:23:31.928205  2164 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0428 22:23:32.143999  2164 solver.cpp:237] Iteration 2200, loss = 0.0127413
I0428 22:23:32.144073  2164 solver.cpp:253]     Train net output #0: loss = 0.0127412 (* 1 = 0.0127412 loss)
I0428 22:23:32.144093  2164 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0428 22:23:32.363705  2164 solver.cpp:237] Iteration 2300, loss = 0.113056
I0428 22:23:32.363780  2164 solver.cpp:253]     Train net output #0: loss = 0.113056 (* 1 = 0.113056 loss)
I0428 22:23:32.363801  2164 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0428 22:23:32.586343  2164 solver.cpp:237] Iteration 2400, loss = 0.00819128
I0428 22:23:32.586421  2164 solver.cpp:253]     Train net output #0: loss = 0.00819128 (* 1 = 0.00819128 loss)
I0428 22:23:32.586447  2164 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0428 22:23:32.812037  2164 solver.cpp:237] Iteration 2500, loss = 0.0232169
I0428 22:23:32.812119  2164 solver.cpp:253]     Train net output #0: loss = 0.0232169 (* 1 = 0.0232169 loss)
I0428 22:23:32.812146  2164 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0428 22:23:33.026036  2164 solver.cpp:237] Iteration 2600, loss = 0.0807569
I0428 22:23:33.026119  2164 solver.cpp:253]     Train net output #0: loss = 0.0807569 (* 1 = 0.0807569 loss)
I0428 22:23:33.026144  2164 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0428 22:23:33.243649  2164 solver.cpp:237] Iteration 2700, loss = 0.0631208
I0428 22:23:33.243737  2164 solver.cpp:253]     Train net output #0: loss = 0.0631209 (* 1 = 0.0631209 loss)
I0428 22:23:33.243762  2164 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0428 22:23:33.475703  2164 solver.cpp:237] Iteration 2800, loss = 0.00614306
I0428 22:23:33.475781  2164 solver.cpp:253]     Train net output #0: loss = 0.00614313 (* 1 = 0.00614313 loss)
I0428 22:23:33.475805  2164 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0428 22:23:33.695745  2164 solver.cpp:237] Iteration 2900, loss = 0.0383818
I0428 22:23:33.695823  2164 solver.cpp:253]     Train net output #0: loss = 0.0383818 (* 1 = 0.0383818 loss)
I0428 22:23:33.695843  2164 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0428 22:23:33.903687  2164 solver.cpp:237] Iteration 3000, loss = 0.0295817
I0428 22:23:33.903762  2164 solver.cpp:253]     Train net output #0: loss = 0.0295818 (* 1 = 0.0295818 loss)
I0428 22:23:33.903781  2164 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0428 22:23:34.119683  2164 solver.cpp:237] Iteration 3100, loss = 0.0228346
I0428 22:23:34.119771  2164 solver.cpp:253]     Train net output #0: loss = 0.0228346 (* 1 = 0.0228346 loss)
I0428 22:23:34.119801  2164 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0428 22:23:34.342233  2164 solver.cpp:237] Iteration 3200, loss = 0.00848646
I0428 22:23:34.342324  2164 solver.cpp:253]     Train net output #0: loss = 0.0084865 (* 1 = 0.0084865 loss)
I0428 22:23:34.342346  2164 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0428 22:23:34.557991  2164 solver.cpp:237] Iteration 3300, loss = 0.0476615
I0428 22:23:34.558082  2164 solver.cpp:253]     Train net output #0: loss = 0.0476615 (* 1 = 0.0476615 loss)
I0428 22:23:34.558106  2164 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0428 22:23:34.779569  2164 solver.cpp:237] Iteration 3400, loss = 0.0075994
I0428 22:23:34.779666  2164 solver.cpp:253]     Train net output #0: loss = 0.00759945 (* 1 = 0.00759945 loss)
I0428 22:23:34.779686  2164 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0428 22:23:35.001989  2164 solver.cpp:237] Iteration 3500, loss = 0.00624279
I0428 22:23:35.002079  2164 solver.cpp:253]     Train net output #0: loss = 0.00624284 (* 1 = 0.00624284 loss)
I0428 22:23:35.002102  2164 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0428 22:23:35.210919  2164 solver.cpp:237] Iteration 3600, loss = 0.0427415
I0428 22:23:35.211004  2164 solver.cpp:253]     Train net output #0: loss = 0.0427416 (* 1 = 0.0427416 loss)
I0428 22:23:35.211029  2164 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0428 22:23:35.421962  2164 solver.cpp:237] Iteration 3700, loss = 0.015883
I0428 22:23:35.422051  2164 solver.cpp:253]     Train net output #0: loss = 0.015883 (* 1 = 0.015883 loss)
I0428 22:23:35.422075  2164 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0428 22:23:35.648998  2164 solver.cpp:237] Iteration 3800, loss = 0.00523207
I0428 22:23:35.649085  2164 solver.cpp:253]     Train net output #0: loss = 0.00523214 (* 1 = 0.00523214 loss)
I0428 22:23:35.649109  2164 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0428 22:23:35.869616  2164 solver.cpp:237] Iteration 3900, loss = 0.0334105
I0428 22:23:35.869705  2164 solver.cpp:253]     Train net output #0: loss = 0.0334106 (* 1 = 0.0334106 loss)
I0428 22:23:35.869730  2164 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0428 22:23:36.081528  2164 solver.cpp:237] Iteration 4000, loss = 0.0182451
I0428 22:23:36.081619  2164 solver.cpp:253]     Train net output #0: loss = 0.0182452 (* 1 = 0.0182452 loss)
I0428 22:23:36.081642  2164 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0428 22:23:36.294272  2164 solver.cpp:237] Iteration 4100, loss = 0.0475202
I0428 22:23:36.294364  2164 solver.cpp:253]     Train net output #0: loss = 0.0475203 (* 1 = 0.0475203 loss)
I0428 22:23:36.294395  2164 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0428 22:23:36.521827  2164 solver.cpp:237] Iteration 4200, loss = 0.0109354
I0428 22:23:36.521919  2164 solver.cpp:253]     Train net output #0: loss = 0.0109355 (* 1 = 0.0109355 loss)
I0428 22:23:36.521949  2164 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0428 22:23:36.725888  2164 solver.cpp:237] Iteration 4300, loss = 0.0462428
I0428 22:23:36.725937  2164 solver.cpp:253]     Train net output #0: loss = 0.0462429 (* 1 = 0.0462429 loss)
I0428 22:23:36.725950  2164 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0428 22:23:36.951071  2164 solver.cpp:237] Iteration 4400, loss = 0.0229963
I0428 22:23:36.951165  2164 solver.cpp:253]     Train net output #0: loss = 0.0229963 (* 1 = 0.0229963 loss)
I0428 22:23:36.951198  2164 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0428 22:23:37.161993  2164 solver.cpp:237] Iteration 4500, loss = 0.00597889
I0428 22:23:37.162081  2164 solver.cpp:253]     Train net output #0: loss = 0.00597895 (* 1 = 0.00597895 loss)
I0428 22:23:37.162107  2164 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0428 22:23:37.374300  2164 solver.cpp:237] Iteration 4600, loss = 0.0115209
I0428 22:23:37.374389  2164 solver.cpp:253]     Train net output #0: loss = 0.0115209 (* 1 = 0.0115209 loss)
I0428 22:23:37.374413  2164 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0428 22:23:37.549675  2164 solver.cpp:237] Iteration 4700, loss = 0.00532901
I0428 22:23:37.549762  2164 solver.cpp:253]     Train net output #0: loss = 0.00532905 (* 1 = 0.00532905 loss)
I0428 22:23:37.549785  2164 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0428 22:23:37.724992  2164 solver.cpp:237] Iteration 4800, loss = 0.0254249
I0428 22:23:37.725080  2164 solver.cpp:253]     Train net output #0: loss = 0.025425 (* 1 = 0.025425 loss)
I0428 22:23:37.725102  2164 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0428 22:23:37.900480  2164 solver.cpp:237] Iteration 4900, loss = 0.00354374
I0428 22:23:37.900564  2164 solver.cpp:253]     Train net output #0: loss = 0.00354376 (* 1 = 0.00354376 loss)
I0428 22:23:37.900615  2164 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0428 22:23:38.091975  2164 solver.cpp:341] Iteration 5000, Testing net (#0)
I0428 22:23:38.248517  2164 solver.cpp:409]     Test net output #0: accuracy = 0.9886
I0428 22:23:38.248594  2164 solver.cpp:409]     Test net output #1: loss = 0.0318233 (* 1 = 0.0318233 loss)
I0428 22:23:38.249583  2164 solver.cpp:237] Iteration 5000, loss = 0.0334763
I0428 22:23:38.249634  2164 solver.cpp:253]     Train net output #0: loss = 0.0334763 (* 1 = 0.0334763 loss)
I0428 22:23:38.249667  2164 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0428 22:23:38.435725  2164 solver.cpp:237] Iteration 5100, loss = 0.024546
I0428 22:23:38.435813  2164 solver.cpp:253]     Train net output #0: loss = 0.024546 (* 1 = 0.024546 loss)
I0428 22:23:38.435838  2164 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0428 22:23:38.612474  2164 solver.cpp:237] Iteration 5200, loss = 0.00738627
I0428 22:23:38.612565  2164 solver.cpp:253]     Train net output #0: loss = 0.00738629 (* 1 = 0.00738629 loss)
I0428 22:23:38.612589  2164 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0428 22:23:38.783815  2164 solver.cpp:237] Iteration 5300, loss = 0.00190094
I0428 22:23:38.783903  2164 solver.cpp:253]     Train net output #0: loss = 0.00190096 (* 1 = 0.00190096 loss)
I0428 22:23:38.783927  2164 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0428 22:23:39.002127  2164 solver.cpp:237] Iteration 5400, loss = 0.0115549
I0428 22:23:39.002212  2164 solver.cpp:253]     Train net output #0: loss = 0.0115549 (* 1 = 0.0115549 loss)
I0428 22:23:39.002238  2164 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0428 22:23:39.191910  2164 solver.cpp:237] Iteration 5500, loss = 0.00845364
I0428 22:23:39.192001  2164 solver.cpp:253]     Train net output #0: loss = 0.00845365 (* 1 = 0.00845365 loss)
I0428 22:23:39.192030  2164 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0428 22:23:39.362886  2164 solver.cpp:237] Iteration 5600, loss = 0.00155767
I0428 22:23:39.362975  2164 solver.cpp:253]     Train net output #0: loss = 0.00155769 (* 1 = 0.00155769 loss)
I0428 22:23:39.363006  2164 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0428 22:23:39.534972  2164 solver.cpp:237] Iteration 5700, loss = 0.00280508
I0428 22:23:39.535060  2164 solver.cpp:253]     Train net output #0: loss = 0.00280509 (* 1 = 0.00280509 loss)
I0428 22:23:39.535091  2164 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0428 22:23:39.707382  2164 solver.cpp:237] Iteration 5800, loss = 0.0598177
I0428 22:23:39.707471  2164 solver.cpp:253]     Train net output #0: loss = 0.0598177 (* 1 = 0.0598177 loss)
I0428 22:23:39.707502  2164 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0428 22:23:39.885810  2164 solver.cpp:237] Iteration 5900, loss = 0.00290896
I0428 22:23:39.885897  2164 solver.cpp:253]     Train net output #0: loss = 0.00290896 (* 1 = 0.00290896 loss)
I0428 22:23:39.885928  2164 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0428 22:23:40.058995  2164 solver.cpp:237] Iteration 6000, loss = 0.00318136
I0428 22:23:40.059088  2164 solver.cpp:253]     Train net output #0: loss = 0.00318136 (* 1 = 0.00318136 loss)
I0428 22:23:40.059120  2164 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0428 22:23:40.231490  2164 solver.cpp:237] Iteration 6100, loss = 0.00124243
I0428 22:23:40.231581  2164 solver.cpp:253]     Train net output #0: loss = 0.00124242 (* 1 = 0.00124242 loss)
I0428 22:23:40.231612  2164 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0428 22:23:40.404222  2164 solver.cpp:237] Iteration 6200, loss = 0.00987103
I0428 22:23:40.404310  2164 solver.cpp:253]     Train net output #0: loss = 0.00987102 (* 1 = 0.00987102 loss)
I0428 22:23:40.404341  2164 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0428 22:23:40.576793  2164 solver.cpp:237] Iteration 6300, loss = 0.0121416
I0428 22:23:40.576884  2164 solver.cpp:253]     Train net output #0: loss = 0.0121416 (* 1 = 0.0121416 loss)
I0428 22:23:40.576925  2164 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0428 22:23:40.749491  2164 solver.cpp:237] Iteration 6400, loss = 0.00672198
I0428 22:23:40.749582  2164 solver.cpp:253]     Train net output #0: loss = 0.00672196 (* 1 = 0.00672196 loss)
I0428 22:23:40.749613  2164 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0428 22:23:40.920488  2164 solver.cpp:237] Iteration 6500, loss = 0.0131617
I0428 22:23:40.920580  2164 solver.cpp:253]     Train net output #0: loss = 0.0131616 (* 1 = 0.0131616 loss)
I0428 22:23:40.920611  2164 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0428 22:23:41.093116  2164 solver.cpp:237] Iteration 6600, loss = 0.0170698
I0428 22:23:41.093209  2164 solver.cpp:253]     Train net output #0: loss = 0.0170698 (* 1 = 0.0170698 loss)
I0428 22:23:41.093240  2164 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0428 22:23:41.265242  2164 solver.cpp:237] Iteration 6700, loss = 0.00832492
I0428 22:23:41.265332  2164 solver.cpp:253]     Train net output #0: loss = 0.00832491 (* 1 = 0.00832491 loss)
I0428 22:23:41.265362  2164 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0428 22:23:41.437892  2164 solver.cpp:237] Iteration 6800, loss = 0.00241621
I0428 22:23:41.437983  2164 solver.cpp:253]     Train net output #0: loss = 0.0024162 (* 1 = 0.0024162 loss)
I0428 22:23:41.438012  2164 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0428 22:23:41.620095  2164 solver.cpp:237] Iteration 6900, loss = 0.00533781
I0428 22:23:41.620187  2164 solver.cpp:253]     Train net output #0: loss = 0.00533781 (* 1 = 0.00533781 loss)
I0428 22:23:41.620218  2164 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0428 22:23:41.792311  2164 solver.cpp:237] Iteration 7000, loss = 0.00480855
I0428 22:23:41.792402  2164 solver.cpp:253]     Train net output #0: loss = 0.00480854 (* 1 = 0.00480854 loss)
I0428 22:23:41.792431  2164 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0428 22:23:41.964794  2164 solver.cpp:237] Iteration 7100, loss = 0.0106182
I0428 22:23:41.964886  2164 solver.cpp:253]     Train net output #0: loss = 0.0106181 (* 1 = 0.0106181 loss)
I0428 22:23:41.964923  2164 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0428 22:23:42.136665  2164 solver.cpp:237] Iteration 7200, loss = 0.00590891
I0428 22:23:42.136752  2164 solver.cpp:253]     Train net output #0: loss = 0.0059089 (* 1 = 0.0059089 loss)
I0428 22:23:42.136781  2164 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0428 22:23:42.308871  2164 solver.cpp:237] Iteration 7300, loss = 0.0271835
I0428 22:23:42.308971  2164 solver.cpp:253]     Train net output #0: loss = 0.0271835 (* 1 = 0.0271835 loss)
I0428 22:23:42.309002  2164 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0428 22:23:42.488811  2164 solver.cpp:237] Iteration 7400, loss = 0.00790345
I0428 22:23:42.488905  2164 solver.cpp:253]     Train net output #0: loss = 0.00790345 (* 1 = 0.00790345 loss)
I0428 22:23:42.488939  2164 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0428 22:23:42.659975  2164 solver.cpp:237] Iteration 7500, loss = 0.00238107
I0428 22:23:42.660061  2164 solver.cpp:253]     Train net output #0: loss = 0.00238107 (* 1 = 0.00238107 loss)
I0428 22:23:42.660089  2164 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0428 22:23:42.838310  2164 solver.cpp:237] Iteration 7600, loss = 0.00479693
I0428 22:23:42.838397  2164 solver.cpp:253]     Train net output #0: loss = 0.00479693 (* 1 = 0.00479693 loss)
I0428 22:23:42.838424  2164 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0428 22:23:43.039824  2164 solver.cpp:237] Iteration 7700, loss = 0.0209094
I0428 22:23:43.039904  2164 solver.cpp:253]     Train net output #0: loss = 0.0209094 (* 1 = 0.0209094 loss)
I0428 22:23:43.039929  2164 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0428 22:23:43.223376  2164 solver.cpp:237] Iteration 7800, loss = 0.00345621
I0428 22:23:43.223469  2164 solver.cpp:253]     Train net output #0: loss = 0.0034562 (* 1 = 0.0034562 loss)
I0428 22:23:43.223498  2164 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0428 22:23:43.405339  2164 solver.cpp:237] Iteration 7900, loss = 0.00257881
I0428 22:23:43.405444  2164 solver.cpp:253]     Train net output #0: loss = 0.0025788 (* 1 = 0.0025788 loss)
I0428 22:23:43.405472  2164 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0428 22:23:43.615743  2164 solver.cpp:237] Iteration 8000, loss = 0.00761737
I0428 22:23:43.615823  2164 solver.cpp:253]     Train net output #0: loss = 0.00761735 (* 1 = 0.00761735 loss)
I0428 22:23:43.615854  2164 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0428 22:23:43.788811  2164 solver.cpp:237] Iteration 8100, loss = 0.011147
I0428 22:23:43.788903  2164 solver.cpp:253]     Train net output #0: loss = 0.011147 (* 1 = 0.011147 loss)
I0428 22:23:43.788935  2164 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0428 22:23:43.961555  2164 solver.cpp:237] Iteration 8200, loss = 0.00613102
I0428 22:23:43.961643  2164 solver.cpp:253]     Train net output #0: loss = 0.00613101 (* 1 = 0.00613101 loss)
I0428 22:23:43.961674  2164 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0428 22:23:44.133821  2164 solver.cpp:237] Iteration 8300, loss = 0.0384226
I0428 22:23:44.133911  2164 solver.cpp:253]     Train net output #0: loss = 0.0384226 (* 1 = 0.0384226 loss)
I0428 22:23:44.133944  2164 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0428 22:23:44.306519  2164 solver.cpp:237] Iteration 8400, loss = 0.00532777
I0428 22:23:44.306607  2164 solver.cpp:253]     Train net output #0: loss = 0.00532777 (* 1 = 0.00532777 loss)
I0428 22:23:44.306639  2164 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0428 22:23:44.479676  2164 solver.cpp:237] Iteration 8500, loss = 0.00546664
I0428 22:23:44.479768  2164 solver.cpp:253]     Train net output #0: loss = 0.00546664 (* 1 = 0.00546664 loss)
I0428 22:23:44.479799  2164 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0428 22:23:44.660959  2164 solver.cpp:237] Iteration 8600, loss = 0.000571242
I0428 22:23:44.661049  2164 solver.cpp:253]     Train net output #0: loss = 0.00057124 (* 1 = 0.00057124 loss)
I0428 22:23:44.661073  2164 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0428 22:23:44.831257  2164 solver.cpp:237] Iteration 8700, loss = 0.00382856
I0428 22:23:44.831347  2164 solver.cpp:253]     Train net output #0: loss = 0.00382856 (* 1 = 0.00382856 loss)
I0428 22:23:44.831373  2164 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0428 22:23:45.001870  2164 solver.cpp:237] Iteration 8800, loss = 0.00130137
I0428 22:23:45.001957  2164 solver.cpp:253]     Train net output #0: loss = 0.00130137 (* 1 = 0.00130137 loss)
I0428 22:23:45.001983  2164 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0428 22:23:45.171844  2164 solver.cpp:237] Iteration 8900, loss = 0.000354433
I0428 22:23:45.171931  2164 solver.cpp:253]     Train net output #0: loss = 0.000354425 (* 1 = 0.000354425 loss)
I0428 22:23:45.171958  2164 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0428 22:23:45.341826  2164 solver.cpp:237] Iteration 9000, loss = 0.0196362
I0428 22:23:45.341915  2164 solver.cpp:253]     Train net output #0: loss = 0.0196362 (* 1 = 0.0196362 loss)
I0428 22:23:45.341943  2164 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0428 22:23:45.512027  2164 solver.cpp:237] Iteration 9100, loss = 0.00546214
I0428 22:23:45.512115  2164 solver.cpp:253]     Train net output #0: loss = 0.00546215 (* 1 = 0.00546215 loss)
I0428 22:23:45.512142  2164 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0428 22:23:45.681991  2164 solver.cpp:237] Iteration 9200, loss = 0.00290899
I0428 22:23:45.682080  2164 solver.cpp:253]     Train net output #0: loss = 0.002909 (* 1 = 0.002909 loss)
I0428 22:23:45.682106  2164 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0428 22:23:45.863258  2164 solver.cpp:237] Iteration 9300, loss = 0.012873
I0428 22:23:45.863340  2164 solver.cpp:253]     Train net output #0: loss = 0.0128731 (* 1 = 0.0128731 loss)
I0428 22:23:45.863368  2164 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0428 22:23:46.054893  2164 solver.cpp:237] Iteration 9400, loss = 0.0452674
I0428 22:23:46.054927  2164 solver.cpp:253]     Train net output #0: loss = 0.0452674 (* 1 = 0.0452674 loss)
I0428 22:23:46.054968  2164 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0428 22:23:46.225590  2164 solver.cpp:237] Iteration 9500, loss = 0.00461194
I0428 22:23:46.225623  2164 solver.cpp:253]     Train net output #0: loss = 0.00461196 (* 1 = 0.00461196 loss)
I0428 22:23:46.225632  2164 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0428 22:23:46.396456  2164 solver.cpp:237] Iteration 9600, loss = 0.00388296
I0428 22:23:46.396489  2164 solver.cpp:253]     Train net output #0: loss = 0.00388298 (* 1 = 0.00388298 loss)
I0428 22:23:46.396498  2164 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0428 22:23:46.567116  2164 solver.cpp:237] Iteration 9700, loss = 0.00195399
I0428 22:23:46.567148  2164 solver.cpp:253]     Train net output #0: loss = 0.00195402 (* 1 = 0.00195402 loss)
I0428 22:23:46.567157  2164 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0428 22:23:46.737849  2164 solver.cpp:237] Iteration 9800, loss = 0.01421
I0428 22:23:46.737882  2164 solver.cpp:253]     Train net output #0: loss = 0.01421 (* 1 = 0.01421 loss)
I0428 22:23:46.737891  2164 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0428 22:23:46.908710  2164 solver.cpp:237] Iteration 9900, loss = 0.0034266
I0428 22:23:46.908743  2164 solver.cpp:253]     Train net output #0: loss = 0.00342662 (* 1 = 0.00342662 loss)
I0428 22:23:46.908752  2164 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0428 22:23:47.083819  2164 solver.cpp:341] Iteration 10000, Testing net (#0)
I0428 22:23:47.225101  2164 solver.cpp:409]     Test net output #0: accuracy = 0.9893
I0428 22:23:47.225190  2164 solver.cpp:409]     Test net output #1: loss = 0.0288487 (* 1 = 0.0288487 loss)
I0428 22:23:47.226078  2164 solver.cpp:237] Iteration 10000, loss = 0.00239847
I0428 22:23:47.226153  2164 solver.cpp:253]     Train net output #0: loss = 0.0023985 (* 1 = 0.0023985 loss)
I0428 22:23:47.226177  2164 sgd_solver.cpp:106] Iteration 10000, lr = 0.00594604
I0428 22:23:47.474750  2164 solver.cpp:237] Iteration 10100, loss = 0.0164584
I0428 22:23:47.474834  2164 solver.cpp:253]     Train net output #0: loss = 0.0164584 (* 1 = 0.0164584 loss)
I0428 22:23:47.474858  2164 sgd_solver.cpp:106] Iteration 10100, lr = 0.00592384
I0428 22:23:47.654796  2164 solver.cpp:237] Iteration 10200, loss = 0.0118692
I0428 22:23:47.654878  2164 solver.cpp:253]     Train net output #0: loss = 0.0118692 (* 1 = 0.0118692 loss)
I0428 22:23:47.654901  2164 sgd_solver.cpp:106] Iteration 10200, lr = 0.00590183
I0428 22:23:47.826061  2164 solver.cpp:237] Iteration 10300, loss = 0.000321548
I0428 22:23:47.826143  2164 solver.cpp:253]     Train net output #0: loss = 0.000321588 (* 1 = 0.000321588 loss)
I0428 22:23:47.826167  2164 sgd_solver.cpp:106] Iteration 10300, lr = 0.00588001
I0428 22:23:47.997511  2164 solver.cpp:237] Iteration 10400, loss = 0.00554029
I0428 22:23:47.997594  2164 solver.cpp:253]     Train net output #0: loss = 0.00554034 (* 1 = 0.00554034 loss)
I0428 22:23:47.997617  2164 sgd_solver.cpp:106] Iteration 10400, lr = 0.00585838
I0428 22:23:48.168527  2164 solver.cpp:237] Iteration 10500, loss = 0.00774695
I0428 22:23:48.168561  2164 solver.cpp:253]     Train net output #0: loss = 0.007747 (* 1 = 0.007747 loss)
I0428 22:23:48.168570  2164 sgd_solver.cpp:106] Iteration 10500, lr = 0.00583693
I0428 22:23:48.339148  2164 solver.cpp:237] Iteration 10600, loss = 0.00373268
I0428 22:23:48.339180  2164 solver.cpp:253]     Train net output #0: loss = 0.00373273 (* 1 = 0.00373273 loss)
I0428 22:23:48.339190  2164 sgd_solver.cpp:106] Iteration 10600, lr = 0.00581567
I0428 22:23:48.509821  2164 solver.cpp:237] Iteration 10700, loss = 0.00503116
I0428 22:23:48.509853  2164 solver.cpp:253]     Train net output #0: loss = 0.00503121 (* 1 = 0.00503121 loss)
I0428 22:23:48.509862  2164 sgd_solver.cpp:106] Iteration 10700, lr = 0.00579458
I0428 22:23:48.680307  2164 solver.cpp:237] Iteration 10800, loss = 0.00267608
I0428 22:23:48.680341  2164 solver.cpp:253]     Train net output #0: loss = 0.00267614 (* 1 = 0.00267614 loss)
I0428 22:23:48.680348  2164 sgd_solver.cpp:106] Iteration 10800, lr = 0.00577368
I0428 22:23:48.850749  2164 solver.cpp:237] Iteration 10900, loss = 0.0022047
I0428 22:23:48.850783  2164 solver.cpp:253]     Train net output #0: loss = 0.00220475 (* 1 = 0.00220475 loss)
I0428 22:23:48.850792  2164 sgd_solver.cpp:106] Iteration 10900, lr = 0.00575295
I0428 22:23:49.021158  2164 solver.cpp:237] Iteration 11000, loss = 0.00237253
I0428 22:23:49.021191  2164 solver.cpp:253]     Train net output #0: loss = 0.00237257 (* 1 = 0.00237257 loss)
I0428 22:23:49.021200  2164 sgd_solver.cpp:106] Iteration 11000, lr = 0.00573239
I0428 22:23:49.191983  2164 solver.cpp:237] Iteration 11100, loss = 0.0137379
I0428 22:23:49.192016  2164 solver.cpp:253]     Train net output #0: loss = 0.013738 (* 1 = 0.013738 loss)
I0428 22:23:49.192025  2164 sgd_solver.cpp:106] Iteration 11100, lr = 0.005712
I0428 22:23:49.362403  2164 solver.cpp:237] Iteration 11200, loss = 0.00801858
I0428 22:23:49.362437  2164 solver.cpp:253]     Train net output #0: loss = 0.00801862 (* 1 = 0.00801862 loss)
I0428 22:23:49.362447  2164 sgd_solver.cpp:106] Iteration 11200, lr = 0.00569178
I0428 22:23:49.533222  2164 solver.cpp:237] Iteration 11300, loss = 0.00272214
I0428 22:23:49.533255  2164 solver.cpp:253]     Train net output #0: loss = 0.00272217 (* 1 = 0.00272217 loss)
I0428 22:23:49.533264  2164 sgd_solver.cpp:106] Iteration 11300, lr = 0.00567173
I0428 22:23:49.703807  2164 solver.cpp:237] Iteration 11400, loss = 0.00729596
I0428 22:23:49.703840  2164 solver.cpp:253]     Train net output #0: loss = 0.007296 (* 1 = 0.007296 loss)
I0428 22:23:49.703848  2164 sgd_solver.cpp:106] Iteration 11400, lr = 0.00565184
I0428 22:23:49.874359  2164 solver.cpp:237] Iteration 11500, loss = 0.0046658
I0428 22:23:49.874392  2164 solver.cpp:253]     Train net output #0: loss = 0.00466584 (* 1 = 0.00466584 loss)
I0428 22:23:49.874400  2164 sgd_solver.cpp:106] Iteration 11500, lr = 0.00563211
I0428 22:23:50.060593  2164 solver.cpp:237] Iteration 11600, loss = 0.00585004
I0428 22:23:50.060668  2164 solver.cpp:253]     Train net output #0: loss = 0.00585007 (* 1 = 0.00585007 loss)
I0428 22:23:50.060688  2164 sgd_solver.cpp:106] Iteration 11600, lr = 0.00561254
I0428 22:23:50.235337  2164 solver.cpp:237] Iteration 11700, loss = 0.00214722
I0428 22:23:50.235419  2164 solver.cpp:253]     Train net output #0: loss = 0.00214726 (* 1 = 0.00214726 loss)
I0428 22:23:50.235441  2164 sgd_solver.cpp:106] Iteration 11700, lr = 0.00559313
I0428 22:23:50.406361  2164 solver.cpp:237] Iteration 11800, loss = 0.00836919
I0428 22:23:50.406442  2164 solver.cpp:253]     Train net output #0: loss = 0.00836922 (* 1 = 0.00836922 loss)
I0428 22:23:50.406466  2164 sgd_solver.cpp:106] Iteration 11800, lr = 0.00557388
I0428 22:23:50.586091  2164 solver.cpp:237] Iteration 11900, loss = 0.00488532
I0428 22:23:50.586179  2164 solver.cpp:253]     Train net output #0: loss = 0.00488536 (* 1 = 0.00488536 loss)
I0428 22:23:50.586202  2164 sgd_solver.cpp:106] Iteration 11900, lr = 0.00555478
I0428 22:23:50.757395  2164 solver.cpp:237] Iteration 12000, loss = 0.00302175
I0428 22:23:50.757480  2164 solver.cpp:253]     Train net output #0: loss = 0.00302179 (* 1 = 0.00302179 loss)
I0428 22:23:50.757503  2164 sgd_solver.cpp:106] Iteration 12000, lr = 0.00553583
I0428 22:23:50.928205  2164 solver.cpp:237] Iteration 12100, loss = 0.00594235
I0428 22:23:50.928287  2164 solver.cpp:253]     Train net output #0: loss = 0.0059424 (* 1 = 0.0059424 loss)
I0428 22:23:50.928309  2164 sgd_solver.cpp:106] Iteration 12100, lr = 0.00551704
I0428 22:23:51.101006  2164 solver.cpp:237] Iteration 12200, loss = 0.00111187
I0428 22:23:51.101099  2164 solver.cpp:253]     Train net output #0: loss = 0.00111192 (* 1 = 0.00111192 loss)
I0428 22:23:51.101128  2164 sgd_solver.cpp:106] Iteration 12200, lr = 0.00549839
I0428 22:23:51.273665  2164 solver.cpp:237] Iteration 12300, loss = 0.00688732
I0428 22:23:51.273699  2164 solver.cpp:253]     Train net output #0: loss = 0.00688737 (* 1 = 0.00688737 loss)
I0428 22:23:51.273707  2164 sgd_solver.cpp:106] Iteration 12300, lr = 0.00547988
I0428 22:23:51.444499  2164 solver.cpp:237] Iteration 12400, loss = 0.00100098
I0428 22:23:51.444533  2164 solver.cpp:253]     Train net output #0: loss = 0.00100103 (* 1 = 0.00100103 loss)
I0428 22:23:51.444542  2164 sgd_solver.cpp:106] Iteration 12400, lr = 0.00546153
I0428 22:23:51.615700  2164 solver.cpp:237] Iteration 12500, loss = 0.0104397
I0428 22:23:51.615732  2164 solver.cpp:253]     Train net output #0: loss = 0.0104397 (* 1 = 0.0104397 loss)
I0428 22:23:51.615741  2164 sgd_solver.cpp:106] Iteration 12500, lr = 0.00544331
I0428 22:23:51.786783  2164 solver.cpp:237] Iteration 12600, loss = 0.0146343
I0428 22:23:51.786818  2164 solver.cpp:253]     Train net output #0: loss = 0.0146343 (* 1 = 0.0146343 loss)
I0428 22:23:51.786826  2164 sgd_solver.cpp:106] Iteration 12600, lr = 0.00542524
I0428 22:23:51.957485  2164 solver.cpp:237] Iteration 12700, loss = 0.00409035
I0428 22:23:51.957520  2164 solver.cpp:253]     Train net output #0: loss = 0.0040904 (* 1 = 0.0040904 loss)
I0428 22:23:51.957530  2164 sgd_solver.cpp:106] Iteration 12700, lr = 0.0054073
I0428 22:23:52.128410  2164 solver.cpp:237] Iteration 12800, loss = 0.00137147
I0428 22:23:52.128444  2164 solver.cpp:253]     Train net output #0: loss = 0.00137152 (* 1 = 0.00137152 loss)
I0428 22:23:52.128453  2164 sgd_solver.cpp:106] Iteration 12800, lr = 0.0053895
I0428 22:23:52.299532  2164 solver.cpp:237] Iteration 12900, loss = 0.00550146
I0428 22:23:52.299623  2164 solver.cpp:253]     Train net output #0: loss = 0.00550152 (* 1 = 0.00550152 loss)
I0428 22:23:52.299649  2164 sgd_solver.cpp:106] Iteration 12900, lr = 0.00537184
I0428 22:23:52.472358  2164 solver.cpp:237] Iteration 13000, loss = 0.00301349
I0428 22:23:52.472446  2164 solver.cpp:253]     Train net output #0: loss = 0.00301355 (* 1 = 0.00301355 loss)
I0428 22:23:52.472473  2164 sgd_solver.cpp:106] Iteration 13000, lr = 0.00535432
I0428 22:23:52.644187  2164 solver.cpp:237] Iteration 13100, loss = 0.000360824
I0428 22:23:52.644222  2164 solver.cpp:253]     Train net output #0: loss = 0.000360879 (* 1 = 0.000360879 loss)
I0428 22:23:52.644229  2164 sgd_solver.cpp:106] Iteration 13100, lr = 0.00533692
I0428 22:23:52.814656  2164 solver.cpp:237] Iteration 13200, loss = 0.00142969
I0428 22:23:52.814688  2164 solver.cpp:253]     Train net output #0: loss = 0.00142973 (* 1 = 0.00142973 loss)
I0428 22:23:52.814697  2164 sgd_solver.cpp:106] Iteration 13200, lr = 0.00531966
I0428 22:23:52.985417  2164 solver.cpp:237] Iteration 13300, loss = 0.0137832
I0428 22:23:52.985450  2164 solver.cpp:253]     Train net output #0: loss = 0.0137833 (* 1 = 0.0137833 loss)
I0428 22:23:52.985460  2164 sgd_solver.cpp:106] Iteration 13300, lr = 0.00530253
I0428 22:23:53.156383  2164 solver.cpp:237] Iteration 13400, loss = 0.00286707
I0428 22:23:53.156419  2164 solver.cpp:253]     Train net output #0: loss = 0.00286712 (* 1 = 0.00286712 loss)
I0428 22:23:53.156429  2164 sgd_solver.cpp:106] Iteration 13400, lr = 0.00528552
I0428 22:23:53.327277  2164 solver.cpp:237] Iteration 13500, loss = 0.00237183
I0428 22:23:53.327309  2164 solver.cpp:253]     Train net output #0: loss = 0.00237188 (* 1 = 0.00237188 loss)
I0428 22:23:53.327318  2164 sgd_solver.cpp:106] Iteration 13500, lr = 0.00526865
I0428 22:23:53.498360  2164 solver.cpp:237] Iteration 13600, loss = 0.000700193
I0428 22:23:53.498394  2164 solver.cpp:253]     Train net output #0: loss = 0.000700246 (* 1 = 0.000700246 loss)
I0428 22:23:53.498402  2164 sgd_solver.cpp:106] Iteration 13600, lr = 0.00525189
I0428 22:23:53.671836  2164 solver.cpp:237] Iteration 13700, loss = 0.00238613
I0428 22:23:53.671870  2164 solver.cpp:253]     Train net output #0: loss = 0.00238619 (* 1 = 0.00238619 loss)
I0428 22:23:53.671880  2164 sgd_solver.cpp:106] Iteration 13700, lr = 0.00523527
I0428 22:23:53.842697  2164 solver.cpp:237] Iteration 13800, loss = 0.00474116
I0428 22:23:53.842730  2164 solver.cpp:253]     Train net output #0: loss = 0.00474122 (* 1 = 0.00474122 loss)
I0428 22:23:53.842738  2164 sgd_solver.cpp:106] Iteration 13800, lr = 0.00521876
I0428 22:23:54.013692  2164 solver.cpp:237] Iteration 13900, loss = 0.00335253
I0428 22:23:54.013748  2164 solver.cpp:253]     Train net output #0: loss = 0.00335259 (* 1 = 0.00335259 loss)
I0428 22:23:54.013759  2164 sgd_solver.cpp:106] Iteration 13900, lr = 0.00520237
I0428 22:23:54.184303  2164 solver.cpp:237] Iteration 14000, loss = 0.00475042
I0428 22:23:54.184336  2164 solver.cpp:253]     Train net output #0: loss = 0.00475048 (* 1 = 0.00475048 loss)
I0428 22:23:54.184345  2164 sgd_solver.cpp:106] Iteration 14000, lr = 0.00518611
I0428 22:23:54.355118  2164 solver.cpp:237] Iteration 14100, loss = 0.0104082
I0428 22:23:54.355152  2164 solver.cpp:253]     Train net output #0: loss = 0.0104082 (* 1 = 0.0104082 loss)
I0428 22:23:54.355160  2164 sgd_solver.cpp:106] Iteration 14100, lr = 0.00516996
I0428 22:23:54.525710  2164 solver.cpp:237] Iteration 14200, loss = 0.00572793
I0428 22:23:54.525744  2164 solver.cpp:253]     Train net output #0: loss = 0.00572798 (* 1 = 0.00572798 loss)
I0428 22:23:54.525753  2164 sgd_solver.cpp:106] Iteration 14200, lr = 0.00515393
I0428 22:23:54.696475  2164 solver.cpp:237] Iteration 14300, loss = 0.00129736
I0428 22:23:54.696506  2164 solver.cpp:253]     Train net output #0: loss = 0.00129741 (* 1 = 0.00129741 loss)
I0428 22:23:54.696516  2164 sgd_solver.cpp:106] Iteration 14300, lr = 0.00513801
I0428 22:23:54.867110  2164 solver.cpp:237] Iteration 14400, loss = 0.00301645
I0428 22:23:54.867143  2164 solver.cpp:253]     Train net output #0: loss = 0.00301649 (* 1 = 0.00301649 loss)
I0428 22:23:54.867152  2164 sgd_solver.cpp:106] Iteration 14400, lr = 0.00512221
I0428 22:23:55.037966  2164 solver.cpp:237] Iteration 14500, loss = 0.00229135
I0428 22:23:55.037998  2164 solver.cpp:253]     Train net output #0: loss = 0.00229141 (* 1 = 0.00229141 loss)
I0428 22:23:55.038007  2164 sgd_solver.cpp:106] Iteration 14500, lr = 0.00510653
I0428 22:23:55.206210  2164 solver.cpp:237] Iteration 14600, loss = 0.00520923
I0428 22:23:55.206244  2164 solver.cpp:253]     Train net output #0: loss = 0.00520928 (* 1 = 0.00520928 loss)
I0428 22:23:55.206254  2164 sgd_solver.cpp:106] Iteration 14600, lr = 0.00509095
I0428 22:23:55.374470  2164 solver.cpp:237] Iteration 14700, loss = 0.0032445
I0428 22:23:55.374505  2164 solver.cpp:253]     Train net output #0: loss = 0.00324455 (* 1 = 0.00324455 loss)
I0428 22:23:55.374513  2164 sgd_solver.cpp:106] Iteration 14700, lr = 0.00507548
I0428 22:23:55.543287  2164 solver.cpp:237] Iteration 14800, loss = 0.0116737
I0428 22:23:55.543320  2164 solver.cpp:253]     Train net output #0: loss = 0.0116738 (* 1 = 0.0116738 loss)
I0428 22:23:55.543329  2164 sgd_solver.cpp:106] Iteration 14800, lr = 0.00506012
I0428 22:23:55.711743  2164 solver.cpp:237] Iteration 14900, loss = 0.00307864
I0428 22:23:55.711776  2164 solver.cpp:253]     Train net output #0: loss = 0.00307869 (* 1 = 0.00307869 loss)
I0428 22:23:55.711786  2164 sgd_solver.cpp:106] Iteration 14900, lr = 0.00504488
I0428 22:23:55.878332  2164 solver.cpp:341] Iteration 15000, Testing net (#0)
I0428 22:23:56.031910  2164 solver.cpp:409]     Test net output #0: accuracy = 0.9903
I0428 22:23:56.032004  2164 solver.cpp:409]     Test net output #1: loss = 0.0294769 (* 1 = 0.0294769 loss)
I0428 22:23:56.032903  2164 solver.cpp:237] Iteration 15000, loss = 0.00257077
I0428 22:23:56.032946  2164 solver.cpp:253]     Train net output #0: loss = 0.00257082 (* 1 = 0.00257082 loss)
I0428 22:23:56.032979  2164 sgd_solver.cpp:106] Iteration 15000, lr = 0.00502973
I0428 22:23:56.249415  2164 solver.cpp:237] Iteration 15100, loss = 0.0034524
I0428 22:23:56.249502  2164 solver.cpp:253]     Train net output #0: loss = 0.00345244 (* 1 = 0.00345244 loss)
I0428 22:23:56.249527  2164 sgd_solver.cpp:106] Iteration 15100, lr = 0.0050147
I0428 22:23:56.428463  2164 solver.cpp:237] Iteration 15200, loss = 0.00707839
I0428 22:23:56.428557  2164 solver.cpp:253]     Train net output #0: loss = 0.00707843 (* 1 = 0.00707843 loss)
I0428 22:23:56.428585  2164 sgd_solver.cpp:106] Iteration 15200, lr = 0.00499976
I0428 22:23:56.606390  2164 solver.cpp:237] Iteration 15300, loss = 0.00229732
I0428 22:23:56.606511  2164 solver.cpp:253]     Train net output #0: loss = 0.00229736 (* 1 = 0.00229736 loss)
I0428 22:23:56.606539  2164 sgd_solver.cpp:106] Iteration 15300, lr = 0.00498494
I0428 22:23:56.785228  2164 solver.cpp:237] Iteration 15400, loss = 0.00231446
I0428 22:23:56.785310  2164 solver.cpp:253]     Train net output #0: loss = 0.00231451 (* 1 = 0.00231451 loss)
I0428 22:23:56.785336  2164 sgd_solver.cpp:106] Iteration 15400, lr = 0.00497021
I0428 22:23:56.964107  2164 solver.cpp:237] Iteration 15500, loss = 0.00320805
I0428 22:23:56.964292  2164 solver.cpp:253]     Train net output #0: loss = 0.0032081 (* 1 = 0.0032081 loss)
I0428 22:23:56.964318  2164 sgd_solver.cpp:106] Iteration 15500, lr = 0.00495558
I0428 22:23:57.143103  2164 solver.cpp:237] Iteration 15600, loss = 0.00458934
I0428 22:23:57.143187  2164 solver.cpp:253]     Train net output #0: loss = 0.00458939 (* 1 = 0.00458939 loss)
I0428 22:23:57.143213  2164 sgd_solver.cpp:106] Iteration 15600, lr = 0.00494106
I0428 22:23:57.322446  2164 solver.cpp:237] Iteration 15700, loss = 0.00517545
I0428 22:23:57.322530  2164 solver.cpp:253]     Train net output #0: loss = 0.0051755 (* 1 = 0.0051755 loss)
I0428 22:23:57.322556  2164 sgd_solver.cpp:106] Iteration 15700, lr = 0.00492663
I0428 22:23:57.498601  2164 solver.cpp:237] Iteration 15800, loss = 0.0155693
I0428 22:23:57.498636  2164 solver.cpp:253]     Train net output #0: loss = 0.0155693 (* 1 = 0.0155693 loss)
I0428 22:23:57.498644  2164 sgd_solver.cpp:106] Iteration 15800, lr = 0.0049123
I0428 22:23:57.674079  2164 solver.cpp:237] Iteration 15900, loss = 0.00356024
I0428 22:23:57.674115  2164 solver.cpp:253]     Train net output #0: loss = 0.00356029 (* 1 = 0.00356029 loss)
I0428 22:23:57.674124  2164 sgd_solver.cpp:106] Iteration 15900, lr = 0.00489807
I0428 22:23:57.851301  2164 solver.cpp:237] Iteration 16000, loss = 0.00421539
I0428 22:23:57.851400  2164 solver.cpp:253]     Train net output #0: loss = 0.00421543 (* 1 = 0.00421543 loss)
I0428 22:23:57.851428  2164 sgd_solver.cpp:106] Iteration 16000, lr = 0.00488394
I0428 22:23:58.030007  2164 solver.cpp:237] Iteration 16100, loss = 0.000872618
I0428 22:23:58.030091  2164 solver.cpp:253]     Train net output #0: loss = 0.000872666 (* 1 = 0.000872666 loss)
I0428 22:23:58.030115  2164 sgd_solver.cpp:106] Iteration 16100, lr = 0.0048699
I0428 22:23:58.210332  2164 solver.cpp:237] Iteration 16200, loss = 0.00200097
I0428 22:23:58.210417  2164 solver.cpp:253]     Train net output #0: loss = 0.00200101 (* 1 = 0.00200101 loss)
I0428 22:23:58.210441  2164 sgd_solver.cpp:106] Iteration 16200, lr = 0.00485595
I0428 22:23:58.388885  2164 solver.cpp:237] Iteration 16300, loss = 0.00133723
I0428 22:23:58.388975  2164 solver.cpp:253]     Train net output #0: loss = 0.00133728 (* 1 = 0.00133728 loss)
I0428 22:23:58.389000  2164 sgd_solver.cpp:106] Iteration 16300, lr = 0.00484209
I0428 22:23:58.567622  2164 solver.cpp:237] Iteration 16400, loss = 0.000294247
I0428 22:23:58.567708  2164 solver.cpp:253]     Train net output #0: loss = 0.000294292 (* 1 = 0.000294292 loss)
I0428 22:23:58.567744  2164 sgd_solver.cpp:106] Iteration 16400, lr = 0.00482833
I0428 22:23:58.746218  2164 solver.cpp:237] Iteration 16500, loss = 0.0102241
I0428 22:23:58.746309  2164 solver.cpp:253]     Train net output #0: loss = 0.0102242 (* 1 = 0.0102242 loss)
I0428 22:23:58.746448  2164 sgd_solver.cpp:106] Iteration 16500, lr = 0.00481466
I0428 22:23:58.924931  2164 solver.cpp:237] Iteration 16600, loss = 0.00412144
I0428 22:23:58.925022  2164 solver.cpp:253]     Train net output #0: loss = 0.00412149 (* 1 = 0.00412149 loss)
I0428 22:23:58.925050  2164 sgd_solver.cpp:106] Iteration 16600, lr = 0.00480108
I0428 22:23:59.101204  2164 solver.cpp:237] Iteration 16700, loss = 0.00230668
I0428 22:23:59.101238  2164 solver.cpp:253]     Train net output #0: loss = 0.00230672 (* 1 = 0.00230672 loss)
I0428 22:23:59.101248  2164 sgd_solver.cpp:106] Iteration 16700, lr = 0.00478759
I0428 22:23:59.276036  2164 solver.cpp:237] Iteration 16800, loss = 0.00732577
I0428 22:23:59.276069  2164 solver.cpp:253]     Train net output #0: loss = 0.00732582 (* 1 = 0.00732582 loss)
I0428 22:23:59.276078  2164 sgd_solver.cpp:106] Iteration 16800, lr = 0.00477418
I0428 22:23:59.451776  2164 solver.cpp:237] Iteration 16900, loss = 0.00861119
I0428 22:23:59.451817  2164 solver.cpp:253]     Train net output #0: loss = 0.00861123 (* 1 = 0.00861123 loss)
I0428 22:23:59.451825  2164 sgd_solver.cpp:106] Iteration 16900, lr = 0.00476086
I0428 22:23:59.631461  2164 solver.cpp:237] Iteration 17000, loss = 0.00327901
I0428 22:23:59.631505  2164 solver.cpp:253]     Train net output #0: loss = 0.00327906 (* 1 = 0.00327906 loss)
I0428 22:23:59.631561  2164 sgd_solver.cpp:106] Iteration 17000, lr = 0.00474763
I0428 22:23:59.811849  2164 solver.cpp:237] Iteration 17100, loss = 0.00274766
I0428 22:23:59.811939  2164 solver.cpp:253]     Train net output #0: loss = 0.0027477 (* 1 = 0.0027477 loss)
I0428 22:23:59.811965  2164 sgd_solver.cpp:106] Iteration 17100, lr = 0.00473449
I0428 22:23:59.991372  2164 solver.cpp:237] Iteration 17200, loss = 0.00138871
I0428 22:23:59.991461  2164 solver.cpp:253]     Train net output #0: loss = 0.00138875 (* 1 = 0.00138875 loss)
I0428 22:23:59.991487  2164 sgd_solver.cpp:106] Iteration 17200, lr = 0.00472143
I0428 22:24:00.170943  2164 solver.cpp:237] Iteration 17300, loss = 0.00744547
I0428 22:24:00.171028  2164 solver.cpp:253]     Train net output #0: loss = 0.00744552 (* 1 = 0.00744552 loss)
I0428 22:24:00.171054  2164 sgd_solver.cpp:106] Iteration 17300, lr = 0.00470845
I0428 22:24:00.351184  2164 solver.cpp:237] Iteration 17400, loss = 0.00241684
I0428 22:24:00.351270  2164 solver.cpp:253]     Train net output #0: loss = 0.0024169 (* 1 = 0.0024169 loss)
I0428 22:24:00.351297  2164 sgd_solver.cpp:106] Iteration 17400, lr = 0.00469556
I0428 22:24:00.531239  2164 solver.cpp:237] Iteration 17500, loss = 0.00153217
I0428 22:24:00.531324  2164 solver.cpp:253]     Train net output #0: loss = 0.00153222 (* 1 = 0.00153222 loss)
I0428 22:24:00.531350  2164 sgd_solver.cpp:106] Iteration 17500, lr = 0.00468274
I0428 22:24:00.711110  2164 solver.cpp:237] Iteration 17600, loss = 0.013759
I0428 22:24:00.711200  2164 solver.cpp:253]     Train net output #0: loss = 0.0137591 (* 1 = 0.0137591 loss)
I0428 22:24:00.711226  2164 sgd_solver.cpp:106] Iteration 17600, lr = 0.00467001
I0428 22:24:00.891108  2164 solver.cpp:237] Iteration 17700, loss = 0.00913375
I0428 22:24:00.891193  2164 solver.cpp:253]     Train net output #0: loss = 0.0091338 (* 1 = 0.0091338 loss)
I0428 22:24:00.891219  2164 sgd_solver.cpp:106] Iteration 17700, lr = 0.00465736
I0428 22:24:01.070931  2164 solver.cpp:237] Iteration 17800, loss = 0.000194223
I0428 22:24:01.071020  2164 solver.cpp:253]     Train net output #0: loss = 0.000194277 (* 1 = 0.000194277 loss)
I0428 22:24:01.071046  2164 sgd_solver.cpp:106] Iteration 17800, lr = 0.00464479
I0428 22:24:01.250855  2164 solver.cpp:237] Iteration 17900, loss = 0.00506387
I0428 22:24:01.250946  2164 solver.cpp:253]     Train net output #0: loss = 0.00506393 (* 1 = 0.00506393 loss)
I0428 22:24:01.250972  2164 sgd_solver.cpp:106] Iteration 17900, lr = 0.0046323
I0428 22:24:01.430747  2164 solver.cpp:237] Iteration 18000, loss = 0.00572824
I0428 22:24:01.430832  2164 solver.cpp:253]     Train net output #0: loss = 0.0057283 (* 1 = 0.0057283 loss)
I0428 22:24:01.430858  2164 sgd_solver.cpp:106] Iteration 18000, lr = 0.00461989
I0428 22:24:01.609639  2164 solver.cpp:237] Iteration 18100, loss = 0.00363526
I0428 22:24:01.609725  2164 solver.cpp:253]     Train net output #0: loss = 0.00363532 (* 1 = 0.00363532 loss)
I0428 22:24:01.609751  2164 sgd_solver.cpp:106] Iteration 18100, lr = 0.00460755
I0428 22:24:01.788239  2164 solver.cpp:237] Iteration 18200, loss = 0.00293584
I0428 22:24:01.788322  2164 solver.cpp:253]     Train net output #0: loss = 0.0029359 (* 1 = 0.0029359 loss)
I0428 22:24:01.788348  2164 sgd_solver.cpp:106] Iteration 18200, lr = 0.00459529
I0428 22:24:01.978957  2164 solver.cpp:237] Iteration 18300, loss = 0.0018615
I0428 22:24:01.979051  2164 solver.cpp:253]     Train net output #0: loss = 0.00186156 (* 1 = 0.00186156 loss)
I0428 22:24:01.979089  2164 sgd_solver.cpp:106] Iteration 18300, lr = 0.00458311
I0428 22:24:02.157361  2164 solver.cpp:237] Iteration 18400, loss = 0.00162624
I0428 22:24:02.157454  2164 solver.cpp:253]     Train net output #0: loss = 0.0016263 (* 1 = 0.0016263 loss)
I0428 22:24:02.157480  2164 sgd_solver.cpp:106] Iteration 18400, lr = 0.004571
I0428 22:24:02.336084  2164 solver.cpp:237] Iteration 18500, loss = 0.00236121
I0428 22:24:02.336120  2164 solver.cpp:253]     Train net output #0: loss = 0.00236126 (* 1 = 0.00236126 loss)
I0428 22:24:02.336158  2164 sgd_solver.cpp:106] Iteration 18500, lr = 0.00455897
I0428 22:24:02.511399  2164 solver.cpp:237] Iteration 18600, loss = 0.0107769
I0428 22:24:02.511487  2164 solver.cpp:253]     Train net output #0: loss = 0.010777 (* 1 = 0.010777 loss)
I0428 22:24:02.511514  2164 sgd_solver.cpp:106] Iteration 18600, lr = 0.00454701
I0428 22:24:02.689599  2164 solver.cpp:237] Iteration 18700, loss = 0.00566534
I0428 22:24:02.689685  2164 solver.cpp:253]     Train net output #0: loss = 0.0056654 (* 1 = 0.0056654 loss)
I0428 22:24:02.689712  2164 sgd_solver.cpp:106] Iteration 18700, lr = 0.00453512
I0428 22:24:02.891356  2164 solver.cpp:237] Iteration 18800, loss = 0.00275271
I0428 22:24:02.891440  2164 solver.cpp:253]     Train net output #0: loss = 0.00275276 (* 1 = 0.00275276 loss)
I0428 22:24:02.891465  2164 sgd_solver.cpp:106] Iteration 18800, lr = 0.0045233
I0428 22:24:03.070013  2164 solver.cpp:237] Iteration 18900, loss = 0.00498361
I0428 22:24:03.070097  2164 solver.cpp:253]     Train net output #0: loss = 0.00498366 (* 1 = 0.00498366 loss)
I0428 22:24:03.070122  2164 sgd_solver.cpp:106] Iteration 18900, lr = 0.00451156
I0428 22:24:03.248622  2164 solver.cpp:237] Iteration 19000, loss = 0.00432971
I0428 22:24:03.248706  2164 solver.cpp:253]     Train net output #0: loss = 0.00432976 (* 1 = 0.00432976 loss)
I0428 22:24:03.248731  2164 sgd_solver.cpp:106] Iteration 19000, lr = 0.00449989
I0428 22:24:03.427141  2164 solver.cpp:237] Iteration 19100, loss = 0.00387262
I0428 22:24:03.427227  2164 solver.cpp:253]     Train net output #0: loss = 0.00387267 (* 1 = 0.00387267 loss)
I0428 22:24:03.427251  2164 sgd_solver.cpp:106] Iteration 19100, lr = 0.00448828
I0428 22:24:03.605937  2164 solver.cpp:237] Iteration 19200, loss = 0.00189352
I0428 22:24:03.606020  2164 solver.cpp:253]     Train net output #0: loss = 0.00189359 (* 1 = 0.00189359 loss)
I0428 22:24:03.606045  2164 sgd_solver.cpp:106] Iteration 19200, lr = 0.00447675
I0428 22:24:03.785349  2164 solver.cpp:237] Iteration 19300, loss = 0.00647036
I0428 22:24:03.785444  2164 solver.cpp:253]     Train net output #0: loss = 0.00647043 (* 1 = 0.00647043 loss)
I0428 22:24:03.785470  2164 sgd_solver.cpp:106] Iteration 19300, lr = 0.00446529
I0428 22:24:03.965481  2164 solver.cpp:237] Iteration 19400, loss = 0.00490985
I0428 22:24:03.965569  2164 solver.cpp:253]     Train net output #0: loss = 0.00490991 (* 1 = 0.00490991 loss)
I0428 22:24:03.965595  2164 sgd_solver.cpp:106] Iteration 19400, lr = 0.00445389
I0428 22:24:04.145889  2164 solver.cpp:237] Iteration 19500, loss = 0.003058
I0428 22:24:04.145977  2164 solver.cpp:253]     Train net output #0: loss = 0.00305807 (* 1 = 0.00305807 loss)
I0428 22:24:04.146004  2164 sgd_solver.cpp:106] Iteration 19500, lr = 0.00444256
I0428 22:24:04.326135  2164 solver.cpp:237] Iteration 19600, loss = 0.00340327
I0428 22:24:04.326223  2164 solver.cpp:253]     Train net output #0: loss = 0.00340333 (* 1 = 0.00340333 loss)
I0428 22:24:04.326249  2164 sgd_solver.cpp:106] Iteration 19600, lr = 0.0044313
I0428 22:24:04.505872  2164 solver.cpp:237] Iteration 19700, loss = 0.000955672
I0428 22:24:04.505957  2164 solver.cpp:253]     Train net output #0: loss = 0.000955736 (* 1 = 0.000955736 loss)
I0428 22:24:04.505983  2164 sgd_solver.cpp:106] Iteration 19700, lr = 0.00442011
I0428 22:24:04.684104  2164 solver.cpp:237] Iteration 19800, loss = 0.00584385
I0428 22:24:04.684139  2164 solver.cpp:253]     Train net output #0: loss = 0.00584392 (* 1 = 0.00584392 loss)
I0428 22:24:04.684149  2164 sgd_solver.cpp:106] Iteration 19800, lr = 0.00440898
I0428 22:24:04.861508  2164 solver.cpp:237] Iteration 19900, loss = 0.000942595
I0428 22:24:04.861595  2164 solver.cpp:253]     Train net output #0: loss = 0.000942658 (* 1 = 0.000942658 loss)
I0428 22:24:04.861621  2164 sgd_solver.cpp:106] Iteration 19900, lr = 0.00439791
I0428 22:24:05.039727  2164 solver.cpp:341] Iteration 20000, Testing net (#0)
I0428 22:24:05.182626  2164 solver.cpp:409]     Test net output #0: accuracy = 0.9908
I0428 22:24:05.182709  2164 solver.cpp:409]     Test net output #1: loss = 0.0274314 (* 1 = 0.0274314 loss)
I0428 22:24:05.183723  2164 solver.cpp:237] Iteration 20000, loss = 0.00792701
I0428 22:24:05.183768  2164 solver.cpp:253]     Train net output #0: loss = 0.00792708 (* 1 = 0.00792708 loss)
I0428 22:24:05.183802  2164 sgd_solver.cpp:106] Iteration 20000, lr = 0.00438691
I0428 22:24:05.401574  2164 solver.cpp:237] Iteration 20100, loss = 0.0149832
I0428 22:24:05.401659  2164 solver.cpp:253]     Train net output #0: loss = 0.0149833 (* 1 = 0.0149833 loss)
I0428 22:24:05.401685  2164 sgd_solver.cpp:106] Iteration 20100, lr = 0.00437598
I0428 22:24:05.582455  2164 solver.cpp:237] Iteration 20200, loss = 0.00324841
I0428 22:24:05.582552  2164 solver.cpp:253]     Train net output #0: loss = 0.00324848 (* 1 = 0.00324848 loss)
I0428 22:24:05.582579  2164 sgd_solver.cpp:106] Iteration 20200, lr = 0.00436511
I0428 22:24:05.763717  2164 solver.cpp:237] Iteration 20300, loss = 0.00123452
I0428 22:24:05.763808  2164 solver.cpp:253]     Train net output #0: loss = 0.00123458 (* 1 = 0.00123458 loss)
I0428 22:24:05.763833  2164 sgd_solver.cpp:106] Iteration 20300, lr = 0.0043543
I0428 22:24:05.945003  2164 solver.cpp:237] Iteration 20400, loss = 0.00467869
I0428 22:24:05.945092  2164 solver.cpp:253]     Train net output #0: loss = 0.00467876 (* 1 = 0.00467876 loss)
I0428 22:24:05.945118  2164 sgd_solver.cpp:106] Iteration 20400, lr = 0.00434355
I0428 22:24:06.126469  2164 solver.cpp:237] Iteration 20500, loss = 0.0020525
I0428 22:24:06.126554  2164 solver.cpp:253]     Train net output #0: loss = 0.00205258 (* 1 = 0.00205258 loss)
I0428 22:24:06.126580  2164 sgd_solver.cpp:106] Iteration 20500, lr = 0.00433286
I0428 22:24:06.307593  2164 solver.cpp:237] Iteration 20600, loss = 0.000337982
I0428 22:24:06.307679  2164 solver.cpp:253]     Train net output #0: loss = 0.000338051 (* 1 = 0.000338051 loss)
I0428 22:24:06.307705  2164 sgd_solver.cpp:106] Iteration 20600, lr = 0.00432224
I0428 22:24:06.488306  2164 solver.cpp:237] Iteration 20700, loss = 0.00120611
I0428 22:24:06.488389  2164 solver.cpp:253]     Train net output #0: loss = 0.00120618 (* 1 = 0.00120618 loss)
I0428 22:24:06.488416  2164 sgd_solver.cpp:106] Iteration 20700, lr = 0.00431168
I0428 22:24:06.668529  2164 solver.cpp:237] Iteration 20800, loss = 0.0095662
I0428 22:24:06.668617  2164 solver.cpp:253]     Train net output #0: loss = 0.00956627 (* 1 = 0.00956627 loss)
I0428 22:24:06.668642  2164 sgd_solver.cpp:106] Iteration 20800, lr = 0.00430117
I0428 22:24:06.849498  2164 solver.cpp:237] Iteration 20900, loss = 0.00266629
I0428 22:24:06.849584  2164 solver.cpp:253]     Train net output #0: loss = 0.00266636 (* 1 = 0.00266636 loss)
I0428 22:24:06.849611  2164 sgd_solver.cpp:106] Iteration 20900, lr = 0.00429073
I0428 22:24:07.034917  2164 solver.cpp:237] Iteration 21000, loss = 0.0023618
I0428 22:24:07.034994  2164 solver.cpp:253]     Train net output #0: loss = 0.00236186 (* 1 = 0.00236186 loss)
I0428 22:24:07.035014  2164 sgd_solver.cpp:106] Iteration 21000, lr = 0.00428034
I0428 22:24:07.229518  2164 solver.cpp:237] Iteration 21100, loss = 0.000767917
I0428 22:24:07.229603  2164 solver.cpp:253]     Train net output #0: loss = 0.00076798 (* 1 = 0.00076798 loss)
I0428 22:24:07.229629  2164 sgd_solver.cpp:106] Iteration 21100, lr = 0.00427002
I0428 22:24:07.410537  2164 solver.cpp:237] Iteration 21200, loss = 0.00232071
I0428 22:24:07.410621  2164 solver.cpp:253]     Train net output #0: loss = 0.00232077 (* 1 = 0.00232077 loss)
I0428 22:24:07.410660  2164 sgd_solver.cpp:106] Iteration 21200, lr = 0.00425975
I0428 22:24:07.591717  2164 solver.cpp:237] Iteration 21300, loss = 0.00419112
I0428 22:24:07.591804  2164 solver.cpp:253]     Train net output #0: loss = 0.00419117 (* 1 = 0.00419117 loss)
I0428 22:24:07.591828  2164 sgd_solver.cpp:106] Iteration 21300, lr = 0.00424954
I0428 22:24:07.775233  2164 solver.cpp:237] Iteration 21400, loss = 0.0031617
I0428 22:24:07.775322  2164 solver.cpp:253]     Train net output #0: loss = 0.00316176 (* 1 = 0.00316176 loss)
I0428 22:24:07.775348  2164 sgd_solver.cpp:106] Iteration 21400, lr = 0.00423938
I0428 22:24:07.955711  2164 solver.cpp:237] Iteration 21500, loss = 0.00340128
I0428 22:24:07.955799  2164 solver.cpp:253]     Train net output #0: loss = 0.00340134 (* 1 = 0.00340134 loss)
I0428 22:24:07.955826  2164 sgd_solver.cpp:106] Iteration 21500, lr = 0.00422929
I0428 22:24:08.137526  2164 solver.cpp:237] Iteration 21600, loss = 0.00726656
I0428 22:24:08.137612  2164 solver.cpp:253]     Train net output #0: loss = 0.00726662 (* 1 = 0.00726662 loss)
I0428 22:24:08.137639  2164 sgd_solver.cpp:106] Iteration 21600, lr = 0.00421924
I0428 22:24:08.342998  2164 solver.cpp:237] Iteration 21700, loss = 0.00522028
I0428 22:24:08.343078  2164 solver.cpp:253]     Train net output #0: loss = 0.00522034 (* 1 = 0.00522034 loss)
I0428 22:24:08.343101  2164 sgd_solver.cpp:106] Iteration 21700, lr = 0.00420926
I0428 22:24:08.551352  2164 solver.cpp:237] Iteration 21800, loss = 0.00139543
I0428 22:24:08.551441  2164 solver.cpp:253]     Train net output #0: loss = 0.00139549 (* 1 = 0.00139549 loss)
I0428 22:24:08.551467  2164 sgd_solver.cpp:106] Iteration 21800, lr = 0.00419933
I0428 22:24:08.733741  2164 solver.cpp:237] Iteration 21900, loss = 0.00247128
I0428 22:24:08.733830  2164 solver.cpp:253]     Train net output #0: loss = 0.00247135 (* 1 = 0.00247135 loss)
I0428 22:24:08.733855  2164 sgd_solver.cpp:106] Iteration 21900, lr = 0.00418945
I0428 22:24:08.936122  2164 solver.cpp:237] Iteration 22000, loss = 0.00166037
I0428 22:24:08.936215  2164 solver.cpp:253]     Train net output #0: loss = 0.00166043 (* 1 = 0.00166043 loss)
I0428 22:24:08.936241  2164 sgd_solver.cpp:106] Iteration 22000, lr = 0.00417963
I0428 22:24:09.113996  2164 solver.cpp:237] Iteration 22100, loss = 0.00460052
I0428 22:24:09.114027  2164 solver.cpp:253]     Train net output #0: loss = 0.00460059 (* 1 = 0.00460059 loss)
I0428 22:24:09.114037  2164 sgd_solver.cpp:106] Iteration 22100, lr = 0.00416986
I0428 22:24:09.290647  2164 solver.cpp:237] Iteration 22200, loss = 0.00277586
I0428 22:24:09.290683  2164 solver.cpp:253]     Train net output #0: loss = 0.00277592 (* 1 = 0.00277592 loss)
I0428 22:24:09.290693  2164 sgd_solver.cpp:106] Iteration 22200, lr = 0.00416014
I0428 22:24:09.470762  2164 solver.cpp:237] Iteration 22300, loss = 0.00988318
I0428 22:24:09.470849  2164 solver.cpp:253]     Train net output #0: loss = 0.00988324 (* 1 = 0.00988324 loss)
I0428 22:24:09.470873  2164 sgd_solver.cpp:106] Iteration 22300, lr = 0.00415048
I0428 22:24:09.651793  2164 solver.cpp:237] Iteration 22400, loss = 0.00282436
I0428 22:24:09.651878  2164 solver.cpp:253]     Train net output #0: loss = 0.00282443 (* 1 = 0.00282443 loss)
I0428 22:24:09.651904  2164 sgd_solver.cpp:106] Iteration 22400, lr = 0.00414087
I0428 22:24:09.830178  2164 solver.cpp:237] Iteration 22500, loss = 0.00263016
I0428 22:24:09.830212  2164 solver.cpp:253]     Train net output #0: loss = 0.00263023 (* 1 = 0.00263023 loss)
I0428 22:24:09.830221  2164 sgd_solver.cpp:106] Iteration 22500, lr = 0.00413131
I0428 22:24:10.005996  2164 solver.cpp:237] Iteration 22600, loss = 0.00310634
I0428 22:24:10.006029  2164 solver.cpp:253]     Train net output #0: loss = 0.00310641 (* 1 = 0.00310641 loss)
I0428 22:24:10.006038  2164 sgd_solver.cpp:106] Iteration 22600, lr = 0.0041218
I0428 22:24:10.182210  2164 solver.cpp:237] Iteration 22700, loss = 0.00664359
I0428 22:24:10.182245  2164 solver.cpp:253]     Train net output #0: loss = 0.00664366 (* 1 = 0.00664366 loss)
I0428 22:24:10.182255  2164 sgd_solver.cpp:106] Iteration 22700, lr = 0.00411234
I0428 22:24:10.360817  2164 solver.cpp:237] Iteration 22800, loss = 0.00220394
I0428 22:24:10.360913  2164 solver.cpp:253]     Train net output #0: loss = 0.00220401 (* 1 = 0.00220401 loss)
I0428 22:24:10.360940  2164 sgd_solver.cpp:106] Iteration 22800, lr = 0.00410293
I0428 22:24:10.542352  2164 solver.cpp:237] Iteration 22900, loss = 0.00205026
I0428 22:24:10.542438  2164 solver.cpp:253]     Train net output #0: loss = 0.00205033 (* 1 = 0.00205033 loss)
I0428 22:24:10.542465  2164 sgd_solver.cpp:106] Iteration 22900, lr = 0.00409358
I0428 22:24:10.724088  2164 solver.cpp:237] Iteration 23000, loss = 0.00280929
I0428 22:24:10.724177  2164 solver.cpp:253]     Train net output #0: loss = 0.00280935 (* 1 = 0.00280935 loss)
I0428 22:24:10.724202  2164 sgd_solver.cpp:106] Iteration 23000, lr = 0.00408427
I0428 22:24:10.904815  2164 solver.cpp:237] Iteration 23100, loss = 0.0041809
I0428 22:24:10.904911  2164 solver.cpp:253]     Train net output #0: loss = 0.00418097 (* 1 = 0.00418097 loss)
I0428 22:24:10.904940  2164 sgd_solver.cpp:106] Iteration 23100, lr = 0.00407501
I0428 22:24:11.085532  2164 solver.cpp:237] Iteration 23200, loss = 0.00441952
I0428 22:24:11.085624  2164 solver.cpp:253]     Train net output #0: loss = 0.00441958 (* 1 = 0.00441958 loss)
I0428 22:24:11.085651  2164 sgd_solver.cpp:106] Iteration 23200, lr = 0.0040658
I0428 22:24:11.265050  2164 solver.cpp:237] Iteration 23300, loss = 0.0109861
I0428 22:24:11.265085  2164 solver.cpp:253]     Train net output #0: loss = 0.0109861 (* 1 = 0.0109861 loss)
I0428 22:24:11.265094  2164 sgd_solver.cpp:106] Iteration 23300, lr = 0.00405664
I0428 22:24:11.441373  2164 solver.cpp:237] Iteration 23400, loss = 0.00305949
I0428 22:24:11.441407  2164 solver.cpp:253]     Train net output #0: loss = 0.00305956 (* 1 = 0.00305956 loss)
I0428 22:24:11.441416  2164 sgd_solver.cpp:106] Iteration 23400, lr = 0.00404753
I0428 22:24:11.618170  2164 solver.cpp:237] Iteration 23500, loss = 0.00413424
I0428 22:24:11.618206  2164 solver.cpp:253]     Train net output #0: loss = 0.0041343 (* 1 = 0.0041343 loss)
I0428 22:24:11.618216  2164 sgd_solver.cpp:106] Iteration 23500, lr = 0.00403847
I0428 22:24:11.798530  2164 solver.cpp:237] Iteration 23600, loss = 0.000709455
I0428 22:24:11.798615  2164 solver.cpp:253]     Train net output #0: loss = 0.00070951 (* 1 = 0.00070951 loss)
I0428 22:24:11.798641  2164 sgd_solver.cpp:106] Iteration 23600, lr = 0.00402945
I0428 22:24:11.980407  2164 solver.cpp:237] Iteration 23700, loss = 0.00162881
I0428 22:24:11.980492  2164 solver.cpp:253]     Train net output #0: loss = 0.00162887 (* 1 = 0.00162887 loss)
I0428 22:24:11.980518  2164 sgd_solver.cpp:106] Iteration 23700, lr = 0.00402048
I0428 22:24:12.162506  2164 solver.cpp:237] Iteration 23800, loss = 0.0012299
I0428 22:24:12.162592  2164 solver.cpp:253]     Train net output #0: loss = 0.00122996 (* 1 = 0.00122996 loss)
I0428 22:24:12.162617  2164 sgd_solver.cpp:106] Iteration 23800, lr = 0.00401155
I0428 22:24:12.343590  2164 solver.cpp:237] Iteration 23900, loss = 0.000272781
I0428 22:24:12.343672  2164 solver.cpp:253]     Train net output #0: loss = 0.000272842 (* 1 = 0.000272842 loss)
I0428 22:24:12.343698  2164 sgd_solver.cpp:106] Iteration 23900, lr = 0.00400267
I0428 22:24:12.524063  2164 solver.cpp:237] Iteration 24000, loss = 0.00869245
I0428 22:24:12.524150  2164 solver.cpp:253]     Train net output #0: loss = 0.00869251 (* 1 = 0.00869251 loss)
I0428 22:24:12.524179  2164 sgd_solver.cpp:106] Iteration 24000, lr = 0.00399384
I0428 22:24:12.714483  2164 solver.cpp:237] Iteration 24100, loss = 0.00427428
I0428 22:24:12.714566  2164 solver.cpp:253]     Train net output #0: loss = 0.00427434 (* 1 = 0.00427434 loss)
I0428 22:24:12.714592  2164 sgd_solver.cpp:106] Iteration 24100, lr = 0.00398505
I0428 22:24:12.896354  2164 solver.cpp:237] Iteration 24200, loss = 0.00236579
I0428 22:24:12.896441  2164 solver.cpp:253]     Train net output #0: loss = 0.00236585 (* 1 = 0.00236585 loss)
I0428 22:24:12.896467  2164 sgd_solver.cpp:106] Iteration 24200, lr = 0.00397631
I0428 22:24:13.077664  2164 solver.cpp:237] Iteration 24300, loss = 0.00658261
I0428 22:24:13.077751  2164 solver.cpp:253]     Train net output #0: loss = 0.00658268 (* 1 = 0.00658268 loss)
I0428 22:24:13.077777  2164 sgd_solver.cpp:106] Iteration 24300, lr = 0.00396761
I0428 22:24:13.258240  2164 solver.cpp:237] Iteration 24400, loss = 0.00695938
I0428 22:24:13.258327  2164 solver.cpp:253]     Train net output #0: loss = 0.00695944 (* 1 = 0.00695944 loss)
I0428 22:24:13.258352  2164 sgd_solver.cpp:106] Iteration 24400, lr = 0.00395896
I0428 22:24:13.438664  2164 solver.cpp:237] Iteration 24500, loss = 0.00317439
I0428 22:24:13.438772  2164 solver.cpp:253]     Train net output #0: loss = 0.00317445 (* 1 = 0.00317445 loss)
I0428 22:24:13.438797  2164 sgd_solver.cpp:106] Iteration 24500, lr = 0.00395035
I0428 22:24:13.619541  2164 solver.cpp:237] Iteration 24600, loss = 0.00227201
I0428 22:24:13.619624  2164 solver.cpp:253]     Train net output #0: loss = 0.00227207 (* 1 = 0.00227207 loss)
I0428 22:24:13.619650  2164 sgd_solver.cpp:106] Iteration 24600, lr = 0.00394178
I0428 22:24:13.806613  2164 solver.cpp:237] Iteration 24700, loss = 0.00125066
I0428 22:24:13.806710  2164 solver.cpp:253]     Train net output #0: loss = 0.00125072 (* 1 = 0.00125072 loss)
I0428 22:24:13.806736  2164 sgd_solver.cpp:106] Iteration 24700, lr = 0.00393326
I0428 22:24:14.005369  2164 solver.cpp:237] Iteration 24800, loss = 0.00703961
I0428 22:24:14.005404  2164 solver.cpp:253]     Train net output #0: loss = 0.00703967 (* 1 = 0.00703967 loss)
I0428 22:24:14.005414  2164 sgd_solver.cpp:106] Iteration 24800, lr = 0.00392478
I0428 22:24:14.183040  2164 solver.cpp:237] Iteration 24900, loss = 0.00238134
I0428 22:24:14.183074  2164 solver.cpp:253]     Train net output #0: loss = 0.00238141 (* 1 = 0.00238141 loss)
I0428 22:24:14.183084  2164 sgd_solver.cpp:106] Iteration 24900, lr = 0.00391634
I0428 22:24:14.358990  2164 solver.cpp:341] Iteration 25000, Testing net (#0)
I0428 22:24:14.493549  2164 solver.cpp:409]     Test net output #0: accuracy = 0.9903
I0428 22:24:14.493644  2164 solver.cpp:409]     Test net output #1: loss = 0.025982 (* 1 = 0.025982 loss)
I0428 22:24:14.494593  2164 solver.cpp:237] Iteration 25000, loss = 0.00146695
I0428 22:24:14.494631  2164 solver.cpp:253]     Train net output #0: loss = 0.00146701 (* 1 = 0.00146701 loss)
I0428 22:24:14.494652  2164 sgd_solver.cpp:106] Iteration 25000, lr = 0.00390795
I0428 22:24:14.681049  2164 solver.cpp:237] Iteration 25100, loss = 0.0115535
I0428 22:24:14.681146  2164 solver.cpp:253]     Train net output #0: loss = 0.0115536 (* 1 = 0.0115536 loss)
I0428 22:24:14.681172  2164 sgd_solver.cpp:106] Iteration 25100, lr = 0.0038996
I0428 22:24:14.854734  2164 solver.cpp:237] Iteration 25200, loss = 0.0081063
I0428 22:24:14.854825  2164 solver.cpp:253]     Train net output #0: loss = 0.00810636 (* 1 = 0.00810636 loss)
I0428 22:24:14.854851  2164 sgd_solver.cpp:106] Iteration 25200, lr = 0.00389128
I0428 22:24:15.029036  2164 solver.cpp:237] Iteration 25300, loss = 0.00016519
I0428 22:24:15.029124  2164 solver.cpp:253]     Train net output #0: loss = 0.00016525 (* 1 = 0.00016525 loss)
I0428 22:24:15.029150  2164 sgd_solver.cpp:106] Iteration 25300, lr = 0.00388301
I0428 22:24:15.203619  2164 solver.cpp:237] Iteration 25400, loss = 0.00417469
I0428 22:24:15.203707  2164 solver.cpp:253]     Train net output #0: loss = 0.00417475 (* 1 = 0.00417475 loss)
I0428 22:24:15.203733  2164 sgd_solver.cpp:106] Iteration 25400, lr = 0.00387478
I0428 22:24:15.383594  2164 solver.cpp:237] Iteration 25500, loss = 0.00449461
I0428 22:24:15.383673  2164 solver.cpp:253]     Train net output #0: loss = 0.00449467 (* 1 = 0.00449467 loss)
I0428 22:24:15.383694  2164 sgd_solver.cpp:106] Iteration 25500, lr = 0.0038666
I0428 22:24:15.557332  2164 solver.cpp:237] Iteration 25600, loss = 0.00306147
I0428 22:24:15.557418  2164 solver.cpp:253]     Train net output #0: loss = 0.00306152 (* 1 = 0.00306152 loss)
I0428 22:24:15.557442  2164 sgd_solver.cpp:106] Iteration 25600, lr = 0.00385845
I0428 22:24:15.730334  2164 solver.cpp:237] Iteration 25700, loss = 0.00267639
I0428 22:24:15.730419  2164 solver.cpp:253]     Train net output #0: loss = 0.00267644 (* 1 = 0.00267644 loss)
I0428 22:24:15.730443  2164 sgd_solver.cpp:106] Iteration 25700, lr = 0.00385034
I0428 22:24:15.903558  2164 solver.cpp:237] Iteration 25800, loss = 0.00162707
I0428 22:24:15.903646  2164 solver.cpp:253]     Train net output #0: loss = 0.00162713 (* 1 = 0.00162713 loss)
I0428 22:24:15.903669  2164 sgd_solver.cpp:106] Iteration 25800, lr = 0.00384227
I0428 22:24:16.077091  2164 solver.cpp:237] Iteration 25900, loss = 0.00155613
I0428 22:24:16.077199  2164 solver.cpp:253]     Train net output #0: loss = 0.00155619 (* 1 = 0.00155619 loss)
I0428 22:24:16.077224  2164 sgd_solver.cpp:106] Iteration 25900, lr = 0.00383424
I0428 22:24:16.250185  2164 solver.cpp:237] Iteration 26000, loss = 0.00206977
I0428 22:24:16.250273  2164 solver.cpp:253]     Train net output #0: loss = 0.00206984 (* 1 = 0.00206984 loss)
I0428 22:24:16.250298  2164 sgd_solver.cpp:106] Iteration 26000, lr = 0.00382625
I0428 22:24:16.423759  2164 solver.cpp:237] Iteration 26100, loss = 0.00963047
I0428 22:24:16.423846  2164 solver.cpp:253]     Train net output #0: loss = 0.00963053 (* 1 = 0.00963053 loss)
I0428 22:24:16.423869  2164 sgd_solver.cpp:106] Iteration 26100, lr = 0.0038183
I0428 22:24:16.597342  2164 solver.cpp:237] Iteration 26200, loss = 0.00501066
I0428 22:24:16.597378  2164 solver.cpp:253]     Train net output #0: loss = 0.00501073 (* 1 = 0.00501073 loss)
I0428 22:24:16.597388  2164 sgd_solver.cpp:106] Iteration 26200, lr = 0.00381038
I0428 22:24:16.768400  2164 solver.cpp:237] Iteration 26300, loss = 0.00232667
I0428 22:24:16.768434  2164 solver.cpp:253]     Train net output #0: loss = 0.00232673 (* 1 = 0.00232673 loss)
I0428 22:24:16.768441  2164 sgd_solver.cpp:106] Iteration 26300, lr = 0.00380251
I0428 22:24:16.939925  2164 solver.cpp:237] Iteration 26400, loss = 0.00434424
I0428 22:24:16.939960  2164 solver.cpp:253]     Train net output #0: loss = 0.0043443 (* 1 = 0.0043443 loss)
I0428 22:24:16.939968  2164 sgd_solver.cpp:106] Iteration 26400, lr = 0.00379467
I0428 22:24:17.111446  2164 solver.cpp:237] Iteration 26500, loss = 0.00413695
I0428 22:24:17.111480  2164 solver.cpp:253]     Train net output #0: loss = 0.00413701 (* 1 = 0.00413701 loss)
I0428 22:24:17.111490  2164 sgd_solver.cpp:106] Iteration 26500, lr = 0.00378687
I0428 22:24:17.283077  2164 solver.cpp:237] Iteration 26600, loss = 0.00346562
I0428 22:24:17.283166  2164 solver.cpp:253]     Train net output #0: loss = 0.00346568 (* 1 = 0.00346568 loss)
I0428 22:24:17.283190  2164 sgd_solver.cpp:106] Iteration 26600, lr = 0.00377911
I0428 22:24:17.457207  2164 solver.cpp:237] Iteration 26700, loss = 0.0019074
I0428 22:24:17.457298  2164 solver.cpp:253]     Train net output #0: loss = 0.00190746 (* 1 = 0.00190746 loss)
I0428 22:24:17.457324  2164 sgd_solver.cpp:106] Iteration 26700, lr = 0.00377138
I0428 22:24:17.631409  2164 solver.cpp:237] Iteration 26800, loss = 0.00611975
I0428 22:24:17.631494  2164 solver.cpp:253]     Train net output #0: loss = 0.00611981 (* 1 = 0.00611981 loss)
I0428 22:24:17.631520  2164 sgd_solver.cpp:106] Iteration 26800, lr = 0.00376369
I0428 22:24:17.805941  2164 solver.cpp:237] Iteration 26900, loss = 0.00478938
I0428 22:24:17.806030  2164 solver.cpp:253]     Train net output #0: loss = 0.00478944 (* 1 = 0.00478944 loss)
I0428 22:24:17.806056  2164 sgd_solver.cpp:106] Iteration 26900, lr = 0.00375604
I0428 22:24:17.980605  2164 solver.cpp:237] Iteration 27000, loss = 0.00320889
I0428 22:24:17.980690  2164 solver.cpp:253]     Train net output #0: loss = 0.00320895 (* 1 = 0.00320895 loss)
I0428 22:24:17.980717  2164 sgd_solver.cpp:106] Iteration 27000, lr = 0.00374842
I0428 22:24:18.155051  2164 solver.cpp:237] Iteration 27100, loss = 0.00356509
I0428 22:24:18.155141  2164 solver.cpp:253]     Train net output #0: loss = 0.00356515 (* 1 = 0.00356515 loss)
I0428 22:24:18.155167  2164 sgd_solver.cpp:106] Iteration 27100, lr = 0.00374084
I0428 22:24:18.329254  2164 solver.cpp:237] Iteration 27200, loss = 0.000990902
I0428 22:24:18.329288  2164 solver.cpp:253]     Train net output #0: loss = 0.000990968 (* 1 = 0.000990968 loss)
I0428 22:24:18.329298  2164 sgd_solver.cpp:106] Iteration 27200, lr = 0.0037333
I0428 22:24:18.500885  2164 solver.cpp:237] Iteration 27300, loss = 0.00561884
I0428 22:24:18.500927  2164 solver.cpp:253]     Train net output #0: loss = 0.00561891 (* 1 = 0.00561891 loss)
I0428 22:24:18.500937  2164 sgd_solver.cpp:106] Iteration 27300, lr = 0.00372579
I0428 22:24:18.672204  2164 solver.cpp:237] Iteration 27400, loss = 0.000893962
I0428 22:24:18.672236  2164 solver.cpp:253]     Train net output #0: loss = 0.000894029 (* 1 = 0.000894029 loss)
I0428 22:24:18.672276  2164 sgd_solver.cpp:106] Iteration 27400, lr = 0.00371832
I0428 22:24:18.843633  2164 solver.cpp:237] Iteration 27500, loss = 0.00742461
I0428 22:24:18.843668  2164 solver.cpp:253]     Train net output #0: loss = 0.00742468 (* 1 = 0.00742468 loss)
I0428 22:24:18.843677  2164 sgd_solver.cpp:106] Iteration 27500, lr = 0.00371088
I0428 22:24:19.014407  2164 solver.cpp:237] Iteration 27600, loss = 0.0145887
I0428 22:24:19.014441  2164 solver.cpp:253]     Train net output #0: loss = 0.0145887 (* 1 = 0.0145887 loss)
I0428 22:24:19.014451  2164 sgd_solver.cpp:106] Iteration 27600, lr = 0.00370347
I0428 22:24:19.186586  2164 solver.cpp:237] Iteration 27700, loss = 0.00288407
I0428 22:24:19.186620  2164 solver.cpp:253]     Train net output #0: loss = 0.00288413 (* 1 = 0.00288413 loss)
I0428 22:24:19.186628  2164 sgd_solver.cpp:106] Iteration 27700, lr = 0.0036961
I0428 22:24:19.358625  2164 solver.cpp:237] Iteration 27800, loss = 0.00124386
I0428 22:24:19.358659  2164 solver.cpp:253]     Train net output #0: loss = 0.00124392 (* 1 = 0.00124392 loss)
I0428 22:24:19.358667  2164 sgd_solver.cpp:106] Iteration 27800, lr = 0.00368877
I0428 22:24:19.530635  2164 solver.cpp:237] Iteration 27900, loss = 0.00480133
I0428 22:24:19.530668  2164 solver.cpp:253]     Train net output #0: loss = 0.00480139 (* 1 = 0.00480139 loss)
I0428 22:24:19.530678  2164 sgd_solver.cpp:106] Iteration 27900, lr = 0.00368146
I0428 22:24:19.702505  2164 solver.cpp:237] Iteration 28000, loss = 0.00176722
I0428 22:24:19.702539  2164 solver.cpp:253]     Train net output #0: loss = 0.00176728 (* 1 = 0.00176728 loss)
I0428 22:24:19.702548  2164 sgd_solver.cpp:106] Iteration 28000, lr = 0.0036742
I0428 22:24:19.874586  2164 solver.cpp:237] Iteration 28100, loss = 0.000342967
I0428 22:24:19.874619  2164 solver.cpp:253]     Train net output #0: loss = 0.000343029 (* 1 = 0.000343029 loss)
I0428 22:24:19.874629  2164 sgd_solver.cpp:106] Iteration 28100, lr = 0.00366696
I0428 22:24:20.047212  2164 solver.cpp:237] Iteration 28200, loss = 0.00117522
I0428 22:24:20.047245  2164 solver.cpp:253]     Train net output #0: loss = 0.00117528 (* 1 = 0.00117528 loss)
I0428 22:24:20.047255  2164 sgd_solver.cpp:106] Iteration 28200, lr = 0.00365976
I0428 22:24:20.219285  2164 solver.cpp:237] Iteration 28300, loss = 0.00839957
I0428 22:24:20.219319  2164 solver.cpp:253]     Train net output #0: loss = 0.00839963 (* 1 = 0.00839963 loss)
I0428 22:24:20.219328  2164 sgd_solver.cpp:106] Iteration 28300, lr = 0.00365259
I0428 22:24:20.391734  2164 solver.cpp:237] Iteration 28400, loss = 0.00259631
I0428 22:24:20.391769  2164 solver.cpp:253]     Train net output #0: loss = 0.00259637 (* 1 = 0.00259637 loss)
I0428 22:24:20.391778  2164 sgd_solver.cpp:106] Iteration 28400, lr = 0.00364545
I0428 22:24:20.563822  2164 solver.cpp:237] Iteration 28500, loss = 0.0023555
I0428 22:24:20.563856  2164 solver.cpp:253]     Train net output #0: loss = 0.00235555 (* 1 = 0.00235555 loss)
I0428 22:24:20.563866  2164 sgd_solver.cpp:106] Iteration 28500, lr = 0.00363835
I0428 22:24:20.736173  2164 solver.cpp:237] Iteration 28600, loss = 0.00077033
I0428 22:24:20.736207  2164 solver.cpp:253]     Train net output #0: loss = 0.000770388 (* 1 = 0.000770388 loss)
I0428 22:24:20.736217  2164 sgd_solver.cpp:106] Iteration 28600, lr = 0.00363128
I0428 22:24:20.908620  2164 solver.cpp:237] Iteration 28700, loss = 0.00242643
I0428 22:24:20.908654  2164 solver.cpp:253]     Train net output #0: loss = 0.00242649 (* 1 = 0.00242649 loss)
I0428 22:24:20.908664  2164 sgd_solver.cpp:106] Iteration 28700, lr = 0.00362424
I0428 22:24:21.080838  2164 solver.cpp:237] Iteration 28800, loss = 0.00398636
I0428 22:24:21.080871  2164 solver.cpp:253]     Train net output #0: loss = 0.00398642 (* 1 = 0.00398642 loss)
I0428 22:24:21.080880  2164 sgd_solver.cpp:106] Iteration 28800, lr = 0.00361723
I0428 22:24:21.252822  2164 solver.cpp:237] Iteration 28900, loss = 0.00322455
I0428 22:24:21.252856  2164 solver.cpp:253]     Train net output #0: loss = 0.00322461 (* 1 = 0.00322461 loss)
I0428 22:24:21.252894  2164 sgd_solver.cpp:106] Iteration 28900, lr = 0.00361025
I0428 22:24:21.440997  2164 solver.cpp:237] Iteration 29000, loss = 0.00295478
I0428 22:24:21.441084  2164 solver.cpp:253]     Train net output #0: loss = 0.00295484 (* 1 = 0.00295484 loss)
I0428 22:24:21.441110  2164 sgd_solver.cpp:106] Iteration 29000, lr = 0.00360331
I0428 22:24:21.613698  2164 solver.cpp:237] Iteration 29100, loss = 0.00630777
I0428 22:24:21.613785  2164 solver.cpp:253]     Train net output #0: loss = 0.00630783 (* 1 = 0.00630783 loss)
I0428 22:24:21.613809  2164 sgd_solver.cpp:106] Iteration 29100, lr = 0.0035964
I0428 22:24:21.785883  2164 solver.cpp:237] Iteration 29200, loss = 0.00490508
I0428 22:24:21.785917  2164 solver.cpp:253]     Train net output #0: loss = 0.00490515 (* 1 = 0.00490515 loss)
I0428 22:24:21.785925  2164 sgd_solver.cpp:106] Iteration 29200, lr = 0.00358951
I0428 22:24:21.957877  2164 solver.cpp:237] Iteration 29300, loss = 0.00134529
I0428 22:24:21.957911  2164 solver.cpp:253]     Train net output #0: loss = 0.00134535 (* 1 = 0.00134535 loss)
I0428 22:24:21.957921  2164 sgd_solver.cpp:106] Iteration 29300, lr = 0.00358266
I0428 22:24:22.130105  2164 solver.cpp:237] Iteration 29400, loss = 0.00228729
I0428 22:24:22.130136  2164 solver.cpp:253]     Train net output #0: loss = 0.00228735 (* 1 = 0.00228735 loss)
I0428 22:24:22.130146  2164 sgd_solver.cpp:106] Iteration 29400, lr = 0.00357584
I0428 22:24:22.301852  2164 solver.cpp:237] Iteration 29500, loss = 0.00141873
I0428 22:24:22.301885  2164 solver.cpp:253]     Train net output #0: loss = 0.00141879 (* 1 = 0.00141879 loss)
I0428 22:24:22.301894  2164 sgd_solver.cpp:106] Iteration 29500, lr = 0.00356905
I0428 22:24:22.473837  2164 solver.cpp:237] Iteration 29600, loss = 0.0044815
I0428 22:24:22.473871  2164 solver.cpp:253]     Train net output #0: loss = 0.00448156 (* 1 = 0.00448156 loss)
I0428 22:24:22.473881  2164 sgd_solver.cpp:106] Iteration 29600, lr = 0.00356228
I0428 22:24:22.645731  2164 solver.cpp:237] Iteration 29700, loss = 0.00252118
I0428 22:24:22.645766  2164 solver.cpp:253]     Train net output #0: loss = 0.00252125 (* 1 = 0.00252125 loss)
I0428 22:24:22.645776  2164 sgd_solver.cpp:106] Iteration 29700, lr = 0.00355555
I0428 22:24:22.817914  2164 solver.cpp:237] Iteration 29800, loss = 0.00916214
I0428 22:24:22.817948  2164 solver.cpp:253]     Train net output #0: loss = 0.0091622 (* 1 = 0.0091622 loss)
I0428 22:24:22.817957  2164 sgd_solver.cpp:106] Iteration 29800, lr = 0.00354885
I0428 22:24:22.989748  2164 solver.cpp:237] Iteration 29900, loss = 0.00255705
I0428 22:24:22.989781  2164 solver.cpp:253]     Train net output #0: loss = 0.00255711 (* 1 = 0.00255711 loss)
I0428 22:24:22.989790  2164 sgd_solver.cpp:106] Iteration 29900, lr = 0.00354218
I0428 22:24:23.160146  2164 solver.cpp:341] Iteration 30000, Testing net (#0)
I0428 22:24:23.300329  2164 solver.cpp:409]     Test net output #0: accuracy = 0.9906
I0428 22:24:23.300417  2164 solver.cpp:409]     Test net output #1: loss = 0.0272802 (* 1 = 0.0272802 loss)
I0428 22:24:23.301348  2164 solver.cpp:237] Iteration 30000, loss = 0.00246957
I0428 22:24:23.301388  2164 solver.cpp:253]     Train net output #0: loss = 0.00246962 (* 1 = 0.00246962 loss)
I0428 22:24:23.301409  2164 sgd_solver.cpp:106] Iteration 30000, lr = 0.00353553
I0428 22:24:23.508040  2164 solver.cpp:237] Iteration 30100, loss = 0.00282727
I0428 22:24:23.508198  2164 solver.cpp:253]     Train net output #0: loss = 0.00282733 (* 1 = 0.00282733 loss)
I0428 22:24:23.508265  2164 sgd_solver.cpp:106] Iteration 30100, lr = 0.00352892
I0428 22:24:23.680673  2164 solver.cpp:237] Iteration 30200, loss = 0.00634662
I0428 22:24:23.680836  2164 solver.cpp:253]     Train net output #0: loss = 0.00634669 (* 1 = 0.00634669 loss)
I0428 22:24:23.680907  2164 sgd_solver.cpp:106] Iteration 30200, lr = 0.00352233
I0428 22:24:23.853274  2164 solver.cpp:237] Iteration 30300, loss = 0.00213191
I0428 22:24:23.853433  2164 solver.cpp:253]     Train net output #0: loss = 0.00213197 (* 1 = 0.00213197 loss)
I0428 22:24:23.853519  2164 sgd_solver.cpp:106] Iteration 30300, lr = 0.00351578
I0428 22:24:24.025759  2164 solver.cpp:237] Iteration 30400, loss = 0.00190202
I0428 22:24:24.025946  2164 solver.cpp:253]     Train net output #0: loss = 0.00190208 (* 1 = 0.00190208 loss)
I0428 22:24:24.026007  2164 sgd_solver.cpp:106] Iteration 30400, lr = 0.00350925
I0428 22:24:24.198392  2164 solver.cpp:237] Iteration 30500, loss = 0.00267339
I0428 22:24:24.198552  2164 solver.cpp:253]     Train net output #0: loss = 0.00267344 (* 1 = 0.00267344 loss)
I0428 22:24:24.198607  2164 sgd_solver.cpp:106] Iteration 30500, lr = 0.00350275
I0428 22:24:24.371098  2164 solver.cpp:237] Iteration 30600, loss = 0.00386118
I0428 22:24:24.371132  2164 solver.cpp:253]     Train net output #0: loss = 0.00386123 (* 1 = 0.00386123 loss)
I0428 22:24:24.371141  2164 sgd_solver.cpp:106] Iteration 30600, lr = 0.00349627
I0428 22:24:24.541720  2164 solver.cpp:237] Iteration 30700, loss = 0.00419434
I0428 22:24:24.541754  2164 solver.cpp:253]     Train net output #0: loss = 0.00419439 (* 1 = 0.00419439 loss)
I0428 22:24:24.541764  2164 sgd_solver.cpp:106] Iteration 30700, lr = 0.00348983
I0428 22:24:24.711915  2164 solver.cpp:237] Iteration 30800, loss = 0.00991445
I0428 22:24:24.712004  2164 solver.cpp:253]     Train net output #0: loss = 0.00991451 (* 1 = 0.00991451 loss)
I0428 22:24:24.712029  2164 sgd_solver.cpp:106] Iteration 30800, lr = 0.00348341
I0428 22:24:24.884701  2164 solver.cpp:237] Iteration 30900, loss = 0.00297067
I0428 22:24:24.884788  2164 solver.cpp:253]     Train net output #0: loss = 0.00297072 (* 1 = 0.00297072 loss)
I0428 22:24:24.884814  2164 sgd_solver.cpp:106] Iteration 30900, lr = 0.00347702
I0428 22:24:25.056839  2164 solver.cpp:237] Iteration 31000, loss = 0.0040094
I0428 22:24:25.056936  2164 solver.cpp:253]     Train net output #0: loss = 0.00400946 (* 1 = 0.00400946 loss)
I0428 22:24:25.056963  2164 sgd_solver.cpp:106] Iteration 31000, lr = 0.00347066
I0428 22:24:25.228943  2164 solver.cpp:237] Iteration 31100, loss = 0.000650538
I0428 22:24:25.229032  2164 solver.cpp:253]     Train net output #0: loss = 0.000650594 (* 1 = 0.000650594 loss)
I0428 22:24:25.229056  2164 sgd_solver.cpp:106] Iteration 31100, lr = 0.00346433
I0428 22:24:25.401144  2164 solver.cpp:237] Iteration 31200, loss = 0.00139647
I0428 22:24:25.401232  2164 solver.cpp:253]     Train net output #0: loss = 0.00139653 (* 1 = 0.00139653 loss)
I0428 22:24:25.401257  2164 sgd_solver.cpp:106] Iteration 31200, lr = 0.00345802
I0428 22:24:25.573775  2164 solver.cpp:237] Iteration 31300, loss = 0.00116735
I0428 22:24:25.573860  2164 solver.cpp:253]     Train net output #0: loss = 0.00116741 (* 1 = 0.00116741 loss)
I0428 22:24:25.573885  2164 sgd_solver.cpp:106] Iteration 31300, lr = 0.00345174
I0428 22:24:25.745785  2164 solver.cpp:237] Iteration 31400, loss = 0.0002655
I0428 22:24:25.745870  2164 solver.cpp:253]     Train net output #0: loss = 0.000265555 (* 1 = 0.000265555 loss)
I0428 22:24:25.745896  2164 sgd_solver.cpp:106] Iteration 31400, lr = 0.00344548
I0428 22:24:25.917989  2164 solver.cpp:237] Iteration 31500, loss = 0.00819854
I0428 22:24:25.918076  2164 solver.cpp:253]     Train net output #0: loss = 0.00819861 (* 1 = 0.00819861 loss)
I0428 22:24:25.918102  2164 sgd_solver.cpp:106] Iteration 31500, lr = 0.00343925
I0428 22:24:26.090616  2164 solver.cpp:237] Iteration 31600, loss = 0.0042562
I0428 22:24:26.090699  2164 solver.cpp:253]     Train net output #0: loss = 0.00425626 (* 1 = 0.00425626 loss)
I0428 22:24:26.090739  2164 sgd_solver.cpp:106] Iteration 31600, lr = 0.00343305
I0428 22:24:26.260666  2164 solver.cpp:237] Iteration 31700, loss = 0.00246437
I0428 22:24:26.260702  2164 solver.cpp:253]     Train net output #0: loss = 0.00246443 (* 1 = 0.00246443 loss)
I0428 22:24:26.260710  2164 sgd_solver.cpp:106] Iteration 31700, lr = 0.00342687
I0428 22:24:26.430984  2164 solver.cpp:237] Iteration 31800, loss = 0.00592805
I0428 22:24:26.431072  2164 solver.cpp:253]     Train net output #0: loss = 0.00592811 (* 1 = 0.00592811 loss)
I0428 22:24:26.431098  2164 sgd_solver.cpp:106] Iteration 31800, lr = 0.00342072
I0428 22:24:26.604435  2164 solver.cpp:237] Iteration 31900, loss = 0.00652841
I0428 22:24:26.604522  2164 solver.cpp:253]     Train net output #0: loss = 0.00652847 (* 1 = 0.00652847 loss)
I0428 22:24:26.604548  2164 sgd_solver.cpp:106] Iteration 31900, lr = 0.0034146
I0428 22:24:26.776818  2164 solver.cpp:237] Iteration 32000, loss = 0.00297876
I0428 22:24:26.776922  2164 solver.cpp:253]     Train net output #0: loss = 0.00297883 (* 1 = 0.00297883 loss)
I0428 22:24:26.776949  2164 sgd_solver.cpp:106] Iteration 32000, lr = 0.0034085
I0428 22:24:26.949116  2164 solver.cpp:237] Iteration 32100, loss = 0.0022419
I0428 22:24:26.949201  2164 solver.cpp:253]     Train net output #0: loss = 0.00224196 (* 1 = 0.00224196 loss)
I0428 22:24:26.949226  2164 sgd_solver.cpp:106] Iteration 32100, lr = 0.00340242
I0428 22:24:27.121809  2164 solver.cpp:237] Iteration 32200, loss = 0.00127177
I0428 22:24:27.122012  2164 solver.cpp:253]     Train net output #0: loss = 0.00127184 (* 1 = 0.00127184 loss)
I0428 22:24:27.122040  2164 sgd_solver.cpp:106] Iteration 32200, lr = 0.00339637
I0428 22:24:27.293988  2164 solver.cpp:237] Iteration 32300, loss = 0.00699603
I0428 22:24:27.294073  2164 solver.cpp:253]     Train net output #0: loss = 0.00699609 (* 1 = 0.00699609 loss)
I0428 22:24:27.294098  2164 sgd_solver.cpp:106] Iteration 32300, lr = 0.00339035
I0428 22:24:27.466370  2164 solver.cpp:237] Iteration 32400, loss = 0.00242653
I0428 22:24:27.466464  2164 solver.cpp:253]     Train net output #0: loss = 0.00242659 (* 1 = 0.00242659 loss)
I0428 22:24:27.466490  2164 sgd_solver.cpp:106] Iteration 32400, lr = 0.00338435
I0428 22:24:27.636811  2164 solver.cpp:237] Iteration 32500, loss = 0.00146241
I0428 22:24:27.636847  2164 solver.cpp:253]     Train net output #0: loss = 0.00146248 (* 1 = 0.00146248 loss)
I0428 22:24:27.636855  2164 sgd_solver.cpp:106] Iteration 32500, lr = 0.00337838
I0428 22:24:27.806228  2164 solver.cpp:237] Iteration 32600, loss = 0.0106835
I0428 22:24:27.806262  2164 solver.cpp:253]     Train net output #0: loss = 0.0106836 (* 1 = 0.0106836 loss)
I0428 22:24:27.806270  2164 sgd_solver.cpp:106] Iteration 32600, lr = 0.00337243
I0428 22:24:27.976348  2164 solver.cpp:237] Iteration 32700, loss = 0.00759867
I0428 22:24:27.976436  2164 solver.cpp:253]     Train net output #0: loss = 0.00759873 (* 1 = 0.00759873 loss)
I0428 22:24:27.976462  2164 sgd_solver.cpp:106] Iteration 32700, lr = 0.0033665
I0428 22:24:28.149758  2164 solver.cpp:237] Iteration 32800, loss = 0.000153884
I0428 22:24:28.149845  2164 solver.cpp:253]     Train net output #0: loss = 0.00015395 (* 1 = 0.00015395 loss)
I0428 22:24:28.149870  2164 sgd_solver.cpp:106] Iteration 32800, lr = 0.0033606
I0428 22:24:28.328644  2164 solver.cpp:237] Iteration 32900, loss = 0.00387961
I0428 22:24:28.328722  2164 solver.cpp:253]     Train net output #0: loss = 0.00387968 (* 1 = 0.00387968 loss)
I0428 22:24:28.328743  2164 sgd_solver.cpp:106] Iteration 32900, lr = 0.00335473
I0428 22:24:28.533190  2164 solver.cpp:237] Iteration 33000, loss = 0.00400436
I0428 22:24:28.533282  2164 solver.cpp:253]     Train net output #0: loss = 0.00400443 (* 1 = 0.00400443 loss)
I0428 22:24:28.533309  2164 sgd_solver.cpp:106] Iteration 33000, lr = 0.00334887
I0428 22:24:28.710139  2164 solver.cpp:237] Iteration 33100, loss = 0.00304592
I0428 22:24:28.710227  2164 solver.cpp:253]     Train net output #0: loss = 0.00304599 (* 1 = 0.00304599 loss)
I0428 22:24:28.710266  2164 sgd_solver.cpp:106] Iteration 33100, lr = 0.00334304
I0428 22:24:28.884290  2164 solver.cpp:237] Iteration 33200, loss = 0.00264779
I0428 22:24:28.884377  2164 solver.cpp:253]     Train net output #0: loss = 0.00264786 (* 1 = 0.00264786 loss)
I0428 22:24:28.884402  2164 sgd_solver.cpp:106] Iteration 33200, lr = 0.00333724
I0428 22:24:29.058701  2164 solver.cpp:237] Iteration 33300, loss = 0.00164962
I0428 22:24:29.058792  2164 solver.cpp:253]     Train net output #0: loss = 0.00164968 (* 1 = 0.00164968 loss)
I0428 22:24:29.058822  2164 sgd_solver.cpp:106] Iteration 33300, lr = 0.00333146
I0428 22:24:29.232584  2164 solver.cpp:237] Iteration 33400, loss = 0.0015634
I0428 22:24:29.232620  2164 solver.cpp:253]     Train net output #0: loss = 0.00156346 (* 1 = 0.00156346 loss)
I0428 22:24:29.232628  2164 sgd_solver.cpp:106] Iteration 33400, lr = 0.0033257
I0428 22:24:29.401824  2164 solver.cpp:237] Iteration 33500, loss = 0.00201631
I0428 22:24:29.401857  2164 solver.cpp:253]     Train net output #0: loss = 0.00201637 (* 1 = 0.00201637 loss)
I0428 22:24:29.401866  2164 sgd_solver.cpp:106] Iteration 33500, lr = 0.00331996
I0428 22:24:29.574471  2164 solver.cpp:237] Iteration 33600, loss = 0.00905661
I0428 22:24:29.574568  2164 solver.cpp:253]     Train net output #0: loss = 0.00905666 (* 1 = 0.00905666 loss)
I0428 22:24:29.574594  2164 sgd_solver.cpp:106] Iteration 33600, lr = 0.00331425
I0428 22:24:29.747015  2164 solver.cpp:237] Iteration 33700, loss = 0.00490389
I0428 22:24:29.747102  2164 solver.cpp:253]     Train net output #0: loss = 0.00490395 (* 1 = 0.00490395 loss)
I0428 22:24:29.747155  2164 sgd_solver.cpp:106] Iteration 33700, lr = 0.00330856
I0428 22:24:29.919333  2164 solver.cpp:237] Iteration 33800, loss = 0.00227374
I0428 22:24:29.919419  2164 solver.cpp:253]     Train net output #0: loss = 0.0022738 (* 1 = 0.0022738 loss)
I0428 22:24:29.919443  2164 sgd_solver.cpp:106] Iteration 33800, lr = 0.00330289
I0428 22:24:30.104171  2164 solver.cpp:237] Iteration 33900, loss = 0.00408066
I0428 22:24:30.104257  2164 solver.cpp:253]     Train net output #0: loss = 0.00408072 (* 1 = 0.00408072 loss)
I0428 22:24:30.104284  2164 sgd_solver.cpp:106] Iteration 33900, lr = 0.00329725
I0428 22:24:30.276474  2164 solver.cpp:237] Iteration 34000, loss = 0.00408774
I0428 22:24:30.276561  2164 solver.cpp:253]     Train net output #0: loss = 0.0040878 (* 1 = 0.0040878 loss)
I0428 22:24:30.276587  2164 sgd_solver.cpp:106] Iteration 34000, lr = 0.00329163
I0428 22:24:30.449050  2164 solver.cpp:237] Iteration 34100, loss = 0.00342509
I0428 22:24:30.449136  2164 solver.cpp:253]     Train net output #0: loss = 0.00342515 (* 1 = 0.00342515 loss)
I0428 22:24:30.449161  2164 sgd_solver.cpp:106] Iteration 34100, lr = 0.00328603
I0428 22:24:30.620998  2164 solver.cpp:237] Iteration 34200, loss = 0.00190839
I0428 22:24:30.621088  2164 solver.cpp:253]     Train net output #0: loss = 0.00190845 (* 1 = 0.00190845 loss)
I0428 22:24:30.621114  2164 sgd_solver.cpp:106] Iteration 34200, lr = 0.00328045
I0428 22:24:30.792814  2164 solver.cpp:237] Iteration 34300, loss = 0.00580761
I0428 22:24:30.792904  2164 solver.cpp:253]     Train net output #0: loss = 0.00580767 (* 1 = 0.00580767 loss)
I0428 22:24:30.792932  2164 sgd_solver.cpp:106] Iteration 34300, lr = 0.00327489
I0428 22:24:30.964815  2164 solver.cpp:237] Iteration 34400, loss = 0.0047952
I0428 22:24:30.964908  2164 solver.cpp:253]     Train net output #0: loss = 0.00479525 (* 1 = 0.00479525 loss)
I0428 22:24:30.964936  2164 sgd_solver.cpp:106] Iteration 34400, lr = 0.00326936
I0428 22:24:31.136158  2164 solver.cpp:237] Iteration 34500, loss = 0.0031557
I0428 22:24:31.136194  2164 solver.cpp:253]     Train net output #0: loss = 0.00315574 (* 1 = 0.00315574 loss)
I0428 22:24:31.136204  2164 sgd_solver.cpp:106] Iteration 34500, lr = 0.00326385
I0428 22:24:31.308081  2164 solver.cpp:237] Iteration 34600, loss = 0.00361837
I0428 22:24:31.308171  2164 solver.cpp:253]     Train net output #0: loss = 0.00361842 (* 1 = 0.00361842 loss)
I0428 22:24:31.308197  2164 sgd_solver.cpp:106] Iteration 34600, lr = 0.00325836
I0428 22:24:31.482033  2164 solver.cpp:237] Iteration 34700, loss = 0.00109421
I0428 22:24:31.482121  2164 solver.cpp:253]     Train net output #0: loss = 0.00109426 (* 1 = 0.00109426 loss)
I0428 22:24:31.482147  2164 sgd_solver.cpp:106] Iteration 34700, lr = 0.00325289
I0428 22:24:31.656258  2164 solver.cpp:237] Iteration 34800, loss = 0.0055173
I0428 22:24:31.656347  2164 solver.cpp:253]     Train net output #0: loss = 0.00551734 (* 1 = 0.00551734 loss)
I0428 22:24:31.656371  2164 sgd_solver.cpp:106] Iteration 34800, lr = 0.00324744
I0428 22:24:31.830133  2164 solver.cpp:237] Iteration 34900, loss = 0.000877851
I0428 22:24:31.830222  2164 solver.cpp:253]     Train net output #0: loss = 0.000877898 (* 1 = 0.000877898 loss)
I0428 22:24:31.830248  2164 sgd_solver.cpp:106] Iteration 34900, lr = 0.00324202
I0428 22:24:31.999583  2164 solver.cpp:341] Iteration 35000, Testing net (#0)
I0428 22:24:32.116247  2271 blocking_queue.cpp:50] Waiting for data
I0428 22:24:32.147583  2164 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0428 22:24:32.147671  2164 solver.cpp:409]     Test net output #1: loss = 0.0265638 (* 1 = 0.0265638 loss)
I0428 22:24:32.148640  2164 solver.cpp:237] Iteration 35000, loss = 0.00728101
I0428 22:24:32.148685  2164 solver.cpp:253]     Train net output #0: loss = 0.00728106 (* 1 = 0.00728106 loss)
I0428 22:24:32.148716  2164 sgd_solver.cpp:106] Iteration 35000, lr = 0.00323661
I0428 22:24:32.363747  2164 solver.cpp:237] Iteration 35100, loss = 0.013873
I0428 22:24:32.363834  2164 solver.cpp:253]     Train net output #0: loss = 0.0138731 (* 1 = 0.0138731 loss)
I0428 22:24:32.363884  2164 sgd_solver.cpp:106] Iteration 35100, lr = 0.00323123
I0428 22:24:32.544523  2164 solver.cpp:237] Iteration 35200, loss = 0.00281938
I0428 22:24:32.544613  2164 solver.cpp:253]     Train net output #0: loss = 0.00281942 (* 1 = 0.00281942 loss)
I0428 22:24:32.544638  2164 sgd_solver.cpp:106] Iteration 35200, lr = 0.00322586
I0428 22:24:32.725837  2164 solver.cpp:237] Iteration 35300, loss = 0.00127113
I0428 22:24:32.725922  2164 solver.cpp:253]     Train net output #0: loss = 0.00127118 (* 1 = 0.00127118 loss)
I0428 22:24:32.725947  2164 sgd_solver.cpp:106] Iteration 35300, lr = 0.00322052
I0428 22:24:32.907191  2164 solver.cpp:237] Iteration 35400, loss = 0.00488327
I0428 22:24:32.907275  2164 solver.cpp:253]     Train net output #0: loss = 0.00488332 (* 1 = 0.00488332 loss)
I0428 22:24:32.907301  2164 sgd_solver.cpp:106] Iteration 35400, lr = 0.0032152
I0428 22:24:33.088393  2164 solver.cpp:237] Iteration 35500, loss = 0.00164782
I0428 22:24:33.088485  2164 solver.cpp:253]     Train net output #0: loss = 0.00164787 (* 1 = 0.00164787 loss)
I0428 22:24:33.088512  2164 sgd_solver.cpp:106] Iteration 35500, lr = 0.0032099
I0428 22:24:33.269708  2164 solver.cpp:237] Iteration 35600, loss = 0.000325452
I0428 22:24:33.269798  2164 solver.cpp:253]     Train net output #0: loss = 0.000325502 (* 1 = 0.000325502 loss)
I0428 22:24:33.269824  2164 sgd_solver.cpp:106] Iteration 35600, lr = 0.00320462
I0428 22:24:33.451028  2164 solver.cpp:237] Iteration 35700, loss = 0.00119273
I0428 22:24:33.451117  2164 solver.cpp:253]     Train net output #0: loss = 0.00119278 (* 1 = 0.00119278 loss)
I0428 22:24:33.451143  2164 sgd_solver.cpp:106] Iteration 35700, lr = 0.00319936
I0428 22:24:33.633817  2164 solver.cpp:237] Iteration 35800, loss = 0.00788495
I0428 22:24:33.633898  2164 solver.cpp:253]     Train net output #0: loss = 0.00788501 (* 1 = 0.00788501 loss)
I0428 22:24:33.633919  2164 sgd_solver.cpp:106] Iteration 35800, lr = 0.00319412
I0428 22:24:33.847604  2164 solver.cpp:237] Iteration 35900, loss = 0.00240775
I0428 22:24:33.847690  2164 solver.cpp:253]     Train net output #0: loss = 0.00240781 (* 1 = 0.00240781 loss)
I0428 22:24:33.847717  2164 sgd_solver.cpp:106] Iteration 35900, lr = 0.0031889
I0428 22:24:34.027154  2164 solver.cpp:237] Iteration 36000, loss = 0.00238922
I0428 22:24:34.027240  2164 solver.cpp:253]     Train net output #0: loss = 0.00238928 (* 1 = 0.00238928 loss)
I0428 22:24:34.027281  2164 sgd_solver.cpp:106] Iteration 36000, lr = 0.0031837
I0428 22:24:34.207273  2164 solver.cpp:237] Iteration 36100, loss = 0.00075454
I0428 22:24:34.207360  2164 solver.cpp:253]     Train net output #0: loss = 0.000754594 (* 1 = 0.000754594 loss)
I0428 22:24:34.207386  2164 sgd_solver.cpp:106] Iteration 36100, lr = 0.00317852
I0428 22:24:34.387181  2164 solver.cpp:237] Iteration 36200, loss = 0.002482
I0428 22:24:34.387269  2164 solver.cpp:253]     Train net output #0: loss = 0.00248206 (* 1 = 0.00248206 loss)
I0428 22:24:34.387293  2164 sgd_solver.cpp:106] Iteration 36200, lr = 0.00317335
I0428 22:24:34.567270  2164 solver.cpp:237] Iteration 36300, loss = 0.00374576
I0428 22:24:34.567358  2164 solver.cpp:253]     Train net output #0: loss = 0.00374582 (* 1 = 0.00374582 loss)
I0428 22:24:34.567383  2164 sgd_solver.cpp:106] Iteration 36300, lr = 0.00316821
I0428 22:24:34.747143  2164 solver.cpp:237] Iteration 36400, loss = 0.00317321
I0428 22:24:34.747228  2164 solver.cpp:253]     Train net output #0: loss = 0.00317328 (* 1 = 0.00317328 loss)
I0428 22:24:34.747253  2164 sgd_solver.cpp:106] Iteration 36400, lr = 0.00316309
I0428 22:24:34.927078  2164 solver.cpp:237] Iteration 36500, loss = 0.00277861
I0428 22:24:34.927162  2164 solver.cpp:253]     Train net output #0: loss = 0.00277867 (* 1 = 0.00277867 loss)
I0428 22:24:34.927187  2164 sgd_solver.cpp:106] Iteration 36500, lr = 0.00315799
I0428 22:24:35.106356  2164 solver.cpp:237] Iteration 36600, loss = 0.00600912
I0428 22:24:35.106441  2164 solver.cpp:253]     Train net output #0: loss = 0.00600919 (* 1 = 0.00600919 loss)
I0428 22:24:35.106494  2164 sgd_solver.cpp:106] Iteration 36600, lr = 0.0031529
I0428 22:24:35.285958  2164 solver.cpp:237] Iteration 36700, loss = 0.00467485
I0428 22:24:35.286044  2164 solver.cpp:253]     Train net output #0: loss = 0.00467492 (* 1 = 0.00467492 loss)
I0428 22:24:35.286070  2164 sgd_solver.cpp:106] Iteration 36700, lr = 0.00314784
I0428 22:24:35.465509  2164 solver.cpp:237] Iteration 36800, loss = 0.00132755
I0428 22:24:35.465595  2164 solver.cpp:253]     Train net output #0: loss = 0.00132761 (* 1 = 0.00132761 loss)
I0428 22:24:35.465621  2164 sgd_solver.cpp:106] Iteration 36800, lr = 0.00314279
I0428 22:24:35.644960  2164 solver.cpp:237] Iteration 36900, loss = 0.00210282
I0428 22:24:35.645047  2164 solver.cpp:253]     Train net output #0: loss = 0.00210289 (* 1 = 0.00210289 loss)
I0428 22:24:35.645073  2164 sgd_solver.cpp:106] Iteration 36900, lr = 0.00313776
I0428 22:24:35.823833  2164 solver.cpp:237] Iteration 37000, loss = 0.00127262
I0428 22:24:35.823920  2164 solver.cpp:253]     Train net output #0: loss = 0.00127269 (* 1 = 0.00127269 loss)
I0428 22:24:35.823945  2164 sgd_solver.cpp:106] Iteration 37000, lr = 0.00313276
I0428 22:24:36.002962  2164 solver.cpp:237] Iteration 37100, loss = 0.00445469
I0428 22:24:36.003051  2164 solver.cpp:253]     Train net output #0: loss = 0.00445476 (* 1 = 0.00445476 loss)
I0428 22:24:36.003077  2164 sgd_solver.cpp:106] Iteration 37100, lr = 0.00312777
I0428 22:24:36.180881  2164 solver.cpp:237] Iteration 37200, loss = 0.00242094
I0428 22:24:36.180924  2164 solver.cpp:253]     Train net output #0: loss = 0.002421 (* 1 = 0.002421 loss)
I0428 22:24:36.180934  2164 sgd_solver.cpp:106] Iteration 37200, lr = 0.0031228
I0428 22:24:36.356812  2164 solver.cpp:237] Iteration 37300, loss = 0.00866521
I0428 22:24:36.356850  2164 solver.cpp:253]     Train net output #0: loss = 0.00866528 (* 1 = 0.00866528 loss)
I0428 22:24:36.356859  2164 sgd_solver.cpp:106] Iteration 37300, lr = 0.00311784
I0428 22:24:36.535001  2164 solver.cpp:237] Iteration 37400, loss = 0.00244529
I0428 22:24:36.535089  2164 solver.cpp:253]     Train net output #0: loss = 0.00244536 (* 1 = 0.00244536 loss)
I0428 22:24:36.535115  2164 sgd_solver.cpp:106] Iteration 37400, lr = 0.00311291
I0428 22:24:36.714736  2164 solver.cpp:237] Iteration 37500, loss = 0.00238837
I0428 22:24:36.714820  2164 solver.cpp:253]     Train net output #0: loss = 0.00238844 (* 1 = 0.00238844 loss)
I0428 22:24:36.714845  2164 sgd_solver.cpp:106] Iteration 37500, lr = 0.00310799
I0428 22:24:36.894810  2164 solver.cpp:237] Iteration 37600, loss = 0.00271362
I0428 22:24:36.894897  2164 solver.cpp:253]     Train net output #0: loss = 0.00271369 (* 1 = 0.00271369 loss)
I0428 22:24:36.894922  2164 sgd_solver.cpp:106] Iteration 37600, lr = 0.00310309
I0428 22:24:37.074758  2164 solver.cpp:237] Iteration 37700, loss = 0.00620709
I0428 22:24:37.074843  2164 solver.cpp:253]     Train net output #0: loss = 0.00620716 (* 1 = 0.00620716 loss)
I0428 22:24:37.074868  2164 sgd_solver.cpp:106] Iteration 37700, lr = 0.00309821
I0428 22:24:37.255036  2164 solver.cpp:237] Iteration 37800, loss = 0.00216472
I0428 22:24:37.255125  2164 solver.cpp:253]     Train net output #0: loss = 0.00216479 (* 1 = 0.00216479 loss)
I0428 22:24:37.255152  2164 sgd_solver.cpp:106] Iteration 37800, lr = 0.00309335
I0428 22:24:37.433965  2164 solver.cpp:237] Iteration 37900, loss = 0.0018154
I0428 22:24:37.434001  2164 solver.cpp:253]     Train net output #0: loss = 0.00181547 (* 1 = 0.00181547 loss)
I0428 22:24:37.434011  2164 sgd_solver.cpp:106] Iteration 37900, lr = 0.00308851
I0428 22:24:37.609706  2164 solver.cpp:237] Iteration 38000, loss = 0.00252277
I0428 22:24:37.609792  2164 solver.cpp:253]     Train net output #0: loss = 0.00252283 (* 1 = 0.00252283 loss)
I0428 22:24:37.609817  2164 sgd_solver.cpp:106] Iteration 38000, lr = 0.00308368
I0428 22:24:37.789114  2164 solver.cpp:237] Iteration 38100, loss = 0.00377128
I0428 22:24:37.789201  2164 solver.cpp:253]     Train net output #0: loss = 0.00377134 (* 1 = 0.00377134 loss)
I0428 22:24:37.789249  2164 sgd_solver.cpp:106] Iteration 38100, lr = 0.00307887
I0428 22:24:37.968922  2164 solver.cpp:237] Iteration 38200, loss = 0.00414954
I0428 22:24:37.969008  2164 solver.cpp:253]     Train net output #0: loss = 0.0041496 (* 1 = 0.0041496 loss)
I0428 22:24:37.969033  2164 sgd_solver.cpp:106] Iteration 38200, lr = 0.00307408
I0428 22:24:38.148960  2164 solver.cpp:237] Iteration 38300, loss = 0.0100406
I0428 22:24:38.149047  2164 solver.cpp:253]     Train net output #0: loss = 0.0100407 (* 1 = 0.0100407 loss)
I0428 22:24:38.149073  2164 sgd_solver.cpp:106] Iteration 38300, lr = 0.0030693
I0428 22:24:38.325273  2164 solver.cpp:237] Iteration 38400, loss = 0.00294096
I0428 22:24:38.325309  2164 solver.cpp:253]     Train net output #0: loss = 0.00294102 (* 1 = 0.00294102 loss)
I0428 22:24:38.325317  2164 sgd_solver.cpp:106] Iteration 38400, lr = 0.00306454
I0428 22:24:38.501430  2164 solver.cpp:237] Iteration 38500, loss = 0.00377262
I0428 22:24:38.501464  2164 solver.cpp:253]     Train net output #0: loss = 0.00377268 (* 1 = 0.00377268 loss)
I0428 22:24:38.501473  2164 sgd_solver.cpp:106] Iteration 38500, lr = 0.0030598
I0428 22:24:38.677459  2164 solver.cpp:237] Iteration 38600, loss = 0.000616864
I0428 22:24:38.677495  2164 solver.cpp:253]     Train net output #0: loss = 0.000616924 (* 1 = 0.000616924 loss)
I0428 22:24:38.677502  2164 sgd_solver.cpp:106] Iteration 38600, lr = 0.00305508
I0428 22:24:38.853617  2164 solver.cpp:237] Iteration 38700, loss = 0.00132365
I0428 22:24:38.853652  2164 solver.cpp:253]     Train net output #0: loss = 0.00132372 (* 1 = 0.00132372 loss)
I0428 22:24:38.853662  2164 sgd_solver.cpp:106] Iteration 38700, lr = 0.00305038
I0428 22:24:39.029472  2164 solver.cpp:237] Iteration 38800, loss = 0.0011335
I0428 22:24:39.029559  2164 solver.cpp:253]     Train net output #0: loss = 0.00113356 (* 1 = 0.00113356 loss)
I0428 22:24:39.029587  2164 sgd_solver.cpp:106] Iteration 38800, lr = 0.00304569
I0428 22:24:39.240211  2164 solver.cpp:237] Iteration 38900, loss = 0.000247982
I0428 22:24:39.240298  2164 solver.cpp:253]     Train net output #0: loss = 0.000248041 (* 1 = 0.000248041 loss)
I0428 22:24:39.240324  2164 sgd_solver.cpp:106] Iteration 38900, lr = 0.00304101
I0428 22:24:39.420972  2164 solver.cpp:237] Iteration 39000, loss = 0.00805471
I0428 22:24:39.421061  2164 solver.cpp:253]     Train net output #0: loss = 0.00805477 (* 1 = 0.00805477 loss)
I0428 22:24:39.421085  2164 sgd_solver.cpp:106] Iteration 39000, lr = 0.00303636
I0428 22:24:39.601184  2164 solver.cpp:237] Iteration 39100, loss = 0.00409693
I0428 22:24:39.601270  2164 solver.cpp:253]     Train net output #0: loss = 0.00409699 (* 1 = 0.00409699 loss)
I0428 22:24:39.601296  2164 sgd_solver.cpp:106] Iteration 39100, lr = 0.00303172
I0428 22:24:39.781244  2164 solver.cpp:237] Iteration 39200, loss = 0.00252096
I0428 22:24:39.781330  2164 solver.cpp:253]     Train net output #0: loss = 0.00252102 (* 1 = 0.00252102 loss)
I0428 22:24:39.781355  2164 sgd_solver.cpp:106] Iteration 39200, lr = 0.0030271
I0428 22:24:39.960813  2164 solver.cpp:237] Iteration 39300, loss = 0.00549714
I0428 22:24:39.960904  2164 solver.cpp:253]     Train net output #0: loss = 0.0054972 (* 1 = 0.0054972 loss)
I0428 22:24:39.960932  2164 sgd_solver.cpp:106] Iteration 39300, lr = 0.00302249
I0428 22:24:40.136410  2164 solver.cpp:237] Iteration 39400, loss = 0.00620727
I0428 22:24:40.136446  2164 solver.cpp:253]     Train net output #0: loss = 0.00620733 (* 1 = 0.00620733 loss)
I0428 22:24:40.136456  2164 sgd_solver.cpp:106] Iteration 39400, lr = 0.0030179
I0428 22:24:40.312208  2164 solver.cpp:237] Iteration 39500, loss = 0.00288242
I0428 22:24:40.312242  2164 solver.cpp:253]     Train net output #0: loss = 0.00288248 (* 1 = 0.00288248 loss)
I0428 22:24:40.312250  2164 sgd_solver.cpp:106] Iteration 39500, lr = 0.00301333
I0428 22:24:40.491740  2164 solver.cpp:237] Iteration 39600, loss = 0.00222481
I0428 22:24:40.491827  2164 solver.cpp:253]     Train net output #0: loss = 0.00222487 (* 1 = 0.00222487 loss)
I0428 22:24:40.491852  2164 sgd_solver.cpp:106] Iteration 39600, lr = 0.00300877
I0428 22:24:40.672276  2164 solver.cpp:237] Iteration 39700, loss = 0.00124742
I0428 22:24:40.672363  2164 solver.cpp:253]     Train net output #0: loss = 0.00124748 (* 1 = 0.00124748 loss)
I0428 22:24:40.672387  2164 sgd_solver.cpp:106] Iteration 39700, lr = 0.00300423
I0428 22:24:40.852067  2164 solver.cpp:237] Iteration 39800, loss = 0.00687409
I0428 22:24:40.852155  2164 solver.cpp:253]     Train net output #0: loss = 0.00687415 (* 1 = 0.00687415 loss)
I0428 22:24:40.852181  2164 sgd_solver.cpp:106] Iteration 39800, lr = 0.0029997
I0428 22:24:41.031682  2164 solver.cpp:237] Iteration 39900, loss = 0.00234228
I0428 22:24:41.031767  2164 solver.cpp:253]     Train net output #0: loss = 0.00234234 (* 1 = 0.00234234 loss)
I0428 22:24:41.031793  2164 sgd_solver.cpp:106] Iteration 39900, lr = 0.00299519
I0428 22:24:41.214232  2164 solver.cpp:341] Iteration 40000, Testing net (#0)
I0428 22:24:41.325788  2164 solver.cpp:409]     Test net output #0: accuracy = 0.99
I0428 22:24:41.325862  2164 solver.cpp:409]     Test net output #1: loss = 0.02521 (* 1 = 0.02521 loss)
I0428 22:24:41.327188  2164 solver.cpp:237] Iteration 40000, loss = 0.00146954
I0428 22:24:41.327224  2164 solver.cpp:253]     Train net output #0: loss = 0.0014696 (* 1 = 0.0014696 loss)
I0428 22:24:41.327245  2164 sgd_solver.cpp:106] Iteration 40000, lr = 0.0029907
I0428 22:24:41.513068  2164 solver.cpp:237] Iteration 40100, loss = 0.0100878
I0428 22:24:41.513151  2164 solver.cpp:253]     Train net output #0: loss = 0.0100879 (* 1 = 0.0100879 loss)
I0428 22:24:41.513176  2164 sgd_solver.cpp:106] Iteration 40100, lr = 0.00298622
I0428 22:24:41.693245  2164 solver.cpp:237] Iteration 40200, loss = 0.0073462
I0428 22:24:41.693332  2164 solver.cpp:253]     Train net output #0: loss = 0.00734625 (* 1 = 0.00734625 loss)
I0428 22:24:41.693358  2164 sgd_solver.cpp:106] Iteration 40200, lr = 0.00298176
I0428 22:24:41.874008  2164 solver.cpp:237] Iteration 40300, loss = 0.000152544
I0428 22:24:41.874092  2164 solver.cpp:253]     Train net output #0: loss = 0.000152604 (* 1 = 0.000152604 loss)
I0428 22:24:41.874119  2164 sgd_solver.cpp:106] Iteration 40300, lr = 0.00297731
I0428 22:24:42.054553  2164 solver.cpp:237] Iteration 40400, loss = 0.00364556
I0428 22:24:42.054639  2164 solver.cpp:253]     Train net output #0: loss = 0.00364561 (* 1 = 0.00364561 loss)
I0428 22:24:42.054666  2164 sgd_solver.cpp:106] Iteration 40400, lr = 0.00297288
I0428 22:24:42.235450  2164 solver.cpp:237] Iteration 40500, loss = 0.00383357
I0428 22:24:42.235549  2164 solver.cpp:253]     Train net output #0: loss = 0.00383363 (* 1 = 0.00383363 loss)
I0428 22:24:42.235579  2164 sgd_solver.cpp:106] Iteration 40500, lr = 0.00296846
I0428 22:24:42.415782  2164 solver.cpp:237] Iteration 40600, loss = 0.00283832
I0428 22:24:42.415870  2164 solver.cpp:253]     Train net output #0: loss = 0.00283838 (* 1 = 0.00283838 loss)
I0428 22:24:42.415895  2164 sgd_solver.cpp:106] Iteration 40600, lr = 0.00296406
I0428 22:24:42.626965  2164 solver.cpp:237] Iteration 40700, loss = 0.00254678
I0428 22:24:42.627046  2164 solver.cpp:253]     Train net output #0: loss = 0.00254684 (* 1 = 0.00254684 loss)
I0428 22:24:42.627066  2164 sgd_solver.cpp:106] Iteration 40700, lr = 0.00295968
I0428 22:24:42.853153  2164 solver.cpp:237] Iteration 40800, loss = 0.00163307
I0428 22:24:42.853240  2164 solver.cpp:253]     Train net output #0: loss = 0.00163312 (* 1 = 0.00163312 loss)
I0428 22:24:42.853262  2164 sgd_solver.cpp:106] Iteration 40800, lr = 0.0029553
I0428 22:24:43.073319  2164 solver.cpp:237] Iteration 40900, loss = 0.00157895
I0428 22:24:43.073395  2164 solver.cpp:253]     Train net output #0: loss = 0.00157901 (* 1 = 0.00157901 loss)
I0428 22:24:43.073413  2164 sgd_solver.cpp:106] Iteration 40900, lr = 0.00295095
I0428 22:24:43.301200  2164 solver.cpp:237] Iteration 41000, loss = 0.00190318
I0428 22:24:43.301292  2164 solver.cpp:253]     Train net output #0: loss = 0.00190323 (* 1 = 0.00190323 loss)
I0428 22:24:43.301321  2164 sgd_solver.cpp:106] Iteration 41000, lr = 0.00294661
I0428 22:24:43.524981  2164 solver.cpp:237] Iteration 41100, loss = 0.00881345
I0428 22:24:43.525059  2164 solver.cpp:253]     Train net output #0: loss = 0.0088135 (* 1 = 0.0088135 loss)
I0428 22:24:43.525081  2164 sgd_solver.cpp:106] Iteration 41100, lr = 0.00294228
I0428 22:24:43.753342  2164 solver.cpp:237] Iteration 41200, loss = 0.004855
I0428 22:24:43.753420  2164 solver.cpp:253]     Train net output #0: loss = 0.00485505 (* 1 = 0.00485505 loss)
I0428 22:24:43.753439  2164 sgd_solver.cpp:106] Iteration 41200, lr = 0.00293797
I0428 22:24:43.999107  2164 solver.cpp:237] Iteration 41300, loss = 0.00219274
I0428 22:24:43.999153  2164 solver.cpp:253]     Train net output #0: loss = 0.00219279 (* 1 = 0.00219279 loss)
I0428 22:24:43.999162  2164 sgd_solver.cpp:106] Iteration 41300, lr = 0.00293367
I0428 22:24:44.238940  2164 solver.cpp:237] Iteration 41400, loss = 0.00402012
I0428 22:24:44.238983  2164 solver.cpp:253]     Train net output #0: loss = 0.00402018 (* 1 = 0.00402018 loss)
I0428 22:24:44.238992  2164 sgd_solver.cpp:106] Iteration 41400, lr = 0.00292939
I0428 22:24:44.476397  2164 solver.cpp:237] Iteration 41500, loss = 0.00403473
I0428 22:24:44.476485  2164 solver.cpp:253]     Train net output #0: loss = 0.00403479 (* 1 = 0.00403479 loss)
I0428 22:24:44.476511  2164 sgd_solver.cpp:106] Iteration 41500, lr = 0.00292513
I0428 22:24:44.710944  2164 solver.cpp:237] Iteration 41600, loss = 0.00340394
I0428 22:24:44.711019  2164 solver.cpp:253]     Train net output #0: loss = 0.003404 (* 1 = 0.003404 loss)
I0428 22:24:44.711038  2164 sgd_solver.cpp:106] Iteration 41600, lr = 0.00292087
I0428 22:24:44.928695  2164 solver.cpp:237] Iteration 41700, loss = 0.00188158
I0428 22:24:44.928771  2164 solver.cpp:253]     Train net output #0: loss = 0.00188163 (* 1 = 0.00188163 loss)
I0428 22:24:44.928791  2164 sgd_solver.cpp:106] Iteration 41700, lr = 0.00291664
I0428 22:24:45.144284  2164 solver.cpp:237] Iteration 41800, loss = 0.00568966
I0428 22:24:45.144371  2164 solver.cpp:253]     Train net output #0: loss = 0.00568972 (* 1 = 0.00568972 loss)
I0428 22:24:45.144392  2164 sgd_solver.cpp:106] Iteration 41800, lr = 0.00291241
I0428 22:24:45.388746  2164 solver.cpp:237] Iteration 41900, loss = 0.00473512
I0428 22:24:45.388823  2164 solver.cpp:253]     Train net output #0: loss = 0.00473516 (* 1 = 0.00473516 loss)
I0428 22:24:45.388841  2164 sgd_solver.cpp:106] Iteration 41900, lr = 0.0029082
I0428 22:24:45.606991  2164 solver.cpp:237] Iteration 42000, loss = 0.00316522
I0428 22:24:45.607079  2164 solver.cpp:253]     Train net output #0: loss = 0.00316527 (* 1 = 0.00316527 loss)
I0428 22:24:45.607100  2164 sgd_solver.cpp:106] Iteration 42000, lr = 0.00290401
I0428 22:24:45.834584  2164 solver.cpp:237] Iteration 42100, loss = 0.00375406
I0428 22:24:45.834671  2164 solver.cpp:253]     Train net output #0: loss = 0.0037541 (* 1 = 0.0037541 loss)
I0428 22:24:45.834694  2164 sgd_solver.cpp:106] Iteration 42100, lr = 0.00289982
I0428 22:24:46.065146  2164 solver.cpp:237] Iteration 42200, loss = 0.00110596
I0428 22:24:46.065234  2164 solver.cpp:253]     Train net output #0: loss = 0.001106 (* 1 = 0.001106 loss)
I0428 22:24:46.065258  2164 sgd_solver.cpp:106] Iteration 42200, lr = 0.00289566
I0428 22:24:46.285148  2164 solver.cpp:237] Iteration 42300, loss = 0.00533496
I0428 22:24:46.285236  2164 solver.cpp:253]     Train net output #0: loss = 0.00533501 (* 1 = 0.00533501 loss)
I0428 22:24:46.285259  2164 sgd_solver.cpp:106] Iteration 42300, lr = 0.0028915
I0428 22:24:46.522646  2164 solver.cpp:237] Iteration 42400, loss = 0.000844274
I0428 22:24:46.522719  2164 solver.cpp:253]     Train net output #0: loss = 0.000844318 (* 1 = 0.000844318 loss)
I0428 22:24:46.522737  2164 sgd_solver.cpp:106] Iteration 42400, lr = 0.00288736
I0428 22:24:46.742964  2164 solver.cpp:237] Iteration 42500, loss = 0.00732078
I0428 22:24:46.743039  2164 solver.cpp:253]     Train net output #0: loss = 0.00732083 (* 1 = 0.00732083 loss)
I0428 22:24:46.743059  2164 sgd_solver.cpp:106] Iteration 42500, lr = 0.00288324
I0428 22:24:46.966917  2164 solver.cpp:237] Iteration 42600, loss = 0.0133187
I0428 22:24:46.967018  2164 solver.cpp:253]     Train net output #0: loss = 0.0133187 (* 1 = 0.0133187 loss)
I0428 22:24:46.967037  2164 sgd_solver.cpp:106] Iteration 42600, lr = 0.00287913
I0428 22:24:47.202553  2164 solver.cpp:237] Iteration 42700, loss = 0.00286244
I0428 22:24:47.202638  2164 solver.cpp:253]     Train net output #0: loss = 0.00286249 (* 1 = 0.00286249 loss)
I0428 22:24:47.202662  2164 sgd_solver.cpp:106] Iteration 42700, lr = 0.00287503
I0428 22:24:47.435478  2164 solver.cpp:237] Iteration 42800, loss = 0.0013067
I0428 22:24:47.435555  2164 solver.cpp:253]     Train net output #0: loss = 0.00130674 (* 1 = 0.00130674 loss)
I0428 22:24:47.435575  2164 sgd_solver.cpp:106] Iteration 42800, lr = 0.00287094
I0428 22:24:47.654932  2164 solver.cpp:237] Iteration 42900, loss = 0.00483876
I0428 22:24:47.655007  2164 solver.cpp:253]     Train net output #0: loss = 0.00483881 (* 1 = 0.00483881 loss)
I0428 22:24:47.655025  2164 sgd_solver.cpp:106] Iteration 42900, lr = 0.00286687
I0428 22:24:47.886999  2164 solver.cpp:237] Iteration 43000, loss = 0.00156594
I0428 22:24:47.887078  2164 solver.cpp:253]     Train net output #0: loss = 0.00156599 (* 1 = 0.00156599 loss)
I0428 22:24:47.887099  2164 sgd_solver.cpp:106] Iteration 43000, lr = 0.00286281
I0428 22:24:48.128329  2164 solver.cpp:237] Iteration 43100, loss = 0.000330882
I0428 22:24:48.128417  2164 solver.cpp:253]     Train net output #0: loss = 0.000330934 (* 1 = 0.000330934 loss)
I0428 22:24:48.128443  2164 sgd_solver.cpp:106] Iteration 43100, lr = 0.00285877
I0428 22:24:48.358960  2164 solver.cpp:237] Iteration 43200, loss = 0.00118657
I0428 22:24:48.359037  2164 solver.cpp:253]     Train net output #0: loss = 0.00118662 (* 1 = 0.00118662 loss)
I0428 22:24:48.359056  2164 sgd_solver.cpp:106] Iteration 43200, lr = 0.00285474
I0428 22:24:48.584949  2164 solver.cpp:237] Iteration 43300, loss = 0.0073412
I0428 22:24:48.585036  2164 solver.cpp:253]     Train net output #0: loss = 0.00734126 (* 1 = 0.00734126 loss)
I0428 22:24:48.585057  2164 sgd_solver.cpp:106] Iteration 43300, lr = 0.00285072
I0428 22:24:48.814996  2164 solver.cpp:237] Iteration 43400, loss = 0.00239383
I0428 22:24:48.815074  2164 solver.cpp:253]     Train net output #0: loss = 0.00239389 (* 1 = 0.00239389 loss)
I0428 22:24:48.815096  2164 sgd_solver.cpp:106] Iteration 43400, lr = 0.00284672
I0428 22:24:49.037703  2164 solver.cpp:237] Iteration 43500, loss = 0.00236879
I0428 22:24:49.037789  2164 solver.cpp:253]     Train net output #0: loss = 0.00236884 (* 1 = 0.00236884 loss)
I0428 22:24:49.037827  2164 sgd_solver.cpp:106] Iteration 43500, lr = 0.00284272
I0428 22:24:49.274588  2164 solver.cpp:237] Iteration 43600, loss = 0.000735704
I0428 22:24:49.274669  2164 solver.cpp:253]     Train net output #0: loss = 0.000735759 (* 1 = 0.000735759 loss)
I0428 22:24:49.274689  2164 sgd_solver.cpp:106] Iteration 43600, lr = 0.00283875
I0428 22:24:49.498353  2164 solver.cpp:237] Iteration 43700, loss = 0.00256771
I0428 22:24:49.498441  2164 solver.cpp:253]     Train net output #0: loss = 0.00256777 (* 1 = 0.00256777 loss)
I0428 22:24:49.498468  2164 sgd_solver.cpp:106] Iteration 43700, lr = 0.00283478
I0428 22:24:49.721163  2164 solver.cpp:237] Iteration 43800, loss = 0.00351814
I0428 22:24:49.721251  2164 solver.cpp:253]     Train net output #0: loss = 0.0035182 (* 1 = 0.0035182 loss)
I0428 22:24:49.721273  2164 sgd_solver.cpp:106] Iteration 43800, lr = 0.00283083
I0428 22:24:49.956408  2164 solver.cpp:237] Iteration 43900, loss = 0.0030765
I0428 22:24:49.956495  2164 solver.cpp:253]     Train net output #0: loss = 0.00307655 (* 1 = 0.00307655 loss)
I0428 22:24:49.956517  2164 sgd_solver.cpp:106] Iteration 43900, lr = 0.00282689
I0428 22:24:50.186946  2164 solver.cpp:237] Iteration 44000, loss = 0.00277522
I0428 22:24:50.187023  2164 solver.cpp:253]     Train net output #0: loss = 0.00277527 (* 1 = 0.00277527 loss)
I0428 22:24:50.187041  2164 sgd_solver.cpp:106] Iteration 44000, lr = 0.00282296
I0428 22:24:50.410934  2164 solver.cpp:237] Iteration 44100, loss = 0.00579475
I0428 22:24:50.411031  2164 solver.cpp:253]     Train net output #0: loss = 0.00579481 (* 1 = 0.00579481 loss)
I0428 22:24:50.411049  2164 sgd_solver.cpp:106] Iteration 44100, lr = 0.00281905
I0428 22:24:50.634593  2164 solver.cpp:237] Iteration 44200, loss = 0.00458349
I0428 22:24:50.634670  2164 solver.cpp:253]     Train net output #0: loss = 0.00458354 (* 1 = 0.00458354 loss)
I0428 22:24:50.634693  2164 sgd_solver.cpp:106] Iteration 44200, lr = 0.00281514
I0428 22:24:50.844398  2164 solver.cpp:237] Iteration 44300, loss = 0.00130518
I0428 22:24:50.844483  2164 solver.cpp:253]     Train net output #0: loss = 0.00130523 (* 1 = 0.00130523 loss)
I0428 22:24:50.844508  2164 sgd_solver.cpp:106] Iteration 44300, lr = 0.00281125
I0428 22:24:51.075007  2164 solver.cpp:237] Iteration 44400, loss = 0.00206757
I0428 22:24:51.075088  2164 solver.cpp:253]     Train net output #0: loss = 0.00206763 (* 1 = 0.00206763 loss)
I0428 22:24:51.075110  2164 sgd_solver.cpp:106] Iteration 44400, lr = 0.00280738
I0428 22:24:51.313309  2164 solver.cpp:237] Iteration 44500, loss = 0.00121064
I0428 22:24:51.313388  2164 solver.cpp:253]     Train net output #0: loss = 0.0012107 (* 1 = 0.0012107 loss)
I0428 22:24:51.313412  2164 sgd_solver.cpp:106] Iteration 44500, lr = 0.00280351
I0428 22:24:51.546972  2164 solver.cpp:237] Iteration 44600, loss = 0.00449325
I0428 22:24:51.547046  2164 solver.cpp:253]     Train net output #0: loss = 0.00449331 (* 1 = 0.00449331 loss)
I0428 22:24:51.547066  2164 sgd_solver.cpp:106] Iteration 44600, lr = 0.00279966
I0428 22:24:51.781347  2164 solver.cpp:237] Iteration 44700, loss = 0.00241483
I0428 22:24:51.781424  2164 solver.cpp:253]     Train net output #0: loss = 0.00241489 (* 1 = 0.00241489 loss)
I0428 22:24:51.781447  2164 sgd_solver.cpp:106] Iteration 44700, lr = 0.00279582
I0428 22:24:52.008363  2164 solver.cpp:237] Iteration 44800, loss = 0.00826901
I0428 22:24:52.008450  2164 solver.cpp:253]     Train net output #0: loss = 0.00826907 (* 1 = 0.00826907 loss)
I0428 22:24:52.008472  2164 sgd_solver.cpp:106] Iteration 44800, lr = 0.00279199
I0428 22:24:52.242949  2164 solver.cpp:237] Iteration 44900, loss = 0.00246922
I0428 22:24:52.243023  2164 solver.cpp:253]     Train net output #0: loss = 0.00246928 (* 1 = 0.00246928 loss)
I0428 22:24:52.243041  2164 sgd_solver.cpp:106] Iteration 44900, lr = 0.00278818
I0428 22:24:52.471252  2164 solver.cpp:341] Iteration 45000, Testing net (#0)
I0428 22:24:52.593776  2164 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0428 22:24:52.593860  2164 solver.cpp:409]     Test net output #1: loss = 0.0265133 (* 1 = 0.0265133 loss)
I0428 22:24:52.594789  2164 solver.cpp:237] Iteration 45000, loss = 0.00225563
I0428 22:24:52.594832  2164 solver.cpp:253]     Train net output #0: loss = 0.00225569 (* 1 = 0.00225569 loss)
I0428 22:24:52.594853  2164 sgd_solver.cpp:106] Iteration 45000, lr = 0.00278438
I0428 22:24:52.814906  2164 solver.cpp:237] Iteration 45100, loss = 0.0027539
I0428 22:24:52.814985  2164 solver.cpp:253]     Train net output #0: loss = 0.00275396 (* 1 = 0.00275396 loss)
I0428 22:24:52.815006  2164 sgd_solver.cpp:106] Iteration 45100, lr = 0.00278059
I0428 22:24:53.038846  2164 solver.cpp:237] Iteration 45200, loss = 0.00608624
I0428 22:24:53.038920  2164 solver.cpp:253]     Train net output #0: loss = 0.0060863 (* 1 = 0.0060863 loss)
I0428 22:24:53.038939  2164 sgd_solver.cpp:106] Iteration 45200, lr = 0.00277681
I0428 22:24:53.269170  2164 solver.cpp:237] Iteration 45300, loss = 0.00215113
I0428 22:24:53.269259  2164 solver.cpp:253]     Train net output #0: loss = 0.0021512 (* 1 = 0.0021512 loss)
I0428 22:24:53.269286  2164 sgd_solver.cpp:106] Iteration 45300, lr = 0.00277304
I0428 22:24:53.506978  2164 solver.cpp:237] Iteration 45400, loss = 0.00180695
I0428 22:24:53.507051  2164 solver.cpp:253]     Train net output #0: loss = 0.00180701 (* 1 = 0.00180701 loss)
I0428 22:24:53.507074  2164 sgd_solver.cpp:106] Iteration 45400, lr = 0.00276929
I0428 22:24:53.716619  2164 solver.cpp:237] Iteration 45500, loss = 0.0024459
I0428 22:24:53.716696  2164 solver.cpp:253]     Train net output #0: loss = 0.00244596 (* 1 = 0.00244596 loss)
I0428 22:24:53.716739  2164 sgd_solver.cpp:106] Iteration 45500, lr = 0.00276554
I0428 22:24:53.952121  2164 solver.cpp:237] Iteration 45600, loss = 0.00368173
I0428 22:24:53.952209  2164 solver.cpp:253]     Train net output #0: loss = 0.00368179 (* 1 = 0.00368179 loss)
I0428 22:24:53.952235  2164 sgd_solver.cpp:106] Iteration 45600, lr = 0.00276181
I0428 22:24:54.186934  2164 solver.cpp:237] Iteration 45700, loss = 0.00412285
I0428 22:24:54.187013  2164 solver.cpp:253]     Train net output #0: loss = 0.00412292 (* 1 = 0.00412292 loss)
I0428 22:24:54.187037  2164 sgd_solver.cpp:106] Iteration 45700, lr = 0.00275809
I0428 22:24:54.400586  2164 solver.cpp:237] Iteration 45800, loss = 0.0094075
I0428 22:24:54.400665  2164 solver.cpp:253]     Train net output #0: loss = 0.00940756 (* 1 = 0.00940756 loss)
I0428 22:24:54.400686  2164 sgd_solver.cpp:106] Iteration 45800, lr = 0.00275438
I0428 22:24:54.625169  2164 solver.cpp:237] Iteration 45900, loss = 0.00296703
I0428 22:24:54.625258  2164 solver.cpp:253]     Train net output #0: loss = 0.00296709 (* 1 = 0.00296709 loss)
I0428 22:24:54.625286  2164 sgd_solver.cpp:106] Iteration 45900, lr = 0.00275069
I0428 22:24:54.848578  2164 solver.cpp:237] Iteration 46000, loss = 0.00366148
I0428 22:24:54.848654  2164 solver.cpp:253]     Train net output #0: loss = 0.00366154 (* 1 = 0.00366154 loss)
I0428 22:24:54.848673  2164 sgd_solver.cpp:106] Iteration 46000, lr = 0.002747
I0428 22:24:55.069732  2164 solver.cpp:237] Iteration 46100, loss = 0.000620274
I0428 22:24:55.069828  2164 solver.cpp:253]     Train net output #0: loss = 0.000620335 (* 1 = 0.000620335 loss)
I0428 22:24:55.069854  2164 sgd_solver.cpp:106] Iteration 46100, lr = 0.00274333
I0428 22:24:55.298974  2164 solver.cpp:237] Iteration 46200, loss = 0.00120883
I0428 22:24:55.299051  2164 solver.cpp:253]     Train net output #0: loss = 0.00120889 (* 1 = 0.00120889 loss)
I0428 22:24:55.299073  2164 sgd_solver.cpp:106] Iteration 46200, lr = 0.00273967
I0428 22:24:55.531447  2164 solver.cpp:237] Iteration 46300, loss = 0.00109591
I0428 22:24:55.531524  2164 solver.cpp:253]     Train net output #0: loss = 0.00109597 (* 1 = 0.00109597 loss)
I0428 22:24:55.531544  2164 sgd_solver.cpp:106] Iteration 46300, lr = 0.00273602
I0428 22:24:55.753162  2164 solver.cpp:237] Iteration 46400, loss = 0.000237309
I0428 22:24:55.753249  2164 solver.cpp:253]     Train net output #0: loss = 0.000237367 (* 1 = 0.000237367 loss)
I0428 22:24:55.753289  2164 sgd_solver.cpp:106] Iteration 46400, lr = 0.00273238
I0428 22:24:55.987545  2164 solver.cpp:237] Iteration 46500, loss = 0.00776495
I0428 22:24:55.987624  2164 solver.cpp:253]     Train net output #0: loss = 0.00776501 (* 1 = 0.00776501 loss)
I0428 22:24:55.987646  2164 sgd_solver.cpp:106] Iteration 46500, lr = 0.00272875
I0428 22:24:56.219089  2164 solver.cpp:237] Iteration 46600, loss = 0.0041481
I0428 22:24:56.219166  2164 solver.cpp:253]     Train net output #0: loss = 0.00414816 (* 1 = 0.00414816 loss)
I0428 22:24:56.219184  2164 sgd_solver.cpp:106] Iteration 46600, lr = 0.00272513
I0428 22:24:56.448828  2164 solver.cpp:237] Iteration 46700, loss = 0.00255145
I0428 22:24:56.448911  2164 solver.cpp:253]     Train net output #0: loss = 0.0025515 (* 1 = 0.0025515 loss)
I0428 22:24:56.448935  2164 sgd_solver.cpp:106] Iteration 46700, lr = 0.00272153
I0428 22:24:56.672832  2164 solver.cpp:237] Iteration 46800, loss = 0.00532196
I0428 22:24:56.672917  2164 solver.cpp:253]     Train net output #0: loss = 0.00532202 (* 1 = 0.00532202 loss)
I0428 22:24:56.672940  2164 sgd_solver.cpp:106] Iteration 46800, lr = 0.00271793
I0428 22:24:56.909189  2164 solver.cpp:237] Iteration 46900, loss = 0.00588468
I0428 22:24:56.909276  2164 solver.cpp:253]     Train net output #0: loss = 0.00588474 (* 1 = 0.00588474 loss)
I0428 22:24:56.909301  2164 sgd_solver.cpp:106] Iteration 46900, lr = 0.00271435
I0428 22:24:57.147522  2164 solver.cpp:237] Iteration 47000, loss = 0.00279832
I0428 22:24:57.147708  2164 solver.cpp:253]     Train net output #0: loss = 0.00279838 (* 1 = 0.00279838 loss)
I0428 22:24:57.147729  2164 sgd_solver.cpp:106] Iteration 47000, lr = 0.00271078
I0428 22:24:57.369722  2164 solver.cpp:237] Iteration 47100, loss = 0.00214023
I0428 22:24:57.369810  2164 solver.cpp:253]     Train net output #0: loss = 0.0021403 (* 1 = 0.0021403 loss)
I0428 22:24:57.369835  2164 sgd_solver.cpp:106] Iteration 47100, lr = 0.00270722
I0428 22:24:57.588594  2164 solver.cpp:237] Iteration 47200, loss = 0.00128456
I0428 22:24:57.588680  2164 solver.cpp:253]     Train net output #0: loss = 0.00128462 (* 1 = 0.00128462 loss)
I0428 22:24:57.588704  2164 sgd_solver.cpp:106] Iteration 47200, lr = 0.00270367
I0428 22:24:57.822767  2164 solver.cpp:237] Iteration 47300, loss = 0.0066493
I0428 22:24:57.822844  2164 solver.cpp:253]     Train net output #0: loss = 0.00664936 (* 1 = 0.00664936 loss)
I0428 22:24:57.822862  2164 sgd_solver.cpp:106] Iteration 47300, lr = 0.00270013
I0428 22:24:58.055039  2164 solver.cpp:237] Iteration 47400, loss = 0.00234684
I0428 22:24:58.055116  2164 solver.cpp:253]     Train net output #0: loss = 0.00234691 (* 1 = 0.00234691 loss)
I0428 22:24:58.055135  2164 sgd_solver.cpp:106] Iteration 47400, lr = 0.0026966
I0428 22:24:58.296936  2164 solver.cpp:237] Iteration 47500, loss = 0.0014911
I0428 22:24:58.297009  2164 solver.cpp:253]     Train net output #0: loss = 0.00149117 (* 1 = 0.00149117 loss)
I0428 22:24:58.297029  2164 sgd_solver.cpp:106] Iteration 47500, lr = 0.00269308
I0428 22:24:58.527053  2164 solver.cpp:237] Iteration 47600, loss = 0.00972051
I0428 22:24:58.527132  2164 solver.cpp:253]     Train net output #0: loss = 0.00972058 (* 1 = 0.00972058 loss)
I0428 22:24:58.527150  2164 sgd_solver.cpp:106] Iteration 47600, lr = 0.00268957
I0428 22:24:58.752961  2164 solver.cpp:237] Iteration 47700, loss = 0.00716698
I0428 22:24:58.753037  2164 solver.cpp:253]     Train net output #0: loss = 0.00716705 (* 1 = 0.00716705 loss)
I0428 22:24:58.753056  2164 sgd_solver.cpp:106] Iteration 47700, lr = 0.00268607
I0428 22:24:58.988975  2164 solver.cpp:237] Iteration 47800, loss = 0.000150589
I0428 22:24:58.989049  2164 solver.cpp:253]     Train net output #0: loss = 0.000150657 (* 1 = 0.000150657 loss)
I0428 22:24:58.989068  2164 sgd_solver.cpp:106] Iteration 47800, lr = 0.00268259
I0428 22:24:59.226830  2164 solver.cpp:237] Iteration 47900, loss = 0.00372747
I0428 22:24:59.226918  2164 solver.cpp:253]     Train net output #0: loss = 0.00372754 (* 1 = 0.00372754 loss)
I0428 22:24:59.226943  2164 sgd_solver.cpp:106] Iteration 47900, lr = 0.00267911
I0428 22:24:59.469049  2164 solver.cpp:237] Iteration 48000, loss = 0.00377304
I0428 22:24:59.469131  2164 solver.cpp:253]     Train net output #0: loss = 0.00377311 (* 1 = 0.00377311 loss)
I0428 22:24:59.469151  2164 sgd_solver.cpp:106] Iteration 48000, lr = 0.00267565
I0428 22:24:59.699095  2164 solver.cpp:237] Iteration 48100, loss = 0.00275867
I0428 22:24:59.699172  2164 solver.cpp:253]     Train net output #0: loss = 0.00275874 (* 1 = 0.00275874 loss)
I0428 22:24:59.699194  2164 sgd_solver.cpp:106] Iteration 48100, lr = 0.00267219
I0428 22:24:59.915719  2164 solver.cpp:237] Iteration 48200, loss = 0.00255895
I0428 22:24:59.915797  2164 solver.cpp:253]     Train net output #0: loss = 0.00255902 (* 1 = 0.00255902 loss)
I0428 22:24:59.915818  2164 sgd_solver.cpp:106] Iteration 48200, lr = 0.00266875
I0428 22:25:00.133007  2164 solver.cpp:237] Iteration 48300, loss = 0.00164729
I0428 22:25:00.133085  2164 solver.cpp:253]     Train net output #0: loss = 0.00164735 (* 1 = 0.00164735 loss)
I0428 22:25:00.133103  2164 sgd_solver.cpp:106] Iteration 48300, lr = 0.00266532
I0428 22:25:00.371616  2164 solver.cpp:237] Iteration 48400, loss = 0.00156824
I0428 22:25:00.371695  2164 solver.cpp:253]     Train net output #0: loss = 0.00156831 (* 1 = 0.00156831 loss)
I0428 22:25:00.371713  2164 sgd_solver.cpp:106] Iteration 48400, lr = 0.00266189
I0428 22:25:00.613210  2164 solver.cpp:237] Iteration 48500, loss = 0.00178635
I0428 22:25:00.613299  2164 solver.cpp:253]     Train net output #0: loss = 0.00178642 (* 1 = 0.00178642 loss)
I0428 22:25:00.613350  2164 sgd_solver.cpp:106] Iteration 48500, lr = 0.00265848
I0428 22:25:00.843107  2164 solver.cpp:237] Iteration 48600, loss = 0.00881739
I0428 22:25:00.843183  2164 solver.cpp:253]     Train net output #0: loss = 0.00881746 (* 1 = 0.00881746 loss)
I0428 22:25:00.843202  2164 sgd_solver.cpp:106] Iteration 48600, lr = 0.00265507
I0428 22:25:01.073200  2164 solver.cpp:237] Iteration 48700, loss = 0.00490084
I0428 22:25:01.073289  2164 solver.cpp:253]     Train net output #0: loss = 0.00490091 (* 1 = 0.00490091 loss)
I0428 22:25:01.073313  2164 sgd_solver.cpp:106] Iteration 48700, lr = 0.00265168
I0428 22:25:01.296969  2164 solver.cpp:237] Iteration 48800, loss = 0.00219766
I0428 22:25:01.297046  2164 solver.cpp:253]     Train net output #0: loss = 0.00219773 (* 1 = 0.00219773 loss)
I0428 22:25:01.297065  2164 sgd_solver.cpp:106] Iteration 48800, lr = 0.0026483
I0428 22:25:01.528664  2164 solver.cpp:237] Iteration 48900, loss = 0.00387011
I0428 22:25:01.528751  2164 solver.cpp:253]     Train net output #0: loss = 0.00387018 (* 1 = 0.00387018 loss)
I0428 22:25:01.528775  2164 sgd_solver.cpp:106] Iteration 48900, lr = 0.00264493
I0428 22:25:01.770891  2164 solver.cpp:237] Iteration 49000, loss = 0.00394765
I0428 22:25:01.770979  2164 solver.cpp:253]     Train net output #0: loss = 0.00394772 (* 1 = 0.00394772 loss)
I0428 22:25:01.771003  2164 sgd_solver.cpp:106] Iteration 49000, lr = 0.00264156
I0428 22:25:02.005229  2164 solver.cpp:237] Iteration 49100, loss = 0.00341577
I0428 22:25:02.005318  2164 solver.cpp:253]     Train net output #0: loss = 0.00341584 (* 1 = 0.00341584 loss)
I0428 22:25:02.005345  2164 sgd_solver.cpp:106] Iteration 49100, lr = 0.00263821
I0428 22:25:02.234819  2164 solver.cpp:237] Iteration 49200, loss = 0.00193199
I0428 22:25:02.234906  2164 solver.cpp:253]     Train net output #0: loss = 0.00193206 (* 1 = 0.00193206 loss)
I0428 22:25:02.234930  2164 sgd_solver.cpp:106] Iteration 49200, lr = 0.00263487
I0428 22:25:02.468957  2164 solver.cpp:237] Iteration 49300, loss = 0.00552897
I0428 22:25:02.469033  2164 solver.cpp:253]     Train net output #0: loss = 0.00552904 (* 1 = 0.00552904 loss)
I0428 22:25:02.469053  2164 sgd_solver.cpp:106] Iteration 49300, lr = 0.00263153
I0428 22:25:02.713207  2164 solver.cpp:237] Iteration 49400, loss = 0.00465503
I0428 22:25:02.713292  2164 solver.cpp:253]     Train net output #0: loss = 0.00465509 (* 1 = 0.00465509 loss)
I0428 22:25:02.713318  2164 sgd_solver.cpp:106] Iteration 49400, lr = 0.00262821
I0428 22:25:02.944953  2164 solver.cpp:237] Iteration 49500, loss = 0.00313634
I0428 22:25:02.945029  2164 solver.cpp:253]     Train net output #0: loss = 0.00313641 (* 1 = 0.00313641 loss)
I0428 22:25:02.945047  2164 sgd_solver.cpp:106] Iteration 49500, lr = 0.0026249
I0428 22:25:03.178838  2164 solver.cpp:237] Iteration 49600, loss = 0.00382598
I0428 22:25:03.178926  2164 solver.cpp:253]     Train net output #0: loss = 0.00382604 (* 1 = 0.00382604 loss)
I0428 22:25:03.178949  2164 sgd_solver.cpp:106] Iteration 49600, lr = 0.00262159
I0428 22:25:03.420900  2164 solver.cpp:237] Iteration 49700, loss = 0.00110217
I0428 22:25:03.420979  2164 solver.cpp:253]     Train net output #0: loss = 0.00110224 (* 1 = 0.00110224 loss)
I0428 22:25:03.420999  2164 sgd_solver.cpp:106] Iteration 49700, lr = 0.0026183
I0428 22:25:03.667071  2164 solver.cpp:237] Iteration 49800, loss = 0.00522166
I0428 22:25:03.667145  2164 solver.cpp:253]     Train net output #0: loss = 0.00522172 (* 1 = 0.00522172 loss)
I0428 22:25:03.667163  2164 sgd_solver.cpp:106] Iteration 49800, lr = 0.00261501
I0428 22:25:03.893021  2164 solver.cpp:237] Iteration 49900, loss = 0.000821124
I0428 22:25:03.893100  2164 solver.cpp:253]     Train net output #0: loss = 0.000821184 (* 1 = 0.000821184 loss)
I0428 22:25:03.893121  2164 sgd_solver.cpp:106] Iteration 49900, lr = 0.00261174
I0428 22:25:04.129413  2164 solver.cpp:459] Snapshotting to binary proto file _iter_50000.caffemodel
I0428 22:25:04.138023  2164 sgd_solver.cpp:269] Snapshotting solver state to binary proto file _iter_50000.solverstate
I0428 22:25:04.142226  2164 solver.cpp:321] Iteration 50000, loss = 0.00744524
I0428 22:25:04.142282  2164 solver.cpp:341] Iteration 50000, Testing net (#0)
I0428 22:25:04.282764  2164 solver.cpp:409]     Test net output #0: accuracy = 0.9912
I0428 22:25:04.282842  2164 solver.cpp:409]     Test net output #1: loss = 0.0260643 (* 1 = 0.0260643 loss)
I0428 22:25:04.282861  2164 solver.cpp:326] Optimization Done.
I0428 22:25:04.282874  2164 caffe.cpp:215] Optimization Done.
