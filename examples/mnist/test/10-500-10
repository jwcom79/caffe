I0429 12:03:21.976327  3523 caffe.cpp:184] Using GPUs 0
I0429 12:03:22.277637  3523 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 5000
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
solver_mode: GPU
device_id: 0
net: "examples/mnist/test/lenet_train_test.prototxt"
I0429 12:03:22.277685  3523 solver.cpp:91] Creating training net from net file: examples/mnist/test/lenet_train_test.prototxt
I0429 12:03:22.278072  3523 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0429 12:03:22.278092  3523 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0429 12:03:22.278173  3523 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0429 12:03:22.278256  3523 layer_factory.hpp:77] Creating layer mnist
I0429 12:03:22.278776  3523 net.cpp:106] Creating Layer mnist
I0429 12:03:22.278798  3523 net.cpp:411] mnist -> data
I0429 12:03:22.278828  3523 net.cpp:411] mnist -> label
I0429 12:03:22.280385  3528 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_train_lmdb
I0429 12:03:22.286779  3523 data_layer.cpp:41] output data size: 64,1,28,28
I0429 12:03:22.287739  3523 net.cpp:150] Setting up mnist
I0429 12:03:22.287763  3523 net.cpp:157] Top shape: 64 1 28 28 (50176)
I0429 12:03:22.287768  3523 net.cpp:157] Top shape: 64 (64)
I0429 12:03:22.287771  3523 net.cpp:165] Memory required for data: 200960
I0429 12:03:22.287781  3523 layer_factory.hpp:77] Creating layer conv1
I0429 12:03:22.287799  3523 net.cpp:106] Creating Layer conv1
I0429 12:03:22.287806  3523 net.cpp:454] conv1 <- data
I0429 12:03:22.287818  3523 net.cpp:411] conv1 -> conv1
I0429 12:03:22.405658  3523 net.cpp:150] Setting up conv1
I0429 12:03:22.405686  3523 net.cpp:157] Top shape: 64 20 24 24 (737280)
I0429 12:03:22.405691  3523 net.cpp:165] Memory required for data: 3150080
I0429 12:03:22.405732  3523 layer_factory.hpp:77] Creating layer pool1
I0429 12:03:22.405747  3523 net.cpp:106] Creating Layer pool1
I0429 12:03:22.405752  3523 net.cpp:454] pool1 <- conv1
I0429 12:03:22.405758  3523 net.cpp:411] pool1 -> pool1
I0429 12:03:22.407060  3523 net.cpp:150] Setting up pool1
I0429 12:03:22.407099  3523 net.cpp:157] Top shape: 64 20 12 12 (184320)
I0429 12:03:22.407114  3523 net.cpp:165] Memory required for data: 3887360
I0429 12:03:22.407124  3523 layer_factory.hpp:77] Creating layer conv2
I0429 12:03:22.407147  3523 net.cpp:106] Creating Layer conv2
I0429 12:03:22.407157  3523 net.cpp:454] conv2 <- pool1
I0429 12:03:22.407172  3523 net.cpp:411] conv2 -> conv2
I0429 12:03:22.412677  3523 net.cpp:150] Setting up conv2
I0429 12:03:22.412714  3523 net.cpp:157] Top shape: 64 50 8 8 (204800)
I0429 12:03:22.412724  3523 net.cpp:165] Memory required for data: 4706560
I0429 12:03:22.412750  3523 layer_factory.hpp:77] Creating layer pool2
I0429 12:03:22.412770  3523 net.cpp:106] Creating Layer pool2
I0429 12:03:22.412782  3523 net.cpp:454] pool2 <- conv2
I0429 12:03:22.412796  3523 net.cpp:411] pool2 -> pool2
I0429 12:03:22.414381  3523 net.cpp:150] Setting up pool2
I0429 12:03:22.414413  3523 net.cpp:157] Top shape: 64 50 4 4 (51200)
I0429 12:03:22.414423  3523 net.cpp:165] Memory required for data: 4911360
I0429 12:03:22.414433  3523 layer_factory.hpp:77] Creating layer ip1
I0429 12:03:22.414448  3523 net.cpp:106] Creating Layer ip1
I0429 12:03:22.414458  3523 net.cpp:454] ip1 <- pool2
I0429 12:03:22.414474  3523 net.cpp:411] ip1 -> ip1
I0429 12:03:22.415644  3523 net.cpp:150] Setting up ip1
I0429 12:03:22.415674  3523 net.cpp:157] Top shape: 64 10 (640)
I0429 12:03:22.415683  3523 net.cpp:165] Memory required for data: 4913920
I0429 12:03:22.415704  3523 layer_factory.hpp:77] Creating layer relu1
I0429 12:03:22.415721  3523 net.cpp:106] Creating Layer relu1
I0429 12:03:22.415751  3523 net.cpp:454] relu1 <- ip1
I0429 12:03:22.415772  3523 net.cpp:397] relu1 -> ip1 (in-place)
I0429 12:03:22.417240  3523 net.cpp:150] Setting up relu1
I0429 12:03:22.417273  3523 net.cpp:157] Top shape: 64 10 (640)
I0429 12:03:22.417281  3523 net.cpp:165] Memory required for data: 4916480
I0429 12:03:22.417290  3523 layer_factory.hpp:77] Creating layer ip2
I0429 12:03:22.417314  3523 net.cpp:106] Creating Layer ip2
I0429 12:03:22.417323  3523 net.cpp:454] ip2 <- ip1
I0429 12:03:22.417337  3523 net.cpp:411] ip2 -> ip2
I0429 12:03:22.417670  3523 net.cpp:150] Setting up ip2
I0429 12:03:22.417690  3523 net.cpp:157] Top shape: 64 500 (32000)
I0429 12:03:22.417697  3523 net.cpp:165] Memory required for data: 5044480
I0429 12:03:22.417711  3523 layer_factory.hpp:77] Creating layer relu2
I0429 12:03:22.417732  3523 net.cpp:106] Creating Layer relu2
I0429 12:03:22.417740  3523 net.cpp:454] relu2 <- ip2
I0429 12:03:22.417757  3523 net.cpp:397] relu2 -> ip2 (in-place)
I0429 12:03:22.419185  3523 net.cpp:150] Setting up relu2
I0429 12:03:22.419220  3523 net.cpp:157] Top shape: 64 500 (32000)
I0429 12:03:22.419230  3523 net.cpp:165] Memory required for data: 5172480
I0429 12:03:22.419239  3523 layer_factory.hpp:77] Creating layer ip3
I0429 12:03:22.419257  3523 net.cpp:106] Creating Layer ip3
I0429 12:03:22.419266  3523 net.cpp:454] ip3 <- ip2
I0429 12:03:22.419286  3523 net.cpp:411] ip3 -> ip3
I0429 12:03:22.419608  3523 net.cpp:150] Setting up ip3
I0429 12:03:22.419627  3523 net.cpp:157] Top shape: 64 10 (640)
I0429 12:03:22.419636  3523 net.cpp:165] Memory required for data: 5175040
I0429 12:03:22.419654  3523 layer_factory.hpp:77] Creating layer loss
I0429 12:03:22.419680  3523 net.cpp:106] Creating Layer loss
I0429 12:03:22.419692  3523 net.cpp:454] loss <- ip3
I0429 12:03:22.419706  3523 net.cpp:454] loss <- label
I0429 12:03:22.419723  3523 net.cpp:411] loss -> loss
I0429 12:03:22.419749  3523 layer_factory.hpp:77] Creating layer loss
I0429 12:03:22.421421  3523 net.cpp:150] Setting up loss
I0429 12:03:22.421448  3523 net.cpp:157] Top shape: (1)
I0429 12:03:22.421458  3523 net.cpp:160]     with loss weight 1
I0429 12:03:22.421514  3523 net.cpp:165] Memory required for data: 5175044
I0429 12:03:22.421526  3523 net.cpp:226] loss needs backward computation.
I0429 12:03:22.421541  3523 net.cpp:226] ip3 needs backward computation.
I0429 12:03:22.421556  3523 net.cpp:226] relu2 needs backward computation.
I0429 12:03:22.421571  3523 net.cpp:226] ip2 needs backward computation.
I0429 12:03:22.421586  3523 net.cpp:226] relu1 needs backward computation.
I0429 12:03:22.421596  3523 net.cpp:226] ip1 needs backward computation.
I0429 12:03:22.421604  3523 net.cpp:226] pool2 needs backward computation.
I0429 12:03:22.421613  3523 net.cpp:226] conv2 needs backward computation.
I0429 12:03:22.421622  3523 net.cpp:226] pool1 needs backward computation.
I0429 12:03:22.421632  3523 net.cpp:226] conv1 needs backward computation.
I0429 12:03:22.421640  3523 net.cpp:228] mnist does not need backward computation.
I0429 12:03:22.421653  3523 net.cpp:270] This network produces output loss
I0429 12:03:22.421675  3523 net.cpp:283] Network initialization done.
I0429 12:03:22.422473  3523 solver.cpp:181] Creating test net (#0) specified by net file: examples/mnist/test/lenet_train_test.prototxt
I0429 12:03:22.422536  3523 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0429 12:03:22.422751  3523 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0429 12:03:22.422919  3523 layer_factory.hpp:77] Creating layer mnist
I0429 12:03:22.423153  3523 net.cpp:106] Creating Layer mnist
I0429 12:03:22.423174  3523 net.cpp:411] mnist -> data
I0429 12:03:22.423195  3523 net.cpp:411] mnist -> label
I0429 12:03:22.423954  3530 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_test_lmdb
I0429 12:03:22.424209  3523 data_layer.cpp:41] output data size: 100,1,28,28
I0429 12:03:22.425904  3523 net.cpp:150] Setting up mnist
I0429 12:03:22.425935  3523 net.cpp:157] Top shape: 100 1 28 28 (78400)
I0429 12:03:22.425950  3523 net.cpp:157] Top shape: 100 (100)
I0429 12:03:22.425958  3523 net.cpp:165] Memory required for data: 314000
I0429 12:03:22.425971  3523 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0429 12:03:22.425986  3523 net.cpp:106] Creating Layer label_mnist_1_split
I0429 12:03:22.425993  3523 net.cpp:454] label_mnist_1_split <- label
I0429 12:03:22.426005  3523 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_0
I0429 12:03:22.426022  3523 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_1
I0429 12:03:22.426115  3523 net.cpp:150] Setting up label_mnist_1_split
I0429 12:03:22.426131  3523 net.cpp:157] Top shape: 100 (100)
I0429 12:03:22.426141  3523 net.cpp:157] Top shape: 100 (100)
I0429 12:03:22.426146  3523 net.cpp:165] Memory required for data: 314800
I0429 12:03:22.426158  3523 layer_factory.hpp:77] Creating layer conv1
I0429 12:03:22.426177  3523 net.cpp:106] Creating Layer conv1
I0429 12:03:22.426188  3523 net.cpp:454] conv1 <- data
I0429 12:03:22.426204  3523 net.cpp:411] conv1 -> conv1
I0429 12:03:22.431421  3523 net.cpp:150] Setting up conv1
I0429 12:03:22.431457  3523 net.cpp:157] Top shape: 100 20 24 24 (1152000)
I0429 12:03:22.431469  3523 net.cpp:165] Memory required for data: 4922800
I0429 12:03:22.431499  3523 layer_factory.hpp:77] Creating layer pool1
I0429 12:03:22.431521  3523 net.cpp:106] Creating Layer pool1
I0429 12:03:22.431531  3523 net.cpp:454] pool1 <- conv1
I0429 12:03:22.431553  3523 net.cpp:411] pool1 -> pool1
I0429 12:03:22.433099  3523 net.cpp:150] Setting up pool1
I0429 12:03:22.433130  3523 net.cpp:157] Top shape: 100 20 12 12 (288000)
I0429 12:03:22.433137  3523 net.cpp:165] Memory required for data: 6074800
I0429 12:03:22.433145  3523 layer_factory.hpp:77] Creating layer conv2
I0429 12:03:22.433167  3523 net.cpp:106] Creating Layer conv2
I0429 12:03:22.433178  3523 net.cpp:454] conv2 <- pool1
I0429 12:03:22.433194  3523 net.cpp:411] conv2 -> conv2
I0429 12:03:22.438012  3523 net.cpp:150] Setting up conv2
I0429 12:03:22.438042  3523 net.cpp:157] Top shape: 100 50 8 8 (320000)
I0429 12:03:22.438053  3523 net.cpp:165] Memory required for data: 7354800
I0429 12:03:22.438073  3523 layer_factory.hpp:77] Creating layer pool2
I0429 12:03:22.438087  3523 net.cpp:106] Creating Layer pool2
I0429 12:03:22.438096  3523 net.cpp:454] pool2 <- conv2
I0429 12:03:22.438107  3523 net.cpp:411] pool2 -> pool2
I0429 12:03:22.439496  3523 net.cpp:150] Setting up pool2
I0429 12:03:22.439525  3523 net.cpp:157] Top shape: 100 50 4 4 (80000)
I0429 12:03:22.439532  3523 net.cpp:165] Memory required for data: 7674800
I0429 12:03:22.439540  3523 layer_factory.hpp:77] Creating layer ip1
I0429 12:03:22.439555  3523 net.cpp:106] Creating Layer ip1
I0429 12:03:22.439563  3523 net.cpp:454] ip1 <- pool2
I0429 12:03:22.439579  3523 net.cpp:411] ip1 -> ip1
I0429 12:03:22.439908  3523 net.cpp:150] Setting up ip1
I0429 12:03:22.439924  3523 net.cpp:157] Top shape: 100 10 (1000)
I0429 12:03:22.439931  3523 net.cpp:165] Memory required for data: 7678800
I0429 12:03:22.439949  3523 layer_factory.hpp:77] Creating layer relu1
I0429 12:03:22.439963  3523 net.cpp:106] Creating Layer relu1
I0429 12:03:22.439971  3523 net.cpp:454] relu1 <- ip1
I0429 12:03:22.439981  3523 net.cpp:397] relu1 -> ip1 (in-place)
I0429 12:03:22.441301  3523 net.cpp:150] Setting up relu1
I0429 12:03:22.441332  3523 net.cpp:157] Top shape: 100 10 (1000)
I0429 12:03:22.441340  3523 net.cpp:165] Memory required for data: 7682800
I0429 12:03:22.441349  3523 layer_factory.hpp:77] Creating layer ip2
I0429 12:03:22.441365  3523 net.cpp:106] Creating Layer ip2
I0429 12:03:22.441372  3523 net.cpp:454] ip2 <- ip1
I0429 12:03:22.441391  3523 net.cpp:411] ip2 -> ip2
I0429 12:03:22.441690  3523 net.cpp:150] Setting up ip2
I0429 12:03:22.441707  3523 net.cpp:157] Top shape: 100 500 (50000)
I0429 12:03:22.441736  3523 net.cpp:165] Memory required for data: 7882800
I0429 12:03:22.441752  3523 layer_factory.hpp:77] Creating layer relu2
I0429 12:03:22.441764  3523 net.cpp:106] Creating Layer relu2
I0429 12:03:22.441771  3523 net.cpp:454] relu2 <- ip2
I0429 12:03:22.441782  3523 net.cpp:397] relu2 -> ip2 (in-place)
I0429 12:03:22.443100  3523 net.cpp:150] Setting up relu2
I0429 12:03:22.443128  3523 net.cpp:157] Top shape: 100 500 (50000)
I0429 12:03:22.443136  3523 net.cpp:165] Memory required for data: 8082800
I0429 12:03:22.443145  3523 layer_factory.hpp:77] Creating layer ip3
I0429 12:03:22.443161  3523 net.cpp:106] Creating Layer ip3
I0429 12:03:22.443168  3523 net.cpp:454] ip3 <- ip2
I0429 12:03:22.443181  3523 net.cpp:411] ip3 -> ip3
I0429 12:03:22.443476  3523 net.cpp:150] Setting up ip3
I0429 12:03:22.443493  3523 net.cpp:157] Top shape: 100 10 (1000)
I0429 12:03:22.443500  3523 net.cpp:165] Memory required for data: 8086800
I0429 12:03:22.443518  3523 layer_factory.hpp:77] Creating layer ip3_ip3_0_split
I0429 12:03:22.443534  3523 net.cpp:106] Creating Layer ip3_ip3_0_split
I0429 12:03:22.443542  3523 net.cpp:454] ip3_ip3_0_split <- ip3
I0429 12:03:22.443552  3523 net.cpp:411] ip3_ip3_0_split -> ip3_ip3_0_split_0
I0429 12:03:22.443564  3523 net.cpp:411] ip3_ip3_0_split -> ip3_ip3_0_split_1
I0429 12:03:22.443640  3523 net.cpp:150] Setting up ip3_ip3_0_split
I0429 12:03:22.443655  3523 net.cpp:157] Top shape: 100 10 (1000)
I0429 12:03:22.443663  3523 net.cpp:157] Top shape: 100 10 (1000)
I0429 12:03:22.443670  3523 net.cpp:165] Memory required for data: 8094800
I0429 12:03:22.443677  3523 layer_factory.hpp:77] Creating layer accuracy
I0429 12:03:22.443687  3523 net.cpp:106] Creating Layer accuracy
I0429 12:03:22.443694  3523 net.cpp:454] accuracy <- ip3_ip3_0_split_0
I0429 12:03:22.443703  3523 net.cpp:454] accuracy <- label_mnist_1_split_0
I0429 12:03:22.443717  3523 net.cpp:411] accuracy -> accuracy
I0429 12:03:22.443732  3523 net.cpp:150] Setting up accuracy
I0429 12:03:22.443742  3523 net.cpp:157] Top shape: (1)
I0429 12:03:22.443748  3523 net.cpp:165] Memory required for data: 8094804
I0429 12:03:22.443754  3523 layer_factory.hpp:77] Creating layer loss
I0429 12:03:22.443764  3523 net.cpp:106] Creating Layer loss
I0429 12:03:22.443771  3523 net.cpp:454] loss <- ip3_ip3_0_split_1
I0429 12:03:22.443780  3523 net.cpp:454] loss <- label_mnist_1_split_1
I0429 12:03:22.443792  3523 net.cpp:411] loss -> loss
I0429 12:03:22.443807  3523 layer_factory.hpp:77] Creating layer loss
I0429 12:03:22.445308  3523 net.cpp:150] Setting up loss
I0429 12:03:22.445335  3523 net.cpp:157] Top shape: (1)
I0429 12:03:22.445343  3523 net.cpp:160]     with loss weight 1
I0429 12:03:22.445355  3523 net.cpp:165] Memory required for data: 8094808
I0429 12:03:22.445363  3523 net.cpp:226] loss needs backward computation.
I0429 12:03:22.445371  3523 net.cpp:228] accuracy does not need backward computation.
I0429 12:03:22.445379  3523 net.cpp:226] ip3_ip3_0_split needs backward computation.
I0429 12:03:22.445385  3523 net.cpp:226] ip3 needs backward computation.
I0429 12:03:22.445392  3523 net.cpp:226] relu2 needs backward computation.
I0429 12:03:22.445399  3523 net.cpp:226] ip2 needs backward computation.
I0429 12:03:22.445405  3523 net.cpp:226] relu1 needs backward computation.
I0429 12:03:22.445422  3523 net.cpp:226] ip1 needs backward computation.
I0429 12:03:22.445430  3523 net.cpp:226] pool2 needs backward computation.
I0429 12:03:22.445436  3523 net.cpp:226] conv2 needs backward computation.
I0429 12:03:22.445441  3523 net.cpp:226] pool1 needs backward computation.
I0429 12:03:22.445447  3523 net.cpp:226] conv1 needs backward computation.
I0429 12:03:22.445454  3523 net.cpp:228] label_mnist_1_split does not need backward computation.
I0429 12:03:22.445462  3523 net.cpp:228] mnist does not need backward computation.
I0429 12:03:22.445467  3523 net.cpp:270] This network produces output accuracy
I0429 12:03:22.445475  3523 net.cpp:270] This network produces output loss
I0429 12:03:22.445498  3523 net.cpp:283] Network initialization done.
I0429 12:03:22.445616  3523 solver.cpp:60] Solver scaffolding done.
I0429 12:03:22.446288  3523 caffe.cpp:212] Starting Optimization
I0429 12:03:22.446303  3523 solver.cpp:288] Solving LeNet
I0429 12:03:22.446310  3523 solver.cpp:289] Learning Rate Policy: inv
I0429 12:03:22.446879  3523 solver.cpp:341] Iteration 0, Testing net (#0)
I0429 12:03:22.536671  3523 solver.cpp:409]     Test net output #0: accuracy = 0.0747
I0429 12:03:22.536715  3523 solver.cpp:409]     Test net output #1: loss = 2.32431 (* 1 = 2.32431 loss)
I0429 12:03:22.539336  3523 solver.cpp:237] Iteration 0, loss = 2.31393
I0429 12:03:22.539367  3523 solver.cpp:253]     Train net output #0: loss = 2.31393 (* 1 = 2.31393 loss)
I0429 12:03:22.539386  3523 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0429 12:03:22.721236  3523 solver.cpp:237] Iteration 100, loss = 0.238018
I0429 12:03:22.721262  3523 solver.cpp:253]     Train net output #0: loss = 0.238018 (* 1 = 0.238018 loss)
I0429 12:03:22.721268  3523 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0429 12:03:22.894271  3523 solver.cpp:237] Iteration 200, loss = 0.199359
I0429 12:03:22.894299  3523 solver.cpp:253]     Train net output #0: loss = 0.199359 (* 1 = 0.199359 loss)
I0429 12:03:22.894305  3523 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0429 12:03:23.061630  3523 solver.cpp:237] Iteration 300, loss = 0.178529
I0429 12:03:23.061656  3523 solver.cpp:253]     Train net output #0: loss = 0.178529 (* 1 = 0.178529 loss)
I0429 12:03:23.061662  3523 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0429 12:03:23.228425  3523 solver.cpp:237] Iteration 400, loss = 0.209214
I0429 12:03:23.228447  3523 solver.cpp:253]     Train net output #0: loss = 0.209214 (* 1 = 0.209214 loss)
I0429 12:03:23.228453  3523 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0429 12:03:23.394765  3523 solver.cpp:237] Iteration 500, loss = 0.0331461
I0429 12:03:23.394788  3523 solver.cpp:253]     Train net output #0: loss = 0.033146 (* 1 = 0.033146 loss)
I0429 12:03:23.394793  3523 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0429 12:03:23.561092  3523 solver.cpp:237] Iteration 600, loss = 0.0729821
I0429 12:03:23.561115  3523 solver.cpp:253]     Train net output #0: loss = 0.0729821 (* 1 = 0.0729821 loss)
I0429 12:03:23.561120  3523 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0429 12:03:23.727403  3523 solver.cpp:237] Iteration 700, loss = 0.138878
I0429 12:03:23.727427  3523 solver.cpp:253]     Train net output #0: loss = 0.138878 (* 1 = 0.138878 loss)
I0429 12:03:23.727432  3523 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0429 12:03:23.894134  3523 solver.cpp:237] Iteration 800, loss = 0.303558
I0429 12:03:23.894156  3523 solver.cpp:253]     Train net output #0: loss = 0.303558 (* 1 = 0.303558 loss)
I0429 12:03:23.894162  3523 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0429 12:03:24.060891  3523 solver.cpp:237] Iteration 900, loss = 0.113742
I0429 12:03:24.060919  3523 solver.cpp:253]     Train net output #0: loss = 0.113742 (* 1 = 0.113742 loss)
I0429 12:03:24.060925  3523 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0429 12:03:24.227128  3523 solver.cpp:237] Iteration 1000, loss = 0.0521797
I0429 12:03:24.227150  3523 solver.cpp:253]     Train net output #0: loss = 0.0521796 (* 1 = 0.0521796 loss)
I0429 12:03:24.227155  3523 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0429 12:03:24.393121  3523 solver.cpp:237] Iteration 1100, loss = 0.0301902
I0429 12:03:24.393144  3523 solver.cpp:253]     Train net output #0: loss = 0.03019 (* 1 = 0.03019 loss)
I0429 12:03:24.393149  3523 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0429 12:03:24.560063  3523 solver.cpp:237] Iteration 1200, loss = 0.0349371
I0429 12:03:24.560086  3523 solver.cpp:253]     Train net output #0: loss = 0.0349369 (* 1 = 0.0349369 loss)
I0429 12:03:24.560091  3523 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0429 12:03:24.726002  3523 solver.cpp:237] Iteration 1300, loss = 0.0700855
I0429 12:03:24.726024  3523 solver.cpp:253]     Train net output #0: loss = 0.0700853 (* 1 = 0.0700853 loss)
I0429 12:03:24.726052  3523 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0429 12:03:24.893069  3523 solver.cpp:237] Iteration 1400, loss = 0.0104957
I0429 12:03:24.893090  3523 solver.cpp:253]     Train net output #0: loss = 0.0104954 (* 1 = 0.0104954 loss)
I0429 12:03:24.893095  3523 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0429 12:03:25.059571  3523 solver.cpp:237] Iteration 1500, loss = 0.0810996
I0429 12:03:25.059592  3523 solver.cpp:253]     Train net output #0: loss = 0.0810994 (* 1 = 0.0810994 loss)
I0429 12:03:25.059597  3523 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0429 12:03:25.225680  3523 solver.cpp:237] Iteration 1600, loss = 0.12406
I0429 12:03:25.225702  3523 solver.cpp:253]     Train net output #0: loss = 0.12406 (* 1 = 0.12406 loss)
I0429 12:03:25.225708  3523 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0429 12:03:25.389840  3523 solver.cpp:237] Iteration 1700, loss = 0.0693719
I0429 12:03:25.389863  3523 solver.cpp:253]     Train net output #0: loss = 0.0693717 (* 1 = 0.0693717 loss)
I0429 12:03:25.389868  3523 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0429 12:03:25.558910  3523 solver.cpp:237] Iteration 1800, loss = 0.0121368
I0429 12:03:25.558946  3523 solver.cpp:253]     Train net output #0: loss = 0.0121366 (* 1 = 0.0121366 loss)
I0429 12:03:25.558955  3523 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0429 12:03:25.726686  3523 solver.cpp:237] Iteration 1900, loss = 0.132315
I0429 12:03:25.726711  3523 solver.cpp:253]     Train net output #0: loss = 0.132315 (* 1 = 0.132315 loss)
I0429 12:03:25.726717  3523 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0429 12:03:25.895606  3523 solver.cpp:237] Iteration 2000, loss = 0.0202659
I0429 12:03:25.895632  3523 solver.cpp:253]     Train net output #0: loss = 0.0202657 (* 1 = 0.0202657 loss)
I0429 12:03:25.895637  3523 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0429 12:03:26.065212  3523 solver.cpp:237] Iteration 2100, loss = 0.00523759
I0429 12:03:26.065237  3523 solver.cpp:253]     Train net output #0: loss = 0.00523727 (* 1 = 0.00523727 loss)
I0429 12:03:26.065244  3523 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0429 12:03:26.232998  3523 solver.cpp:237] Iteration 2200, loss = 0.0267871
I0429 12:03:26.233022  3523 solver.cpp:253]     Train net output #0: loss = 0.0267868 (* 1 = 0.0267868 loss)
I0429 12:03:26.233028  3523 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0429 12:03:26.397910  3523 solver.cpp:237] Iteration 2300, loss = 0.0805168
I0429 12:03:26.397933  3523 solver.cpp:253]     Train net output #0: loss = 0.0805165 (* 1 = 0.0805165 loss)
I0429 12:03:26.397938  3523 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0429 12:03:26.566946  3523 solver.cpp:237] Iteration 2400, loss = 0.0351361
I0429 12:03:26.566967  3523 solver.cpp:253]     Train net output #0: loss = 0.0351358 (* 1 = 0.0351358 loss)
I0429 12:03:26.566973  3523 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0429 12:03:26.732813  3523 solver.cpp:237] Iteration 2500, loss = 0.0183761
I0429 12:03:26.732837  3523 solver.cpp:253]     Train net output #0: loss = 0.0183758 (* 1 = 0.0183758 loss)
I0429 12:03:26.732843  3523 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0429 12:03:26.900697  3523 solver.cpp:237] Iteration 2600, loss = 0.0983317
I0429 12:03:26.900718  3523 solver.cpp:253]     Train net output #0: loss = 0.0983314 (* 1 = 0.0983314 loss)
I0429 12:03:26.900724  3523 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0429 12:03:27.067571  3523 solver.cpp:237] Iteration 2700, loss = 0.217174
I0429 12:03:27.067592  3523 solver.cpp:253]     Train net output #0: loss = 0.217174 (* 1 = 0.217174 loss)
I0429 12:03:27.067598  3523 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0429 12:03:27.233873  3523 solver.cpp:237] Iteration 2800, loss = 0.000692797
I0429 12:03:27.233896  3523 solver.cpp:253]     Train net output #0: loss = 0.000692505 (* 1 = 0.000692505 loss)
I0429 12:03:27.233901  3523 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0429 12:03:27.400583  3523 solver.cpp:237] Iteration 2900, loss = 0.0105105
I0429 12:03:27.400604  3523 solver.cpp:253]     Train net output #0: loss = 0.0105103 (* 1 = 0.0105103 loss)
I0429 12:03:27.400610  3523 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0429 12:03:27.567194  3523 solver.cpp:237] Iteration 3000, loss = 0.0659892
I0429 12:03:27.567216  3523 solver.cpp:253]     Train net output #0: loss = 0.0659889 (* 1 = 0.0659889 loss)
I0429 12:03:27.567222  3523 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0429 12:03:27.733508  3523 solver.cpp:237] Iteration 3100, loss = 0.00646498
I0429 12:03:27.733532  3523 solver.cpp:253]     Train net output #0: loss = 0.00646474 (* 1 = 0.00646474 loss)
I0429 12:03:27.733538  3523 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0429 12:03:27.899931  3523 solver.cpp:237] Iteration 3200, loss = 0.0278837
I0429 12:03:27.899953  3523 solver.cpp:253]     Train net output #0: loss = 0.0278835 (* 1 = 0.0278835 loss)
I0429 12:03:27.899960  3523 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0429 12:03:28.066272  3523 solver.cpp:237] Iteration 3300, loss = 0.0281295
I0429 12:03:28.066293  3523 solver.cpp:253]     Train net output #0: loss = 0.0281292 (* 1 = 0.0281292 loss)
I0429 12:03:28.066299  3523 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0429 12:03:28.232372  3523 solver.cpp:237] Iteration 3400, loss = 0.00613676
I0429 12:03:28.232394  3523 solver.cpp:253]     Train net output #0: loss = 0.00613648 (* 1 = 0.00613648 loss)
I0429 12:03:28.232400  3523 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0429 12:03:28.399076  3523 solver.cpp:237] Iteration 3500, loss = 0.0144107
I0429 12:03:28.399098  3523 solver.cpp:253]     Train net output #0: loss = 0.0144104 (* 1 = 0.0144104 loss)
I0429 12:03:28.399104  3523 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0429 12:03:28.565608  3523 solver.cpp:237] Iteration 3600, loss = 0.10978
I0429 12:03:28.565632  3523 solver.cpp:253]     Train net output #0: loss = 0.10978 (* 1 = 0.10978 loss)
I0429 12:03:28.565639  3523 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0429 12:03:28.732700  3523 solver.cpp:237] Iteration 3700, loss = 0.0406488
I0429 12:03:28.732722  3523 solver.cpp:253]     Train net output #0: loss = 0.0406485 (* 1 = 0.0406485 loss)
I0429 12:03:28.732728  3523 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0429 12:03:28.899441  3523 solver.cpp:237] Iteration 3800, loss = 0.0182635
I0429 12:03:28.899461  3523 solver.cpp:253]     Train net output #0: loss = 0.0182632 (* 1 = 0.0182632 loss)
I0429 12:03:28.899467  3523 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0429 12:03:29.065724  3523 solver.cpp:237] Iteration 3900, loss = 0.0638302
I0429 12:03:29.065745  3523 solver.cpp:253]     Train net output #0: loss = 0.06383 (* 1 = 0.06383 loss)
I0429 12:03:29.065752  3523 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0429 12:03:29.232358  3523 solver.cpp:237] Iteration 4000, loss = 0.0213844
I0429 12:03:29.232380  3523 solver.cpp:253]     Train net output #0: loss = 0.0213842 (* 1 = 0.0213842 loss)
I0429 12:03:29.232385  3523 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0429 12:03:29.398028  3523 solver.cpp:237] Iteration 4100, loss = 0.0356201
I0429 12:03:29.398052  3523 solver.cpp:253]     Train net output #0: loss = 0.0356199 (* 1 = 0.0356199 loss)
I0429 12:03:29.398058  3523 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0429 12:03:29.564788  3523 solver.cpp:237] Iteration 4200, loss = 0.0074552
I0429 12:03:29.564810  3523 solver.cpp:253]     Train net output #0: loss = 0.00745504 (* 1 = 0.00745504 loss)
I0429 12:03:29.564816  3523 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0429 12:03:29.731390  3523 solver.cpp:237] Iteration 4300, loss = 0.0687928
I0429 12:03:29.731415  3523 solver.cpp:253]     Train net output #0: loss = 0.0687927 (* 1 = 0.0687927 loss)
I0429 12:03:29.731420  3523 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0429 12:03:29.896872  3523 solver.cpp:237] Iteration 4400, loss = 0.0139835
I0429 12:03:29.896898  3523 solver.cpp:253]     Train net output #0: loss = 0.0139835 (* 1 = 0.0139835 loss)
I0429 12:03:29.896924  3523 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0429 12:03:30.063088  3523 solver.cpp:237] Iteration 4500, loss = 0.0129889
I0429 12:03:30.063110  3523 solver.cpp:253]     Train net output #0: loss = 0.0129888 (* 1 = 0.0129888 loss)
I0429 12:03:30.063117  3523 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0429 12:03:30.229243  3523 solver.cpp:237] Iteration 4600, loss = 0.00374628
I0429 12:03:30.229265  3523 solver.cpp:253]     Train net output #0: loss = 0.00374623 (* 1 = 0.00374623 loss)
I0429 12:03:30.229270  3523 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0429 12:03:30.395557  3523 solver.cpp:237] Iteration 4700, loss = 0.0183108
I0429 12:03:30.395579  3523 solver.cpp:253]     Train net output #0: loss = 0.0183108 (* 1 = 0.0183108 loss)
I0429 12:03:30.395584  3523 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0429 12:03:30.561929  3523 solver.cpp:237] Iteration 4800, loss = 0.0446284
I0429 12:03:30.561952  3523 solver.cpp:253]     Train net output #0: loss = 0.0446283 (* 1 = 0.0446283 loss)
I0429 12:03:30.561957  3523 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0429 12:03:30.727905  3523 solver.cpp:237] Iteration 4900, loss = 0.0126857
I0429 12:03:30.727927  3523 solver.cpp:253]     Train net output #0: loss = 0.0126856 (* 1 = 0.0126856 loss)
I0429 12:03:30.727932  3523 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0429 12:03:30.892976  3523 solver.cpp:341] Iteration 5000, Testing net (#0)
I0429 12:03:30.961879  3523 solver.cpp:409]     Test net output #0: accuracy = 0.9835
I0429 12:03:30.961905  3523 solver.cpp:409]     Test net output #1: loss = 0.0541497 (* 1 = 0.0541497 loss)
I0429 12:03:30.962621  3523 solver.cpp:237] Iteration 5000, loss = 0.0229211
I0429 12:03:30.962641  3523 solver.cpp:253]     Train net output #0: loss = 0.022921 (* 1 = 0.022921 loss)
I0429 12:03:30.962648  3523 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0429 12:03:31.123440  3523 solver.cpp:237] Iteration 5100, loss = 0.0471167
I0429 12:03:31.123462  3523 solver.cpp:253]     Train net output #0: loss = 0.0471167 (* 1 = 0.0471167 loss)
I0429 12:03:31.123467  3523 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0429 12:03:31.284610  3523 solver.cpp:237] Iteration 5200, loss = 0.012855
I0429 12:03:31.284632  3523 solver.cpp:253]     Train net output #0: loss = 0.0128549 (* 1 = 0.0128549 loss)
I0429 12:03:31.284637  3523 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0429 12:03:31.445696  3523 solver.cpp:237] Iteration 5300, loss = 0.00630767
I0429 12:03:31.445720  3523 solver.cpp:253]     Train net output #0: loss = 0.00630762 (* 1 = 0.00630762 loss)
I0429 12:03:31.445726  3523 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0429 12:03:31.606297  3523 solver.cpp:237] Iteration 5400, loss = 0.0396542
I0429 12:03:31.606320  3523 solver.cpp:253]     Train net output #0: loss = 0.0396542 (* 1 = 0.0396542 loss)
I0429 12:03:31.606326  3523 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0429 12:03:31.767550  3523 solver.cpp:237] Iteration 5500, loss = 0.00431852
I0429 12:03:31.767572  3523 solver.cpp:253]     Train net output #0: loss = 0.00431847 (* 1 = 0.00431847 loss)
I0429 12:03:31.767578  3523 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0429 12:03:31.928884  3523 solver.cpp:237] Iteration 5600, loss = 0.00288345
I0429 12:03:31.928911  3523 solver.cpp:253]     Train net output #0: loss = 0.00288338 (* 1 = 0.00288338 loss)
I0429 12:03:31.928916  3523 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0429 12:03:32.090580  3523 solver.cpp:237] Iteration 5700, loss = 0.00226443
I0429 12:03:32.090633  3523 solver.cpp:253]     Train net output #0: loss = 0.00226436 (* 1 = 0.00226436 loss)
I0429 12:03:32.090648  3523 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0429 12:03:32.258019  3523 solver.cpp:237] Iteration 5800, loss = 0.0219369
I0429 12:03:32.258050  3523 solver.cpp:253]     Train net output #0: loss = 0.0219368 (* 1 = 0.0219368 loss)
I0429 12:03:32.258087  3523 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0429 12:03:32.437382  3523 solver.cpp:237] Iteration 5900, loss = 0.04195
I0429 12:03:32.437415  3523 solver.cpp:253]     Train net output #0: loss = 0.0419499 (* 1 = 0.0419499 loss)
I0429 12:03:32.437424  3523 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0429 12:03:32.600069  3523 solver.cpp:237] Iteration 6000, loss = 0.00565977
I0429 12:03:32.600092  3523 solver.cpp:253]     Train net output #0: loss = 0.00565969 (* 1 = 0.00565969 loss)
I0429 12:03:32.600098  3523 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0429 12:03:32.762290  3523 solver.cpp:237] Iteration 6100, loss = 0.00524451
I0429 12:03:32.762318  3523 solver.cpp:253]     Train net output #0: loss = 0.00524442 (* 1 = 0.00524442 loss)
I0429 12:03:32.762325  3523 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0429 12:03:32.924120  3523 solver.cpp:237] Iteration 6200, loss = 0.0169831
I0429 12:03:32.924147  3523 solver.cpp:253]     Train net output #0: loss = 0.016983 (* 1 = 0.016983 loss)
I0429 12:03:32.924154  3523 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0429 12:03:33.086444  3523 solver.cpp:237] Iteration 6300, loss = 0.00558213
I0429 12:03:33.086469  3523 solver.cpp:253]     Train net output #0: loss = 0.00558201 (* 1 = 0.00558201 loss)
I0429 12:03:33.086475  3523 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0429 12:03:33.248633  3523 solver.cpp:237] Iteration 6400, loss = 0.00803196
I0429 12:03:33.248657  3523 solver.cpp:253]     Train net output #0: loss = 0.00803183 (* 1 = 0.00803183 loss)
I0429 12:03:33.248664  3523 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0429 12:03:33.411234  3523 solver.cpp:237] Iteration 6500, loss = 0.0128169
I0429 12:03:33.411257  3523 solver.cpp:253]     Train net output #0: loss = 0.0128168 (* 1 = 0.0128168 loss)
I0429 12:03:33.411263  3523 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0429 12:03:33.578959  3523 solver.cpp:237] Iteration 6600, loss = 0.00648807
I0429 12:03:33.578994  3523 solver.cpp:253]     Train net output #0: loss = 0.00648795 (* 1 = 0.00648795 loss)
I0429 12:03:33.579004  3523 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0429 12:03:33.747319  3523 solver.cpp:237] Iteration 6700, loss = 0.00697172
I0429 12:03:33.747344  3523 solver.cpp:253]     Train net output #0: loss = 0.00697159 (* 1 = 0.00697159 loss)
I0429 12:03:33.747350  3523 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0429 12:03:33.912508  3523 solver.cpp:237] Iteration 6800, loss = 0.00284554
I0429 12:03:33.912533  3523 solver.cpp:253]     Train net output #0: loss = 0.00284541 (* 1 = 0.00284541 loss)
I0429 12:03:33.912539  3523 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0429 12:03:34.076501  3523 solver.cpp:237] Iteration 6900, loss = 0.010314
I0429 12:03:34.076526  3523 solver.cpp:253]     Train net output #0: loss = 0.0103139 (* 1 = 0.0103139 loss)
I0429 12:03:34.076532  3523 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0429 12:03:34.238409  3523 solver.cpp:237] Iteration 7000, loss = 0.0263857
I0429 12:03:34.238430  3523 solver.cpp:253]     Train net output #0: loss = 0.0263856 (* 1 = 0.0263856 loss)
I0429 12:03:34.238436  3523 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0429 12:03:34.399497  3523 solver.cpp:237] Iteration 7100, loss = 0.0549661
I0429 12:03:34.399520  3523 solver.cpp:253]     Train net output #0: loss = 0.054966 (* 1 = 0.054966 loss)
I0429 12:03:34.399525  3523 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0429 12:03:34.561651  3523 solver.cpp:237] Iteration 7200, loss = 0.00493482
I0429 12:03:34.561678  3523 solver.cpp:253]     Train net output #0: loss = 0.00493469 (* 1 = 0.00493469 loss)
I0429 12:03:34.561684  3523 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0429 12:03:34.722385  3523 solver.cpp:237] Iteration 7300, loss = 0.0206204
I0429 12:03:34.722406  3523 solver.cpp:253]     Train net output #0: loss = 0.0206203 (* 1 = 0.0206203 loss)
I0429 12:03:34.722411  3523 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0429 12:03:34.883038  3523 solver.cpp:237] Iteration 7400, loss = 0.00382431
I0429 12:03:34.883080  3523 solver.cpp:253]     Train net output #0: loss = 0.00382418 (* 1 = 0.00382418 loss)
I0429 12:03:34.883085  3523 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0429 12:03:35.043741  3523 solver.cpp:237] Iteration 7500, loss = 0.00418695
I0429 12:03:35.043762  3523 solver.cpp:253]     Train net output #0: loss = 0.00418682 (* 1 = 0.00418682 loss)
I0429 12:03:35.043768  3523 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0429 12:03:35.205839  3523 solver.cpp:237] Iteration 7600, loss = 0.00984748
I0429 12:03:35.205862  3523 solver.cpp:253]     Train net output #0: loss = 0.00984735 (* 1 = 0.00984735 loss)
I0429 12:03:35.205874  3523 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0429 12:03:35.370043  3523 solver.cpp:237] Iteration 7700, loss = 0.0106125
I0429 12:03:35.370071  3523 solver.cpp:253]     Train net output #0: loss = 0.0106124 (* 1 = 0.0106124 loss)
I0429 12:03:35.370079  3523 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0429 12:03:35.533504  3523 solver.cpp:237] Iteration 7800, loss = 0.00269454
I0429 12:03:35.533527  3523 solver.cpp:253]     Train net output #0: loss = 0.00269442 (* 1 = 0.00269442 loss)
I0429 12:03:35.533534  3523 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0429 12:03:35.695571  3523 solver.cpp:237] Iteration 7900, loss = 0.00734685
I0429 12:03:35.695600  3523 solver.cpp:253]     Train net output #0: loss = 0.00734672 (* 1 = 0.00734672 loss)
I0429 12:03:35.695605  3523 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0429 12:03:35.857475  3523 solver.cpp:237] Iteration 8000, loss = 0.0178509
I0429 12:03:35.857503  3523 solver.cpp:253]     Train net output #0: loss = 0.0178507 (* 1 = 0.0178507 loss)
I0429 12:03:35.857508  3523 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0429 12:03:36.019493  3523 solver.cpp:237] Iteration 8100, loss = 0.0686611
I0429 12:03:36.019516  3523 solver.cpp:253]     Train net output #0: loss = 0.068661 (* 1 = 0.068661 loss)
I0429 12:03:36.019522  3523 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0429 12:03:36.182065  3523 solver.cpp:237] Iteration 8200, loss = 0.00487106
I0429 12:03:36.182086  3523 solver.cpp:253]     Train net output #0: loss = 0.00487093 (* 1 = 0.00487093 loss)
I0429 12:03:36.182091  3523 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0429 12:03:36.343394  3523 solver.cpp:237] Iteration 8300, loss = 0.0468204
I0429 12:03:36.343416  3523 solver.cpp:253]     Train net output #0: loss = 0.0468203 (* 1 = 0.0468203 loss)
I0429 12:03:36.343421  3523 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0429 12:03:36.504732  3523 solver.cpp:237] Iteration 8400, loss = 0.0129908
I0429 12:03:36.504756  3523 solver.cpp:253]     Train net output #0: loss = 0.0129906 (* 1 = 0.0129906 loss)
I0429 12:03:36.504762  3523 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0429 12:03:36.665998  3523 solver.cpp:237] Iteration 8500, loss = 0.0034776
I0429 12:03:36.666020  3523 solver.cpp:253]     Train net output #0: loss = 0.00347747 (* 1 = 0.00347747 loss)
I0429 12:03:36.666026  3523 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0429 12:03:36.826926  3523 solver.cpp:237] Iteration 8600, loss = 0.00106049
I0429 12:03:36.826957  3523 solver.cpp:253]     Train net output #0: loss = 0.00106035 (* 1 = 0.00106035 loss)
I0429 12:03:36.826968  3523 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0429 12:03:36.987586  3523 solver.cpp:237] Iteration 8700, loss = 0.00374992
I0429 12:03:36.987607  3523 solver.cpp:253]     Train net output #0: loss = 0.00374978 (* 1 = 0.00374978 loss)
I0429 12:03:36.987613  3523 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0429 12:03:37.149093  3523 solver.cpp:237] Iteration 8800, loss = 0.00202236
I0429 12:03:37.149114  3523 solver.cpp:253]     Train net output #0: loss = 0.00202221 (* 1 = 0.00202221 loss)
I0429 12:03:37.149121  3523 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0429 12:03:37.309954  3523 solver.cpp:237] Iteration 8900, loss = 0.00113247
I0429 12:03:37.309983  3523 solver.cpp:253]     Train net output #0: loss = 0.00113232 (* 1 = 0.00113232 loss)
I0429 12:03:37.310017  3523 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0429 12:03:37.470754  3523 solver.cpp:237] Iteration 9000, loss = 0.00805654
I0429 12:03:37.470780  3523 solver.cpp:253]     Train net output #0: loss = 0.0080564 (* 1 = 0.0080564 loss)
I0429 12:03:37.470787  3523 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0429 12:03:37.632401  3523 solver.cpp:237] Iteration 9100, loss = 0.00872517
I0429 12:03:37.632424  3523 solver.cpp:253]     Train net output #0: loss = 0.00872504 (* 1 = 0.00872504 loss)
I0429 12:03:37.632431  3523 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0429 12:03:37.793931  3523 solver.cpp:237] Iteration 9200, loss = 0.00284009
I0429 12:03:37.793952  3523 solver.cpp:253]     Train net output #0: loss = 0.00283997 (* 1 = 0.00283997 loss)
I0429 12:03:37.793958  3523 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0429 12:03:37.954855  3523 solver.cpp:237] Iteration 9300, loss = 0.00151426
I0429 12:03:37.954879  3523 solver.cpp:253]     Train net output #0: loss = 0.00151414 (* 1 = 0.00151414 loss)
I0429 12:03:37.954884  3523 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0429 12:03:38.115663  3523 solver.cpp:237] Iteration 9400, loss = 0.00724942
I0429 12:03:38.115684  3523 solver.cpp:253]     Train net output #0: loss = 0.00724929 (* 1 = 0.00724929 loss)
I0429 12:03:38.115690  3523 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0429 12:03:38.277761  3523 solver.cpp:237] Iteration 9500, loss = 0.0035544
I0429 12:03:38.277783  3523 solver.cpp:253]     Train net output #0: loss = 0.00355427 (* 1 = 0.00355427 loss)
I0429 12:03:38.277789  3523 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0429 12:03:38.438786  3523 solver.cpp:237] Iteration 9600, loss = 0.00142971
I0429 12:03:38.438808  3523 solver.cpp:253]     Train net output #0: loss = 0.00142958 (* 1 = 0.00142958 loss)
I0429 12:03:38.438813  3523 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0429 12:03:38.600525  3523 solver.cpp:237] Iteration 9700, loss = 0.00208828
I0429 12:03:38.600548  3523 solver.cpp:253]     Train net output #0: loss = 0.00208814 (* 1 = 0.00208814 loss)
I0429 12:03:38.600553  3523 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0429 12:03:38.761286  3523 solver.cpp:237] Iteration 9800, loss = 0.0192019
I0429 12:03:38.761317  3523 solver.cpp:253]     Train net output #0: loss = 0.0192018 (* 1 = 0.0192018 loss)
I0429 12:03:38.761322  3523 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0429 12:03:38.922050  3523 solver.cpp:237] Iteration 9900, loss = 0.00294365
I0429 12:03:38.922072  3523 solver.cpp:253]     Train net output #0: loss = 0.00294351 (* 1 = 0.00294351 loss)
I0429 12:03:38.922078  3523 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0429 12:03:39.081641  3523 solver.cpp:341] Iteration 10000, Testing net (#0)
I0429 12:03:39.089319  3523 blocking_queue.cpp:50] Data layer prefetch queue empty
I0429 12:03:39.166136  3523 solver.cpp:409]     Test net output #0: accuracy = 0.9856
I0429 12:03:39.166167  3523 solver.cpp:409]     Test net output #1: loss = 0.0485565 (* 1 = 0.0485565 loss)
I0429 12:03:39.167068  3523 solver.cpp:237] Iteration 10000, loss = 0.00113004
I0429 12:03:39.167090  3523 solver.cpp:253]     Train net output #0: loss = 0.00112991 (* 1 = 0.00112991 loss)
I0429 12:03:39.167101  3523 sgd_solver.cpp:106] Iteration 10000, lr = 0.00594604
I0429 12:03:39.327167  3523 solver.cpp:237] Iteration 10100, loss = 0.00865562
I0429 12:03:39.327189  3523 solver.cpp:253]     Train net output #0: loss = 0.00865549 (* 1 = 0.00865549 loss)
I0429 12:03:39.327194  3523 sgd_solver.cpp:106] Iteration 10100, lr = 0.00592384
I0429 12:03:39.487711  3523 solver.cpp:237] Iteration 10200, loss = 0.0101386
I0429 12:03:39.487735  3523 solver.cpp:253]     Train net output #0: loss = 0.0101384 (* 1 = 0.0101384 loss)
I0429 12:03:39.487740  3523 sgd_solver.cpp:106] Iteration 10200, lr = 0.00590183
I0429 12:03:39.646898  3523 solver.cpp:237] Iteration 10300, loss = 0.00112627
I0429 12:03:39.646937  3523 solver.cpp:253]     Train net output #0: loss = 0.00112613 (* 1 = 0.00112613 loss)
I0429 12:03:39.646944  3523 sgd_solver.cpp:106] Iteration 10300, lr = 0.00588001
I0429 12:03:39.807822  3523 solver.cpp:237] Iteration 10400, loss = 0.00380584
I0429 12:03:39.807843  3523 solver.cpp:253]     Train net output #0: loss = 0.00380571 (* 1 = 0.00380571 loss)
I0429 12:03:39.807849  3523 sgd_solver.cpp:106] Iteration 10400, lr = 0.00585838
I0429 12:03:39.967988  3523 solver.cpp:237] Iteration 10500, loss = 0.0037734
I0429 12:03:39.968009  3523 solver.cpp:253]     Train net output #0: loss = 0.00377326 (* 1 = 0.00377326 loss)
I0429 12:03:39.968015  3523 sgd_solver.cpp:106] Iteration 10500, lr = 0.00583693
I0429 12:03:40.127214  3523 solver.cpp:237] Iteration 10600, loss = 0.00199152
I0429 12:03:40.127236  3523 solver.cpp:253]     Train net output #0: loss = 0.00199138 (* 1 = 0.00199138 loss)
I0429 12:03:40.127241  3523 sgd_solver.cpp:106] Iteration 10600, lr = 0.00581567
I0429 12:03:40.292544  3523 solver.cpp:237] Iteration 10700, loss = 0.00459989
I0429 12:03:40.292577  3523 solver.cpp:253]     Train net output #0: loss = 0.00459977 (* 1 = 0.00459977 loss)
I0429 12:03:40.292585  3523 sgd_solver.cpp:106] Iteration 10700, lr = 0.00579458
I0429 12:03:40.453938  3523 solver.cpp:237] Iteration 10800, loss = 0.00596961
I0429 12:03:40.453965  3523 solver.cpp:253]     Train net output #0: loss = 0.00596948 (* 1 = 0.00596948 loss)
I0429 12:03:40.453971  3523 sgd_solver.cpp:106] Iteration 10800, lr = 0.00577368
I0429 12:03:40.614408  3523 solver.cpp:237] Iteration 10900, loss = 0.00292895
I0429 12:03:40.614431  3523 solver.cpp:253]     Train net output #0: loss = 0.00292882 (* 1 = 0.00292882 loss)
I0429 12:03:40.614437  3523 sgd_solver.cpp:106] Iteration 10900, lr = 0.00575295
I0429 12:03:40.774888  3523 solver.cpp:237] Iteration 11000, loss = 0.000738084
I0429 12:03:40.774909  3523 solver.cpp:253]     Train net output #0: loss = 0.000737951 (* 1 = 0.000737951 loss)
I0429 12:03:40.774915  3523 sgd_solver.cpp:106] Iteration 11000, lr = 0.00573239
I0429 12:03:40.935293  3523 solver.cpp:237] Iteration 11100, loss = 0.00642174
I0429 12:03:40.935315  3523 solver.cpp:253]     Train net output #0: loss = 0.0064216 (* 1 = 0.0064216 loss)
I0429 12:03:40.935322  3523 sgd_solver.cpp:106] Iteration 11100, lr = 0.005712
I0429 12:03:41.105521  3523 solver.cpp:237] Iteration 11200, loss = 0.00738287
I0429 12:03:41.105553  3523 solver.cpp:253]     Train net output #0: loss = 0.00738273 (* 1 = 0.00738273 loss)
I0429 12:03:41.105562  3523 sgd_solver.cpp:106] Iteration 11200, lr = 0.00569178
I0429 12:03:41.271133  3523 solver.cpp:237] Iteration 11300, loss = 0.00259418
I0429 12:03:41.271158  3523 solver.cpp:253]     Train net output #0: loss = 0.00259405 (* 1 = 0.00259405 loss)
I0429 12:03:41.271164  3523 sgd_solver.cpp:106] Iteration 11300, lr = 0.00567173
I0429 12:03:41.436015  3523 solver.cpp:237] Iteration 11400, loss = 0.00501487
I0429 12:03:41.436040  3523 solver.cpp:253]     Train net output #0: loss = 0.00501474 (* 1 = 0.00501474 loss)
I0429 12:03:41.436046  3523 sgd_solver.cpp:106] Iteration 11400, lr = 0.00565184
I0429 12:03:41.601735  3523 solver.cpp:237] Iteration 11500, loss = 0.00426322
I0429 12:03:41.601760  3523 solver.cpp:253]     Train net output #0: loss = 0.00426308 (* 1 = 0.00426308 loss)
I0429 12:03:41.601768  3523 sgd_solver.cpp:106] Iteration 11500, lr = 0.00563211
I0429 12:03:41.764727  3523 solver.cpp:237] Iteration 11600, loss = 0.00737984
I0429 12:03:41.764755  3523 solver.cpp:253]     Train net output #0: loss = 0.00737971 (* 1 = 0.00737971 loss)
I0429 12:03:41.764761  3523 sgd_solver.cpp:106] Iteration 11600, lr = 0.00561254
I0429 12:03:41.925354  3523 solver.cpp:237] Iteration 11700, loss = 0.00627476
I0429 12:03:41.925377  3523 solver.cpp:253]     Train net output #0: loss = 0.00627462 (* 1 = 0.00627462 loss)
I0429 12:03:41.925384  3523 sgd_solver.cpp:106] Iteration 11700, lr = 0.00559313
I0429 12:03:42.086748  3523 solver.cpp:237] Iteration 11800, loss = 0.00844914
I0429 12:03:42.086771  3523 solver.cpp:253]     Train net output #0: loss = 0.00844901 (* 1 = 0.00844901 loss)
I0429 12:03:42.086803  3523 sgd_solver.cpp:106] Iteration 11800, lr = 0.00557388
I0429 12:03:42.246192  3523 solver.cpp:237] Iteration 11900, loss = 0.00308978
I0429 12:03:42.246212  3523 solver.cpp:253]     Train net output #0: loss = 0.00308965 (* 1 = 0.00308965 loss)
I0429 12:03:42.246218  3523 sgd_solver.cpp:106] Iteration 11900, lr = 0.00555478
I0429 12:03:42.406899  3523 solver.cpp:237] Iteration 12000, loss = 0.00267214
I0429 12:03:42.406921  3523 solver.cpp:253]     Train net output #0: loss = 0.00267201 (* 1 = 0.00267201 loss)
I0429 12:03:42.406927  3523 sgd_solver.cpp:106] Iteration 12000, lr = 0.00553583
I0429 12:03:42.566344  3523 solver.cpp:237] Iteration 12100, loss = 0.00435148
I0429 12:03:42.566365  3523 solver.cpp:253]     Train net output #0: loss = 0.00435136 (* 1 = 0.00435136 loss)
I0429 12:03:42.566371  3523 sgd_solver.cpp:106] Iteration 12100, lr = 0.00551704
I0429 12:03:42.727370  3523 solver.cpp:237] Iteration 12200, loss = 0.0030612
I0429 12:03:42.727392  3523 solver.cpp:253]     Train net output #0: loss = 0.00306107 (* 1 = 0.00306107 loss)
I0429 12:03:42.727404  3523 sgd_solver.cpp:106] Iteration 12200, lr = 0.00549839
I0429 12:03:42.886754  3523 solver.cpp:237] Iteration 12300, loss = 0.00532432
I0429 12:03:42.886773  3523 solver.cpp:253]     Train net output #0: loss = 0.00532419 (* 1 = 0.00532419 loss)
I0429 12:03:42.886780  3523 sgd_solver.cpp:106] Iteration 12300, lr = 0.00547988
I0429 12:03:43.047864  3523 solver.cpp:237] Iteration 12400, loss = 0.00168604
I0429 12:03:43.047888  3523 solver.cpp:253]     Train net output #0: loss = 0.0016859 (* 1 = 0.0016859 loss)
I0429 12:03:43.047894  3523 sgd_solver.cpp:106] Iteration 12400, lr = 0.00546153
I0429 12:03:43.215574  3523 solver.cpp:237] Iteration 12500, loss = 0.00669326
I0429 12:03:43.215603  3523 solver.cpp:253]     Train net output #0: loss = 0.00669313 (* 1 = 0.00669313 loss)
I0429 12:03:43.215611  3523 sgd_solver.cpp:106] Iteration 12500, lr = 0.00544331
I0429 12:03:43.379206  3523 solver.cpp:237] Iteration 12600, loss = 0.0200156
I0429 12:03:43.379230  3523 solver.cpp:253]     Train net output #0: loss = 0.0200155 (* 1 = 0.0200155 loss)
I0429 12:03:43.379235  3523 sgd_solver.cpp:106] Iteration 12600, lr = 0.00542524
I0429 12:03:43.542474  3523 solver.cpp:237] Iteration 12700, loss = 0.00391983
I0429 12:03:43.542505  3523 solver.cpp:253]     Train net output #0: loss = 0.0039197 (* 1 = 0.0039197 loss)
I0429 12:03:43.542510  3523 sgd_solver.cpp:106] Iteration 12700, lr = 0.0054073
I0429 12:03:43.707109  3523 solver.cpp:237] Iteration 12800, loss = 0.00230388
I0429 12:03:43.707134  3523 solver.cpp:253]     Train net output #0: loss = 0.00230375 (* 1 = 0.00230375 loss)
I0429 12:03:43.707139  3523 sgd_solver.cpp:106] Iteration 12800, lr = 0.0053895
I0429 12:03:43.871608  3523 solver.cpp:237] Iteration 12900, loss = 0.00518454
I0429 12:03:43.871633  3523 solver.cpp:253]     Train net output #0: loss = 0.0051844 (* 1 = 0.0051844 loss)
I0429 12:03:43.871639  3523 sgd_solver.cpp:106] Iteration 12900, lr = 0.00537184
I0429 12:03:44.035336  3523 solver.cpp:237] Iteration 13000, loss = 0.00210778
I0429 12:03:44.035362  3523 solver.cpp:253]     Train net output #0: loss = 0.00210765 (* 1 = 0.00210765 loss)
I0429 12:03:44.035367  3523 sgd_solver.cpp:106] Iteration 13000, lr = 0.00535432
I0429 12:03:44.197988  3523 solver.cpp:237] Iteration 13100, loss = 0.000319305
I0429 12:03:44.198009  3523 solver.cpp:253]     Train net output #0: loss = 0.000319171 (* 1 = 0.000319171 loss)
I0429 12:03:44.198014  3523 sgd_solver.cpp:106] Iteration 13100, lr = 0.00533692
I0429 12:03:44.360587  3523 solver.cpp:237] Iteration 13200, loss = 0.000347263
I0429 12:03:44.360610  3523 solver.cpp:253]     Train net output #0: loss = 0.000347136 (* 1 = 0.000347136 loss)
I0429 12:03:44.360615  3523 sgd_solver.cpp:106] Iteration 13200, lr = 0.00531966
I0429 12:03:44.523288  3523 solver.cpp:237] Iteration 13300, loss = 0.00466528
I0429 12:03:44.523320  3523 solver.cpp:253]     Train net output #0: loss = 0.00466516 (* 1 = 0.00466516 loss)
I0429 12:03:44.523352  3523 sgd_solver.cpp:106] Iteration 13300, lr = 0.00530253
I0429 12:03:44.686580  3523 solver.cpp:237] Iteration 13400, loss = 0.00648198
I0429 12:03:44.686604  3523 solver.cpp:253]     Train net output #0: loss = 0.00648186 (* 1 = 0.00648186 loss)
I0429 12:03:44.686609  3523 sgd_solver.cpp:106] Iteration 13400, lr = 0.00528552
I0429 12:03:44.849571  3523 solver.cpp:237] Iteration 13500, loss = 0.00185
I0429 12:03:44.849596  3523 solver.cpp:253]     Train net output #0: loss = 0.00184988 (* 1 = 0.00184988 loss)
I0429 12:03:44.849601  3523 sgd_solver.cpp:106] Iteration 13500, lr = 0.00526865
I0429 12:03:45.013188  3523 solver.cpp:237] Iteration 13600, loss = 0.00156963
I0429 12:03:45.013209  3523 solver.cpp:253]     Train net output #0: loss = 0.00156952 (* 1 = 0.00156952 loss)
I0429 12:03:45.013214  3523 sgd_solver.cpp:106] Iteration 13600, lr = 0.00525189
I0429 12:03:45.175817  3523 solver.cpp:237] Iteration 13700, loss = 0.00479442
I0429 12:03:45.175837  3523 solver.cpp:253]     Train net output #0: loss = 0.00479431 (* 1 = 0.00479431 loss)
I0429 12:03:45.175843  3523 sgd_solver.cpp:106] Iteration 13700, lr = 0.00523527
I0429 12:03:45.339637  3523 solver.cpp:237] Iteration 13800, loss = 0.0012709
I0429 12:03:45.339658  3523 solver.cpp:253]     Train net output #0: loss = 0.00127079 (* 1 = 0.00127079 loss)
I0429 12:03:45.339663  3523 sgd_solver.cpp:106] Iteration 13800, lr = 0.00521876
I0429 12:03:45.502450  3523 solver.cpp:237] Iteration 13900, loss = 0.00226354
I0429 12:03:45.502476  3523 solver.cpp:253]     Train net output #0: loss = 0.00226342 (* 1 = 0.00226342 loss)
I0429 12:03:45.502486  3523 sgd_solver.cpp:106] Iteration 13900, lr = 0.00520237
I0429 12:03:45.665519  3523 solver.cpp:237] Iteration 14000, loss = 0.00492079
I0429 12:03:45.665541  3523 solver.cpp:253]     Train net output #0: loss = 0.00492067 (* 1 = 0.00492067 loss)
I0429 12:03:45.665546  3523 sgd_solver.cpp:106] Iteration 14000, lr = 0.00518611
I0429 12:03:45.828256  3523 solver.cpp:237] Iteration 14100, loss = 0.00622961
I0429 12:03:45.828277  3523 solver.cpp:253]     Train net output #0: loss = 0.0062295 (* 1 = 0.0062295 loss)
I0429 12:03:45.828284  3523 sgd_solver.cpp:106] Iteration 14100, lr = 0.00516996
I0429 12:03:45.991466  3523 solver.cpp:237] Iteration 14200, loss = 0.00510622
I0429 12:03:45.991488  3523 solver.cpp:253]     Train net output #0: loss = 0.00510611 (* 1 = 0.00510611 loss)
I0429 12:03:45.991494  3523 sgd_solver.cpp:106] Iteration 14200, lr = 0.00515393
I0429 12:03:46.154438  3523 solver.cpp:237] Iteration 14300, loss = 0.000440721
I0429 12:03:46.154460  3523 solver.cpp:253]     Train net output #0: loss = 0.000440611 (* 1 = 0.000440611 loss)
I0429 12:03:46.154466  3523 sgd_solver.cpp:106] Iteration 14300, lr = 0.00513801
I0429 12:03:46.317394  3523 solver.cpp:237] Iteration 14400, loss = 0.00273063
I0429 12:03:46.317415  3523 solver.cpp:253]     Train net output #0: loss = 0.00273052 (* 1 = 0.00273052 loss)
I0429 12:03:46.317421  3523 sgd_solver.cpp:106] Iteration 14400, lr = 0.00512221
I0429 12:03:46.480545  3523 solver.cpp:237] Iteration 14500, loss = 0.00567602
I0429 12:03:46.480569  3523 solver.cpp:253]     Train net output #0: loss = 0.00567591 (* 1 = 0.00567591 loss)
I0429 12:03:46.480576  3523 sgd_solver.cpp:106] Iteration 14500, lr = 0.00510653
I0429 12:03:46.643980  3523 solver.cpp:237] Iteration 14600, loss = 0.00574315
I0429 12:03:46.644003  3523 solver.cpp:253]     Train net output #0: loss = 0.00574304 (* 1 = 0.00574304 loss)
I0429 12:03:46.644008  3523 sgd_solver.cpp:106] Iteration 14600, lr = 0.00509095
I0429 12:03:46.806880  3523 solver.cpp:237] Iteration 14700, loss = 0.0030545
I0429 12:03:46.806901  3523 solver.cpp:253]     Train net output #0: loss = 0.00305439 (* 1 = 0.00305439 loss)
I0429 12:03:46.806907  3523 sgd_solver.cpp:106] Iteration 14700, lr = 0.00507548
I0429 12:03:46.970015  3523 solver.cpp:237] Iteration 14800, loss = 0.0112695
I0429 12:03:46.970036  3523 solver.cpp:253]     Train net output #0: loss = 0.0112694 (* 1 = 0.0112694 loss)
I0429 12:03:46.970058  3523 sgd_solver.cpp:106] Iteration 14800, lr = 0.00506012
I0429 12:03:47.132910  3523 solver.cpp:237] Iteration 14900, loss = 0.00192511
I0429 12:03:47.132930  3523 solver.cpp:253]     Train net output #0: loss = 0.001925 (* 1 = 0.001925 loss)
I0429 12:03:47.132936  3523 sgd_solver.cpp:106] Iteration 14900, lr = 0.00504488
I0429 12:03:47.294169  3523 solver.cpp:341] Iteration 15000, Testing net (#0)
I0429 12:03:47.376233  3523 solver.cpp:409]     Test net output #0: accuracy = 0.9863
I0429 12:03:47.376268  3523 solver.cpp:409]     Test net output #1: loss = 0.0485025 (* 1 = 0.0485025 loss)
I0429 12:03:47.377127  3523 solver.cpp:237] Iteration 15000, loss = 0.00136405
I0429 12:03:47.377149  3523 solver.cpp:253]     Train net output #0: loss = 0.00136394 (* 1 = 0.00136394 loss)
I0429 12:03:47.377161  3523 sgd_solver.cpp:106] Iteration 15000, lr = 0.00502973
I0429 12:03:47.543455  3523 solver.cpp:237] Iteration 15100, loss = 0.00433071
I0429 12:03:47.543478  3523 solver.cpp:253]     Train net output #0: loss = 0.0043306 (* 1 = 0.0043306 loss)
I0429 12:03:47.543483  3523 sgd_solver.cpp:106] Iteration 15100, lr = 0.0050147
I0429 12:03:47.709945  3523 solver.cpp:237] Iteration 15200, loss = 0.00423624
I0429 12:03:47.709969  3523 solver.cpp:253]     Train net output #0: loss = 0.00423613 (* 1 = 0.00423613 loss)
I0429 12:03:47.709975  3523 sgd_solver.cpp:106] Iteration 15200, lr = 0.00499976
I0429 12:03:47.876546  3523 solver.cpp:237] Iteration 15300, loss = 0.00128896
I0429 12:03:47.876570  3523 solver.cpp:253]     Train net output #0: loss = 0.00128885 (* 1 = 0.00128885 loss)
I0429 12:03:47.876575  3523 sgd_solver.cpp:106] Iteration 15300, lr = 0.00498494
I0429 12:03:48.042507  3523 solver.cpp:237] Iteration 15400, loss = 0.00204059
I0429 12:03:48.042529  3523 solver.cpp:253]     Train net output #0: loss = 0.00204048 (* 1 = 0.00204048 loss)
I0429 12:03:48.042536  3523 sgd_solver.cpp:106] Iteration 15400, lr = 0.00497021
I0429 12:03:48.209453  3523 solver.cpp:237] Iteration 15500, loss = 0.00710287
I0429 12:03:48.209475  3523 solver.cpp:253]     Train net output #0: loss = 0.00710277 (* 1 = 0.00710277 loss)
I0429 12:03:48.209481  3523 sgd_solver.cpp:106] Iteration 15500, lr = 0.00495558
I0429 12:03:48.376444  3523 solver.cpp:237] Iteration 15600, loss = 0.0107763
I0429 12:03:48.376466  3523 solver.cpp:253]     Train net output #0: loss = 0.0107762 (* 1 = 0.0107762 loss)
I0429 12:03:48.376471  3523 sgd_solver.cpp:106] Iteration 15600, lr = 0.00494106
I0429 12:03:48.541877  3523 solver.cpp:237] Iteration 15700, loss = 0.00230453
I0429 12:03:48.541898  3523 solver.cpp:253]     Train net output #0: loss = 0.00230442 (* 1 = 0.00230442 loss)
I0429 12:03:48.541903  3523 sgd_solver.cpp:106] Iteration 15700, lr = 0.00492663
I0429 12:03:48.710525  3523 solver.cpp:237] Iteration 15800, loss = 0.00606856
I0429 12:03:48.710547  3523 solver.cpp:253]     Train net output #0: loss = 0.00606846 (* 1 = 0.00606846 loss)
I0429 12:03:48.710553  3523 sgd_solver.cpp:106] Iteration 15800, lr = 0.0049123
I0429 12:03:48.878111  3523 solver.cpp:237] Iteration 15900, loss = 0.00746356
I0429 12:03:48.878132  3523 solver.cpp:253]     Train net output #0: loss = 0.00746345 (* 1 = 0.00746345 loss)
I0429 12:03:48.878137  3523 sgd_solver.cpp:106] Iteration 15900, lr = 0.00489807
I0429 12:03:49.046159  3523 solver.cpp:237] Iteration 16000, loss = 0.00218595
I0429 12:03:49.046181  3523 solver.cpp:253]     Train net output #0: loss = 0.00218584 (* 1 = 0.00218584 loss)
I0429 12:03:49.046187  3523 sgd_solver.cpp:106] Iteration 16000, lr = 0.00488394
I0429 12:03:49.213711  3523 solver.cpp:237] Iteration 16100, loss = 0.000767927
I0429 12:03:49.213734  3523 solver.cpp:253]     Train net output #0: loss = 0.000767821 (* 1 = 0.000767821 loss)
I0429 12:03:49.213739  3523 sgd_solver.cpp:106] Iteration 16100, lr = 0.0048699
I0429 12:03:49.382719  3523 solver.cpp:237] Iteration 16200, loss = 0.00154663
I0429 12:03:49.382753  3523 solver.cpp:253]     Train net output #0: loss = 0.00154652 (* 1 = 0.00154652 loss)
I0429 12:03:49.382762  3523 sgd_solver.cpp:106] Iteration 16200, lr = 0.00485595
I0429 12:03:49.549808  3523 solver.cpp:237] Iteration 16300, loss = 0.000540699
I0429 12:03:49.549836  3523 solver.cpp:253]     Train net output #0: loss = 0.000540592 (* 1 = 0.000540592 loss)
I0429 12:03:49.549844  3523 sgd_solver.cpp:106] Iteration 16300, lr = 0.00484209
I0429 12:03:49.718683  3523 solver.cpp:237] Iteration 16400, loss = 0.00100984
I0429 12:03:49.718709  3523 solver.cpp:253]     Train net output #0: loss = 0.00100973 (* 1 = 0.00100973 loss)
I0429 12:03:49.718715  3523 sgd_solver.cpp:106] Iteration 16400, lr = 0.00482833
I0429 12:03:49.886265  3523 solver.cpp:237] Iteration 16500, loss = 0.00470302
I0429 12:03:49.886287  3523 solver.cpp:253]     Train net output #0: loss = 0.00470292 (* 1 = 0.00470292 loss)
I0429 12:03:49.886293  3523 sgd_solver.cpp:106] Iteration 16500, lr = 0.00481466
I0429 12:03:50.053787  3523 solver.cpp:237] Iteration 16600, loss = 0.00551445
I0429 12:03:50.053812  3523 solver.cpp:253]     Train net output #0: loss = 0.00551434 (* 1 = 0.00551434 loss)
I0429 12:03:50.053817  3523 sgd_solver.cpp:106] Iteration 16600, lr = 0.00480108
I0429 12:03:50.221770  3523 solver.cpp:237] Iteration 16700, loss = 0.00286859
I0429 12:03:50.221792  3523 solver.cpp:253]     Train net output #0: loss = 0.00286849 (* 1 = 0.00286849 loss)
I0429 12:03:50.221797  3523 sgd_solver.cpp:106] Iteration 16700, lr = 0.00478759
I0429 12:03:50.389610  3523 solver.cpp:237] Iteration 16800, loss = 0.00194216
I0429 12:03:50.389632  3523 solver.cpp:253]     Train net output #0: loss = 0.00194206 (* 1 = 0.00194206 loss)
I0429 12:03:50.389638  3523 sgd_solver.cpp:106] Iteration 16800, lr = 0.00477418
I0429 12:03:50.557392  3523 solver.cpp:237] Iteration 16900, loss = 0.00626153
I0429 12:03:50.557420  3523 solver.cpp:253]     Train net output #0: loss = 0.00626143 (* 1 = 0.00626143 loss)
I0429 12:03:50.557425  3523 sgd_solver.cpp:106] Iteration 16900, lr = 0.00476086
I0429 12:03:50.725257  3523 solver.cpp:237] Iteration 17000, loss = 0.0025122
I0429 12:03:50.725287  3523 solver.cpp:253]     Train net output #0: loss = 0.0025121 (* 1 = 0.0025121 loss)
I0429 12:03:50.725293  3523 sgd_solver.cpp:106] Iteration 17000, lr = 0.00474763
I0429 12:03:50.892140  3523 solver.cpp:237] Iteration 17100, loss = 0.000844922
I0429 12:03:50.892163  3523 solver.cpp:253]     Train net output #0: loss = 0.000844826 (* 1 = 0.000844826 loss)
I0429 12:03:50.892168  3523 sgd_solver.cpp:106] Iteration 17100, lr = 0.00473449
I0429 12:03:51.059844  3523 solver.cpp:237] Iteration 17200, loss = 0.00121024
I0429 12:03:51.059867  3523 solver.cpp:253]     Train net output #0: loss = 0.00121014 (* 1 = 0.00121014 loss)
I0429 12:03:51.059873  3523 sgd_solver.cpp:106] Iteration 17200, lr = 0.00472143
I0429 12:03:51.227229  3523 solver.cpp:237] Iteration 17300, loss = 0.00788059
I0429 12:03:51.227251  3523 solver.cpp:253]     Train net output #0: loss = 0.00788049 (* 1 = 0.00788049 loss)
I0429 12:03:51.227255  3523 sgd_solver.cpp:106] Iteration 17300, lr = 0.00470845
I0429 12:03:51.395097  3523 solver.cpp:237] Iteration 17400, loss = 0.00202611
I0429 12:03:51.395119  3523 solver.cpp:253]     Train net output #0: loss = 0.00202601 (* 1 = 0.00202601 loss)
I0429 12:03:51.395124  3523 sgd_solver.cpp:106] Iteration 17400, lr = 0.00469556
I0429 12:03:51.562695  3523 solver.cpp:237] Iteration 17500, loss = 0.0007057
I0429 12:03:51.562716  3523 solver.cpp:253]     Train net output #0: loss = 0.000705599 (* 1 = 0.000705599 loss)
I0429 12:03:51.562721  3523 sgd_solver.cpp:106] Iteration 17500, lr = 0.00468274
I0429 12:03:51.730228  3523 solver.cpp:237] Iteration 17600, loss = 0.00553434
I0429 12:03:51.730250  3523 solver.cpp:253]     Train net output #0: loss = 0.00553424 (* 1 = 0.00553424 loss)
I0429 12:03:51.730257  3523 sgd_solver.cpp:106] Iteration 17600, lr = 0.00467001
I0429 12:03:51.898555  3523 solver.cpp:237] Iteration 17700, loss = 0.00590183
I0429 12:03:51.898576  3523 solver.cpp:253]     Train net output #0: loss = 0.00590173 (* 1 = 0.00590173 loss)
I0429 12:03:51.898581  3523 sgd_solver.cpp:106] Iteration 17700, lr = 0.00465736
I0429 12:03:52.065625  3523 solver.cpp:237] Iteration 17800, loss = 0.000467923
I0429 12:03:52.065735  3523 solver.cpp:253]     Train net output #0: loss = 0.000467822 (* 1 = 0.000467822 loss)
I0429 12:03:52.065743  3523 sgd_solver.cpp:106] Iteration 17800, lr = 0.00464479
I0429 12:03:52.233108  3523 solver.cpp:237] Iteration 17900, loss = 0.00304023
I0429 12:03:52.233129  3523 solver.cpp:253]     Train net output #0: loss = 0.00304013 (* 1 = 0.00304013 loss)
I0429 12:03:52.233135  3523 sgd_solver.cpp:106] Iteration 17900, lr = 0.0046323
I0429 12:03:52.400789  3523 solver.cpp:237] Iteration 18000, loss = 0.0032698
I0429 12:03:52.400810  3523 solver.cpp:253]     Train net output #0: loss = 0.00326971 (* 1 = 0.00326971 loss)
I0429 12:03:52.400817  3523 sgd_solver.cpp:106] Iteration 18000, lr = 0.00461989
I0429 12:03:52.567911  3523 solver.cpp:237] Iteration 18100, loss = 0.0015296
I0429 12:03:52.567937  3523 solver.cpp:253]     Train net output #0: loss = 0.00152951 (* 1 = 0.00152951 loss)
I0429 12:03:52.567942  3523 sgd_solver.cpp:106] Iteration 18100, lr = 0.00460755
I0429 12:03:52.735613  3523 solver.cpp:237] Iteration 18200, loss = 0.00397291
I0429 12:03:52.735636  3523 solver.cpp:253]     Train net output #0: loss = 0.00397282 (* 1 = 0.00397282 loss)
I0429 12:03:52.735642  3523 sgd_solver.cpp:106] Iteration 18200, lr = 0.00459529
I0429 12:03:52.903208  3523 solver.cpp:237] Iteration 18300, loss = 0.00393397
I0429 12:03:52.903230  3523 solver.cpp:253]     Train net output #0: loss = 0.00393387 (* 1 = 0.00393387 loss)
I0429 12:03:52.903235  3523 sgd_solver.cpp:106] Iteration 18300, lr = 0.00458311
I0429 12:03:53.071012  3523 solver.cpp:237] Iteration 18400, loss = 0.00277318
I0429 12:03:53.071040  3523 solver.cpp:253]     Train net output #0: loss = 0.00277308 (* 1 = 0.00277308 loss)
I0429 12:03:53.071048  3523 sgd_solver.cpp:106] Iteration 18400, lr = 0.004571
I0429 12:03:53.238040  3523 solver.cpp:237] Iteration 18500, loss = 0.000879642
I0429 12:03:53.238062  3523 solver.cpp:253]     Train net output #0: loss = 0.000879547 (* 1 = 0.000879547 loss)
I0429 12:03:53.238067  3523 sgd_solver.cpp:106] Iteration 18500, lr = 0.00455897
I0429 12:03:53.406352  3523 solver.cpp:237] Iteration 18600, loss = 0.00266525
I0429 12:03:53.406373  3523 solver.cpp:253]     Train net output #0: loss = 0.00266516 (* 1 = 0.00266516 loss)
I0429 12:03:53.406378  3523 sgd_solver.cpp:106] Iteration 18600, lr = 0.00454701
I0429 12:03:53.573844  3523 solver.cpp:237] Iteration 18700, loss = 0.00595759
I0429 12:03:53.573866  3523 solver.cpp:253]     Train net output #0: loss = 0.0059575 (* 1 = 0.0059575 loss)
I0429 12:03:53.573873  3523 sgd_solver.cpp:106] Iteration 18700, lr = 0.00453512
I0429 12:03:53.740996  3523 solver.cpp:237] Iteration 18800, loss = 0.00331382
I0429 12:03:53.741020  3523 solver.cpp:253]     Train net output #0: loss = 0.00331373 (* 1 = 0.00331373 loss)
I0429 12:03:53.741026  3523 sgd_solver.cpp:106] Iteration 18800, lr = 0.0045233
I0429 12:03:53.908920  3523 solver.cpp:237] Iteration 18900, loss = 0.0025317
I0429 12:03:53.908941  3523 solver.cpp:253]     Train net output #0: loss = 0.0025316 (* 1 = 0.0025316 loss)
I0429 12:03:53.908946  3523 sgd_solver.cpp:106] Iteration 18900, lr = 0.00451156
I0429 12:03:54.076580  3523 solver.cpp:237] Iteration 19000, loss = 0.00377041
I0429 12:03:54.076601  3523 solver.cpp:253]     Train net output #0: loss = 0.00377032 (* 1 = 0.00377032 loss)
I0429 12:03:54.076607  3523 sgd_solver.cpp:106] Iteration 19000, lr = 0.00449989
I0429 12:03:54.244089  3523 solver.cpp:237] Iteration 19100, loss = 0.00523357
I0429 12:03:54.244110  3523 solver.cpp:253]     Train net output #0: loss = 0.00523348 (* 1 = 0.00523348 loss)
I0429 12:03:54.244115  3523 sgd_solver.cpp:106] Iteration 19100, lr = 0.00448828
I0429 12:03:54.412006  3523 solver.cpp:237] Iteration 19200, loss = 0.00491118
I0429 12:03:54.412029  3523 solver.cpp:253]     Train net output #0: loss = 0.00491109 (* 1 = 0.00491109 loss)
I0429 12:03:54.412034  3523 sgd_solver.cpp:106] Iteration 19200, lr = 0.00447675
I0429 12:03:54.579670  3523 solver.cpp:237] Iteration 19300, loss = 0.00743687
I0429 12:03:54.579692  3523 solver.cpp:253]     Train net output #0: loss = 0.00743678 (* 1 = 0.00743678 loss)
I0429 12:03:54.579716  3523 sgd_solver.cpp:106] Iteration 19300, lr = 0.00446529
I0429 12:03:54.747087  3523 solver.cpp:237] Iteration 19400, loss = 0.00378657
I0429 12:03:54.747109  3523 solver.cpp:253]     Train net output #0: loss = 0.00378649 (* 1 = 0.00378649 loss)
I0429 12:03:54.747115  3523 sgd_solver.cpp:106] Iteration 19400, lr = 0.00445389
I0429 12:03:54.914643  3523 solver.cpp:237] Iteration 19500, loss = 0.00189869
I0429 12:03:54.914665  3523 solver.cpp:253]     Train net output #0: loss = 0.0018986 (* 1 = 0.0018986 loss)
I0429 12:03:54.914672  3523 sgd_solver.cpp:106] Iteration 19500, lr = 0.00444256
I0429 12:03:55.081974  3523 solver.cpp:237] Iteration 19600, loss = 0.00218548
I0429 12:03:55.081996  3523 solver.cpp:253]     Train net output #0: loss = 0.0021854 (* 1 = 0.0021854 loss)
I0429 12:03:55.082002  3523 sgd_solver.cpp:106] Iteration 19600, lr = 0.0044313
I0429 12:03:55.249371  3523 solver.cpp:237] Iteration 19700, loss = 0.00257393
I0429 12:03:55.249392  3523 solver.cpp:253]     Train net output #0: loss = 0.00257384 (* 1 = 0.00257384 loss)
I0429 12:03:55.249397  3523 sgd_solver.cpp:106] Iteration 19700, lr = 0.00442011
I0429 12:03:55.417145  3523 solver.cpp:237] Iteration 19800, loss = 0.006525
I0429 12:03:55.417168  3523 solver.cpp:253]     Train net output #0: loss = 0.00652491 (* 1 = 0.00652491 loss)
I0429 12:03:55.417173  3523 sgd_solver.cpp:106] Iteration 19800, lr = 0.00440898
I0429 12:03:55.584115  3523 solver.cpp:237] Iteration 19900, loss = 0.00188263
I0429 12:03:55.584141  3523 solver.cpp:253]     Train net output #0: loss = 0.00188254 (* 1 = 0.00188254 loss)
I0429 12:03:55.584146  3523 sgd_solver.cpp:106] Iteration 19900, lr = 0.00439791
I0429 12:03:55.750584  3523 solver.cpp:341] Iteration 20000, Testing net (#0)
I0429 12:03:55.841255  3523 solver.cpp:409]     Test net output #0: accuracy = 0.9875
I0429 12:03:55.841280  3523 solver.cpp:409]     Test net output #1: loss = 0.0436444 (* 1 = 0.0436444 loss)
I0429 12:03:55.842010  3523 solver.cpp:237] Iteration 20000, loss = 0.00532616
I0429 12:03:55.842027  3523 solver.cpp:253]     Train net output #0: loss = 0.00532607 (* 1 = 0.00532607 loss)
I0429 12:03:55.842073  3523 sgd_solver.cpp:106] Iteration 20000, lr = 0.00438691
I0429 12:03:56.002797  3523 solver.cpp:237] Iteration 20100, loss = 0.0150825
I0429 12:03:56.002821  3523 solver.cpp:253]     Train net output #0: loss = 0.0150824 (* 1 = 0.0150824 loss)
I0429 12:03:56.002826  3523 sgd_solver.cpp:106] Iteration 20100, lr = 0.00437598
I0429 12:03:56.163522  3523 solver.cpp:237] Iteration 20200, loss = 0.00466608
I0429 12:03:56.163544  3523 solver.cpp:253]     Train net output #0: loss = 0.00466599 (* 1 = 0.00466599 loss)
I0429 12:03:56.163550  3523 sgd_solver.cpp:106] Iteration 20200, lr = 0.00436511
I0429 12:03:56.326437  3523 solver.cpp:237] Iteration 20300, loss = 0.00290916
I0429 12:03:56.326474  3523 solver.cpp:253]     Train net output #0: loss = 0.00290907 (* 1 = 0.00290907 loss)
I0429 12:03:56.326484  3523 sgd_solver.cpp:106] Iteration 20300, lr = 0.0043543
I0429 12:03:56.493340  3523 solver.cpp:237] Iteration 20400, loss = 0.00562242
I0429 12:03:56.493376  3523 solver.cpp:253]     Train net output #0: loss = 0.00562233 (* 1 = 0.00562233 loss)
I0429 12:03:56.493382  3523 sgd_solver.cpp:106] Iteration 20400, lr = 0.00434355
I0429 12:03:56.655447  3523 solver.cpp:237] Iteration 20500, loss = 0.00113655
I0429 12:03:56.655472  3523 solver.cpp:253]     Train net output #0: loss = 0.00113646 (* 1 = 0.00113646 loss)
I0429 12:03:56.655478  3523 sgd_solver.cpp:106] Iteration 20500, lr = 0.00433286
I0429 12:03:56.816844  3523 solver.cpp:237] Iteration 20600, loss = 0.000371544
I0429 12:03:56.816871  3523 solver.cpp:253]     Train net output #0: loss = 0.000371456 (* 1 = 0.000371456 loss)
I0429 12:03:56.816877  3523 sgd_solver.cpp:106] Iteration 20600, lr = 0.00432224
I0429 12:03:56.978798  3523 solver.cpp:237] Iteration 20700, loss = 0.000513019
I0429 12:03:56.978822  3523 solver.cpp:253]     Train net output #0: loss = 0.000512933 (* 1 = 0.000512933 loss)
I0429 12:03:56.978849  3523 sgd_solver.cpp:106] Iteration 20700, lr = 0.00431168
I0429 12:03:57.141340  3523 solver.cpp:237] Iteration 20800, loss = 0.0054674
I0429 12:03:57.141366  3523 solver.cpp:253]     Train net output #0: loss = 0.00546732 (* 1 = 0.00546732 loss)
I0429 12:03:57.141372  3523 sgd_solver.cpp:106] Iteration 20800, lr = 0.00430117
I0429 12:03:57.302543  3523 solver.cpp:237] Iteration 20900, loss = 0.00553275
I0429 12:03:57.302568  3523 solver.cpp:253]     Train net output #0: loss = 0.00553266 (* 1 = 0.00553266 loss)
I0429 12:03:57.302580  3523 sgd_solver.cpp:106] Iteration 20900, lr = 0.00429073
I0429 12:03:57.462644  3523 solver.cpp:237] Iteration 21000, loss = 0.00156362
I0429 12:03:57.462666  3523 solver.cpp:253]     Train net output #0: loss = 0.00156354 (* 1 = 0.00156354 loss)
I0429 12:03:57.462672  3523 sgd_solver.cpp:106] Iteration 21000, lr = 0.00428034
I0429 12:03:57.623587  3523 solver.cpp:237] Iteration 21100, loss = 0.00125973
I0429 12:03:57.623610  3523 solver.cpp:253]     Train net output #0: loss = 0.00125965 (* 1 = 0.00125965 loss)
I0429 12:03:57.623615  3523 sgd_solver.cpp:106] Iteration 21100, lr = 0.00427002
I0429 12:03:57.784533  3523 solver.cpp:237] Iteration 21200, loss = 0.00421926
I0429 12:03:57.784555  3523 solver.cpp:253]     Train net output #0: loss = 0.00421918 (* 1 = 0.00421918 loss)
I0429 12:03:57.784560  3523 sgd_solver.cpp:106] Iteration 21200, lr = 0.00425975
I0429 12:03:57.945510  3523 solver.cpp:237] Iteration 21300, loss = 0.00155111
I0429 12:03:57.945533  3523 solver.cpp:253]     Train net output #0: loss = 0.00155103 (* 1 = 0.00155103 loss)
I0429 12:03:57.945538  3523 sgd_solver.cpp:106] Iteration 21300, lr = 0.00424954
I0429 12:03:58.106529  3523 solver.cpp:237] Iteration 21400, loss = 0.0015772
I0429 12:03:58.106550  3523 solver.cpp:253]     Train net output #0: loss = 0.00157712 (* 1 = 0.00157712 loss)
I0429 12:03:58.106556  3523 sgd_solver.cpp:106] Iteration 21400, lr = 0.00423938
I0429 12:03:58.266996  3523 solver.cpp:237] Iteration 21500, loss = 0.00272747
I0429 12:03:58.267017  3523 solver.cpp:253]     Train net output #0: loss = 0.00272739 (* 1 = 0.00272739 loss)
I0429 12:03:58.267022  3523 sgd_solver.cpp:106] Iteration 21500, lr = 0.00422929
I0429 12:03:58.427659  3523 solver.cpp:237] Iteration 21600, loss = 0.00586715
I0429 12:03:58.427680  3523 solver.cpp:253]     Train net output #0: loss = 0.00586707 (* 1 = 0.00586707 loss)
I0429 12:03:58.427685  3523 sgd_solver.cpp:106] Iteration 21600, lr = 0.00421924
I0429 12:03:58.588367  3523 solver.cpp:237] Iteration 21700, loss = 0.00568505
I0429 12:03:58.588392  3523 solver.cpp:253]     Train net output #0: loss = 0.00568497 (* 1 = 0.00568497 loss)
I0429 12:03:58.588397  3523 sgd_solver.cpp:106] Iteration 21700, lr = 0.00420926
I0429 12:03:58.749658  3523 solver.cpp:237] Iteration 21800, loss = 0.00072016
I0429 12:03:58.749680  3523 solver.cpp:253]     Train net output #0: loss = 0.000720078 (* 1 = 0.000720078 loss)
I0429 12:03:58.749686  3523 sgd_solver.cpp:106] Iteration 21800, lr = 0.00419933
I0429 12:03:58.909590  3523 solver.cpp:237] Iteration 21900, loss = 0.00265629
I0429 12:03:58.909611  3523 solver.cpp:253]     Train net output #0: loss = 0.00265621 (* 1 = 0.00265621 loss)
I0429 12:03:58.909616  3523 sgd_solver.cpp:106] Iteration 21900, lr = 0.00418945
I0429 12:03:59.069957  3523 solver.cpp:237] Iteration 22000, loss = 0.00371237
I0429 12:03:59.069978  3523 solver.cpp:253]     Train net output #0: loss = 0.00371229 (* 1 = 0.00371229 loss)
I0429 12:03:59.069984  3523 sgd_solver.cpp:106] Iteration 22000, lr = 0.00417963
I0429 12:03:59.230000  3523 solver.cpp:237] Iteration 22100, loss = 0.0055679
I0429 12:03:59.230023  3523 solver.cpp:253]     Train net output #0: loss = 0.00556782 (* 1 = 0.00556782 loss)
I0429 12:03:59.230029  3523 sgd_solver.cpp:106] Iteration 22100, lr = 0.00416986
I0429 12:03:59.390527  3523 solver.cpp:237] Iteration 22200, loss = 0.00289382
I0429 12:03:59.390548  3523 solver.cpp:253]     Train net output #0: loss = 0.00289374 (* 1 = 0.00289374 loss)
I0429 12:03:59.390571  3523 sgd_solver.cpp:106] Iteration 22200, lr = 0.00416014
I0429 12:03:59.550832  3523 solver.cpp:237] Iteration 22300, loss = 0.00990685
I0429 12:03:59.550854  3523 solver.cpp:253]     Train net output #0: loss = 0.00990677 (* 1 = 0.00990677 loss)
I0429 12:03:59.550859  3523 sgd_solver.cpp:106] Iteration 22300, lr = 0.00415048
I0429 12:03:59.713968  3523 solver.cpp:237] Iteration 22400, loss = 0.00177221
I0429 12:03:59.714015  3523 solver.cpp:253]     Train net output #0: loss = 0.00177213 (* 1 = 0.00177213 loss)
I0429 12:03:59.714033  3523 sgd_solver.cpp:106] Iteration 22400, lr = 0.00414087
I0429 12:03:59.878551  3523 solver.cpp:237] Iteration 22500, loss = 0.00108102
I0429 12:03:59.878581  3523 solver.cpp:253]     Train net output #0: loss = 0.00108094 (* 1 = 0.00108094 loss)
I0429 12:03:59.878587  3523 sgd_solver.cpp:106] Iteration 22500, lr = 0.00413131
I0429 12:04:00.040915  3523 solver.cpp:237] Iteration 22600, loss = 0.00422546
I0429 12:04:00.040940  3523 solver.cpp:253]     Train net output #0: loss = 0.00422538 (* 1 = 0.00422538 loss)
I0429 12:04:00.040953  3523 sgd_solver.cpp:106] Iteration 22600, lr = 0.0041218
I0429 12:04:00.203114  3523 solver.cpp:237] Iteration 22700, loss = 0.00423025
I0429 12:04:00.203138  3523 solver.cpp:253]     Train net output #0: loss = 0.00423016 (* 1 = 0.00423016 loss)
I0429 12:04:00.203145  3523 sgd_solver.cpp:106] Iteration 22700, lr = 0.00411234
I0429 12:04:00.365023  3523 solver.cpp:237] Iteration 22800, loss = 0.00132996
I0429 12:04:00.365048  3523 solver.cpp:253]     Train net output #0: loss = 0.00132988 (* 1 = 0.00132988 loss)
I0429 12:04:00.365056  3523 sgd_solver.cpp:106] Iteration 22800, lr = 0.00410293
I0429 12:04:00.525874  3523 solver.cpp:237] Iteration 22900, loss = 0.00230716
I0429 12:04:00.525898  3523 solver.cpp:253]     Train net output #0: loss = 0.00230708 (* 1 = 0.00230708 loss)
I0429 12:04:00.525907  3523 sgd_solver.cpp:106] Iteration 22900, lr = 0.00409358
I0429 12:04:00.686980  3523 solver.cpp:237] Iteration 23000, loss = 0.00575299
I0429 12:04:00.687001  3523 solver.cpp:253]     Train net output #0: loss = 0.00575291 (* 1 = 0.00575291 loss)
I0429 12:04:00.687007  3523 sgd_solver.cpp:106] Iteration 23000, lr = 0.00408427
I0429 12:04:00.848117  3523 solver.cpp:237] Iteration 23100, loss = 0.00823414
I0429 12:04:00.848140  3523 solver.cpp:253]     Train net output #0: loss = 0.00823407 (* 1 = 0.00823407 loss)
I0429 12:04:00.848145  3523 sgd_solver.cpp:106] Iteration 23100, lr = 0.00407501
I0429 12:04:01.008350  3523 solver.cpp:237] Iteration 23200, loss = 0.00228882
I0429 12:04:01.008371  3523 solver.cpp:253]     Train net output #0: loss = 0.00228875 (* 1 = 0.00228875 loss)
I0429 12:04:01.008378  3523 sgd_solver.cpp:106] Iteration 23200, lr = 0.0040658
I0429 12:04:01.169338  3523 solver.cpp:237] Iteration 23300, loss = 0.00565944
I0429 12:04:01.169359  3523 solver.cpp:253]     Train net output #0: loss = 0.00565936 (* 1 = 0.00565936 loss)
I0429 12:04:01.169365  3523 sgd_solver.cpp:106] Iteration 23300, lr = 0.00405664
I0429 12:04:01.329219  3523 solver.cpp:237] Iteration 23400, loss = 0.00660455
I0429 12:04:01.329241  3523 solver.cpp:253]     Train net output #0: loss = 0.00660447 (* 1 = 0.00660447 loss)
I0429 12:04:01.329246  3523 sgd_solver.cpp:106] Iteration 23400, lr = 0.00404753
I0429 12:04:01.491000  3523 solver.cpp:237] Iteration 23500, loss = 0.00238182
I0429 12:04:01.491025  3523 solver.cpp:253]     Train net output #0: loss = 0.00238174 (* 1 = 0.00238174 loss)
I0429 12:04:01.491031  3523 sgd_solver.cpp:106] Iteration 23500, lr = 0.00403847
I0429 12:04:01.652325  3523 solver.cpp:237] Iteration 23600, loss = 0.000825229
I0429 12:04:01.652354  3523 solver.cpp:253]     Train net output #0: loss = 0.000825145 (* 1 = 0.000825145 loss)
I0429 12:04:01.652359  3523 sgd_solver.cpp:106] Iteration 23600, lr = 0.00402945
I0429 12:04:01.811980  3523 solver.cpp:237] Iteration 23700, loss = 0.00142672
I0429 12:04:01.812000  3523 solver.cpp:253]     Train net output #0: loss = 0.00142664 (* 1 = 0.00142664 loss)
I0429 12:04:01.812006  3523 sgd_solver.cpp:106] Iteration 23700, lr = 0.00402048
I0429 12:04:01.972331  3523 solver.cpp:237] Iteration 23800, loss = 0.000742502
I0429 12:04:01.972352  3523 solver.cpp:253]     Train net output #0: loss = 0.000742419 (* 1 = 0.000742419 loss)
I0429 12:04:01.972357  3523 sgd_solver.cpp:106] Iteration 23800, lr = 0.00401155
I0429 12:04:02.132858  3523 solver.cpp:237] Iteration 23900, loss = 0.000897505
I0429 12:04:02.132880  3523 solver.cpp:253]     Train net output #0: loss = 0.000897421 (* 1 = 0.000897421 loss)
I0429 12:04:02.132887  3523 sgd_solver.cpp:106] Iteration 23900, lr = 0.00400267
I0429 12:04:02.292889  3523 solver.cpp:237] Iteration 24000, loss = 0.00446433
I0429 12:04:02.292914  3523 solver.cpp:253]     Train net output #0: loss = 0.00446425 (* 1 = 0.00446425 loss)
I0429 12:04:02.292920  3523 sgd_solver.cpp:106] Iteration 24000, lr = 0.00399384
I0429 12:04:02.452814  3523 solver.cpp:237] Iteration 24100, loss = 0.00511985
I0429 12:04:02.452836  3523 solver.cpp:253]     Train net output #0: loss = 0.00511976 (* 1 = 0.00511976 loss)
I0429 12:04:02.452841  3523 sgd_solver.cpp:106] Iteration 24100, lr = 0.00398505
I0429 12:04:02.613121  3523 solver.cpp:237] Iteration 24200, loss = 0.00275814
I0429 12:04:02.613148  3523 solver.cpp:253]     Train net output #0: loss = 0.00275806 (* 1 = 0.00275806 loss)
I0429 12:04:02.613154  3523 sgd_solver.cpp:106] Iteration 24200, lr = 0.00397631
I0429 12:04:02.773270  3523 solver.cpp:237] Iteration 24300, loss = 0.00202725
I0429 12:04:02.773294  3523 solver.cpp:253]     Train net output #0: loss = 0.00202716 (* 1 = 0.00202716 loss)
I0429 12:04:02.773300  3523 sgd_solver.cpp:106] Iteration 24300, lr = 0.00396761
I0429 12:04:02.934298  3523 solver.cpp:237] Iteration 24400, loss = 0.00659098
I0429 12:04:02.934320  3523 solver.cpp:253]     Train net output #0: loss = 0.0065909 (* 1 = 0.0065909 loss)
I0429 12:04:02.934326  3523 sgd_solver.cpp:106] Iteration 24400, lr = 0.00395896
I0429 12:04:03.094836  3523 solver.cpp:237] Iteration 24500, loss = 0.00261571
I0429 12:04:03.094859  3523 solver.cpp:253]     Train net output #0: loss = 0.00261563 (* 1 = 0.00261563 loss)
I0429 12:04:03.094864  3523 sgd_solver.cpp:106] Iteration 24500, lr = 0.00395035
I0429 12:04:03.255712  3523 solver.cpp:237] Iteration 24600, loss = 0.000898657
I0429 12:04:03.255738  3523 solver.cpp:253]     Train net output #0: loss = 0.000898579 (* 1 = 0.000898579 loss)
I0429 12:04:03.255743  3523 sgd_solver.cpp:106] Iteration 24600, lr = 0.00394178
I0429 12:04:03.416254  3523 solver.cpp:237] Iteration 24700, loss = 0.00114364
I0429 12:04:03.416275  3523 solver.cpp:253]     Train net output #0: loss = 0.00114356 (* 1 = 0.00114356 loss)
I0429 12:04:03.416281  3523 sgd_solver.cpp:106] Iteration 24700, lr = 0.00393326
I0429 12:04:03.576539  3523 solver.cpp:237] Iteration 24800, loss = 0.00763215
I0429 12:04:03.576560  3523 solver.cpp:253]     Train net output #0: loss = 0.00763208 (* 1 = 0.00763208 loss)
I0429 12:04:03.576565  3523 sgd_solver.cpp:106] Iteration 24800, lr = 0.00392478
I0429 12:04:03.737260  3523 solver.cpp:237] Iteration 24900, loss = 0.00159691
I0429 12:04:03.737283  3523 solver.cpp:253]     Train net output #0: loss = 0.00159684 (* 1 = 0.00159684 loss)
I0429 12:04:03.737289  3523 sgd_solver.cpp:106] Iteration 24900, lr = 0.00391634
I0429 12:04:03.896359  3523 solver.cpp:341] Iteration 25000, Testing net (#0)
I0429 12:04:03.979430  3523 solver.cpp:409]     Test net output #0: accuracy = 0.9873
I0429 12:04:03.979457  3523 solver.cpp:409]     Test net output #1: loss = 0.0425849 (* 1 = 0.0425849 loss)
I0429 12:04:03.980176  3523 solver.cpp:237] Iteration 25000, loss = 0.000917344
I0429 12:04:03.980193  3523 solver.cpp:253]     Train net output #0: loss = 0.000917269 (* 1 = 0.000917269 loss)
I0429 12:04:03.980206  3523 sgd_solver.cpp:106] Iteration 25000, lr = 0.00390795
I0429 12:04:04.140666  3523 solver.cpp:237] Iteration 25100, loss = 0.00672764
I0429 12:04:04.140688  3523 solver.cpp:253]     Train net output #0: loss = 0.00672756 (* 1 = 0.00672756 loss)
I0429 12:04:04.140693  3523 sgd_solver.cpp:106] Iteration 25100, lr = 0.0038996
I0429 12:04:04.301388  3523 solver.cpp:237] Iteration 25200, loss = 0.00685483
I0429 12:04:04.301414  3523 solver.cpp:253]     Train net output #0: loss = 0.00685476 (* 1 = 0.00685476 loss)
I0429 12:04:04.301420  3523 sgd_solver.cpp:106] Iteration 25200, lr = 0.00389128
I0429 12:04:04.463218  3523 solver.cpp:237] Iteration 25300, loss = 0.000447422
I0429 12:04:04.463244  3523 solver.cpp:253]     Train net output #0: loss = 0.000447349 (* 1 = 0.000447349 loss)
I0429 12:04:04.463250  3523 sgd_solver.cpp:106] Iteration 25300, lr = 0.00388301
I0429 12:04:04.625102  3523 solver.cpp:237] Iteration 25400, loss = 0.00307785
I0429 12:04:04.625125  3523 solver.cpp:253]     Train net output #0: loss = 0.00307778 (* 1 = 0.00307778 loss)
I0429 12:04:04.625130  3523 sgd_solver.cpp:106] Iteration 25400, lr = 0.00387478
I0429 12:04:04.787061  3523 solver.cpp:237] Iteration 25500, loss = 0.00341965
I0429 12:04:04.787084  3523 solver.cpp:253]     Train net output #0: loss = 0.00341958 (* 1 = 0.00341958 loss)
I0429 12:04:04.787089  3523 sgd_solver.cpp:106] Iteration 25500, lr = 0.0038666
I0429 12:04:04.949734  3523 solver.cpp:237] Iteration 25600, loss = 0.00162119
I0429 12:04:04.949758  3523 solver.cpp:253]     Train net output #0: loss = 0.00162112 (* 1 = 0.00162112 loss)
I0429 12:04:04.949762  3523 sgd_solver.cpp:106] Iteration 25600, lr = 0.00385845
I0429 12:04:05.112505  3523 solver.cpp:237] Iteration 25700, loss = 0.00426631
I0429 12:04:05.112526  3523 solver.cpp:253]     Train net output #0: loss = 0.00426624 (* 1 = 0.00426624 loss)
I0429 12:04:05.112532  3523 sgd_solver.cpp:106] Iteration 25700, lr = 0.00385034
I0429 12:04:05.275501  3523 solver.cpp:237] Iteration 25800, loss = 0.00437817
I0429 12:04:05.275521  3523 solver.cpp:253]     Train net output #0: loss = 0.00437809 (* 1 = 0.00437809 loss)
I0429 12:04:05.275527  3523 sgd_solver.cpp:106] Iteration 25800, lr = 0.00384227
I0429 12:04:05.437491  3523 solver.cpp:237] Iteration 25900, loss = 0.00253435
I0429 12:04:05.437513  3523 solver.cpp:253]     Train net output #0: loss = 0.00253428 (* 1 = 0.00253428 loss)
I0429 12:04:05.437520  3523 sgd_solver.cpp:106] Iteration 25900, lr = 0.00383424
I0429 12:04:05.600075  3523 solver.cpp:237] Iteration 26000, loss = 0.000925913
I0429 12:04:05.600097  3523 solver.cpp:253]     Train net output #0: loss = 0.000925838 (* 1 = 0.000925838 loss)
I0429 12:04:05.600102  3523 sgd_solver.cpp:106] Iteration 26000, lr = 0.00382625
I0429 12:04:05.761880  3523 solver.cpp:237] Iteration 26100, loss = 0.00324956
I0429 12:04:05.761904  3523 solver.cpp:253]     Train net output #0: loss = 0.00324949 (* 1 = 0.00324949 loss)
I0429 12:04:05.761910  3523 sgd_solver.cpp:106] Iteration 26100, lr = 0.0038183
I0429 12:04:05.923720  3523 solver.cpp:237] Iteration 26200, loss = 0.00576037
I0429 12:04:05.923744  3523 solver.cpp:253]     Train net output #0: loss = 0.00576029 (* 1 = 0.00576029 loss)
I0429 12:04:05.923749  3523 sgd_solver.cpp:106] Iteration 26200, lr = 0.00381038
I0429 12:04:06.085347  3523 solver.cpp:237] Iteration 26300, loss = 0.00388002
I0429 12:04:06.085369  3523 solver.cpp:253]     Train net output #0: loss = 0.00387994 (* 1 = 0.00387994 loss)
I0429 12:04:06.085379  3523 sgd_solver.cpp:106] Iteration 26300, lr = 0.00380251
I0429 12:04:06.248082  3523 solver.cpp:237] Iteration 26400, loss = 0.00248141
I0429 12:04:06.248103  3523 solver.cpp:253]     Train net output #0: loss = 0.00248133 (* 1 = 0.00248133 loss)
I0429 12:04:06.248116  3523 sgd_solver.cpp:106] Iteration 26400, lr = 0.00379467
I0429 12:04:06.409873  3523 solver.cpp:237] Iteration 26500, loss = 0.00360629
I0429 12:04:06.409893  3523 solver.cpp:253]     Train net output #0: loss = 0.00360622 (* 1 = 0.00360622 loss)
I0429 12:04:06.409910  3523 sgd_solver.cpp:106] Iteration 26500, lr = 0.00378687
I0429 12:04:06.573935  3523 solver.cpp:237] Iteration 26600, loss = 0.00453821
I0429 12:04:06.573971  3523 solver.cpp:253]     Train net output #0: loss = 0.00453814 (* 1 = 0.00453814 loss)
I0429 12:04:06.573982  3523 sgd_solver.cpp:106] Iteration 26600, lr = 0.00377911
I0429 12:04:06.738692  3523 solver.cpp:237] Iteration 26700, loss = 0.00443474
I0429 12:04:06.738719  3523 solver.cpp:253]     Train net output #0: loss = 0.00443466 (* 1 = 0.00443466 loss)
I0429 12:04:06.738726  3523 sgd_solver.cpp:106] Iteration 26700, lr = 0.00377138
I0429 12:04:06.901954  3523 solver.cpp:237] Iteration 26800, loss = 0.00737272
I0429 12:04:06.901978  3523 solver.cpp:253]     Train net output #0: loss = 0.00737265 (* 1 = 0.00737265 loss)
I0429 12:04:06.901984  3523 sgd_solver.cpp:106] Iteration 26800, lr = 0.00376369
I0429 12:04:07.065035  3523 solver.cpp:237] Iteration 26900, loss = 0.00375435
I0429 12:04:07.065059  3523 solver.cpp:253]     Train net output #0: loss = 0.00375428 (* 1 = 0.00375428 loss)
I0429 12:04:07.065065  3523 sgd_solver.cpp:106] Iteration 26900, lr = 0.00375604
I0429 12:04:07.228749  3523 solver.cpp:237] Iteration 27000, loss = 0.00196411
I0429 12:04:07.228773  3523 solver.cpp:253]     Train net output #0: loss = 0.00196403 (* 1 = 0.00196403 loss)
I0429 12:04:07.228780  3523 sgd_solver.cpp:106] Iteration 27000, lr = 0.00374842
I0429 12:04:07.392436  3523 solver.cpp:237] Iteration 27100, loss = 0.00193868
I0429 12:04:07.392465  3523 solver.cpp:253]     Train net output #0: loss = 0.00193861 (* 1 = 0.00193861 loss)
I0429 12:04:07.392472  3523 sgd_solver.cpp:106] Iteration 27100, lr = 0.00374084
I0429 12:04:07.555624  3523 solver.cpp:237] Iteration 27200, loss = 0.00219376
I0429 12:04:07.555652  3523 solver.cpp:253]     Train net output #0: loss = 0.00219369 (* 1 = 0.00219369 loss)
I0429 12:04:07.555658  3523 sgd_solver.cpp:106] Iteration 27200, lr = 0.0037333
I0429 12:04:07.718386  3523 solver.cpp:237] Iteration 27300, loss = 0.00618421
I0429 12:04:07.718408  3523 solver.cpp:253]     Train net output #0: loss = 0.00618414 (* 1 = 0.00618414 loss)
I0429 12:04:07.718415  3523 sgd_solver.cpp:106] Iteration 27300, lr = 0.00372579
I0429 12:04:07.880760  3523 solver.cpp:237] Iteration 27400, loss = 0.00174265
I0429 12:04:07.880782  3523 solver.cpp:253]     Train net output #0: loss = 0.00174258 (* 1 = 0.00174258 loss)
I0429 12:04:07.880789  3523 sgd_solver.cpp:106] Iteration 27400, lr = 0.00371832
I0429 12:04:08.044239  3523 solver.cpp:237] Iteration 27500, loss = 0.00504227
I0429 12:04:08.044261  3523 solver.cpp:253]     Train net output #0: loss = 0.0050422 (* 1 = 0.0050422 loss)
I0429 12:04:08.044266  3523 sgd_solver.cpp:106] Iteration 27500, lr = 0.00371088
I0429 12:04:08.207693  3523 solver.cpp:237] Iteration 27600, loss = 0.013486
I0429 12:04:08.207717  3523 solver.cpp:253]     Train net output #0: loss = 0.013486 (* 1 = 0.013486 loss)
I0429 12:04:08.207733  3523 sgd_solver.cpp:106] Iteration 27600, lr = 0.00370347
I0429 12:04:08.368969  3523 solver.cpp:237] Iteration 27700, loss = 0.00512856
I0429 12:04:08.368991  3523 solver.cpp:253]     Train net output #0: loss = 0.00512848 (* 1 = 0.00512848 loss)
I0429 12:04:08.368996  3523 sgd_solver.cpp:106] Iteration 27700, lr = 0.0036961
I0429 12:04:08.531189  3523 solver.cpp:237] Iteration 27800, loss = 0.00303874
I0429 12:04:08.531210  3523 solver.cpp:253]     Train net output #0: loss = 0.00303867 (* 1 = 0.00303867 loss)
I0429 12:04:08.531216  3523 sgd_solver.cpp:106] Iteration 27800, lr = 0.00368877
I0429 12:04:08.699532  3523 solver.cpp:237] Iteration 27900, loss = 0.00592325
I0429 12:04:08.699564  3523 solver.cpp:253]     Train net output #0: loss = 0.00592317 (* 1 = 0.00592317 loss)
I0429 12:04:08.699574  3523 sgd_solver.cpp:106] Iteration 27900, lr = 0.00368146
I0429 12:04:08.863554  3523 solver.cpp:237] Iteration 28000, loss = 0.00114359
I0429 12:04:08.863579  3523 solver.cpp:253]     Train net output #0: loss = 0.00114352 (* 1 = 0.00114352 loss)
I0429 12:04:08.863584  3523 sgd_solver.cpp:106] Iteration 28000, lr = 0.0036742
I0429 12:04:09.026377  3523 solver.cpp:237] Iteration 28100, loss = 0.000402263
I0429 12:04:09.026401  3523 solver.cpp:253]     Train net output #0: loss = 0.00040219 (* 1 = 0.00040219 loss)
I0429 12:04:09.026407  3523 sgd_solver.cpp:106] Iteration 28100, lr = 0.00366696
I0429 12:04:09.190330  3523 solver.cpp:237] Iteration 28200, loss = 0.000596872
I0429 12:04:09.190373  3523 solver.cpp:253]     Train net output #0: loss = 0.000596796 (* 1 = 0.000596796 loss)
I0429 12:04:09.190382  3523 sgd_solver.cpp:106] Iteration 28200, lr = 0.00365976
I0429 12:04:09.353718  3523 solver.cpp:237] Iteration 28300, loss = 0.00534934
I0429 12:04:09.353740  3523 solver.cpp:253]     Train net output #0: loss = 0.00534926 (* 1 = 0.00534926 loss)
I0429 12:04:09.353747  3523 sgd_solver.cpp:106] Iteration 28300, lr = 0.00365259
I0429 12:04:09.517022  3523 solver.cpp:237] Iteration 28400, loss = 0.00536181
I0429 12:04:09.517048  3523 solver.cpp:253]     Train net output #0: loss = 0.00536173 (* 1 = 0.00536173 loss)
I0429 12:04:09.517055  3523 sgd_solver.cpp:106] Iteration 28400, lr = 0.00364545
I0429 12:04:09.680447  3523 solver.cpp:237] Iteration 28500, loss = 0.0015224
I0429 12:04:09.680471  3523 solver.cpp:253]     Train net output #0: loss = 0.00152233 (* 1 = 0.00152233 loss)
I0429 12:04:09.680477  3523 sgd_solver.cpp:106] Iteration 28500, lr = 0.00363835
I0429 12:04:09.843272  3523 solver.cpp:237] Iteration 28600, loss = 0.00139385
I0429 12:04:09.843293  3523 solver.cpp:253]     Train net output #0: loss = 0.00139376 (* 1 = 0.00139376 loss)
I0429 12:04:09.843299  3523 sgd_solver.cpp:106] Iteration 28600, lr = 0.00363128
I0429 12:04:10.005753  3523 solver.cpp:237] Iteration 28700, loss = 0.00401314
I0429 12:04:10.005774  3523 solver.cpp:253]     Train net output #0: loss = 0.00401305 (* 1 = 0.00401305 loss)
I0429 12:04:10.005780  3523 sgd_solver.cpp:106] Iteration 28700, lr = 0.00362424
I0429 12:04:10.167796  3523 solver.cpp:237] Iteration 28800, loss = 0.001615
I0429 12:04:10.167819  3523 solver.cpp:253]     Train net output #0: loss = 0.00161492 (* 1 = 0.00161492 loss)
I0429 12:04:10.167824  3523 sgd_solver.cpp:106] Iteration 28800, lr = 0.00361723
I0429 12:04:10.330008  3523 solver.cpp:237] Iteration 28900, loss = 0.00157806
I0429 12:04:10.330029  3523 solver.cpp:253]     Train net output #0: loss = 0.00157797 (* 1 = 0.00157797 loss)
I0429 12:04:10.330035  3523 sgd_solver.cpp:106] Iteration 28900, lr = 0.00361025
I0429 12:04:10.492563  3523 solver.cpp:237] Iteration 29000, loss = 0.00269707
I0429 12:04:10.492588  3523 solver.cpp:253]     Train net output #0: loss = 0.00269698 (* 1 = 0.00269698 loss)
I0429 12:04:10.492594  3523 sgd_solver.cpp:106] Iteration 29000, lr = 0.00360331
I0429 12:04:10.655997  3523 solver.cpp:237] Iteration 29100, loss = 0.00614002
I0429 12:04:10.656018  3523 solver.cpp:253]     Train net output #0: loss = 0.00613994 (* 1 = 0.00613994 loss)
I0429 12:04:10.656023  3523 sgd_solver.cpp:106] Iteration 29100, lr = 0.0035964
I0429 12:04:10.819394  3523 solver.cpp:237] Iteration 29200, loss = 0.00551835
I0429 12:04:10.819417  3523 solver.cpp:253]     Train net output #0: loss = 0.00551826 (* 1 = 0.00551826 loss)
I0429 12:04:10.819423  3523 sgd_solver.cpp:106] Iteration 29200, lr = 0.00358951
I0429 12:04:10.982313  3523 solver.cpp:237] Iteration 29300, loss = 0.0010332
I0429 12:04:10.982337  3523 solver.cpp:253]     Train net output #0: loss = 0.00103311 (* 1 = 0.00103311 loss)
I0429 12:04:10.982345  3523 sgd_solver.cpp:106] Iteration 29300, lr = 0.00358266
I0429 12:04:11.144577  3523 solver.cpp:237] Iteration 29400, loss = 0.00308188
I0429 12:04:11.144598  3523 solver.cpp:253]     Train net output #0: loss = 0.00308178 (* 1 = 0.00308178 loss)
I0429 12:04:11.144603  3523 sgd_solver.cpp:106] Iteration 29400, lr = 0.00357584
I0429 12:04:11.306282  3523 solver.cpp:237] Iteration 29500, loss = 0.00371183
I0429 12:04:11.306304  3523 solver.cpp:253]     Train net output #0: loss = 0.00371174 (* 1 = 0.00371174 loss)
I0429 12:04:11.306310  3523 sgd_solver.cpp:106] Iteration 29500, lr = 0.00356905
I0429 12:04:11.468443  3523 solver.cpp:237] Iteration 29600, loss = 0.00573268
I0429 12:04:11.468464  3523 solver.cpp:253]     Train net output #0: loss = 0.00573259 (* 1 = 0.00573259 loss)
I0429 12:04:11.468469  3523 sgd_solver.cpp:106] Iteration 29600, lr = 0.00356228
I0429 12:04:11.630823  3523 solver.cpp:237] Iteration 29700, loss = 0.00292567
I0429 12:04:11.630861  3523 solver.cpp:253]     Train net output #0: loss = 0.00292558 (* 1 = 0.00292558 loss)
I0429 12:04:11.630868  3523 sgd_solver.cpp:106] Iteration 29700, lr = 0.00355555
I0429 12:04:11.793401  3523 solver.cpp:237] Iteration 29800, loss = 0.00955791
I0429 12:04:11.793424  3523 solver.cpp:253]     Train net output #0: loss = 0.00955782 (* 1 = 0.00955782 loss)
I0429 12:04:11.793431  3523 sgd_solver.cpp:106] Iteration 29800, lr = 0.00354885
I0429 12:04:11.955714  3523 solver.cpp:237] Iteration 29900, loss = 0.00181087
I0429 12:04:11.955739  3523 solver.cpp:253]     Train net output #0: loss = 0.00181078 (* 1 = 0.00181078 loss)
I0429 12:04:11.955761  3523 sgd_solver.cpp:106] Iteration 29900, lr = 0.00354218
I0429 12:04:12.116091  3523 solver.cpp:341] Iteration 30000, Testing net (#0)
I0429 12:04:12.201042  3523 solver.cpp:409]     Test net output #0: accuracy = 0.9875
I0429 12:04:12.201069  3523 solver.cpp:409]     Test net output #1: loss = 0.0436274 (* 1 = 0.0436274 loss)
I0429 12:04:12.201797  3523 solver.cpp:237] Iteration 30000, loss = 0.00107856
I0429 12:04:12.201813  3523 solver.cpp:253]     Train net output #0: loss = 0.00107847 (* 1 = 0.00107847 loss)
I0429 12:04:12.201831  3523 sgd_solver.cpp:106] Iteration 30000, lr = 0.00353553
I0429 12:04:12.371137  3523 solver.cpp:237] Iteration 30100, loss = 0.00422337
I0429 12:04:12.371160  3523 solver.cpp:253]     Train net output #0: loss = 0.00422327 (* 1 = 0.00422327 loss)
I0429 12:04:12.371166  3523 sgd_solver.cpp:106] Iteration 30100, lr = 0.00352892
I0429 12:04:12.540689  3523 solver.cpp:237] Iteration 30200, loss = 0.00424656
I0429 12:04:12.540712  3523 solver.cpp:253]     Train net output #0: loss = 0.00424647 (* 1 = 0.00424647 loss)
I0429 12:04:12.540719  3523 sgd_solver.cpp:106] Iteration 30200, lr = 0.00352233
I0429 12:04:12.709714  3523 solver.cpp:237] Iteration 30300, loss = 0.00147837
I0429 12:04:12.709754  3523 solver.cpp:253]     Train net output #0: loss = 0.00147828 (* 1 = 0.00147828 loss)
I0429 12:04:12.709766  3523 sgd_solver.cpp:106] Iteration 30300, lr = 0.00351578
I0429 12:04:12.878337  3523 solver.cpp:237] Iteration 30400, loss = 0.00236401
I0429 12:04:12.878360  3523 solver.cpp:253]     Train net output #0: loss = 0.00236392 (* 1 = 0.00236392 loss)
I0429 12:04:12.878365  3523 sgd_solver.cpp:106] Iteration 30400, lr = 0.00350925
I0429 12:04:13.046269  3523 solver.cpp:237] Iteration 30500, loss = 0.00567121
I0429 12:04:13.046291  3523 solver.cpp:253]     Train net output #0: loss = 0.00567112 (* 1 = 0.00567112 loss)
I0429 12:04:13.046298  3523 sgd_solver.cpp:106] Iteration 30500, lr = 0.00350275
I0429 12:04:13.215812  3523 solver.cpp:237] Iteration 30600, loss = 0.00844152
I0429 12:04:13.215838  3523 solver.cpp:253]     Train net output #0: loss = 0.00844143 (* 1 = 0.00844143 loss)
I0429 12:04:13.215852  3523 sgd_solver.cpp:106] Iteration 30600, lr = 0.00349627
I0429 12:04:13.384675  3523 solver.cpp:237] Iteration 30700, loss = 0.00246295
I0429 12:04:13.384699  3523 solver.cpp:253]     Train net output #0: loss = 0.00246286 (* 1 = 0.00246286 loss)
I0429 12:04:13.384706  3523 sgd_solver.cpp:106] Iteration 30700, lr = 0.00348983
I0429 12:04:13.553894  3523 solver.cpp:237] Iteration 30800, loss = 0.00630538
I0429 12:04:13.553922  3523 solver.cpp:253]     Train net output #0: loss = 0.0063053 (* 1 = 0.0063053 loss)
I0429 12:04:13.553928  3523 sgd_solver.cpp:106] Iteration 30800, lr = 0.00348341
I0429 12:04:13.723961  3523 solver.cpp:237] Iteration 30900, loss = 0.00565683
I0429 12:04:13.723984  3523 solver.cpp:253]     Train net output #0: loss = 0.00565674 (* 1 = 0.00565674 loss)
I0429 12:04:13.723990  3523 sgd_solver.cpp:106] Iteration 30900, lr = 0.00347702
I0429 12:04:13.893362  3523 solver.cpp:237] Iteration 31000, loss = 0.0026066
I0429 12:04:13.893383  3523 solver.cpp:253]     Train net output #0: loss = 0.00260651 (* 1 = 0.00260651 loss)
I0429 12:04:13.893389  3523 sgd_solver.cpp:106] Iteration 31000, lr = 0.00347066
I0429 12:04:14.062783  3523 solver.cpp:237] Iteration 31100, loss = 0.000843069
I0429 12:04:14.062804  3523 solver.cpp:253]     Train net output #0: loss = 0.000842975 (* 1 = 0.000842975 loss)
I0429 12:04:14.062827  3523 sgd_solver.cpp:106] Iteration 31100, lr = 0.00346433
I0429 12:04:14.231858  3523 solver.cpp:237] Iteration 31200, loss = 0.00140315
I0429 12:04:14.231885  3523 solver.cpp:253]     Train net output #0: loss = 0.00140306 (* 1 = 0.00140306 loss)
I0429 12:04:14.231896  3523 sgd_solver.cpp:106] Iteration 31200, lr = 0.00345802
I0429 12:04:14.400457  3523 solver.cpp:237] Iteration 31300, loss = 0.000854072
I0429 12:04:14.400480  3523 solver.cpp:253]     Train net output #0: loss = 0.00085398 (* 1 = 0.00085398 loss)
I0429 12:04:14.400485  3523 sgd_solver.cpp:106] Iteration 31300, lr = 0.00345174
I0429 12:04:14.568902  3523 solver.cpp:237] Iteration 31400, loss = 0.000874515
I0429 12:04:14.568929  3523 solver.cpp:253]     Train net output #0: loss = 0.000874425 (* 1 = 0.000874425 loss)
I0429 12:04:14.568935  3523 sgd_solver.cpp:106] Iteration 31400, lr = 0.00344548
I0429 12:04:14.737453  3523 solver.cpp:237] Iteration 31500, loss = 0.00467679
I0429 12:04:14.737478  3523 solver.cpp:253]     Train net output #0: loss = 0.0046767 (* 1 = 0.0046767 loss)
I0429 12:04:14.737484  3523 sgd_solver.cpp:106] Iteration 31500, lr = 0.00343925
I0429 12:04:14.905850  3523 solver.cpp:237] Iteration 31600, loss = 0.00539717
I0429 12:04:14.905872  3523 solver.cpp:253]     Train net output #0: loss = 0.00539708 (* 1 = 0.00539708 loss)
I0429 12:04:14.905879  3523 sgd_solver.cpp:106] Iteration 31600, lr = 0.00343305
I0429 12:04:15.075556  3523 solver.cpp:237] Iteration 31700, loss = 0.00278332
I0429 12:04:15.075577  3523 solver.cpp:253]     Train net output #0: loss = 0.00278323 (* 1 = 0.00278323 loss)
I0429 12:04:15.075582  3523 sgd_solver.cpp:106] Iteration 31700, lr = 0.00342687
I0429 12:04:15.244499  3523 solver.cpp:237] Iteration 31800, loss = 0.0023671
I0429 12:04:15.244523  3523 solver.cpp:253]     Train net output #0: loss = 0.00236701 (* 1 = 0.00236701 loss)
I0429 12:04:15.244531  3523 sgd_solver.cpp:106] Iteration 31800, lr = 0.00342072
I0429 12:04:15.414438  3523 solver.cpp:237] Iteration 31900, loss = 0.00683045
I0429 12:04:15.414461  3523 solver.cpp:253]     Train net output #0: loss = 0.00683036 (* 1 = 0.00683036 loss)
I0429 12:04:15.414468  3523 sgd_solver.cpp:106] Iteration 31900, lr = 0.0034146
I0429 12:04:15.582833  3523 solver.cpp:237] Iteration 32000, loss = 0.00261274
I0429 12:04:15.582854  3523 solver.cpp:253]     Train net output #0: loss = 0.00261265 (* 1 = 0.00261265 loss)
I0429 12:04:15.582859  3523 sgd_solver.cpp:106] Iteration 32000, lr = 0.0034085
I0429 12:04:15.752557  3523 solver.cpp:237] Iteration 32100, loss = 0.00101743
I0429 12:04:15.752579  3523 solver.cpp:253]     Train net output #0: loss = 0.00101734 (* 1 = 0.00101734 loss)
I0429 12:04:15.752585  3523 sgd_solver.cpp:106] Iteration 32100, lr = 0.00340242
I0429 12:04:15.921452  3523 solver.cpp:237] Iteration 32200, loss = 0.00107939
I0429 12:04:15.921474  3523 solver.cpp:253]     Train net output #0: loss = 0.0010793 (* 1 = 0.0010793 loss)
I0429 12:04:15.921479  3523 sgd_solver.cpp:106] Iteration 32200, lr = 0.00339637
I0429 12:04:16.090687  3523 solver.cpp:237] Iteration 32300, loss = 0.0080587
I0429 12:04:16.090708  3523 solver.cpp:253]     Train net output #0: loss = 0.00805862 (* 1 = 0.00805862 loss)
I0429 12:04:16.090713  3523 sgd_solver.cpp:106] Iteration 32300, lr = 0.00339035
I0429 12:04:16.260293  3523 solver.cpp:237] Iteration 32400, loss = 0.00152148
I0429 12:04:16.260314  3523 solver.cpp:253]     Train net output #0: loss = 0.00152139 (* 1 = 0.00152139 loss)
I0429 12:04:16.260319  3523 sgd_solver.cpp:106] Iteration 32400, lr = 0.00338435
I0429 12:04:16.429576  3523 solver.cpp:237] Iteration 32500, loss = 0.00120876
I0429 12:04:16.429597  3523 solver.cpp:253]     Train net output #0: loss = 0.00120867 (* 1 = 0.00120867 loss)
I0429 12:04:16.429603  3523 sgd_solver.cpp:106] Iteration 32500, lr = 0.00337838
I0429 12:04:16.598932  3523 solver.cpp:237] Iteration 32600, loss = 0.00708374
I0429 12:04:16.598958  3523 solver.cpp:253]     Train net output #0: loss = 0.00708365 (* 1 = 0.00708365 loss)
I0429 12:04:16.598984  3523 sgd_solver.cpp:106] Iteration 32600, lr = 0.00337243
I0429 12:04:16.768472  3523 solver.cpp:237] Iteration 32700, loss = 0.00770564
I0429 12:04:16.768493  3523 solver.cpp:253]     Train net output #0: loss = 0.00770555 (* 1 = 0.00770555 loss)
I0429 12:04:16.768499  3523 sgd_solver.cpp:106] Iteration 32700, lr = 0.0033665
I0429 12:04:16.937687  3523 solver.cpp:237] Iteration 32800, loss = 0.000388904
I0429 12:04:16.937708  3523 solver.cpp:253]     Train net output #0: loss = 0.000388815 (* 1 = 0.000388815 loss)
I0429 12:04:16.937714  3523 sgd_solver.cpp:106] Iteration 32800, lr = 0.0033606
I0429 12:04:17.105779  3523 solver.cpp:237] Iteration 32900, loss = 0.00272205
I0429 12:04:17.105800  3523 solver.cpp:253]     Train net output #0: loss = 0.00272197 (* 1 = 0.00272197 loss)
I0429 12:04:17.105806  3523 sgd_solver.cpp:106] Iteration 32900, lr = 0.00335473
I0429 12:04:17.275120  3523 solver.cpp:237] Iteration 33000, loss = 0.00328758
I0429 12:04:17.275144  3523 solver.cpp:253]     Train net output #0: loss = 0.0032875 (* 1 = 0.0032875 loss)
I0429 12:04:17.275151  3523 sgd_solver.cpp:106] Iteration 33000, lr = 0.00334887
I0429 12:04:17.443912  3523 solver.cpp:237] Iteration 33100, loss = 0.00152403
I0429 12:04:17.443933  3523 solver.cpp:253]     Train net output #0: loss = 0.00152394 (* 1 = 0.00152394 loss)
I0429 12:04:17.443939  3523 sgd_solver.cpp:106] Iteration 33100, lr = 0.00334304
I0429 12:04:17.611963  3523 solver.cpp:237] Iteration 33200, loss = 0.00425682
I0429 12:04:17.611984  3523 solver.cpp:253]     Train net output #0: loss = 0.00425673 (* 1 = 0.00425673 loss)
I0429 12:04:17.611989  3523 sgd_solver.cpp:106] Iteration 33200, lr = 0.00333724
I0429 12:04:17.781131  3523 solver.cpp:237] Iteration 33300, loss = 0.00460687
I0429 12:04:17.781154  3523 solver.cpp:253]     Train net output #0: loss = 0.00460679 (* 1 = 0.00460679 loss)
I0429 12:04:17.781160  3523 sgd_solver.cpp:106] Iteration 33300, lr = 0.00333146
I0429 12:04:17.950039  3523 solver.cpp:237] Iteration 33400, loss = 0.00238699
I0429 12:04:17.950060  3523 solver.cpp:253]     Train net output #0: loss = 0.00238691 (* 1 = 0.00238691 loss)
I0429 12:04:17.950067  3523 sgd_solver.cpp:106] Iteration 33400, lr = 0.0033257
I0429 12:04:18.118695  3523 solver.cpp:237] Iteration 33500, loss = 0.000950526
I0429 12:04:18.118716  3523 solver.cpp:253]     Train net output #0: loss = 0.000950445 (* 1 = 0.000950445 loss)
I0429 12:04:18.118721  3523 sgd_solver.cpp:106] Iteration 33500, lr = 0.00331996
I0429 12:04:18.287564  3523 solver.cpp:237] Iteration 33600, loss = 0.00401159
I0429 12:04:18.287586  3523 solver.cpp:253]     Train net output #0: loss = 0.00401152 (* 1 = 0.00401152 loss)
I0429 12:04:18.287592  3523 sgd_solver.cpp:106] Iteration 33600, lr = 0.00331425
I0429 12:04:18.456789  3523 solver.cpp:237] Iteration 33700, loss = 0.00459545
I0429 12:04:18.456811  3523 solver.cpp:253]     Train net output #0: loss = 0.00459537 (* 1 = 0.00459537 loss)
I0429 12:04:18.456816  3523 sgd_solver.cpp:106] Iteration 33700, lr = 0.00330856
I0429 12:04:18.625705  3523 solver.cpp:237] Iteration 33800, loss = 0.00403991
I0429 12:04:18.625726  3523 solver.cpp:253]     Train net output #0: loss = 0.00403984 (* 1 = 0.00403984 loss)
I0429 12:04:18.625731  3523 sgd_solver.cpp:106] Iteration 33800, lr = 0.00330289
I0429 12:04:18.794977  3523 solver.cpp:237] Iteration 33900, loss = 0.00255071
I0429 12:04:18.795001  3523 solver.cpp:253]     Train net output #0: loss = 0.00255063 (* 1 = 0.00255063 loss)
I0429 12:04:18.795012  3523 sgd_solver.cpp:106] Iteration 33900, lr = 0.00329725
I0429 12:04:18.964061  3523 solver.cpp:237] Iteration 34000, loss = 0.00345044
I0429 12:04:18.964082  3523 solver.cpp:253]     Train net output #0: loss = 0.00345037 (* 1 = 0.00345037 loss)
I0429 12:04:18.964088  3523 sgd_solver.cpp:106] Iteration 34000, lr = 0.00329163
I0429 12:04:19.132699  3523 solver.cpp:237] Iteration 34100, loss = 0.00443174
I0429 12:04:19.132720  3523 solver.cpp:253]     Train net output #0: loss = 0.00443167 (* 1 = 0.00443167 loss)
I0429 12:04:19.132742  3523 sgd_solver.cpp:106] Iteration 34100, lr = 0.00328603
I0429 12:04:19.302274  3523 solver.cpp:237] Iteration 34200, loss = 0.00389083
I0429 12:04:19.302302  3523 solver.cpp:253]     Train net output #0: loss = 0.00389075 (* 1 = 0.00389075 loss)
I0429 12:04:19.302314  3523 sgd_solver.cpp:106] Iteration 34200, lr = 0.00328045
I0429 12:04:19.470986  3523 solver.cpp:237] Iteration 34300, loss = 0.00714721
I0429 12:04:19.471011  3523 solver.cpp:253]     Train net output #0: loss = 0.00714714 (* 1 = 0.00714714 loss)
I0429 12:04:19.471016  3523 sgd_solver.cpp:106] Iteration 34300, lr = 0.00327489
I0429 12:04:19.639483  3523 solver.cpp:237] Iteration 34400, loss = 0.00369965
I0429 12:04:19.639505  3523 solver.cpp:253]     Train net output #0: loss = 0.00369958 (* 1 = 0.00369958 loss)
I0429 12:04:19.639510  3523 sgd_solver.cpp:106] Iteration 34400, lr = 0.00326936
I0429 12:04:19.807802  3523 solver.cpp:237] Iteration 34500, loss = 0.00166414
I0429 12:04:19.807824  3523 solver.cpp:253]     Train net output #0: loss = 0.00166407 (* 1 = 0.00166407 loss)
I0429 12:04:19.807829  3523 sgd_solver.cpp:106] Iteration 34500, lr = 0.00326385
I0429 12:04:19.977430  3523 solver.cpp:237] Iteration 34600, loss = 0.00181458
I0429 12:04:19.977452  3523 solver.cpp:253]     Train net output #0: loss = 0.00181451 (* 1 = 0.00181451 loss)
I0429 12:04:19.977458  3523 sgd_solver.cpp:106] Iteration 34600, lr = 0.00325836
I0429 12:04:20.146616  3523 solver.cpp:237] Iteration 34700, loss = 0.00211393
I0429 12:04:20.146638  3523 solver.cpp:253]     Train net output #0: loss = 0.00211386 (* 1 = 0.00211386 loss)
I0429 12:04:20.146643  3523 sgd_solver.cpp:106] Iteration 34700, lr = 0.00325289
I0429 12:04:20.315233  3523 solver.cpp:237] Iteration 34800, loss = 0.00627096
I0429 12:04:20.315261  3523 solver.cpp:253]     Train net output #0: loss = 0.00627088 (* 1 = 0.00627088 loss)
I0429 12:04:20.315266  3523 sgd_solver.cpp:106] Iteration 34800, lr = 0.00324744
I0429 12:04:20.483645  3523 solver.cpp:237] Iteration 34900, loss = 0.00195018
I0429 12:04:20.483667  3523 solver.cpp:253]     Train net output #0: loss = 0.0019501 (* 1 = 0.0019501 loss)
I0429 12:04:20.483672  3523 sgd_solver.cpp:106] Iteration 34900, lr = 0.00324202
I0429 12:04:20.651254  3523 solver.cpp:341] Iteration 35000, Testing net (#0)
I0429 12:04:20.733600  3523 solver.cpp:409]     Test net output #0: accuracy = 0.9877
I0429 12:04:20.733630  3523 solver.cpp:409]     Test net output #1: loss = 0.0414874 (* 1 = 0.0414874 loss)
I0429 12:04:20.734436  3523 solver.cpp:237] Iteration 35000, loss = 0.00500972
I0429 12:04:20.734452  3523 solver.cpp:253]     Train net output #0: loss = 0.00500964 (* 1 = 0.00500964 loss)
I0429 12:04:20.734470  3523 sgd_solver.cpp:106] Iteration 35000, lr = 0.00323661
I0429 12:04:20.897862  3523 solver.cpp:237] Iteration 35100, loss = 0.0123392
I0429 12:04:20.897883  3523 solver.cpp:253]     Train net output #0: loss = 0.0123391 (* 1 = 0.0123391 loss)
I0429 12:04:20.897889  3523 sgd_solver.cpp:106] Iteration 35100, lr = 0.00323123
I0429 12:04:21.063578  3523 solver.cpp:237] Iteration 35200, loss = 0.00536124
I0429 12:04:21.063624  3523 solver.cpp:253]     Train net output #0: loss = 0.00536116 (* 1 = 0.00536116 loss)
I0429 12:04:21.063638  3523 sgd_solver.cpp:106] Iteration 35200, lr = 0.00322586
I0429 12:04:21.231966  3523 solver.cpp:237] Iteration 35300, loss = 0.00306565
I0429 12:04:21.231992  3523 solver.cpp:253]     Train net output #0: loss = 0.00306557 (* 1 = 0.00306557 loss)
I0429 12:04:21.231999  3523 sgd_solver.cpp:106] Iteration 35300, lr = 0.00322052
I0429 12:04:21.397135  3523 solver.cpp:237] Iteration 35400, loss = 0.00645822
I0429 12:04:21.397159  3523 solver.cpp:253]     Train net output #0: loss = 0.00645814 (* 1 = 0.00645814 loss)
I0429 12:04:21.397164  3523 sgd_solver.cpp:106] Iteration 35400, lr = 0.0032152
I0429 12:04:21.560916  3523 solver.cpp:237] Iteration 35500, loss = 0.00129525
I0429 12:04:21.560940  3523 solver.cpp:253]     Train net output #0: loss = 0.00129517 (* 1 = 0.00129517 loss)
I0429 12:04:21.560945  3523 sgd_solver.cpp:106] Iteration 35500, lr = 0.0032099
I0429 12:04:21.725078  3523 solver.cpp:237] Iteration 35600, loss = 0.000387779
I0429 12:04:21.725102  3523 solver.cpp:253]     Train net output #0: loss = 0.0003877 (* 1 = 0.0003877 loss)
I0429 12:04:21.725108  3523 sgd_solver.cpp:106] Iteration 35600, lr = 0.00320462
I0429 12:04:21.890491  3523 solver.cpp:237] Iteration 35700, loss = 0.000714273
I0429 12:04:21.890516  3523 solver.cpp:253]     Train net output #0: loss = 0.000714192 (* 1 = 0.000714192 loss)
I0429 12:04:21.890522  3523 sgd_solver.cpp:106] Iteration 35700, lr = 0.00319936
I0429 12:04:22.055996  3523 solver.cpp:237] Iteration 35800, loss = 0.00525959
I0429 12:04:22.056022  3523 solver.cpp:253]     Train net output #0: loss = 0.00525951 (* 1 = 0.00525951 loss)
I0429 12:04:22.056028  3523 sgd_solver.cpp:106] Iteration 35800, lr = 0.00319412
I0429 12:04:22.221122  3523 solver.cpp:237] Iteration 35900, loss = 0.00500185
I0429 12:04:22.221259  3523 solver.cpp:253]     Train net output #0: loss = 0.00500177 (* 1 = 0.00500177 loss)
I0429 12:04:22.221271  3523 sgd_solver.cpp:106] Iteration 35900, lr = 0.0031889
I0429 12:04:22.386271  3523 solver.cpp:237] Iteration 36000, loss = 0.00142924
I0429 12:04:22.386297  3523 solver.cpp:253]     Train net output #0: loss = 0.00142916 (* 1 = 0.00142916 loss)
I0429 12:04:22.386303  3523 sgd_solver.cpp:106] Iteration 36000, lr = 0.0031837
I0429 12:04:22.556771  3523 solver.cpp:237] Iteration 36100, loss = 0.00144678
I0429 12:04:22.556814  3523 solver.cpp:253]     Train net output #0: loss = 0.0014467 (* 1 = 0.0014467 loss)
I0429 12:04:22.556824  3523 sgd_solver.cpp:106] Iteration 36100, lr = 0.00317852
I0429 12:04:22.723433  3523 solver.cpp:237] Iteration 36200, loss = 0.00427523
I0429 12:04:22.723458  3523 solver.cpp:253]     Train net output #0: loss = 0.00427515 (* 1 = 0.00427515 loss)
I0429 12:04:22.723464  3523 sgd_solver.cpp:106] Iteration 36200, lr = 0.00317335
I0429 12:04:22.889092  3523 solver.cpp:237] Iteration 36300, loss = 0.00166429
I0429 12:04:22.889118  3523 solver.cpp:253]     Train net output #0: loss = 0.00166421 (* 1 = 0.00166421 loss)
I0429 12:04:22.889124  3523 sgd_solver.cpp:106] Iteration 36300, lr = 0.00316821
I0429 12:04:23.054672  3523 solver.cpp:237] Iteration 36400, loss = 0.00151757
I0429 12:04:23.054702  3523 solver.cpp:253]     Train net output #0: loss = 0.00151749 (* 1 = 0.00151749 loss)
I0429 12:04:23.054709  3523 sgd_solver.cpp:106] Iteration 36400, lr = 0.00316309
I0429 12:04:23.219395  3523 solver.cpp:237] Iteration 36500, loss = 0.00299036
I0429 12:04:23.219424  3523 solver.cpp:253]     Train net output #0: loss = 0.00299028 (* 1 = 0.00299028 loss)
I0429 12:04:23.219431  3523 sgd_solver.cpp:106] Iteration 36500, lr = 0.00315799
I0429 12:04:23.387264  3523 solver.cpp:237] Iteration 36600, loss = 0.005992
I0429 12:04:23.387290  3523 solver.cpp:253]     Train net output #0: loss = 0.00599192 (* 1 = 0.00599192 loss)
I0429 12:04:23.387296  3523 sgd_solver.cpp:106] Iteration 36600, lr = 0.0031529
I0429 12:04:23.552840  3523 solver.cpp:237] Iteration 36700, loss = 0.00564632
I0429 12:04:23.552866  3523 solver.cpp:253]     Train net output #0: loss = 0.00564624 (* 1 = 0.00564624 loss)
I0429 12:04:23.552872  3523 sgd_solver.cpp:106] Iteration 36700, lr = 0.00314784
I0429 12:04:23.718725  3523 solver.cpp:237] Iteration 36800, loss = 0.00136549
I0429 12:04:23.718752  3523 solver.cpp:253]     Train net output #0: loss = 0.00136541 (* 1 = 0.00136541 loss)
I0429 12:04:23.718758  3523 sgd_solver.cpp:106] Iteration 36800, lr = 0.00314279
I0429 12:04:23.884497  3523 solver.cpp:237] Iteration 36900, loss = 0.00322068
I0429 12:04:23.884524  3523 solver.cpp:253]     Train net output #0: loss = 0.0032206 (* 1 = 0.0032206 loss)
I0429 12:04:23.884531  3523 sgd_solver.cpp:106] Iteration 36900, lr = 0.00313776
I0429 12:04:24.049630  3523 solver.cpp:237] Iteration 37000, loss = 0.0035969
I0429 12:04:24.049652  3523 solver.cpp:253]     Train net output #0: loss = 0.00359682 (* 1 = 0.00359682 loss)
I0429 12:04:24.049659  3523 sgd_solver.cpp:106] Iteration 37000, lr = 0.00313276
I0429 12:04:24.214725  3523 solver.cpp:237] Iteration 37100, loss = 0.00562806
I0429 12:04:24.214756  3523 solver.cpp:253]     Train net output #0: loss = 0.00562798 (* 1 = 0.00562798 loss)
I0429 12:04:24.214764  3523 sgd_solver.cpp:106] Iteration 37100, lr = 0.00312777
I0429 12:04:24.378021  3523 solver.cpp:237] Iteration 37200, loss = 0.00277268
I0429 12:04:24.378043  3523 solver.cpp:253]     Train net output #0: loss = 0.0027726 (* 1 = 0.0027726 loss)
I0429 12:04:24.378049  3523 sgd_solver.cpp:106] Iteration 37200, lr = 0.0031228
I0429 12:04:24.542336  3523 solver.cpp:237] Iteration 37300, loss = 0.00950184
I0429 12:04:24.542359  3523 solver.cpp:253]     Train net output #0: loss = 0.00950176 (* 1 = 0.00950176 loss)
I0429 12:04:24.542364  3523 sgd_solver.cpp:106] Iteration 37300, lr = 0.00311784
I0429 12:04:24.706640  3523 solver.cpp:237] Iteration 37400, loss = 0.00204179
I0429 12:04:24.706661  3523 solver.cpp:253]     Train net output #0: loss = 0.0020417 (* 1 = 0.0020417 loss)
I0429 12:04:24.706686  3523 sgd_solver.cpp:106] Iteration 37400, lr = 0.00311291
I0429 12:04:24.871641  3523 solver.cpp:237] Iteration 37500, loss = 0.0011517
I0429 12:04:24.871666  3523 solver.cpp:253]     Train net output #0: loss = 0.00115162 (* 1 = 0.00115162 loss)
I0429 12:04:24.871673  3523 sgd_solver.cpp:106] Iteration 37500, lr = 0.00310799
I0429 12:04:25.036715  3523 solver.cpp:237] Iteration 37600, loss = 0.00396827
I0429 12:04:25.036751  3523 solver.cpp:253]     Train net output #0: loss = 0.00396819 (* 1 = 0.00396819 loss)
I0429 12:04:25.036774  3523 sgd_solver.cpp:106] Iteration 37600, lr = 0.00310309
I0429 12:04:25.200608  3523 solver.cpp:237] Iteration 37700, loss = 0.00382685
I0429 12:04:25.200629  3523 solver.cpp:253]     Train net output #0: loss = 0.00382677 (* 1 = 0.00382677 loss)
I0429 12:04:25.200634  3523 sgd_solver.cpp:106] Iteration 37700, lr = 0.00309821
I0429 12:04:25.366647  3523 solver.cpp:237] Iteration 37800, loss = 0.00160701
I0429 12:04:25.366667  3523 solver.cpp:253]     Train net output #0: loss = 0.00160693 (* 1 = 0.00160693 loss)
I0429 12:04:25.366673  3523 sgd_solver.cpp:106] Iteration 37800, lr = 0.00309335
I0429 12:04:25.532060  3523 solver.cpp:237] Iteration 37900, loss = 0.00222927
I0429 12:04:25.532085  3523 solver.cpp:253]     Train net output #0: loss = 0.00222919 (* 1 = 0.00222919 loss)
I0429 12:04:25.532091  3523 sgd_solver.cpp:106] Iteration 37900, lr = 0.00308851
I0429 12:04:25.697235  3523 solver.cpp:237] Iteration 38000, loss = 0.00530615
I0429 12:04:25.697257  3523 solver.cpp:253]     Train net output #0: loss = 0.00530607 (* 1 = 0.00530607 loss)
I0429 12:04:25.697263  3523 sgd_solver.cpp:106] Iteration 38000, lr = 0.00308368
I0429 12:04:25.863001  3523 solver.cpp:237] Iteration 38100, loss = 0.00809504
I0429 12:04:25.863023  3523 solver.cpp:253]     Train net output #0: loss = 0.00809497 (* 1 = 0.00809497 loss)
I0429 12:04:25.863029  3523 sgd_solver.cpp:106] Iteration 38100, lr = 0.00307887
I0429 12:04:26.028570  3523 solver.cpp:237] Iteration 38200, loss = 0.00257863
I0429 12:04:26.028592  3523 solver.cpp:253]     Train net output #0: loss = 0.00257856 (* 1 = 0.00257856 loss)
I0429 12:04:26.028597  3523 sgd_solver.cpp:106] Iteration 38200, lr = 0.00307408
I0429 12:04:26.194238  3523 solver.cpp:237] Iteration 38300, loss = 0.00627279
I0429 12:04:26.194260  3523 solver.cpp:253]     Train net output #0: loss = 0.00627272 (* 1 = 0.00627272 loss)
I0429 12:04:26.194265  3523 sgd_solver.cpp:106] Iteration 38300, lr = 0.0030693
I0429 12:04:26.359486  3523 solver.cpp:237] Iteration 38400, loss = 0.00493217
I0429 12:04:26.359508  3523 solver.cpp:253]     Train net output #0: loss = 0.00493209 (* 1 = 0.00493209 loss)
I0429 12:04:26.359513  3523 sgd_solver.cpp:106] Iteration 38400, lr = 0.00306454
I0429 12:04:26.524950  3523 solver.cpp:237] Iteration 38500, loss = 0.00284981
I0429 12:04:26.524973  3523 solver.cpp:253]     Train net output #0: loss = 0.00284973 (* 1 = 0.00284973 loss)
I0429 12:04:26.524979  3523 sgd_solver.cpp:106] Iteration 38500, lr = 0.0030598
I0429 12:04:26.688719  3523 solver.cpp:237] Iteration 38600, loss = 0.000922563
I0429 12:04:26.688742  3523 solver.cpp:253]     Train net output #0: loss = 0.000922484 (* 1 = 0.000922484 loss)
I0429 12:04:26.688750  3523 sgd_solver.cpp:106] Iteration 38600, lr = 0.00305508
I0429 12:04:26.852610  3523 solver.cpp:237] Iteration 38700, loss = 0.00137716
I0429 12:04:26.852634  3523 solver.cpp:253]     Train net output #0: loss = 0.00137708 (* 1 = 0.00137708 loss)
I0429 12:04:26.852639  3523 sgd_solver.cpp:106] Iteration 38700, lr = 0.00305038
I0429 12:04:27.017981  3523 solver.cpp:237] Iteration 38800, loss = 0.000840369
I0429 12:04:27.018004  3523 solver.cpp:253]     Train net output #0: loss = 0.00084029 (* 1 = 0.00084029 loss)
I0429 12:04:27.018012  3523 sgd_solver.cpp:106] Iteration 38800, lr = 0.00304569
I0429 12:04:27.182380  3523 solver.cpp:237] Iteration 38900, loss = 0.000869645
I0429 12:04:27.182402  3523 solver.cpp:253]     Train net output #0: loss = 0.000869572 (* 1 = 0.000869572 loss)
I0429 12:04:27.182425  3523 sgd_solver.cpp:106] Iteration 38900, lr = 0.00304101
I0429 12:04:27.347259  3523 solver.cpp:237] Iteration 39000, loss = 0.0047101
I0429 12:04:27.347280  3523 solver.cpp:253]     Train net output #0: loss = 0.00471002 (* 1 = 0.00471002 loss)
I0429 12:04:27.347286  3523 sgd_solver.cpp:106] Iteration 39000, lr = 0.00303636
I0429 12:04:27.511540  3523 solver.cpp:237] Iteration 39100, loss = 0.005469
I0429 12:04:27.511564  3523 solver.cpp:253]     Train net output #0: loss = 0.00546893 (* 1 = 0.00546893 loss)
I0429 12:04:27.511569  3523 sgd_solver.cpp:106] Iteration 39100, lr = 0.00303172
I0429 12:04:27.675468  3523 solver.cpp:237] Iteration 39200, loss = 0.00289871
I0429 12:04:27.675489  3523 solver.cpp:253]     Train net output #0: loss = 0.00289863 (* 1 = 0.00289863 loss)
I0429 12:04:27.675495  3523 sgd_solver.cpp:106] Iteration 39200, lr = 0.0030271
I0429 12:04:27.839970  3523 solver.cpp:237] Iteration 39300, loss = 0.00244974
I0429 12:04:27.839993  3523 solver.cpp:253]     Train net output #0: loss = 0.00244966 (* 1 = 0.00244966 loss)
I0429 12:04:27.839999  3523 sgd_solver.cpp:106] Iteration 39300, lr = 0.00302249
I0429 12:04:28.003751  3523 solver.cpp:237] Iteration 39400, loss = 0.00680842
I0429 12:04:28.003772  3523 solver.cpp:253]     Train net output #0: loss = 0.00680835 (* 1 = 0.00680835 loss)
I0429 12:04:28.003778  3523 sgd_solver.cpp:106] Iteration 39400, lr = 0.0030179
I0429 12:04:28.168756  3523 solver.cpp:237] Iteration 39500, loss = 0.00253635
I0429 12:04:28.168781  3523 solver.cpp:253]     Train net output #0: loss = 0.00253627 (* 1 = 0.00253627 loss)
I0429 12:04:28.168792  3523 sgd_solver.cpp:106] Iteration 39500, lr = 0.00301333
I0429 12:04:28.332618  3523 solver.cpp:237] Iteration 39600, loss = 0.00108849
I0429 12:04:28.332643  3523 solver.cpp:253]     Train net output #0: loss = 0.00108841 (* 1 = 0.00108841 loss)
I0429 12:04:28.332648  3523 sgd_solver.cpp:106] Iteration 39600, lr = 0.00300877
I0429 12:04:28.495755  3523 solver.cpp:237] Iteration 39700, loss = 0.00107212
I0429 12:04:28.495781  3523 solver.cpp:253]     Train net output #0: loss = 0.00107205 (* 1 = 0.00107205 loss)
I0429 12:04:28.495787  3523 sgd_solver.cpp:106] Iteration 39700, lr = 0.00300423
I0429 12:04:28.660825  3523 solver.cpp:237] Iteration 39800, loss = 0.00812987
I0429 12:04:28.660847  3523 solver.cpp:253]     Train net output #0: loss = 0.0081298 (* 1 = 0.0081298 loss)
I0429 12:04:28.660853  3523 sgd_solver.cpp:106] Iteration 39800, lr = 0.0029997
I0429 12:04:28.825248  3523 solver.cpp:237] Iteration 39900, loss = 0.00152688
I0429 12:04:28.825268  3523 solver.cpp:253]     Train net output #0: loss = 0.0015268 (* 1 = 0.0015268 loss)
I0429 12:04:28.825273  3523 sgd_solver.cpp:106] Iteration 39900, lr = 0.00299519
I0429 12:04:28.988459  3523 solver.cpp:341] Iteration 40000, Testing net (#0)
I0429 12:04:29.060104  3523 solver.cpp:409]     Test net output #0: accuracy = 0.988
I0429 12:04:29.060130  3523 solver.cpp:409]     Test net output #1: loss = 0.0414024 (* 1 = 0.0414024 loss)
I0429 12:04:29.060848  3523 solver.cpp:237] Iteration 40000, loss = 0.00164248
I0429 12:04:29.060865  3523 solver.cpp:253]     Train net output #0: loss = 0.00164241 (* 1 = 0.00164241 loss)
I0429 12:04:29.060881  3523 sgd_solver.cpp:106] Iteration 40000, lr = 0.0029907
I0429 12:04:29.223299  3523 solver.cpp:237] Iteration 40100, loss = 0.00779606
I0429 12:04:29.223321  3523 solver.cpp:253]     Train net output #0: loss = 0.00779599 (* 1 = 0.00779599 loss)
I0429 12:04:29.223327  3523 sgd_solver.cpp:106] Iteration 40100, lr = 0.00298622
I0429 12:04:29.389427  3523 solver.cpp:237] Iteration 40200, loss = 0.00767423
I0429 12:04:29.389456  3523 solver.cpp:253]     Train net output #0: loss = 0.00767416 (* 1 = 0.00767416 loss)
I0429 12:04:29.389464  3523 sgd_solver.cpp:106] Iteration 40200, lr = 0.00298176
I0429 12:04:29.552824  3523 solver.cpp:237] Iteration 40300, loss = 0.000347179
I0429 12:04:29.552846  3523 solver.cpp:253]     Train net output #0: loss = 0.000347106 (* 1 = 0.000347106 loss)
I0429 12:04:29.552852  3523 sgd_solver.cpp:106] Iteration 40300, lr = 0.00297731
I0429 12:04:29.714699  3523 solver.cpp:237] Iteration 40400, loss = 0.00286559
I0429 12:04:29.714723  3523 solver.cpp:253]     Train net output #0: loss = 0.00286552 (* 1 = 0.00286552 loss)
I0429 12:04:29.714730  3523 sgd_solver.cpp:106] Iteration 40400, lr = 0.00297288
I0429 12:04:29.876967  3523 solver.cpp:237] Iteration 40500, loss = 0.003038
I0429 12:04:29.876991  3523 solver.cpp:253]     Train net output #0: loss = 0.00303793 (* 1 = 0.00303793 loss)
I0429 12:04:29.876996  3523 sgd_solver.cpp:106] Iteration 40500, lr = 0.00296846
I0429 12:04:30.040175  3523 solver.cpp:237] Iteration 40600, loss = 0.00147161
I0429 12:04:30.040199  3523 solver.cpp:253]     Train net output #0: loss = 0.00147154 (* 1 = 0.00147154 loss)
I0429 12:04:30.040206  3523 sgd_solver.cpp:106] Iteration 40600, lr = 0.00296406
I0429 12:04:30.202613  3523 solver.cpp:237] Iteration 40700, loss = 0.00414389
I0429 12:04:30.202636  3523 solver.cpp:253]     Train net output #0: loss = 0.00414382 (* 1 = 0.00414382 loss)
I0429 12:04:30.202642  3523 sgd_solver.cpp:106] Iteration 40700, lr = 0.00295968
I0429 12:04:30.365702  3523 solver.cpp:237] Iteration 40800, loss = 0.00473107
I0429 12:04:30.365723  3523 solver.cpp:253]     Train net output #0: loss = 0.004731 (* 1 = 0.004731 loss)
I0429 12:04:30.365730  3523 sgd_solver.cpp:106] Iteration 40800, lr = 0.0029553
I0429 12:04:30.529265  3523 solver.cpp:237] Iteration 40900, loss = 0.00232662
I0429 12:04:30.529287  3523 solver.cpp:253]     Train net output #0: loss = 0.00232655 (* 1 = 0.00232655 loss)
I0429 12:04:30.529292  3523 sgd_solver.cpp:106] Iteration 40900, lr = 0.00295095
I0429 12:04:30.692886  3523 solver.cpp:237] Iteration 41000, loss = 0.000880226
I0429 12:04:30.692911  3523 solver.cpp:253]     Train net output #0: loss = 0.00088015 (* 1 = 0.00088015 loss)
I0429 12:04:30.692917  3523 sgd_solver.cpp:106] Iteration 41000, lr = 0.00294661
I0429 12:04:30.854698  3523 solver.cpp:237] Iteration 41100, loss = 0.00442908
I0429 12:04:30.854720  3523 solver.cpp:253]     Train net output #0: loss = 0.00442901 (* 1 = 0.00442901 loss)
I0429 12:04:30.854732  3523 sgd_solver.cpp:106] Iteration 41100, lr = 0.00294228
I0429 12:04:31.016904  3523 solver.cpp:237] Iteration 41200, loss = 0.00419827
I0429 12:04:31.016927  3523 solver.cpp:253]     Train net output #0: loss = 0.0041982 (* 1 = 0.0041982 loss)
I0429 12:04:31.016932  3523 sgd_solver.cpp:106] Iteration 41200, lr = 0.00293797
I0429 12:04:31.180387  3523 solver.cpp:237] Iteration 41300, loss = 0.0041343
I0429 12:04:31.180408  3523 solver.cpp:253]     Train net output #0: loss = 0.00413422 (* 1 = 0.00413422 loss)
I0429 12:04:31.180414  3523 sgd_solver.cpp:106] Iteration 41300, lr = 0.00293367
I0429 12:04:31.342351  3523 solver.cpp:237] Iteration 41400, loss = 0.00270276
I0429 12:04:31.342375  3523 solver.cpp:253]     Train net output #0: loss = 0.00270268 (* 1 = 0.00270268 loss)
I0429 12:04:31.342380  3523 sgd_solver.cpp:106] Iteration 41400, lr = 0.00292939
I0429 12:04:31.505019  3523 solver.cpp:237] Iteration 41500, loss = 0.00349936
I0429 12:04:31.505044  3523 solver.cpp:253]     Train net output #0: loss = 0.00349928 (* 1 = 0.00349928 loss)
I0429 12:04:31.505050  3523 sgd_solver.cpp:106] Iteration 41500, lr = 0.00292513
I0429 12:04:31.667445  3523 solver.cpp:237] Iteration 41600, loss = 0.00442096
I0429 12:04:31.667467  3523 solver.cpp:253]     Train net output #0: loss = 0.00442088 (* 1 = 0.00442088 loss)
I0429 12:04:31.667474  3523 sgd_solver.cpp:106] Iteration 41600, lr = 0.00292087
I0429 12:04:31.830545  3523 solver.cpp:237] Iteration 41700, loss = 0.00365194
I0429 12:04:31.830569  3523 solver.cpp:253]     Train net output #0: loss = 0.00365186 (* 1 = 0.00365186 loss)
I0429 12:04:31.830574  3523 sgd_solver.cpp:106] Iteration 41700, lr = 0.00291664
I0429 12:04:31.992910  3523 solver.cpp:237] Iteration 41800, loss = 0.00706483
I0429 12:04:31.992936  3523 solver.cpp:253]     Train net output #0: loss = 0.00706476 (* 1 = 0.00706476 loss)
I0429 12:04:31.992947  3523 sgd_solver.cpp:106] Iteration 41800, lr = 0.00291241
I0429 12:04:32.155310  3523 solver.cpp:237] Iteration 41900, loss = 0.00390918
I0429 12:04:32.155331  3523 solver.cpp:253]     Train net output #0: loss = 0.00390911 (* 1 = 0.00390911 loss)
I0429 12:04:32.155338  3523 sgd_solver.cpp:106] Iteration 41900, lr = 0.0029082
I0429 12:04:32.318315  3523 solver.cpp:237] Iteration 42000, loss = 0.00152204
I0429 12:04:32.318338  3523 solver.cpp:253]     Train net output #0: loss = 0.00152197 (* 1 = 0.00152197 loss)
I0429 12:04:32.318344  3523 sgd_solver.cpp:106] Iteration 42000, lr = 0.00290401
I0429 12:04:32.479974  3523 solver.cpp:237] Iteration 42100, loss = 0.0019908
I0429 12:04:32.479998  3523 solver.cpp:253]     Train net output #0: loss = 0.00199073 (* 1 = 0.00199073 loss)
I0429 12:04:32.480006  3523 sgd_solver.cpp:106] Iteration 42100, lr = 0.00289982
I0429 12:04:32.647243  3523 solver.cpp:237] Iteration 42200, loss = 0.00236388
I0429 12:04:32.647269  3523 solver.cpp:253]     Train net output #0: loss = 0.00236381 (* 1 = 0.00236381 loss)
I0429 12:04:32.647277  3523 sgd_solver.cpp:106] Iteration 42200, lr = 0.00289566
I0429 12:04:32.810814  3523 solver.cpp:237] Iteration 42300, loss = 0.00588349
I0429 12:04:32.810842  3523 solver.cpp:253]     Train net output #0: loss = 0.00588342 (* 1 = 0.00588342 loss)
I0429 12:04:32.810850  3523 sgd_solver.cpp:106] Iteration 42300, lr = 0.0028915
I0429 12:04:32.973300  3523 solver.cpp:237] Iteration 42400, loss = 0.00206123
I0429 12:04:32.973325  3523 solver.cpp:253]     Train net output #0: loss = 0.00206116 (* 1 = 0.00206116 loss)
I0429 12:04:32.973330  3523 sgd_solver.cpp:106] Iteration 42400, lr = 0.00288736
I0429 12:04:33.136222  3523 solver.cpp:237] Iteration 42500, loss = 0.00493918
I0429 12:04:33.136245  3523 solver.cpp:253]     Train net output #0: loss = 0.00493912 (* 1 = 0.00493912 loss)
I0429 12:04:33.136250  3523 sgd_solver.cpp:106] Iteration 42500, lr = 0.00288324
I0429 12:04:33.298604  3523 solver.cpp:237] Iteration 42600, loss = 0.0123026
I0429 12:04:33.298629  3523 solver.cpp:253]     Train net output #0: loss = 0.0123025 (* 1 = 0.0123025 loss)
I0429 12:04:33.298635  3523 sgd_solver.cpp:106] Iteration 42600, lr = 0.00287913
I0429 12:04:33.462882  3523 solver.cpp:237] Iteration 42700, loss = 0.00536523
I0429 12:04:33.462908  3523 solver.cpp:253]     Train net output #0: loss = 0.00536517 (* 1 = 0.00536517 loss)
I0429 12:04:33.462914  3523 sgd_solver.cpp:106] Iteration 42700, lr = 0.00287503
I0429 12:04:33.626102  3523 solver.cpp:237] Iteration 42800, loss = 0.00298011
I0429 12:04:33.626126  3523 solver.cpp:253]     Train net output #0: loss = 0.00298005 (* 1 = 0.00298005 loss)
I0429 12:04:33.626132  3523 sgd_solver.cpp:106] Iteration 42800, lr = 0.00287094
I0429 12:04:33.788784  3523 solver.cpp:237] Iteration 42900, loss = 0.00711029
I0429 12:04:33.788812  3523 solver.cpp:253]     Train net output #0: loss = 0.00711023 (* 1 = 0.00711023 loss)
I0429 12:04:33.788818  3523 sgd_solver.cpp:106] Iteration 42900, lr = 0.00286687
I0429 12:04:33.958045  3523 solver.cpp:237] Iteration 43000, loss = 0.00150987
I0429 12:04:33.958077  3523 solver.cpp:253]     Train net output #0: loss = 0.0015098 (* 1 = 0.0015098 loss)
I0429 12:04:33.958086  3523 sgd_solver.cpp:106] Iteration 43000, lr = 0.00286281
I0429 12:04:34.122230  3523 solver.cpp:237] Iteration 43100, loss = 0.000384664
I0429 12:04:34.122253  3523 solver.cpp:253]     Train net output #0: loss = 0.000384596 (* 1 = 0.000384596 loss)
I0429 12:04:34.122259  3523 sgd_solver.cpp:106] Iteration 43100, lr = 0.00285877
I0429 12:04:34.285504  3523 solver.cpp:237] Iteration 43200, loss = 0.000748171
I0429 12:04:34.285527  3523 solver.cpp:253]     Train net output #0: loss = 0.000748101 (* 1 = 0.000748101 loss)
I0429 12:04:34.285533  3523 sgd_solver.cpp:106] Iteration 43200, lr = 0.00285474
I0429 12:04:34.449285  3523 solver.cpp:237] Iteration 43300, loss = 0.0051103
I0429 12:04:34.449324  3523 solver.cpp:253]     Train net output #0: loss = 0.00511023 (* 1 = 0.00511023 loss)
I0429 12:04:34.449337  3523 sgd_solver.cpp:106] Iteration 43300, lr = 0.00285072
I0429 12:04:34.612576  3523 solver.cpp:237] Iteration 43400, loss = 0.00492013
I0429 12:04:34.612602  3523 solver.cpp:253]     Train net output #0: loss = 0.00492006 (* 1 = 0.00492006 loss)
I0429 12:04:34.612609  3523 sgd_solver.cpp:106] Iteration 43400, lr = 0.00284672
I0429 12:04:34.776362  3523 solver.cpp:237] Iteration 43500, loss = 0.00140945
I0429 12:04:34.776386  3523 solver.cpp:253]     Train net output #0: loss = 0.00140938 (* 1 = 0.00140938 loss)
I0429 12:04:34.776392  3523 sgd_solver.cpp:106] Iteration 43500, lr = 0.00284272
I0429 12:04:34.939920  3523 solver.cpp:237] Iteration 43600, loss = 0.00153154
I0429 12:04:34.939944  3523 solver.cpp:253]     Train net output #0: loss = 0.00153147 (* 1 = 0.00153147 loss)
I0429 12:04:34.939949  3523 sgd_solver.cpp:106] Iteration 43600, lr = 0.00283875
I0429 12:04:35.103003  3523 solver.cpp:237] Iteration 43700, loss = 0.00449343
I0429 12:04:35.103025  3523 solver.cpp:253]     Train net output #0: loss = 0.00449336 (* 1 = 0.00449336 loss)
I0429 12:04:35.103030  3523 sgd_solver.cpp:106] Iteration 43700, lr = 0.00283478
I0429 12:04:35.265360  3523 solver.cpp:237] Iteration 43800, loss = 0.00186573
I0429 12:04:35.265384  3523 solver.cpp:253]     Train net output #0: loss = 0.00186565 (* 1 = 0.00186565 loss)
I0429 12:04:35.265390  3523 sgd_solver.cpp:106] Iteration 43800, lr = 0.00283083
I0429 12:04:35.427449  3523 solver.cpp:237] Iteration 43900, loss = 0.00155172
I0429 12:04:35.427471  3523 solver.cpp:253]     Train net output #0: loss = 0.00155165 (* 1 = 0.00155165 loss)
I0429 12:04:35.427477  3523 sgd_solver.cpp:106] Iteration 43900, lr = 0.00282689
I0429 12:04:35.590466  3523 solver.cpp:237] Iteration 44000, loss = 0.00282147
I0429 12:04:35.590488  3523 solver.cpp:253]     Train net output #0: loss = 0.0028214 (* 1 = 0.0028214 loss)
I0429 12:04:35.590497  3523 sgd_solver.cpp:106] Iteration 44000, lr = 0.00282296
I0429 12:04:35.753218  3523 solver.cpp:237] Iteration 44100, loss = 0.00584951
I0429 12:04:35.753242  3523 solver.cpp:253]     Train net output #0: loss = 0.00584944 (* 1 = 0.00584944 loss)
I0429 12:04:35.753247  3523 sgd_solver.cpp:106] Iteration 44100, lr = 0.00281905
I0429 12:04:35.915892  3523 solver.cpp:237] Iteration 44200, loss = 0.00571854
I0429 12:04:35.915915  3523 solver.cpp:253]     Train net output #0: loss = 0.00571847 (* 1 = 0.00571847 loss)
I0429 12:04:35.915920  3523 sgd_solver.cpp:106] Iteration 44200, lr = 0.00281514
I0429 12:04:36.078835  3523 solver.cpp:237] Iteration 44300, loss = 0.00143788
I0429 12:04:36.078857  3523 solver.cpp:253]     Train net output #0: loss = 0.00143781 (* 1 = 0.00143781 loss)
I0429 12:04:36.078863  3523 sgd_solver.cpp:106] Iteration 44300, lr = 0.00281125
I0429 12:04:36.241646  3523 solver.cpp:237] Iteration 44400, loss = 0.00333068
I0429 12:04:36.241667  3523 solver.cpp:253]     Train net output #0: loss = 0.0033306 (* 1 = 0.0033306 loss)
I0429 12:04:36.241672  3523 sgd_solver.cpp:106] Iteration 44400, lr = 0.00280738
I0429 12:04:36.404356  3523 solver.cpp:237] Iteration 44500, loss = 0.00348722
I0429 12:04:36.404377  3523 solver.cpp:253]     Train net output #0: loss = 0.00348715 (* 1 = 0.00348715 loss)
I0429 12:04:36.404382  3523 sgd_solver.cpp:106] Iteration 44500, lr = 0.00280351
I0429 12:04:36.567615  3523 solver.cpp:237] Iteration 44600, loss = 0.00533373
I0429 12:04:36.567636  3523 solver.cpp:253]     Train net output #0: loss = 0.00533366 (* 1 = 0.00533366 loss)
I0429 12:04:36.567642  3523 sgd_solver.cpp:106] Iteration 44600, lr = 0.00279966
I0429 12:04:36.729204  3523 solver.cpp:237] Iteration 44700, loss = 0.00266114
I0429 12:04:36.729226  3523 solver.cpp:253]     Train net output #0: loss = 0.00266107 (* 1 = 0.00266107 loss)
I0429 12:04:36.729231  3523 sgd_solver.cpp:106] Iteration 44700, lr = 0.00279582
I0429 12:04:36.892657  3523 solver.cpp:237] Iteration 44800, loss = 0.00947065
I0429 12:04:36.892683  3523 solver.cpp:253]     Train net output #0: loss = 0.00947058 (* 1 = 0.00947058 loss)
I0429 12:04:36.892694  3523 sgd_solver.cpp:106] Iteration 44800, lr = 0.00279199
I0429 12:04:37.055555  3523 solver.cpp:237] Iteration 44900, loss = 0.00199661
I0429 12:04:37.055594  3523 solver.cpp:253]     Train net output #0: loss = 0.00199654 (* 1 = 0.00199654 loss)
I0429 12:04:37.055601  3523 sgd_solver.cpp:106] Iteration 44900, lr = 0.00278818
I0429 12:04:37.215263  3523 solver.cpp:341] Iteration 45000, Testing net (#0)
I0429 12:04:37.309098  3523 solver.cpp:409]     Test net output #0: accuracy = 0.9881
I0429 12:04:37.309126  3523 solver.cpp:409]     Test net output #1: loss = 0.0420423 (* 1 = 0.0420423 loss)
I0429 12:04:37.309860  3523 solver.cpp:237] Iteration 45000, loss = 0.00120528
I0429 12:04:37.309880  3523 solver.cpp:253]     Train net output #0: loss = 0.00120522 (* 1 = 0.00120522 loss)
I0429 12:04:37.309887  3523 sgd_solver.cpp:106] Iteration 45000, lr = 0.00278438
I0429 12:04:37.479334  3523 solver.cpp:237] Iteration 45100, loss = 0.00393039
I0429 12:04:37.479360  3523 solver.cpp:253]     Train net output #0: loss = 0.00393032 (* 1 = 0.00393032 loss)
I0429 12:04:37.479367  3523 sgd_solver.cpp:106] Iteration 45100, lr = 0.00278059
I0429 12:04:37.647174  3523 solver.cpp:237] Iteration 45200, loss = 0.00388794
I0429 12:04:37.647197  3523 solver.cpp:253]     Train net output #0: loss = 0.00388787 (* 1 = 0.00388787 loss)
I0429 12:04:37.647202  3523 sgd_solver.cpp:106] Iteration 45200, lr = 0.00277681
I0429 12:04:37.816293  3523 solver.cpp:237] Iteration 45300, loss = 0.00175085
I0429 12:04:37.816313  3523 solver.cpp:253]     Train net output #0: loss = 0.00175078 (* 1 = 0.00175078 loss)
I0429 12:04:37.816319  3523 sgd_solver.cpp:106] Iteration 45300, lr = 0.00277304
I0429 12:04:37.986068  3523 solver.cpp:237] Iteration 45400, loss = 0.00215314
I0429 12:04:37.986089  3523 solver.cpp:253]     Train net output #0: loss = 0.00215307 (* 1 = 0.00215307 loss)
I0429 12:04:37.986094  3523 sgd_solver.cpp:106] Iteration 45400, lr = 0.00276929
I0429 12:04:38.155221  3523 solver.cpp:237] Iteration 45500, loss = 0.00493086
I0429 12:04:38.155244  3523 solver.cpp:253]     Train net output #0: loss = 0.00493079 (* 1 = 0.00493079 loss)
I0429 12:04:38.155249  3523 sgd_solver.cpp:106] Iteration 45500, lr = 0.00276554
I0429 12:04:38.324661  3523 solver.cpp:237] Iteration 45600, loss = 0.0083114
I0429 12:04:38.324682  3523 solver.cpp:253]     Train net output #0: loss = 0.00831133 (* 1 = 0.00831133 loss)
I0429 12:04:38.324688  3523 sgd_solver.cpp:106] Iteration 45600, lr = 0.00276181
I0429 12:04:38.494737  3523 solver.cpp:237] Iteration 45700, loss = 0.00272287
I0429 12:04:38.494760  3523 solver.cpp:253]     Train net output #0: loss = 0.0027228 (* 1 = 0.0027228 loss)
I0429 12:04:38.494765  3523 sgd_solver.cpp:106] Iteration 45700, lr = 0.00275809
I0429 12:04:38.663434  3523 solver.cpp:237] Iteration 45800, loss = 0.00648716
I0429 12:04:38.663455  3523 solver.cpp:253]     Train net output #0: loss = 0.00648709 (* 1 = 0.00648709 loss)
I0429 12:04:38.663461  3523 sgd_solver.cpp:106] Iteration 45800, lr = 0.00275438
I0429 12:04:38.833068  3523 solver.cpp:237] Iteration 45900, loss = 0.00451316
I0429 12:04:38.833094  3523 solver.cpp:253]     Train net output #0: loss = 0.00451309 (* 1 = 0.00451309 loss)
I0429 12:04:38.833101  3523 sgd_solver.cpp:106] Iteration 45900, lr = 0.00275069
I0429 12:04:39.001987  3523 solver.cpp:237] Iteration 46000, loss = 0.00283614
I0429 12:04:39.002010  3523 solver.cpp:253]     Train net output #0: loss = 0.00283607 (* 1 = 0.00283607 loss)
I0429 12:04:39.002015  3523 sgd_solver.cpp:106] Iteration 46000, lr = 0.002747
I0429 12:04:39.170886  3523 solver.cpp:237] Iteration 46100, loss = 0.00102964
I0429 12:04:39.170908  3523 solver.cpp:253]     Train net output #0: loss = 0.00102956 (* 1 = 0.00102956 loss)
I0429 12:04:39.170914  3523 sgd_solver.cpp:106] Iteration 46100, lr = 0.00274333
I0429 12:04:39.341078  3523 solver.cpp:237] Iteration 46200, loss = 0.0012739
I0429 12:04:39.341100  3523 solver.cpp:253]     Train net output #0: loss = 0.00127383 (* 1 = 0.00127383 loss)
I0429 12:04:39.341106  3523 sgd_solver.cpp:106] Iteration 46200, lr = 0.00273967
I0429 12:04:39.509986  3523 solver.cpp:237] Iteration 46300, loss = 0.000811661
I0429 12:04:39.510032  3523 solver.cpp:253]     Train net output #0: loss = 0.00081159 (* 1 = 0.00081159 loss)
I0429 12:04:39.510040  3523 sgd_solver.cpp:106] Iteration 46300, lr = 0.00273602
I0429 12:04:39.679678  3523 solver.cpp:237] Iteration 46400, loss = 0.000780238
I0429 12:04:39.679698  3523 solver.cpp:253]     Train net output #0: loss = 0.000780164 (* 1 = 0.000780164 loss)
I0429 12:04:39.679704  3523 sgd_solver.cpp:106] Iteration 46400, lr = 0.00273238
I0429 12:04:39.848706  3523 solver.cpp:237] Iteration 46500, loss = 0.00474913
I0429 12:04:39.848726  3523 solver.cpp:253]     Train net output #0: loss = 0.00474906 (* 1 = 0.00474906 loss)
I0429 12:04:39.848732  3523 sgd_solver.cpp:106] Iteration 46500, lr = 0.00272875
I0429 12:04:40.018198  3523 solver.cpp:237] Iteration 46600, loss = 0.00528685
I0429 12:04:40.018220  3523 solver.cpp:253]     Train net output #0: loss = 0.00528677 (* 1 = 0.00528677 loss)
I0429 12:04:40.018226  3523 sgd_solver.cpp:106] Iteration 46600, lr = 0.00272513
I0429 12:04:40.187979  3523 solver.cpp:237] Iteration 46700, loss = 0.00307694
I0429 12:04:40.188001  3523 solver.cpp:253]     Train net output #0: loss = 0.00307686 (* 1 = 0.00307686 loss)
I0429 12:04:40.188006  3523 sgd_solver.cpp:106] Iteration 46700, lr = 0.00272153
I0429 12:04:40.356453  3523 solver.cpp:237] Iteration 46800, loss = 0.00257003
I0429 12:04:40.356475  3523 solver.cpp:253]     Train net output #0: loss = 0.00256996 (* 1 = 0.00256996 loss)
I0429 12:04:40.356482  3523 sgd_solver.cpp:106] Iteration 46800, lr = 0.00271793
I0429 12:04:40.526212  3523 solver.cpp:237] Iteration 46900, loss = 0.00664614
I0429 12:04:40.526238  3523 solver.cpp:253]     Train net output #0: loss = 0.00664607 (* 1 = 0.00664607 loss)
I0429 12:04:40.526244  3523 sgd_solver.cpp:106] Iteration 46900, lr = 0.00271435
I0429 12:04:40.695503  3523 solver.cpp:237] Iteration 47000, loss = 0.00255605
I0429 12:04:40.695525  3523 solver.cpp:253]     Train net output #0: loss = 0.00255598 (* 1 = 0.00255598 loss)
I0429 12:04:40.695531  3523 sgd_solver.cpp:106] Iteration 47000, lr = 0.00271078
I0429 12:04:40.864552  3523 solver.cpp:237] Iteration 47100, loss = 0.00109359
I0429 12:04:40.864575  3523 solver.cpp:253]     Train net output #0: loss = 0.00109351 (* 1 = 0.00109351 loss)
I0429 12:04:40.864580  3523 sgd_solver.cpp:106] Iteration 47100, lr = 0.00270722
I0429 12:04:41.033884  3523 solver.cpp:237] Iteration 47200, loss = 0.0010347
I0429 12:04:41.033905  3523 solver.cpp:253]     Train net output #0: loss = 0.00103463 (* 1 = 0.00103463 loss)
I0429 12:04:41.033910  3523 sgd_solver.cpp:106] Iteration 47200, lr = 0.00270367
I0429 12:04:41.202488  3523 solver.cpp:237] Iteration 47300, loss = 0.0080825
I0429 12:04:41.202510  3523 solver.cpp:253]     Train net output #0: loss = 0.00808242 (* 1 = 0.00808242 loss)
I0429 12:04:41.202515  3523 sgd_solver.cpp:106] Iteration 47300, lr = 0.00270013
I0429 12:04:41.371949  3523 solver.cpp:237] Iteration 47400, loss = 0.00152781
I0429 12:04:41.371970  3523 solver.cpp:253]     Train net output #0: loss = 0.00152773 (* 1 = 0.00152773 loss)
I0429 12:04:41.371975  3523 sgd_solver.cpp:106] Iteration 47400, lr = 0.0026966
I0429 12:04:41.541028  3523 solver.cpp:237] Iteration 47500, loss = 0.00188289
I0429 12:04:41.541049  3523 solver.cpp:253]     Train net output #0: loss = 0.00188282 (* 1 = 0.00188282 loss)
I0429 12:04:41.541054  3523 sgd_solver.cpp:106] Iteration 47500, lr = 0.00269308
I0429 12:04:41.709797  3523 solver.cpp:237] Iteration 47600, loss = 0.00821476
I0429 12:04:41.709822  3523 solver.cpp:253]     Train net output #0: loss = 0.00821469 (* 1 = 0.00821469 loss)
I0429 12:04:41.709828  3523 sgd_solver.cpp:106] Iteration 47600, lr = 0.00268957
I0429 12:04:41.879195  3523 solver.cpp:237] Iteration 47700, loss = 0.00780409
I0429 12:04:41.879225  3523 solver.cpp:253]     Train net output #0: loss = 0.00780402 (* 1 = 0.00780402 loss)
I0429 12:04:41.879231  3523 sgd_solver.cpp:106] Iteration 47700, lr = 0.00268607
I0429 12:04:42.048112  3523 solver.cpp:237] Iteration 47800, loss = 0.000316973
I0429 12:04:42.048135  3523 solver.cpp:253]     Train net output #0: loss = 0.0003169 (* 1 = 0.0003169 loss)
I0429 12:04:42.048156  3523 sgd_solver.cpp:106] Iteration 47800, lr = 0.00268259
I0429 12:04:42.217043  3523 solver.cpp:237] Iteration 47900, loss = 0.00286744
I0429 12:04:42.217064  3523 solver.cpp:253]     Train net output #0: loss = 0.00286737 (* 1 = 0.00286737 loss)
I0429 12:04:42.217070  3523 sgd_solver.cpp:106] Iteration 47900, lr = 0.00267911
I0429 12:04:42.386924  3523 solver.cpp:237] Iteration 48000, loss = 0.00309424
I0429 12:04:42.386946  3523 solver.cpp:253]     Train net output #0: loss = 0.00309416 (* 1 = 0.00309416 loss)
I0429 12:04:42.386952  3523 sgd_solver.cpp:106] Iteration 48000, lr = 0.00267565
I0429 12:04:42.556545  3523 solver.cpp:237] Iteration 48100, loss = 0.001413
I0429 12:04:42.556567  3523 solver.cpp:253]     Train net output #0: loss = 0.00141292 (* 1 = 0.00141292 loss)
I0429 12:04:42.556572  3523 sgd_solver.cpp:106] Iteration 48100, lr = 0.00267219
I0429 12:04:42.724946  3523 solver.cpp:237] Iteration 48200, loss = 0.00407313
I0429 12:04:42.724967  3523 solver.cpp:253]     Train net output #0: loss = 0.00407306 (* 1 = 0.00407306 loss)
I0429 12:04:42.724973  3523 sgd_solver.cpp:106] Iteration 48200, lr = 0.00266875
I0429 12:04:42.895275  3523 solver.cpp:237] Iteration 48300, loss = 0.00449455
I0429 12:04:42.895297  3523 solver.cpp:253]     Train net output #0: loss = 0.00449447 (* 1 = 0.00449447 loss)
I0429 12:04:42.895303  3523 sgd_solver.cpp:106] Iteration 48300, lr = 0.00266532
I0429 12:04:43.065465  3523 solver.cpp:237] Iteration 48400, loss = 0.00224017
I0429 12:04:43.065486  3523 solver.cpp:253]     Train net output #0: loss = 0.00224008 (* 1 = 0.00224008 loss)
I0429 12:04:43.065492  3523 sgd_solver.cpp:106] Iteration 48400, lr = 0.00266189
I0429 12:04:43.233814  3523 solver.cpp:237] Iteration 48500, loss = 0.000892248
I0429 12:04:43.233835  3523 solver.cpp:253]     Train net output #0: loss = 0.00089216 (* 1 = 0.00089216 loss)
I0429 12:04:43.233840  3523 sgd_solver.cpp:106] Iteration 48500, lr = 0.00265848
I0429 12:04:43.404017  3523 solver.cpp:237] Iteration 48600, loss = 0.00451248
I0429 12:04:43.404039  3523 solver.cpp:253]     Train net output #0: loss = 0.00451239 (* 1 = 0.00451239 loss)
I0429 12:04:43.404044  3523 sgd_solver.cpp:106] Iteration 48600, lr = 0.00265507
I0429 12:04:43.573169  3523 solver.cpp:237] Iteration 48700, loss = 0.00399047
I0429 12:04:43.573195  3523 solver.cpp:253]     Train net output #0: loss = 0.00399039 (* 1 = 0.00399039 loss)
I0429 12:04:43.573201  3523 sgd_solver.cpp:106] Iteration 48700, lr = 0.00265168
I0429 12:04:43.742570  3523 solver.cpp:237] Iteration 48800, loss = 0.00379607
I0429 12:04:43.742593  3523 solver.cpp:253]     Train net output #0: loss = 0.00379598 (* 1 = 0.00379598 loss)
I0429 12:04:43.742599  3523 sgd_solver.cpp:106] Iteration 48800, lr = 0.0026483
I0429 12:04:43.911674  3523 solver.cpp:237] Iteration 48900, loss = 0.00274013
I0429 12:04:43.911696  3523 solver.cpp:253]     Train net output #0: loss = 0.00274004 (* 1 = 0.00274004 loss)
I0429 12:04:43.911702  3523 sgd_solver.cpp:106] Iteration 48900, lr = 0.00264493
I0429 12:04:44.081195  3523 solver.cpp:237] Iteration 49000, loss = 0.00344523
I0429 12:04:44.081218  3523 solver.cpp:253]     Train net output #0: loss = 0.00344514 (* 1 = 0.00344514 loss)
I0429 12:04:44.081223  3523 sgd_solver.cpp:106] Iteration 49000, lr = 0.00264156
I0429 12:04:44.250519  3523 solver.cpp:237] Iteration 49100, loss = 0.00410129
I0429 12:04:44.250540  3523 solver.cpp:253]     Train net output #0: loss = 0.0041012 (* 1 = 0.0041012 loss)
I0429 12:04:44.250546  3523 sgd_solver.cpp:106] Iteration 49100, lr = 0.00263821
I0429 12:04:44.420372  3523 solver.cpp:237] Iteration 49200, loss = 0.00367163
I0429 12:04:44.420393  3523 solver.cpp:253]     Train net output #0: loss = 0.00367155 (* 1 = 0.00367155 loss)
I0429 12:04:44.420399  3523 sgd_solver.cpp:106] Iteration 49200, lr = 0.00263487
I0429 12:04:44.589787  3523 solver.cpp:237] Iteration 49300, loss = 0.00670413
I0429 12:04:44.589809  3523 solver.cpp:253]     Train net output #0: loss = 0.00670404 (* 1 = 0.00670404 loss)
I0429 12:04:44.589830  3523 sgd_solver.cpp:106] Iteration 49300, lr = 0.00263153
I0429 12:04:44.759054  3523 solver.cpp:237] Iteration 49400, loss = 0.00404078
I0429 12:04:44.759078  3523 solver.cpp:253]     Train net output #0: loss = 0.00404069 (* 1 = 0.00404069 loss)
I0429 12:04:44.759083  3523 sgd_solver.cpp:106] Iteration 49400, lr = 0.00262821
I0429 12:04:44.927772  3523 solver.cpp:237] Iteration 49500, loss = 0.00146722
I0429 12:04:44.927794  3523 solver.cpp:253]     Train net output #0: loss = 0.00146714 (* 1 = 0.00146714 loss)
I0429 12:04:44.927800  3523 sgd_solver.cpp:106] Iteration 49500, lr = 0.0026249
I0429 12:04:45.096987  3523 solver.cpp:237] Iteration 49600, loss = 0.00211659
I0429 12:04:45.097013  3523 solver.cpp:253]     Train net output #0: loss = 0.00211651 (* 1 = 0.00211651 loss)
I0429 12:04:45.097019  3523 sgd_solver.cpp:106] Iteration 49600, lr = 0.00262159
I0429 12:04:45.265593  3523 solver.cpp:237] Iteration 49700, loss = 0.00238402
I0429 12:04:45.265614  3523 solver.cpp:253]     Train net output #0: loss = 0.00238393 (* 1 = 0.00238393 loss)
I0429 12:04:45.265620  3523 sgd_solver.cpp:106] Iteration 49700, lr = 0.0026183
I0429 12:04:45.435104  3523 solver.cpp:237] Iteration 49800, loss = 0.00571033
I0429 12:04:45.435127  3523 solver.cpp:253]     Train net output #0: loss = 0.00571025 (* 1 = 0.00571025 loss)
I0429 12:04:45.435133  3523 sgd_solver.cpp:106] Iteration 49800, lr = 0.00261501
I0429 12:04:45.604097  3523 solver.cpp:237] Iteration 49900, loss = 0.00190294
I0429 12:04:45.604120  3523 solver.cpp:253]     Train net output #0: loss = 0.00190285 (* 1 = 0.00190285 loss)
I0429 12:04:45.604126  3523 sgd_solver.cpp:106] Iteration 49900, lr = 0.00261174
I0429 12:04:45.771006  3523 solver.cpp:459] Snapshotting to binary proto file _iter_50000.caffemodel
I0429 12:04:45.772753  3523 sgd_solver.cpp:269] Snapshotting solver state to binary proto file _iter_50000.solverstate
I0429 12:04:45.773592  3523 solver.cpp:321] Iteration 50000, loss = 0.00487213
I0429 12:04:45.773608  3523 solver.cpp:341] Iteration 50000, Testing net (#0)
I0429 12:04:45.847455  3523 solver.cpp:409]     Test net output #0: accuracy = 0.9883
I0429 12:04:45.847482  3523 solver.cpp:409]     Test net output #1: loss = 0.040649 (* 1 = 0.040649 loss)
I0429 12:04:45.847487  3523 solver.cpp:326] Optimization Done.
I0429 12:04:45.847496  3523 caffe.cpp:215] Optimization Done.
