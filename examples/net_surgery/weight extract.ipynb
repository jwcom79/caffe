{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "import sys\n",
    "sys.path.insert(0, './python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver = None  # ignore this workaround for lmdb data (can't instantiate two solvers on the same data)\n",
    "#solver = caffe.SGDSolver('examples/mlp/test/mlp_solver.prototxt')\n",
    "net1 = caffe.Net('examples/mlp/test/retrain/mlp_train_test.prototxt','examples/mlp/test/test.caffemodel', caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', (100, 1, 28, 28)),\n",
       " ('label', (100,)),\n",
       " ('data_mnist_0_split_0', (100, 1, 28, 28)),\n",
       " ('data_mnist_0_split_1', (100, 1, 28, 28)),\n",
       " ('label_mnist_1_split_0', (100,)),\n",
       " ('label_mnist_1_split_1', (100,)),\n",
       " ('ip1', (100, 200)),\n",
       " ('ip1-1', (100, 50)),\n",
       " ('ip2', (100, 200)),\n",
       " ('ip2-1', (100, 50)),\n",
       " ('ip3', (100, 10)),\n",
       " ('ip3-1', (100, 20)),\n",
       " ('ip3_flatten', (100, 10)),\n",
       " ('concat1', (100, 30)),\n",
       " ('ip4', (100, 10)),\n",
       " ('ip4_ip4_0_split_0', (100, 10)),\n",
       " ('ip4_ip4_0_split_1', (100, 10)),\n",
       " ('accuracy', ()),\n",
       " ('loss', ())]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# during training, each output is (batch size, feature dim, spatial dim)\n",
    "[(k, v.data.shape) for k, v in net1.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ip1', (200, 784)),\n",
       " ('ip1-1', (50, 784)),\n",
       " ('ip2', (200, 200)),\n",
       " ('ip2-1', (50, 50)),\n",
       " ('ip3', (10, 200)),\n",
       " ('ip3-1', (20, 50)),\n",
       " ('ip4', (10, 30))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just print the weight sizes (we'll omit the biases)\n",
    "[(k, v[0].data.shape) for k, v in net1.params.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net1.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('examples/mlp/test/WB/ip1_w.txt', 'w') as file:\n",
    "    for i in range(200):\n",
    "        for item in net1.params['ip1'][0].data[i]:\n",
    "            file.write(\"{}\\n\".format(item))\n",
    "            \n",
    "file.close()\n",
    "with open('examples/mlp/test/WB/ip1_b.txt', 'w') as file:\n",
    "    for item in net1.params['ip1'][1].data:\n",
    "        file.write(\"{}\\n\".format(item))\n",
    "            \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('examples/mlp/test/WB/ip2_w.txt', 'w') as file:\n",
    "    for i in range(200):\n",
    "        for item in net1.params['ip2'][0].data[i]:\n",
    "            file.write(\"{}\\n\".format(item))\n",
    "            \n",
    "file.close()\n",
    "with open('examples/mlp/test/WB/ip2_b.txt', 'w') as file:\n",
    "    for item in net1.params['ip2'][1].data:\n",
    "        file.write(\"{}\\n\".format(item))\n",
    "            \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('examples/mlp/test/WB/ip3_w.txt', 'w') as file:\n",
    "    for i in range(10):\n",
    "        for item in net1.params['ip3'][0].data[i]:\n",
    "            file.write(\"{}\\n\".format(item))\n",
    "            \n",
    "file.close()\n",
    "with open('examples/mlp/test/WB/ip3_b.txt', 'w') as file:\n",
    "    for item in net1.params['ip3'][1].data:\n",
    "        file.write(\"{}\\n\".format(item))\n",
    "            \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py \n",
    "with h5py.File('pruned_weights.h5', 'w') as hf:\n",
    "    gw = hf.create_group('weights')\n",
    "    gw.create_dataset('W1', data = net1.params['ip1'][0].data)\n",
    "    gw.create_dataset('W2', data = net1.params['ip2'][0].data)\n",
    "    gw.create_dataset('W3', data = net1.params['ip3'][0].data)\n",
    "    \n",
    "    gb = hf.create_group('bias')\n",
    "    gb.create_dataset('B1', data = net1.params['ip1'][1].data)\n",
    "    gb.create_dataset('B2', data = net1.params['ip2'][1].data)\n",
    "    gb.create_dataset('B3', data = net1.params['ip3'][1].data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net1.params['ip1'][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1.save('examples/mlp/test/retrain/weights.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
