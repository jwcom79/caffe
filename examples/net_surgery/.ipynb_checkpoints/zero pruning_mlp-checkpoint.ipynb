{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "caffe_root = '/home/flathead/bitbucket/mycaffe/'\n",
    "os.chdir('../../')\n",
    "import sys\n",
    "sys.path.insert(0, 'python')\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = None  # ignore this workaround for lmdb data (can't instantiate two solvers on the same data)\n",
    "solver = caffe.SGDSolver('examples/mlp/mlp_solver.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1 = solver.net\n",
    "test_net = solver.test_nets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# during training, each output is (batch size, feature dim, spatial dim)\n",
    "[(k, v.data.shape) for k, v in net1.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# just print the weight sizes (we'll omit the biases)\n",
    "[(k, v[0].data.shape) for k, v in net1.params.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat1 = net1.params['ip1'][0].data\n",
    "feat2 = net1.params['ip2'][0].data\n",
    "feat3 = net1.params['ip3'][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "niter = 5000\n",
    "test_interval = 500\n",
    "train_loss = zeros(niter)\n",
    "test_acc = zeros(int(np.ceil(niter / test_interval)))\n",
    "output = zeros((niter, 8, 10))\n",
    "\n",
    "for it in range(niter):\n",
    "    solver.step(1)\n",
    "    #net1.forward()\n",
    "    \n",
    "    train_loss[it] = net1.blobs['loss'].data\n",
    "    \n",
    "    net1.forward(start='ip1')\n",
    "    output[it] = test_net.blobs['ip3'].data[:8]\n",
    "    \n",
    "    if it % test_interval == 0:\n",
    "        print 'iteration', it, 'testing...'\n",
    "        correct = 0\n",
    "        for test_it in range(100):\n",
    "            test_net.forward()\n",
    "            correct += sum(test_net.blobs['ip3'].data.argmax(1) == test_net.blobs['label'].data)\n",
    "        test_acc[it // test_interval] = correct / 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net1.save('examples/mlp/pruning.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Neurons of Layer 1\n",
    "mean_feat1 = [0] * 20\n",
    "std_feat1 = [0] * 20\n",
    "\n",
    "for j in range(20):\n",
    "    mean_feat1[j] = feat1[j].mean()\n",
    "    std_feat1[j] = feat1[j].std()\n",
    "    \n",
    "#Neurons of Layer 2\n",
    "mean_feat2 = [0] * 50\n",
    "std_feat2 = [0] * 50\n",
    "\n",
    "for j in range(50):\n",
    "    mean_feat2[j] = feat2[j].mean()\n",
    "    std_feat2[j] = feat2[j].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neurons of Layer 1\n",
    "posm_feat1 = [0] * 20\n",
    "negm_feat1 = [0] * 20\n",
    "poss_feat1 = [0] * 20\n",
    "negs_feat1 = [0] * 20\n",
    "\n",
    "for j in range(20):\n",
    "    posm_feat1[j] = feat1[j][feat1[j] > mean_feat1[j]].mean()\n",
    "    negm_feat1[j] = feat1[j][feat1[j] < mean_feat1[j]].mean()\n",
    "    poss_feat1[j] = feat1[j][feat1[j] > mean_feat1[j]].std()\n",
    "    negs_feat1[j] = feat1[j][feat1[j] < mean_feat1[j]].std()\n",
    "    \n",
    "#Neurons of Layer 2\n",
    "posm_feat2 = [0] * 50\n",
    "negm_feat2 = [0] * 50\n",
    "poss_feat2 = [0] * 50\n",
    "negs_feat2 = [0] * 50\n",
    "\n",
    "for j in range(50):\n",
    "    posm_feat2[j] = feat2[j][feat2[j] > mean_feat2[j]].mean()\n",
    "    negm_feat2[j] = feat2[j][feat2[j] < mean_feat2[j]].mean()\n",
    "    poss_feat2[j] = feat2[j][feat2[j] > mean_feat2[j]].std()\n",
    "    negs_feat2[j] = feat2[j][feat2[j] < mean_feat2[j]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#í‰í–‰ì´ë™\n",
    "for x in range(20):\n",
    "    feat1[x] = (feat1[x] - mean_feat1[x])\n",
    "    #feat1[x] = (feat1[x] - mean_feat1[x]) / std_feat1[x]\n",
    "for y in range(50):\n",
    "    feat2[y] = (feat2[y] - mean_feat2[y])\n",
    "    #feat2[y] = (feat2[y] - mean_feat2[y]) / std_feat2[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1.save('examples/mlp/pruning.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neurons of Layer 1\n",
    "mean_feat1 = [0] * 20\n",
    "std_feat1 = [0] * 20\n",
    "\n",
    "for j in range(20):\n",
    "    mean_feat1[j] = feat1[j].mean()\n",
    "    std_feat1[j] = feat1[j].std()\n",
    "    \n",
    "#Neurons of Layer 2\n",
    "mean_feat2 = [0] * 50\n",
    "std_feat2 = [0] * 50\n",
    "\n",
    "for j in range(50):\n",
    "    mean_feat2[j] = feat2[j].mean()\n",
    "    std_feat2[j] = feat2[j].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(20):\n",
    "#    print [mean_feat1[j] - 0.5 * std_feat1[j], mean_feat1[j] + 0.5 * std_feat1[j]]\n",
    "    print [negm_feat1[j]-negs_feat1[j], negm_feat1[j]+negs_feat1[j], mean_feat1[j]-std_feat1[j], mean_feat1[j]+std_feat1[j], posm_feat1[j]-poss_feat1[j], posm_feat1[j]+poss_feat1[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(50):\n",
    "    print [negm_feat2[j]-negs_feat2[j], negm_feat2[j]+negs_feat2[j], mean_feat2[j]-std_feat2[j], mean_feat2[j]+std_feat2[j], posm_feat2[j]-poss_feat2[j], posm_feat2[j]+poss_feat2[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0.5 * std range 0 pruning\n",
    "a1 = [0] * 20\n",
    "b1 = [0] * 50\n",
    "a2 = [0] * 20\n",
    "b2 = [0] * 50\n",
    "\n",
    "for x in range(20):\n",
    "    a1[x] = (posm_feat1[x] - mean_feat1[x]) / 2 / std_feat1[x]\n",
    "    a2[x] = (mean_feat1[x] - negm_feat1[x]) / 2 / std_feat1[x]\n",
    "for y in range(50):\n",
    "    b1[y] = (posm_feat2[y] - mean_feat2[y]) / 2 / std_feat2[y]\n",
    "    b2[y] = (mean_feat2[y] - negm_feat2[y]) / 2 / std_feat2[y]\n",
    "    \n",
    "for x in range(20):\n",
    "    for y in range(784):\n",
    "        if (feat1[x,y] >= (mean_feat1[x] - a2[x] * std_feat1[x])) & (feat1[x,y] <= (mean_feat1[x] + a1[x] * std_feat1[x])):\n",
    "        #if (feat1[x,y] >= -1 * std_feat1[x]) & (feat1[x,y] <= 1 * std_feat1[x]):\n",
    "            feat1[x,y] = mean_feat1[x]\n",
    "            \n",
    "for x in range(50):\n",
    "    for y in range(20):\n",
    "        if (feat2[x,y] >= (mean_feat2[x] - b2[y] * std_feat2[x])) & (feat2[x,y] <= (mean_feat2[x] + b1[y] * std_feat2[x])):\n",
    "        #if (feat2[x,y] >= -1 * std_feat2[x]) & (feat2[x,y] <= 1 * std_feat2[x]):\n",
    "            feat2[x,y] = mean_feat2[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 100))\n",
    "#plt.hist(train_net.params['ip1'][0].data)\n",
    "for j in range(1,21):\n",
    "    plt.subplot(21,1,j)\n",
    "    plt.hist(feat1[j-1], bins = 784)\n",
    "    plt.title(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(20):\n",
    "    print (feat1[x] == mean_feat1[x]).sum()\n",
    "for y in range(50):\n",
    "    print (feat2[y] == mean_feat2[y]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1.save('examples/mlp/pruning.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neurons of Layer 1\n",
    "posm_feat1 = [0] * 20\n",
    "negm_feat1 = [0] * 20\n",
    "poss_feat1 = [0] * 20\n",
    "negs_feat1 = [0] * 20\n",
    "\n",
    "for j in range(20):\n",
    "    posm_feat1[j] = feat1[j][feat1[j] > mean_feat1[j]].mean()\n",
    "    negm_feat1[j] = feat1[j][feat1[j] < mean_feat1[j]].mean()\n",
    "    poss_feat1[j] = feat1[j][feat1[j] > mean_feat1[j]].std()\n",
    "    negs_feat1[j] = feat1[j][feat1[j] < mean_feat1[j]].std()\n",
    "    \n",
    "#Neurons of Layer 2\n",
    "posm_feat2 = [0] * 50\n",
    "negm_feat2 = [0] * 50\n",
    "poss_feat2 = [0] * 50\n",
    "negs_feat2 = [0] * 50\n",
    "\n",
    "for j in range(50):\n",
    "    posm_feat2[j] = feat2[j][feat2[j] > mean_feat2[j]].mean()\n",
    "    negm_feat2[j] = feat2[j][feat2[j] < mean_feat2[j]].mean()\n",
    "    poss_feat2[j] = feat2[j][feat2[j] > mean_feat2[j]].std()\n",
    "    negs_feat2[j] = feat2[j][feat2[j] < mean_feat2[j]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(20):\n",
    "    for y in range(784):\n",
    "        if ((feat1[x,y] <= (posm_feat1[x] + (a1[x] * std_feat1[x]))) & (feat1[x,y] >= (posm_feat1[x] - (a1[x] * std_feat1[x])))):\n",
    "        #if ((feat1[x,y] <= (posm_feat1[x] + (a1[x] * poss_feat1[x]))) & (feat1[x,y] >= (posm_feat1[x] - (a1[x] * poss_feat1[x])))):\n",
    "        #if (feat1[x, y] > 0):\n",
    "            feat1[x,y] = posm_feat1[x]\n",
    "        if ((feat1[x,y] <= (negm_feat1[x] + (a2[x] * std_feat1[x]))) & (feat1[x,y] >= (negm_feat1[x] - (a2[x] * std_feat1[x])))):\n",
    "        #if ((feat1[x,y] <= (negm_feat1[x] + (a2[x] * negs_feat1[x]))) & (feat1[x,y] >= (negm_feat1[x] - (a2[x] * negs_feat1[x])))):\n",
    "        #f (feat1[x, y] < 0):\n",
    "            feat1[x,y] = negm_feat1[x]\n",
    "for x in range(50):\n",
    "    for y in range(20):\n",
    "        if ((feat2[x,y] <= (posm_feat2[x] + (b1[x] * std_feat2[x]))) & (feat2[x,y] >= (posm_feat2[x] - (b1[x] * std_feat2[x])))):\n",
    "        #if ((feat2[x,y] <= (posm_feat2[x] + (b1[x] * poss_feat2[x]))) & (feat2[x,y] >= (posm_feat2[x] - (b1[x] * poss_feat2[x])))):\n",
    "        #if (feat2[x, y] > 0):\n",
    "            feat2[x,y] = posm_feat2[x]\n",
    "        if ((feat2[x,y] <= (negm_feat2[x] + (b2[x] * std_feat2[x]))) & (feat2[x,y] >= (negm_feat2[x] - (b2[x] * std_feat2[x])))):\n",
    "        #if ((feat2[x,y] <= (negm_feat2[x] + (b2[x] * negs_feat2[x]))) & (feat2[x,y] >= (negm_feat2[x] - (b2[x] * negs_feat2[x])))):\n",
    "        #if (feat2[x, y] > 0):\n",
    "            feat2[x,y] = negm_feat2[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1.save('examples/mlp/pruning.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(20):\n",
    "    print ((feat1[x] == posm_feat1[x]) | (feat1[x] == negm_feat1[x]) | (feat1[x] == mean_feat1[x])).sum()\n",
    "for y in range(50):\n",
    "    print ((feat2[y] == posm_feat2[y]) | (feat2[y] == negm_feat2[y]) | (feat2[y] == mean_feat2[y])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(20):\n",
    "    #print feat2[j].mean()\n",
    "    #print feat2[j].std()\n",
    "    print feat1[j][feat1[j] > std_feat1[j]].mean()\n",
    "    print feat1[j][feat1[j] < -std_feat1[j]].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
