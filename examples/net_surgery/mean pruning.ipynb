{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "caffe_root = '/home/flathead/bitbucket/mycaffe/'\n",
    "os.chdir('../../')\n",
    "import sys\n",
    "sys.path.insert(0, 'python')\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = None  # ignore this workaround for lmdb data (can't instantiate two solvers on the same data)\n",
    "solver = caffe.SGDSolver('examples/mlp/mlp_solver.prototxt')\n",
    "net1 = solver.net\n",
    "test_net = solver.test_nets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1 = caffe.Net('examples/mlp/mlp_train_test.prototxt',\n",
    "                'examples/mlp/baseline.caffemodel', \n",
    "                 caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# during training, each output is (batch size, feature dim, spatial dim)\n",
    "[(k, v.data.shape) for k, v in net1.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# just print the weight sizes (we'll omit the biases)\n",
    "[(k, v[0].data.shape) for k, v in net1.params.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net1.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat1 = net1.params['ip1'][0].data\n",
    "feat2 = net1.params['ip2'][0].data\n",
    "feat3 = net1.params['ip3'][0].data\n",
    "feat4 = net1.params['ip4'][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = 500\n",
    "l2 = 500\n",
    "l3 = 2000\n",
    "l4 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "#plt.hist(train_net.params['ip1'][0].data)\n",
    "'''\n",
    "for j in range(1,21):\n",
    "    plt.subplot(21,1,j)\n",
    "    plt.hist(feat1[j-1], bins = 784)\n",
    "    plt.title(j)\n",
    "'''\n",
    "plt.subplot(4,1,1)\n",
    "plt.hist(feat1.flat, bins = 500)\n",
    "plt.title(\"Input layer\")\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.hist(feat2.flat, bins = 500)\n",
    "plt.title(\"1'st layer\")\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.hist(feat3.flat, bins = 500)\n",
    "plt.title(\"2'nd layer\")\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.hist(feat4.flat, bins = 500)\n",
    "plt.title(\"Last layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "niter = 5000\n",
    "test_interval = 500\n",
    "train_loss = zeros(niter)\n",
    "test_acc = zeros(int(np.ceil(niter / test_interval)))\n",
    "output = zeros((niter, 8, 10))\n",
    "\n",
    "for it in range(niter):\n",
    "    solver.step(1)\n",
    "    net1.forward()\n",
    "    \n",
    "    train_loss[it] = net1.blobs['loss'].data\n",
    "    \n",
    "    net1.forward(start='ip1')\n",
    "    output[it] = test_net.blobs['ip4'].data[:8]\n",
    "    \n",
    "    if it % test_interval == 0:\n",
    "        print 'iteration', it, 'testing...'\n",
    "        correct = 0\n",
    "        for test_it in range(100):\n",
    "            test_net.forward()\n",
    "            correct += sum(test_net.blobs['ip4'].data.argmax(1) == test_net.blobs['label'].data)\n",
    "        test_acc[it // test_interval] = correct / 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net1.save('examples/mlp/meanpr/baseline.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Neurons of Layer 1\n",
    "mean_feat1 = [0] * l1\n",
    "std_feat1 = [0] * l1\n",
    "\n",
    "for j in range(l1):\n",
    "    mean_feat1[j] = feat1[j].mean()\n",
    "    std_feat1[j] = feat1[j].std()\n",
    "    \n",
    "#Neurons of Layer 2\n",
    "mean_feat2 = [0] * l2\n",
    "std_feat2 = [0] * l2\n",
    "\n",
    "for j in range(l2):\n",
    "    mean_feat2[j] = feat2[j].mean()\n",
    "    std_feat2[j] = feat2[j].std()\n",
    "    \n",
    "#Neurons of Layer 3\n",
    "mean_feat3 = [0] * l3\n",
    "std_feat3 = [0] * l3\n",
    "\n",
    "for j in range(l3):\n",
    "    mean_feat3[j] = feat3[j].mean()\n",
    "    std_feat3[j] = feat3[j].std()\n",
    "    \n",
    "#Neurons of Layer 4\n",
    "mean_feat4 = [0] * l4\n",
    "std_feat4 = [0] * l4\n",
    "\n",
    "for j in range(l4):\n",
    "    mean_feat4[j] = feat4[j].mean()\n",
    "    std_feat4[j] = feat4[j].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize\n",
    "for j in range(l1):\n",
    "    feat1[j] /= 28\n",
    "    \n",
    "for j in range(l2):\n",
    "    feat2[j] /= 4.47213\n",
    "\n",
    "for j in range(l3):\n",
    "    feat3[j] /= 4.47213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalized Variance\n",
    "for j in range(l1):\n",
    "    print feat1[j].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Neurons of Layer 1\n",
    "posm_feat1 = [0] * l1\n",
    "negm_feat1 = [0] * l1\n",
    "poss_feat1 = [0] * l1\n",
    "negs_feat1 = [0] * l1\n",
    "\n",
    "for j in range(l1):\n",
    "    posm_feat1[j] = feat1[j][feat1[j] > mean_feat1[j]].mean()\n",
    "    negm_feat1[j] = feat1[j][feat1[j] < mean_feat1[j]].mean()\n",
    "    poss_feat1[j] = feat1[j][feat1[j] > mean_feat1[j]].std()\n",
    "    negs_feat1[j] = feat1[j][feat1[j] < mean_feat1[j]].std()\n",
    "    \n",
    "#Neurons of Layer 2\n",
    "posm_feat2 = [0] * l2\n",
    "negm_feat2 = [0] * l2\n",
    "poss_feat2 = [0] * l2\n",
    "negs_feat2 = [0] * l2\n",
    "\n",
    "for j in range(l2):\n",
    "    posm_feat2[j] = feat2[j][feat2[j] > mean_feat2[j]].mean()\n",
    "    negm_feat2[j] = feat2[j][feat2[j] < mean_feat2[j]].mean()\n",
    "    poss_feat2[j] = feat2[j][feat2[j] > mean_feat2[j]].std()\n",
    "    negs_feat2[j] = feat2[j][feat2[j] < mean_feat2[j]].std()\n",
    "    \n",
    "#Neurons of Layer 3\n",
    "posm_feat3 = [0] * l3\n",
    "negm_feat3 = [0] * l3\n",
    "poss_feat3 = [0] * l3\n",
    "negs_feat3 = [0] * l3\n",
    "\n",
    "for j in range(l3):\n",
    "    posm_feat3[j] = feat3[j][feat3[j] > mean_feat3[j]].mean()\n",
    "    negm_feat3[j] = feat3[j][feat3[j] < mean_feat3[j]].mean()\n",
    "    poss_feat3[j] = feat3[j][feat3[j] > mean_feat3[j]].std()\n",
    "    negs_feat3[j] = feat3[j][feat3[j] < mean_feat3[j]].std()\n",
    "\n",
    "#Neurons of Layer 4\n",
    "posm_feat4 = [0] * l4\n",
    "negm_feat4 = [0] * l4\n",
    "poss_feat4 = [0] * l4\n",
    "negs_feat4 = [0] * l4\n",
    "\n",
    "for j in range(l4):\n",
    "    posm_feat4[j] = feat4[j][feat4[j] > mean_feat4[j]].mean()\n",
    "    negm_feat4[j] = feat4[j][feat4[j] < mean_feat4[j]].mean()\n",
    "    poss_feat4[j] = feat4[j][feat4[j] > mean_feat4[j]].std()\n",
    "    negs_feat4[j] = feat4[j][feat4[j] < mean_feat4[j]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#평행이동\n",
    "for x in range(l1):\n",
    "    feat1[x] = (feat1[x] - mean_feat1[x])\n",
    "    #feat1[x] = (feat1[x] - mean_feat1[x]) / std_feat1[x]\n",
    "for y in range(l2):\n",
    "    feat2[y] = (feat2[y] - mean_feat2[y])\n",
    "    #feat2[y] = (feat2[y] - mean_feat2[y]) / std_feat2[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#평행이동\n",
    "net1.save('examples/mlp/meanpr/shift.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neurons of Layer 1\n",
    "mean_feat1 = [0] * 20\n",
    "std_feat1 = [0] * 20\n",
    "\n",
    "for j in range(20):\n",
    "    mean_feat1[j] = feat1[j].mean()\n",
    "    std_feat1[j] = feat1[j].std()\n",
    "    \n",
    "#Neurons of Layer 2\n",
    "mean_feat2 = [0] * 50\n",
    "std_feat2 = [0] * 50\n",
    "\n",
    "for j in range(50):\n",
    "    mean_feat2[j] = feat2[j].mean()\n",
    "    std_feat2[j] = feat2[j].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(20):\n",
    "#    print [mean_feat1[j] - 0.5 * std_feat1[j], mean_feat1[j] + 0.5 * std_feat1[j]]\n",
    "    print [negm_feat1[j]-negs_feat1[j], negm_feat1[j]+negs_feat1[j], mean_feat1[j]-std_feat1[j], mean_feat1[j]+std_feat1[j], posm_feat1[j]-poss_feat1[j], posm_feat1[j]+poss_feat1[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(50):\n",
    "    print [negm_feat2[j]-negs_feat2[j], negm_feat2[j]+negs_feat2[j], mean_feat2[j]-std_feat2[j], mean_feat2[j]+std_feat2[j], posm_feat2[j]-poss_feat2[j], posm_feat2[j]+poss_feat2[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0.5 * std range mean pruning\n",
    "r = 0.1\n",
    "'''\n",
    "a1 = [0] * l1\n",
    "b1 = [0] * l2\n",
    "c1 = [0] * l3\n",
    "d1 = [0] * l4\n",
    "a2 = [0] * l1\n",
    "b2 = [0] * l2\n",
    "c2 = [0] * l3\n",
    "d2 = [0] * l4\n",
    "\n",
    "for x in range(l1):\n",
    "    a1[x] = (posm_feat1[x] - mean_feat1[x]) / 2 / std_feat1[x]\n",
    "    a2[x] = (mean_feat1[x] - negm_feat1[x]) / 2 / std_feat1[x]\n",
    "for y in range(l2):\n",
    "    b1[y] = (posm_feat2[y] - mean_feat2[y]) / 2 / std_feat2[y]\n",
    "    b2[y] = (mean_feat2[y] - negm_feat2[y]) / 2 / std_feat2[y]\n",
    "for z in range(l3):\n",
    "    c1[z] = (posm_feat3[z] - mean_feat3[z]) / 2 / std_feat3[z]\n",
    "    c2[z] = (mean_feat3[z] - negm_feat3[z]) / 2 / std_feat3[z]\n",
    "for z in range(l4):\n",
    "    d1[z] = (posm_feat4[z] - mean_feat4[z]) / 2 / std_feat4[z]\n",
    "    d2[z] = (mean_feat4[z] - negm_feat4[z]) / 2 / std_feat4[z]\n",
    "'''    \n",
    "for x in range(l1):\n",
    "    for y in range(784):\n",
    "        #if (feat1[x,y] >= (mean_feat1[x] - a2[x] * std_feat1[x])) & (feat1[x,y] <= (mean_feat1[x] + a1[x] * std_feat1[x])):\n",
    "        if (feat1[x,y] >= -r * std_feat1[x]) & (feat1[x,y] <= r * std_feat1[x]):\n",
    "            #feat1[x,y] = mean_feat1[x]\n",
    "            feat1[x,y] = 0\n",
    "            \n",
    "for x in range(l2):\n",
    "    for y in range(l1):\n",
    "        #if (feat2[x,y] >= (mean_feat2[x] - b2[x] * std_feat2[x])) & (feat2[x,y] <= (mean_feat2[x] + b1[x] * std_feat2[x])):\n",
    "        if (feat2[x,y] >= -r * std_feat2[x]) & (feat2[x,y] <= r * std_feat2[x]):\n",
    "            #feat2[x,y] = mean_feat2[x]\n",
    "            feat2[x,y] = 0\n",
    "    \n",
    "for x in range(l3):\n",
    "    for y in range(l2):\n",
    "        #if (feat3[x,y] >= (mean_feat3[x] - c2[x] * std_feat3[x])) & (feat3[x,y] <= (mean_feat3[x] + c1[x] * std_feat3[x])):\n",
    "        if (feat3[x,y] >= -r * std_feat3[x]) & (feat3[x,y] <= r * std_feat3[x]):\n",
    "            #feat3[x,y] = mean_feat3[x]\n",
    "            feat3[x,y] = 0\n",
    "            \n",
    "for x in range(l4):\n",
    "    for y in range(l3):\n",
    "        #if (feat4[x,y] >= (mean_feat4[x] - d2[x] * std_feat4[x])) & (feat4[x,y] <= (mean_feat4[x] + d1[x] * std_feat4[x])):\n",
    "        if (feat4[x,y] >= -r * std_feat4[x]) & (feat4[x,y] <= r * std_feat4[x]):\n",
    "            #feat4[x,y] = mean_feat4[x]\n",
    "            feat4[x,y] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1.save('examples/mlp/meanpr/prune.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "niter = 10000\n",
    "test_interval = 500\n",
    "train_loss = zeros(niter)\n",
    "test_acc = zeros(int(np.ceil(niter / test_interval)))\n",
    "output = zeros((niter, 8, 10))\n",
    "\n",
    "for it in range(niter):\n",
    "    solver.step(1)\n",
    "    \n",
    "    train_loss[it] = solver.net.blobs['loss'].data\n",
    "    \n",
    "    solver.test_nets[0].forward(start='conv1')\n",
    "    output[it] = solver.test_nets[0].blobs['ip3'].data[:8]\n",
    "    \n",
    "    if it % test_interval == 0:\n",
    "        print 'iteration', it, 'testing...'\n",
    "        correct = 0\n",
    "        for test_it in range(100):\n",
    "            solver.test_nets[0].forward()\n",
    "            correct += sum(solver.test_nets[0].blobs['ip3'].data.argmax(1) == solver.test_nets[0].blobs['label'].data)\n",
    "        test_acc[it // test_interval] = correct / 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "#plt.hist(train_net.params['ip1'][0].data)\n",
    "'''\n",
    "for j in range(1,21):\n",
    "    plt.subplot(21,1,j)\n",
    "    plt.hist(feat1[j-1], bins = 784)\n",
    "    plt.title(j)\n",
    "'''\n",
    "plt.subplot(4,1,1)\n",
    "plt.hist(feat1.flat, bins = 500)\n",
    "plt.title(\"Input layer\")\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.hist(feat2.flat, bins = 500)\n",
    "plt.title(\"1'st layer\")\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.hist(feat3.flat, bins = 500)\n",
    "plt.title(\"2'nd layer\")\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.hist(feat4.flat, bins = 500)\n",
    "plt.title(\"Last layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(l1):\n",
    "    print (feat1[x] == mean_feat1[x]).sum()\n",
    "for y in range(l2):\n",
    "    print (feat2[y] == mean_feat2[y]).sum()\n",
    "for z in range(l3):\n",
    "    print (feat3[y] == mean_feat3[y]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neurons of Layer 1\n",
    "posm_feat1 = [0] * l1\n",
    "negm_feat1 = [0] * l1\n",
    "poss_feat1 = [0] * l1\n",
    "negs_feat1 = [0] * l1\n",
    "\n",
    "for j in range(l1):\n",
    "    posm_feat1[j] = feat1[j][feat1[j] > mean_feat1[j]].mean()\n",
    "    negm_feat1[j] = feat1[j][feat1[j] < mean_feat1[j]].mean()\n",
    "    poss_feat1[j] = feat1[j][feat1[j] > mean_feat1[j]].std()\n",
    "    negs_feat1[j] = feat1[j][feat1[j] < mean_feat1[j]].std()\n",
    "    \n",
    "#Neurons of Layer 2\n",
    "posm_feat2 = [0] * l2\n",
    "negm_feat2 = [0] * l2\n",
    "poss_feat2 = [0] * l2\n",
    "negs_feat2 = [0] * l2\n",
    "\n",
    "for j in range(l2):\n",
    "    posm_feat2[j] = feat2[j][feat2[j] > mean_feat2[j]].mean()\n",
    "    negm_feat2[j] = feat2[j][feat2[j] < mean_feat2[j]].mean()\n",
    "    poss_feat2[j] = feat2[j][feat2[j] > mean_feat2[j]].std()\n",
    "    negs_feat2[j] = feat2[j][feat2[j] < mean_feat2[j]].std()\n",
    "    \n",
    "#Neurons of Layer 3\n",
    "posm_feat3 = [0] * l3\n",
    "negm_feat3 = [0] * l3\n",
    "poss_feat3 = [0] * l3\n",
    "negs_feat3 = [0] * l3\n",
    "\n",
    "for j in range(l3):\n",
    "    posm_feat3[j] = feat3[j][feat3[j] > mean_feat3[j]].mean()\n",
    "    negm_feat3[j] = feat3[j][feat3[j] < mean_feat3[j]].mean()\n",
    "    poss_feat3[j] = feat3[j][feat3[j] > mean_feat3[j]].std()\n",
    "    negs_feat3[j] = feat3[j][feat3[j] < mean_feat3[j]].std()\n",
    "    \n",
    "#Neurons of Layer 4\n",
    "posm_feat4 = [0] * l4\n",
    "negm_feat4 = [0] * l4\n",
    "poss_feat4 = [0] * l4\n",
    "negs_feat4 = [0] * l4\n",
    "\n",
    "for j in range(l4):\n",
    "    posm_feat4[j] = feat4[j][feat4[j] > mean_feat4[j]].mean()\n",
    "    negm_feat4[j] = feat4[j][feat4[j] < mean_feat4[j]].mean()\n",
    "    poss_feat4[j] = feat4[j][feat4[j] > mean_feat4[j]].std()\n",
    "    negs_feat4[j] = feat4[j][feat4[j] < mean_feat4[j]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(l1):\n",
    "    for y in range(784):\n",
    "        if (feat1[x, y] > 0):\n",
    "            feat1[x,y] = posm_feat1[x]\n",
    "        if (feat1[x, y] < 0):\n",
    "            feat1[x,y] = negm_feat1[x]\n",
    "for x in range(l2):\n",
    "    for y in range(l1):\n",
    "        if (feat2[x, y] > 0):\n",
    "            feat2[x,y] = posm_feat2[x]\n",
    "        if (feat2[x, y] < 0):\n",
    "            feat2[x,y] = negm_feat2[x]\n",
    "for x in range(l3):\n",
    "    for y in range(l2):\n",
    "        if (feat3[x, y] > 0):\n",
    "            feat3[x,y] = posm_feat3[x]\n",
    "        if (feat3[x, y] < 0):\n",
    "            feat3[x,y] = negm_feat3[x]\n",
    "for x in range(l4):\n",
    "    for y in range(l3):\n",
    "        if (feat4[x, y] > 0):\n",
    "            feat4[x,y] = posm_feat4[x]\n",
    "        if (feat4[x, y] < 0):\n",
    "            feat4[x,y] = negm_feat4[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.subplot(4,1,1)\n",
    "plt.hist(feat1[0].flat, bins = 500)\n",
    "plt.title(\"Input layer\")\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.hist(feat2[0].flat, bins = 500)\n",
    "plt.title(\"1'st layer\")\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.hist(feat3[0].flat, bins = 500)\n",
    "plt.title(\"2'nd layer\")\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.hist(feat4[0].flat, bins = 500)\n",
    "plt.title(\"Last layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1.save('examples/mlp/meanpr/quant.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(l1):\n",
    "    print ((feat1[x] == posm_feat1[x]) | (feat1[x] == negm_feat1[x]) | (feat1[x] == mean_feat1[x])).sum()\n",
    "for y in range(l2):\n",
    "    print ((feat2[y] == posm_feat2[y]) | (feat2[y] == negm_feat2[y]) | (feat2[y] == mean_feat2[y])).sum()\n",
    "for z in range(l3):\n",
    "    print ((feat3[z] == posm_feat3[z]) | (feat3[z] == negm_feat3[z]) | (feat3[z] == mean_feat3[z])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(20):\n",
    "    #print feat2[j].mean()\n",
    "    #print feat2[j].std()\n",
    "    print feat1[j][feat1[j] > std_feat1[j]].mean()\n",
    "    print feat1[j][feat1[j] < -std_feat1[j]].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
