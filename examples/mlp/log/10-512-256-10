I0328 17:14:58.302837  1497 caffe.cpp:184] Using GPUs 0
I0328 17:14:58.534832  1497 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mlp/mlp"
solver_mode: GPU
device_id: 0
net: "examples/mlp/mlp_train_test.prototxt"
I0328 17:14:58.534936  1497 solver.cpp:91] Creating training net from net file: examples/mlp/mlp_train_test.prototxt
I0328 17:14:58.535209  1497 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0328 17:14:58.535225  1497 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0328 17:14:58.535287  1497 net.cpp:49] Initializing net from parameters: 
name: "MLP"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "data"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "ip4"
  type: "InnerProduct"
  bottom: "ip3"
  top: "ip4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip4"
  bottom: "label"
  top: "loss"
}
I0328 17:14:58.535342  1497 layer_factory.hpp:77] Creating layer mnist
I0328 17:14:58.535787  1497 net.cpp:106] Creating Layer mnist
I0328 17:14:58.535800  1497 net.cpp:411] mnist -> data
I0328 17:14:58.535820  1497 net.cpp:411] mnist -> label
I0328 17:14:58.536535  1501 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_train_lmdb
I0328 17:14:58.542533  1497 data_layer.cpp:41] output data size: 64,1,28,28
I0328 17:14:58.543247  1497 net.cpp:150] Setting up mnist
I0328 17:14:58.543262  1497 net.cpp:157] Top shape: 64 1 28 28 (50176)
I0328 17:14:58.543267  1497 net.cpp:157] Top shape: 64 (64)
I0328 17:14:58.543270  1497 net.cpp:165] Memory required for data: 200960
I0328 17:14:58.543280  1497 layer_factory.hpp:77] Creating layer ip1
I0328 17:14:58.543290  1497 net.cpp:106] Creating Layer ip1
I0328 17:14:58.543295  1497 net.cpp:454] ip1 <- data
I0328 17:14:58.543306  1497 net.cpp:411] ip1 -> ip1
I0328 17:14:58.543822  1497 net.cpp:150] Setting up ip1
I0328 17:14:58.543833  1497 net.cpp:157] Top shape: 64 10 (640)
I0328 17:14:58.543836  1497 net.cpp:165] Memory required for data: 203520
I0328 17:14:58.543848  1497 layer_factory.hpp:77] Creating layer relu1
I0328 17:14:58.543855  1497 net.cpp:106] Creating Layer relu1
I0328 17:14:58.543859  1497 net.cpp:454] relu1 <- ip1
I0328 17:14:58.543864  1497 net.cpp:397] relu1 -> ip1 (in-place)
I0328 17:14:58.649891  1497 net.cpp:150] Setting up relu1
I0328 17:14:58.649919  1497 net.cpp:157] Top shape: 64 10 (640)
I0328 17:14:58.649922  1497 net.cpp:165] Memory required for data: 206080
I0328 17:14:58.649929  1497 layer_factory.hpp:77] Creating layer ip2
I0328 17:14:58.649958  1497 net.cpp:106] Creating Layer ip2
I0328 17:14:58.649963  1497 net.cpp:454] ip2 <- ip1
I0328 17:14:58.649971  1497 net.cpp:411] ip2 -> ip2
I0328 17:14:58.650460  1497 net.cpp:150] Setting up ip2
I0328 17:14:58.650471  1497 net.cpp:157] Top shape: 64 512 (32768)
I0328 17:14:58.650475  1497 net.cpp:165] Memory required for data: 337152
I0328 17:14:58.650485  1497 layer_factory.hpp:77] Creating layer relu2
I0328 17:14:58.650492  1497 net.cpp:106] Creating Layer relu2
I0328 17:14:58.650496  1497 net.cpp:454] relu2 <- ip2
I0328 17:14:58.650501  1497 net.cpp:397] relu2 -> ip2 (in-place)
I0328 17:14:58.651080  1497 net.cpp:150] Setting up relu2
I0328 17:14:58.651093  1497 net.cpp:157] Top shape: 64 512 (32768)
I0328 17:14:58.651095  1497 net.cpp:165] Memory required for data: 468224
I0328 17:14:58.651099  1497 layer_factory.hpp:77] Creating layer ip3
I0328 17:14:58.651105  1497 net.cpp:106] Creating Layer ip3
I0328 17:14:58.651108  1497 net.cpp:454] ip3 <- ip2
I0328 17:14:58.651113  1497 net.cpp:411] ip3 -> ip3
I0328 17:14:58.652218  1497 net.cpp:150] Setting up ip3
I0328 17:14:58.652230  1497 net.cpp:157] Top shape: 64 256 (16384)
I0328 17:14:58.652233  1497 net.cpp:165] Memory required for data: 533760
I0328 17:14:58.652240  1497 layer_factory.hpp:77] Creating layer relu3
I0328 17:14:58.652246  1497 net.cpp:106] Creating Layer relu3
I0328 17:14:58.652250  1497 net.cpp:454] relu3 <- ip3
I0328 17:14:58.652253  1497 net.cpp:397] relu3 -> ip3 (in-place)
I0328 17:14:58.652753  1497 net.cpp:150] Setting up relu3
I0328 17:14:58.652765  1497 net.cpp:157] Top shape: 64 256 (16384)
I0328 17:14:58.652768  1497 net.cpp:165] Memory required for data: 599296
I0328 17:14:58.652772  1497 layer_factory.hpp:77] Creating layer ip4
I0328 17:14:58.652778  1497 net.cpp:106] Creating Layer ip4
I0328 17:14:58.652781  1497 net.cpp:454] ip4 <- ip3
I0328 17:14:58.652786  1497 net.cpp:411] ip4 -> ip4
I0328 17:14:58.653230  1497 net.cpp:150] Setting up ip4
I0328 17:14:58.653245  1497 net.cpp:157] Top shape: 64 10 (640)
I0328 17:14:58.653249  1497 net.cpp:165] Memory required for data: 601856
I0328 17:14:58.653254  1497 layer_factory.hpp:77] Creating layer loss
I0328 17:14:58.653261  1497 net.cpp:106] Creating Layer loss
I0328 17:14:58.653264  1497 net.cpp:454] loss <- ip4
I0328 17:14:58.653269  1497 net.cpp:454] loss <- label
I0328 17:14:58.653275  1497 net.cpp:411] loss -> loss
I0328 17:14:58.653290  1497 layer_factory.hpp:77] Creating layer loss
I0328 17:14:58.653872  1497 net.cpp:150] Setting up loss
I0328 17:14:58.653884  1497 net.cpp:157] Top shape: (1)
I0328 17:14:58.653887  1497 net.cpp:160]     with loss weight 1
I0328 17:14:58.653900  1497 net.cpp:165] Memory required for data: 601860
I0328 17:14:58.653904  1497 net.cpp:226] loss needs backward computation.
I0328 17:14:58.653908  1497 net.cpp:226] ip4 needs backward computation.
I0328 17:14:58.653910  1497 net.cpp:226] relu3 needs backward computation.
I0328 17:14:58.653913  1497 net.cpp:226] ip3 needs backward computation.
I0328 17:14:58.653915  1497 net.cpp:226] relu2 needs backward computation.
I0328 17:14:58.653918  1497 net.cpp:226] ip2 needs backward computation.
I0328 17:14:58.653920  1497 net.cpp:226] relu1 needs backward computation.
I0328 17:14:58.653923  1497 net.cpp:226] ip1 needs backward computation.
I0328 17:14:58.653925  1497 net.cpp:228] mnist does not need backward computation.
I0328 17:14:58.653928  1497 net.cpp:270] This network produces output loss
I0328 17:14:58.653936  1497 net.cpp:283] Network initialization done.
I0328 17:14:58.654196  1497 solver.cpp:181] Creating test net (#0) specified by net file: examples/mlp/mlp_train_test.prototxt
I0328 17:14:58.654219  1497 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0328 17:14:58.654289  1497 net.cpp:49] Initializing net from parameters: 
name: "MLP"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "data"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "ip3"
  top: "ip3"
}
layer {
  name: "ip4"
  type: "InnerProduct"
  bottom: "ip3"
  top: "ip4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip4"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip4"
  bottom: "label"
  top: "loss"
}
I0328 17:14:58.654361  1497 layer_factory.hpp:77] Creating layer mnist
I0328 17:14:58.654461  1497 net.cpp:106] Creating Layer mnist
I0328 17:14:58.654470  1497 net.cpp:411] mnist -> data
I0328 17:14:58.654477  1497 net.cpp:411] mnist -> label
I0328 17:14:58.655689  1503 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_test_lmdb
I0328 17:14:58.655815  1497 data_layer.cpp:41] output data size: 100,1,28,28
I0328 17:14:58.656616  1497 net.cpp:150] Setting up mnist
I0328 17:14:58.656630  1497 net.cpp:157] Top shape: 100 1 28 28 (78400)
I0328 17:14:58.656633  1497 net.cpp:157] Top shape: 100 (100)
I0328 17:14:58.656636  1497 net.cpp:165] Memory required for data: 314000
I0328 17:14:58.656640  1497 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0328 17:14:58.656646  1497 net.cpp:106] Creating Layer label_mnist_1_split
I0328 17:14:58.656648  1497 net.cpp:454] label_mnist_1_split <- label
I0328 17:14:58.656652  1497 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_0
I0328 17:14:58.656659  1497 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_1
I0328 17:14:58.656697  1497 net.cpp:150] Setting up label_mnist_1_split
I0328 17:14:58.656703  1497 net.cpp:157] Top shape: 100 (100)
I0328 17:14:58.656707  1497 net.cpp:157] Top shape: 100 (100)
I0328 17:14:58.656708  1497 net.cpp:165] Memory required for data: 314800
I0328 17:14:58.656711  1497 layer_factory.hpp:77] Creating layer ip1
I0328 17:14:58.656718  1497 net.cpp:106] Creating Layer ip1
I0328 17:14:58.656721  1497 net.cpp:454] ip1 <- data
I0328 17:14:58.656725  1497 net.cpp:411] ip1 -> ip1
I0328 17:14:58.656853  1497 net.cpp:150] Setting up ip1
I0328 17:14:58.656862  1497 net.cpp:157] Top shape: 100 10 (1000)
I0328 17:14:58.656865  1497 net.cpp:165] Memory required for data: 318800
I0328 17:14:58.656873  1497 layer_factory.hpp:77] Creating layer relu1
I0328 17:14:58.656878  1497 net.cpp:106] Creating Layer relu1
I0328 17:14:58.656882  1497 net.cpp:454] relu1 <- ip1
I0328 17:14:58.656885  1497 net.cpp:397] relu1 -> ip1 (in-place)
I0328 17:14:58.657560  1497 net.cpp:150] Setting up relu1
I0328 17:14:58.657577  1497 net.cpp:157] Top shape: 100 10 (1000)
I0328 17:14:58.657580  1497 net.cpp:165] Memory required for data: 322800
I0328 17:14:58.657583  1497 layer_factory.hpp:77] Creating layer ip2
I0328 17:14:58.657591  1497 net.cpp:106] Creating Layer ip2
I0328 17:14:58.657594  1497 net.cpp:454] ip2 <- ip1
I0328 17:14:58.657605  1497 net.cpp:411] ip2 -> ip2
I0328 17:14:58.657735  1497 net.cpp:150] Setting up ip2
I0328 17:14:58.657744  1497 net.cpp:157] Top shape: 100 512 (51200)
I0328 17:14:58.657749  1497 net.cpp:165] Memory required for data: 527600
I0328 17:14:58.657758  1497 layer_factory.hpp:77] Creating layer relu2
I0328 17:14:58.657764  1497 net.cpp:106] Creating Layer relu2
I0328 17:14:58.657768  1497 net.cpp:454] relu2 <- ip2
I0328 17:14:58.657773  1497 net.cpp:397] relu2 -> ip2 (in-place)
I0328 17:14:58.658375  1497 net.cpp:150] Setting up relu2
I0328 17:14:58.658387  1497 net.cpp:157] Top shape: 100 512 (51200)
I0328 17:14:58.658390  1497 net.cpp:165] Memory required for data: 732400
I0328 17:14:58.658393  1497 layer_factory.hpp:77] Creating layer ip3
I0328 17:14:58.658401  1497 net.cpp:106] Creating Layer ip3
I0328 17:14:58.658403  1497 net.cpp:454] ip3 <- ip2
I0328 17:14:58.658408  1497 net.cpp:411] ip3 -> ip3
I0328 17:14:58.659545  1497 net.cpp:150] Setting up ip3
I0328 17:14:58.659556  1497 net.cpp:157] Top shape: 100 256 (25600)
I0328 17:14:58.659559  1497 net.cpp:165] Memory required for data: 834800
I0328 17:14:58.659567  1497 layer_factory.hpp:77] Creating layer relu3
I0328 17:14:58.659572  1497 net.cpp:106] Creating Layer relu3
I0328 17:14:58.659576  1497 net.cpp:454] relu3 <- ip3
I0328 17:14:58.659580  1497 net.cpp:397] relu3 -> ip3 (in-place)
I0328 17:14:58.660148  1497 net.cpp:150] Setting up relu3
I0328 17:14:58.660161  1497 net.cpp:157] Top shape: 100 256 (25600)
I0328 17:14:58.660164  1497 net.cpp:165] Memory required for data: 937200
I0328 17:14:58.660167  1497 layer_factory.hpp:77] Creating layer ip4
I0328 17:14:58.660176  1497 net.cpp:106] Creating Layer ip4
I0328 17:14:58.660179  1497 net.cpp:454] ip4 <- ip3
I0328 17:14:58.660184  1497 net.cpp:411] ip4 -> ip4
I0328 17:14:58.660284  1497 net.cpp:150] Setting up ip4
I0328 17:14:58.660291  1497 net.cpp:157] Top shape: 100 10 (1000)
I0328 17:14:58.660295  1497 net.cpp:165] Memory required for data: 941200
I0328 17:14:58.660300  1497 layer_factory.hpp:77] Creating layer ip4_ip4_0_split
I0328 17:14:58.660305  1497 net.cpp:106] Creating Layer ip4_ip4_0_split
I0328 17:14:58.660306  1497 net.cpp:454] ip4_ip4_0_split <- ip4
I0328 17:14:58.660312  1497 net.cpp:411] ip4_ip4_0_split -> ip4_ip4_0_split_0
I0328 17:14:58.660318  1497 net.cpp:411] ip4_ip4_0_split -> ip4_ip4_0_split_1
I0328 17:14:58.660346  1497 net.cpp:150] Setting up ip4_ip4_0_split
I0328 17:14:58.660354  1497 net.cpp:157] Top shape: 100 10 (1000)
I0328 17:14:58.660358  1497 net.cpp:157] Top shape: 100 10 (1000)
I0328 17:14:58.660361  1497 net.cpp:165] Memory required for data: 949200
I0328 17:14:58.660363  1497 layer_factory.hpp:77] Creating layer accuracy
I0328 17:14:58.660368  1497 net.cpp:106] Creating Layer accuracy
I0328 17:14:58.660370  1497 net.cpp:454] accuracy <- ip4_ip4_0_split_0
I0328 17:14:58.660374  1497 net.cpp:454] accuracy <- label_mnist_1_split_0
I0328 17:14:58.660378  1497 net.cpp:411] accuracy -> accuracy
I0328 17:14:58.660384  1497 net.cpp:150] Setting up accuracy
I0328 17:14:58.660388  1497 net.cpp:157] Top shape: (1)
I0328 17:14:58.660392  1497 net.cpp:165] Memory required for data: 949204
I0328 17:14:58.660393  1497 layer_factory.hpp:77] Creating layer loss
I0328 17:14:58.660399  1497 net.cpp:106] Creating Layer loss
I0328 17:14:58.660403  1497 net.cpp:454] loss <- ip4_ip4_0_split_1
I0328 17:14:58.660406  1497 net.cpp:454] loss <- label_mnist_1_split_1
I0328 17:14:58.660409  1497 net.cpp:411] loss -> loss
I0328 17:14:58.660415  1497 layer_factory.hpp:77] Creating layer loss
I0328 17:14:58.661046  1497 net.cpp:150] Setting up loss
I0328 17:14:58.661058  1497 net.cpp:157] Top shape: (1)
I0328 17:14:58.661062  1497 net.cpp:160]     with loss weight 1
I0328 17:14:58.661067  1497 net.cpp:165] Memory required for data: 949208
I0328 17:14:58.661070  1497 net.cpp:226] loss needs backward computation.
I0328 17:14:58.661073  1497 net.cpp:228] accuracy does not need backward computation.
I0328 17:14:58.661077  1497 net.cpp:226] ip4_ip4_0_split needs backward computation.
I0328 17:14:58.661079  1497 net.cpp:226] ip4 needs backward computation.
I0328 17:14:58.661092  1497 net.cpp:226] relu3 needs backward computation.
I0328 17:14:58.661094  1497 net.cpp:226] ip3 needs backward computation.
I0328 17:14:58.661098  1497 net.cpp:226] relu2 needs backward computation.
I0328 17:14:58.661101  1497 net.cpp:226] ip2 needs backward computation.
I0328 17:14:58.661103  1497 net.cpp:226] relu1 needs backward computation.
I0328 17:14:58.661108  1497 net.cpp:226] ip1 needs backward computation.
I0328 17:14:58.661110  1497 net.cpp:228] label_mnist_1_split does not need backward computation.
I0328 17:14:58.661113  1497 net.cpp:228] mnist does not need backward computation.
I0328 17:14:58.661115  1497 net.cpp:270] This network produces output accuracy
I0328 17:14:58.661118  1497 net.cpp:270] This network produces output loss
I0328 17:14:58.661128  1497 net.cpp:283] Network initialization done.
I0328 17:14:58.661167  1497 solver.cpp:60] Solver scaffolding done.
I0328 17:14:58.661376  1497 caffe.cpp:212] Starting Optimization
I0328 17:14:58.661386  1497 solver.cpp:288] Solving MLP
I0328 17:14:58.661387  1497 solver.cpp:289] Learning Rate Policy: inv
I0328 17:14:58.661804  1497 solver.cpp:341] Iteration 0, Testing net (#0)
I0328 17:14:58.667560  1497 blocking_queue.cpp:50] Data layer prefetch queue empty
I0328 17:14:58.713757  1497 solver.cpp:409]     Test net output #0: accuracy = 0.1164
I0328 17:14:58.713788  1497 solver.cpp:409]     Test net output #1: loss = 2.31085 (* 1 = 2.31085 loss)
I0328 17:14:58.714650  1497 solver.cpp:237] Iteration 0, loss = 2.30028
I0328 17:14:58.714668  1497 solver.cpp:253]     Train net output #0: loss = 2.30028 (* 1 = 2.30028 loss)
I0328 17:14:58.714682  1497 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0328 17:14:58.798033  1497 solver.cpp:237] Iteration 100, loss = 0.43058
I0328 17:14:58.798058  1497 solver.cpp:253]     Train net output #0: loss = 0.43058 (* 1 = 0.43058 loss)
I0328 17:14:58.798064  1497 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0328 17:14:59.694031  1497 solver.cpp:237] Iteration 200, loss = 0.386187
I0328 17:14:59.694070  1497 solver.cpp:253]     Train net output #0: loss = 0.386187 (* 1 = 0.386187 loss)
I0328 17:14:59.694079  1497 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0328 17:15:00.150903  1497 solver.cpp:237] Iteration 300, loss = 0.309828
I0328 17:15:00.150933  1497 solver.cpp:253]     Train net output #0: loss = 0.309828 (* 1 = 0.309828 loss)
I0328 17:15:00.150939  1497 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0328 17:15:00.234169  1497 solver.cpp:237] Iteration 400, loss = 0.204058
I0328 17:15:00.234200  1497 solver.cpp:253]     Train net output #0: loss = 0.204058 (* 1 = 0.204058 loss)
I0328 17:15:00.234205  1497 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0328 17:15:00.315992  1497 solver.cpp:341] Iteration 500, Testing net (#0)
I0328 17:15:00.372828  1497 solver.cpp:409]     Test net output #0: accuracy = 0.904
I0328 17:15:00.372858  1497 solver.cpp:409]     Test net output #1: loss = 0.302172 (* 1 = 0.302172 loss)
I0328 17:15:00.373337  1497 solver.cpp:237] Iteration 500, loss = 0.380804
I0328 17:15:00.373353  1497 solver.cpp:253]     Train net output #0: loss = 0.380804 (* 1 = 0.380804 loss)
I0328 17:15:00.373361  1497 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0328 17:15:00.456296  1497 solver.cpp:237] Iteration 600, loss = 0.314191
I0328 17:15:00.456324  1497 solver.cpp:253]     Train net output #0: loss = 0.314191 (* 1 = 0.314191 loss)
I0328 17:15:00.456329  1497 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0328 17:15:00.539095  1497 solver.cpp:237] Iteration 700, loss = 0.463468
I0328 17:15:00.539122  1497 solver.cpp:253]     Train net output #0: loss = 0.463468 (* 1 = 0.463468 loss)
I0328 17:15:00.539129  1497 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0328 17:15:00.621752  1497 solver.cpp:237] Iteration 800, loss = 0.271849
I0328 17:15:00.621780  1497 solver.cpp:253]     Train net output #0: loss = 0.271849 (* 1 = 0.271849 loss)
I0328 17:15:00.621785  1497 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0328 17:15:00.704450  1497 solver.cpp:237] Iteration 900, loss = 0.231118
I0328 17:15:00.704509  1497 solver.cpp:253]     Train net output #0: loss = 0.231118 (* 1 = 0.231118 loss)
I0328 17:15:00.704515  1497 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0328 17:15:00.786715  1497 solver.cpp:341] Iteration 1000, Testing net (#0)
I0328 17:15:00.838035  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9254
I0328 17:15:00.838065  1497 solver.cpp:409]     Test net output #1: loss = 0.239328 (* 1 = 0.239328 loss)
I0328 17:15:00.838549  1497 solver.cpp:237] Iteration 1000, loss = 0.211211
I0328 17:15:00.838572  1497 solver.cpp:253]     Train net output #0: loss = 0.211211 (* 1 = 0.211211 loss)
I0328 17:15:00.838578  1497 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0328 17:15:00.921838  1497 solver.cpp:237] Iteration 1100, loss = 0.145692
I0328 17:15:00.921869  1497 solver.cpp:253]     Train net output #0: loss = 0.145692 (* 1 = 0.145692 loss)
I0328 17:15:00.921875  1497 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0328 17:15:01.005038  1497 solver.cpp:237] Iteration 1200, loss = 0.332558
I0328 17:15:01.005069  1497 solver.cpp:253]     Train net output #0: loss = 0.332558 (* 1 = 0.332558 loss)
I0328 17:15:01.005076  1497 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0328 17:15:01.087959  1497 solver.cpp:237] Iteration 1300, loss = 0.197114
I0328 17:15:01.087987  1497 solver.cpp:253]     Train net output #0: loss = 0.197114 (* 1 = 0.197114 loss)
I0328 17:15:01.087995  1497 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0328 17:15:01.170476  1497 solver.cpp:237] Iteration 1400, loss = 0.14702
I0328 17:15:01.170502  1497 solver.cpp:253]     Train net output #0: loss = 0.14702 (* 1 = 0.14702 loss)
I0328 17:15:01.170507  1497 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0328 17:15:01.252974  1497 solver.cpp:341] Iteration 1500, Testing net (#0)
I0328 17:15:01.305271  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9329
I0328 17:15:01.305299  1497 solver.cpp:409]     Test net output #1: loss = 0.217375 (* 1 = 0.217375 loss)
I0328 17:15:01.305763  1497 solver.cpp:237] Iteration 1500, loss = 0.235861
I0328 17:15:01.305778  1497 solver.cpp:253]     Train net output #0: loss = 0.235861 (* 1 = 0.235861 loss)
I0328 17:15:01.305784  1497 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0328 17:15:01.389924  1497 solver.cpp:237] Iteration 1600, loss = 0.409566
I0328 17:15:01.389943  1497 solver.cpp:253]     Train net output #0: loss = 0.409566 (* 1 = 0.409566 loss)
I0328 17:15:01.389950  1497 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0328 17:15:01.472882  1497 solver.cpp:237] Iteration 1700, loss = 0.12336
I0328 17:15:01.472905  1497 solver.cpp:253]     Train net output #0: loss = 0.12336 (* 1 = 0.12336 loss)
I0328 17:15:01.472911  1497 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0328 17:15:01.555730  1497 solver.cpp:237] Iteration 1800, loss = 0.119395
I0328 17:15:01.555748  1497 solver.cpp:253]     Train net output #0: loss = 0.119395 (* 1 = 0.119395 loss)
I0328 17:15:01.555763  1497 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0328 17:15:01.638341  1497 solver.cpp:237] Iteration 1900, loss = 0.155773
I0328 17:15:01.638368  1497 solver.cpp:253]     Train net output #0: loss = 0.155773 (* 1 = 0.155773 loss)
I0328 17:15:01.638373  1497 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0328 17:15:01.721216  1497 solver.cpp:341] Iteration 2000, Testing net (#0)
I0328 17:15:01.737303  1504 blocking_queue.cpp:50] Waiting for data
I0328 17:15:01.777511  1497 solver.cpp:409]     Test net output #0: accuracy = 0.93
I0328 17:15:01.777546  1497 solver.cpp:409]     Test net output #1: loss = 0.222348 (* 1 = 0.222348 loss)
I0328 17:15:01.778064  1497 solver.cpp:237] Iteration 2000, loss = 0.183326
I0328 17:15:01.778087  1497 solver.cpp:253]     Train net output #0: loss = 0.183326 (* 1 = 0.183326 loss)
I0328 17:15:01.778103  1497 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0328 17:15:01.861526  1497 solver.cpp:237] Iteration 2100, loss = 0.120772
I0328 17:15:01.861562  1497 solver.cpp:253]     Train net output #0: loss = 0.120772 (* 1 = 0.120772 loss)
I0328 17:15:01.861603  1497 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0328 17:15:01.944339  1497 solver.cpp:237] Iteration 2200, loss = 0.161878
I0328 17:15:01.944371  1497 solver.cpp:253]     Train net output #0: loss = 0.161879 (* 1 = 0.161879 loss)
I0328 17:15:01.944380  1497 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0328 17:15:02.026831  1497 solver.cpp:237] Iteration 2300, loss = 0.279109
I0328 17:15:02.026864  1497 solver.cpp:253]     Train net output #0: loss = 0.279109 (* 1 = 0.279109 loss)
I0328 17:15:02.026872  1497 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0328 17:15:02.109283  1497 solver.cpp:237] Iteration 2400, loss = 0.0985266
I0328 17:15:02.109319  1497 solver.cpp:253]     Train net output #0: loss = 0.0985266 (* 1 = 0.0985266 loss)
I0328 17:15:02.109328  1497 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0328 17:15:02.193181  1497 solver.cpp:341] Iteration 2500, Testing net (#0)
I0328 17:15:02.248180  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9385
I0328 17:15:02.248215  1497 solver.cpp:409]     Test net output #1: loss = 0.196428 (* 1 = 0.196428 loss)
I0328 17:15:02.248690  1497 solver.cpp:237] Iteration 2500, loss = 0.169506
I0328 17:15:02.248711  1497 solver.cpp:253]     Train net output #0: loss = 0.169506 (* 1 = 0.169506 loss)
I0328 17:15:02.248723  1497 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0328 17:15:02.334830  1497 solver.cpp:237] Iteration 2600, loss = 0.354109
I0328 17:15:02.334867  1497 solver.cpp:253]     Train net output #0: loss = 0.354109 (* 1 = 0.354109 loss)
I0328 17:15:02.334875  1497 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0328 17:15:02.418051  1497 solver.cpp:237] Iteration 2700, loss = 0.345469
I0328 17:15:02.418087  1497 solver.cpp:253]     Train net output #0: loss = 0.345469 (* 1 = 0.345469 loss)
I0328 17:15:02.418098  1497 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0328 17:15:02.501341  1497 solver.cpp:237] Iteration 2800, loss = 0.0822691
I0328 17:15:02.501377  1497 solver.cpp:253]     Train net output #0: loss = 0.0822691 (* 1 = 0.0822691 loss)
I0328 17:15:02.501386  1497 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0328 17:15:02.584614  1497 solver.cpp:237] Iteration 2900, loss = 0.111161
I0328 17:15:02.584655  1497 solver.cpp:253]     Train net output #0: loss = 0.111161 (* 1 = 0.111161 loss)
I0328 17:15:02.584662  1497 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0328 17:15:02.666967  1497 solver.cpp:341] Iteration 3000, Testing net (#0)
I0328 17:15:02.739537  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9318
I0328 17:15:02.739575  1497 solver.cpp:409]     Test net output #1: loss = 0.218087 (* 1 = 0.218087 loss)
I0328 17:15:02.740102  1497 solver.cpp:237] Iteration 3000, loss = 0.215469
I0328 17:15:02.740123  1497 solver.cpp:253]     Train net output #0: loss = 0.215469 (* 1 = 0.215469 loss)
I0328 17:15:02.740155  1497 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0328 17:15:02.822672  1497 solver.cpp:237] Iteration 3100, loss = 0.211993
I0328 17:15:02.822707  1497 solver.cpp:253]     Train net output #0: loss = 0.211993 (* 1 = 0.211993 loss)
I0328 17:15:02.822717  1497 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0328 17:15:02.904999  1497 solver.cpp:237] Iteration 3200, loss = 0.151299
I0328 17:15:02.905033  1497 solver.cpp:253]     Train net output #0: loss = 0.151299 (* 1 = 0.151299 loss)
I0328 17:15:02.905052  1497 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0328 17:15:02.987881  1497 solver.cpp:237] Iteration 3300, loss = 0.0787346
I0328 17:15:02.987918  1497 solver.cpp:253]     Train net output #0: loss = 0.0787347 (* 1 = 0.0787347 loss)
I0328 17:15:02.987928  1497 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0328 17:15:03.071646  1497 solver.cpp:237] Iteration 3400, loss = 0.149982
I0328 17:15:03.071691  1497 solver.cpp:253]     Train net output #0: loss = 0.149982 (* 1 = 0.149982 loss)
I0328 17:15:03.071701  1497 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0328 17:15:03.160256  1497 solver.cpp:341] Iteration 3500, Testing net (#0)
I0328 17:15:03.221258  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9494
I0328 17:15:03.221290  1497 solver.cpp:409]     Test net output #1: loss = 0.167617 (* 1 = 0.167617 loss)
I0328 17:15:03.221825  1497 solver.cpp:237] Iteration 3500, loss = 0.0861578
I0328 17:15:03.221843  1497 solver.cpp:253]     Train net output #0: loss = 0.0861578 (* 1 = 0.0861578 loss)
I0328 17:15:03.221849  1497 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0328 17:15:03.309638  1497 solver.cpp:237] Iteration 3600, loss = 0.298948
I0328 17:15:03.309664  1497 solver.cpp:253]     Train net output #0: loss = 0.298948 (* 1 = 0.298948 loss)
I0328 17:15:03.309672  1497 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0328 17:15:03.393183  1497 solver.cpp:237] Iteration 3700, loss = 0.162137
I0328 17:15:03.393205  1497 solver.cpp:253]     Train net output #0: loss = 0.162137 (* 1 = 0.162137 loss)
I0328 17:15:03.393211  1497 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0328 17:15:03.476133  1497 solver.cpp:237] Iteration 3800, loss = 0.213577
I0328 17:15:03.476155  1497 solver.cpp:253]     Train net output #0: loss = 0.213577 (* 1 = 0.213577 loss)
I0328 17:15:03.476160  1497 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0328 17:15:03.559159  1497 solver.cpp:237] Iteration 3900, loss = 0.0755558
I0328 17:15:03.559178  1497 solver.cpp:253]     Train net output #0: loss = 0.0755559 (* 1 = 0.0755559 loss)
I0328 17:15:03.559183  1497 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0328 17:15:03.641865  1497 solver.cpp:341] Iteration 4000, Testing net (#0)
I0328 17:15:03.692399  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9457
I0328 17:15:03.692426  1497 solver.cpp:409]     Test net output #1: loss = 0.173716 (* 1 = 0.173716 loss)
I0328 17:15:03.692903  1497 solver.cpp:237] Iteration 4000, loss = 0.233339
I0328 17:15:03.692925  1497 solver.cpp:253]     Train net output #0: loss = 0.233339 (* 1 = 0.233339 loss)
I0328 17:15:03.692931  1497 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0328 17:15:04.067267  1497 solver.cpp:237] Iteration 4100, loss = 0.121595
I0328 17:15:04.067298  1497 solver.cpp:253]     Train net output #0: loss = 0.121596 (* 1 = 0.121596 loss)
I0328 17:15:04.067304  1497 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0328 17:15:05.043658  1497 solver.cpp:237] Iteration 4200, loss = 0.0958728
I0328 17:15:05.043689  1497 solver.cpp:253]     Train net output #0: loss = 0.0958729 (* 1 = 0.0958729 loss)
I0328 17:15:05.043694  1497 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0328 17:15:05.083387  1497 blocking_queue.cpp:50] Data layer prefetch queue empty
I0328 17:15:05.143666  1497 solver.cpp:237] Iteration 4300, loss = 0.271021
I0328 17:15:05.143748  1497 solver.cpp:253]     Train net output #0: loss = 0.271021 (* 1 = 0.271021 loss)
I0328 17:15:05.143780  1497 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0328 17:15:05.230428  1497 solver.cpp:237] Iteration 4400, loss = 0.0730325
I0328 17:15:05.230514  1497 solver.cpp:253]     Train net output #0: loss = 0.0730327 (* 1 = 0.0730327 loss)
I0328 17:15:05.230545  1497 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0328 17:15:05.316892  1497 solver.cpp:341] Iteration 4500, Testing net (#0)
I0328 17:15:05.388049  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9493
I0328 17:15:05.388087  1497 solver.cpp:409]     Test net output #1: loss = 0.160355 (* 1 = 0.160355 loss)
I0328 17:15:05.388655  1497 solver.cpp:237] Iteration 4500, loss = 0.107233
I0328 17:15:05.388680  1497 solver.cpp:253]     Train net output #0: loss = 0.107234 (* 1 = 0.107234 loss)
I0328 17:15:05.388695  1497 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0328 17:15:05.475749  1497 solver.cpp:237] Iteration 4600, loss = 0.145627
I0328 17:15:05.475782  1497 solver.cpp:253]     Train net output #0: loss = 0.145627 (* 1 = 0.145627 loss)
I0328 17:15:05.475792  1497 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0328 17:15:05.562636  1497 solver.cpp:237] Iteration 4700, loss = 0.144023
I0328 17:15:05.562710  1497 solver.cpp:253]     Train net output #0: loss = 0.144023 (* 1 = 0.144023 loss)
I0328 17:15:05.562721  1497 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0328 17:15:05.649471  1497 solver.cpp:237] Iteration 4800, loss = 0.16095
I0328 17:15:05.649515  1497 solver.cpp:253]     Train net output #0: loss = 0.16095 (* 1 = 0.16095 loss)
I0328 17:15:05.649526  1497 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0328 17:15:05.734993  1497 solver.cpp:237] Iteration 4900, loss = 0.117949
I0328 17:15:05.735026  1497 solver.cpp:253]     Train net output #0: loss = 0.11795 (* 1 = 0.11795 loss)
I0328 17:15:05.735033  1497 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0328 17:15:05.817303  1497 solver.cpp:459] Snapshotting to binary proto file examples/mlp/mlp_iter_5000.caffemodel
I0328 17:15:05.820659  1497 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mlp/mlp_iter_5000.solverstate
I0328 17:15:05.822263  1497 solver.cpp:341] Iteration 5000, Testing net (#0)
I0328 17:15:05.896978  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9531
I0328 17:15:05.897016  1497 solver.cpp:409]     Test net output #1: loss = 0.149911 (* 1 = 0.149911 loss)
I0328 17:15:05.897783  1497 solver.cpp:237] Iteration 5000, loss = 0.190231
I0328 17:15:05.897811  1497 solver.cpp:253]     Train net output #0: loss = 0.190231 (* 1 = 0.190231 loss)
I0328 17:15:05.897820  1497 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0328 17:15:05.983543  1497 solver.cpp:237] Iteration 5100, loss = 0.121286
I0328 17:15:05.983572  1497 solver.cpp:253]     Train net output #0: loss = 0.121286 (* 1 = 0.121286 loss)
I0328 17:15:05.983579  1497 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0328 17:15:06.065979  1497 solver.cpp:237] Iteration 5200, loss = 0.127226
I0328 17:15:06.066002  1497 solver.cpp:253]     Train net output #0: loss = 0.127226 (* 1 = 0.127226 loss)
I0328 17:15:06.066009  1497 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0328 17:15:06.148504  1497 solver.cpp:237] Iteration 5300, loss = 0.0729154
I0328 17:15:06.148525  1497 solver.cpp:253]     Train net output #0: loss = 0.0729155 (* 1 = 0.0729155 loss)
I0328 17:15:06.148530  1497 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0328 17:15:06.230866  1497 solver.cpp:237] Iteration 5400, loss = 0.226868
I0328 17:15:06.230886  1497 solver.cpp:253]     Train net output #0: loss = 0.226868 (* 1 = 0.226868 loss)
I0328 17:15:06.230891  1497 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0328 17:15:06.312611  1497 solver.cpp:341] Iteration 5500, Testing net (#0)
I0328 17:15:06.392843  1497 solver.cpp:409]     Test net output #0: accuracy = 0.954
I0328 17:15:06.392873  1497 solver.cpp:409]     Test net output #1: loss = 0.146895 (* 1 = 0.146895 loss)
I0328 17:15:06.393402  1497 solver.cpp:237] Iteration 5500, loss = 0.124338
I0328 17:15:06.393426  1497 solver.cpp:253]     Train net output #0: loss = 0.124338 (* 1 = 0.124338 loss)
I0328 17:15:06.393435  1497 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0328 17:15:06.476100  1497 solver.cpp:237] Iteration 5600, loss = 0.0690433
I0328 17:15:06.476120  1497 solver.cpp:253]     Train net output #0: loss = 0.0690435 (* 1 = 0.0690435 loss)
I0328 17:15:06.476126  1497 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0328 17:15:06.558873  1497 solver.cpp:237] Iteration 5700, loss = 0.100277
I0328 17:15:06.558892  1497 solver.cpp:253]     Train net output #0: loss = 0.100278 (* 1 = 0.100278 loss)
I0328 17:15:06.558898  1497 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0328 17:15:07.323084  1497 solver.cpp:237] Iteration 5800, loss = 0.212578
I0328 17:15:07.323113  1497 solver.cpp:253]     Train net output #0: loss = 0.212578 (* 1 = 0.212578 loss)
I0328 17:15:07.323119  1497 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0328 17:15:07.926903  1497 solver.cpp:237] Iteration 5900, loss = 0.0642364
I0328 17:15:07.926966  1497 solver.cpp:253]     Train net output #0: loss = 0.0642366 (* 1 = 0.0642366 loss)
I0328 17:15:07.927021  1497 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0328 17:15:08.020725  1497 solver.cpp:341] Iteration 6000, Testing net (#0)
I0328 17:15:08.107782  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9505
I0328 17:15:08.107826  1497 solver.cpp:409]     Test net output #1: loss = 0.151871 (* 1 = 0.151871 loss)
I0328 17:15:08.108449  1497 solver.cpp:237] Iteration 6000, loss = 0.100344
I0328 17:15:08.108486  1497 solver.cpp:253]     Train net output #0: loss = 0.100345 (* 1 = 0.100345 loss)
I0328 17:15:08.108535  1497 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0328 17:15:08.195487  1497 solver.cpp:237] Iteration 6100, loss = 0.0752311
I0328 17:15:08.195523  1497 solver.cpp:253]     Train net output #0: loss = 0.0752314 (* 1 = 0.0752314 loss)
I0328 17:15:08.195528  1497 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0328 17:15:08.282481  1497 solver.cpp:237] Iteration 6200, loss = 0.135071
I0328 17:15:08.282513  1497 solver.cpp:253]     Train net output #0: loss = 0.135071 (* 1 = 0.135071 loss)
I0328 17:15:08.282519  1497 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0328 17:15:08.366441  1497 solver.cpp:237] Iteration 6300, loss = 0.121814
I0328 17:15:08.366479  1497 solver.cpp:253]     Train net output #0: loss = 0.121814 (* 1 = 0.121814 loss)
I0328 17:15:08.366488  1497 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0328 17:15:08.449360  1497 solver.cpp:237] Iteration 6400, loss = 0.166151
I0328 17:15:08.449396  1497 solver.cpp:253]     Train net output #0: loss = 0.166151 (* 1 = 0.166151 loss)
I0328 17:15:08.449407  1497 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0328 17:15:08.531803  1497 solver.cpp:341] Iteration 6500, Testing net (#0)
I0328 17:15:08.605491  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9534
I0328 17:15:08.605532  1497 solver.cpp:409]     Test net output #1: loss = 0.144723 (* 1 = 0.144723 loss)
I0328 17:15:08.606093  1497 solver.cpp:237] Iteration 6500, loss = 0.140158
I0328 17:15:08.606142  1497 solver.cpp:253]     Train net output #0: loss = 0.140159 (* 1 = 0.140159 loss)
I0328 17:15:08.606159  1497 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0328 17:15:08.689337  1497 solver.cpp:237] Iteration 6600, loss = 0.156188
I0328 17:15:08.689374  1497 solver.cpp:253]     Train net output #0: loss = 0.156189 (* 1 = 0.156189 loss)
I0328 17:15:08.689384  1497 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0328 17:15:08.778874  1497 solver.cpp:237] Iteration 6700, loss = 0.213209
I0328 17:15:08.778908  1497 solver.cpp:253]     Train net output #0: loss = 0.213209 (* 1 = 0.213209 loss)
I0328 17:15:08.778915  1497 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0328 17:15:08.861521  1497 solver.cpp:237] Iteration 6800, loss = 0.156379
I0328 17:15:08.861543  1497 solver.cpp:253]     Train net output #0: loss = 0.15638 (* 1 = 0.15638 loss)
I0328 17:15:08.861552  1497 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0328 17:15:08.947371  1497 solver.cpp:237] Iteration 6900, loss = 0.129967
I0328 17:15:08.947424  1497 solver.cpp:253]     Train net output #0: loss = 0.129967 (* 1 = 0.129967 loss)
I0328 17:15:08.947440  1497 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0328 17:15:09.042825  1497 solver.cpp:341] Iteration 7000, Testing net (#0)
I0328 17:15:09.117703  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9512
I0328 17:15:09.117738  1497 solver.cpp:409]     Test net output #1: loss = 0.158069 (* 1 = 0.158069 loss)
I0328 17:15:09.118341  1497 solver.cpp:237] Iteration 7000, loss = 0.0265483
I0328 17:15:09.118362  1497 solver.cpp:253]     Train net output #0: loss = 0.0265487 (* 1 = 0.0265487 loss)
I0328 17:15:09.118374  1497 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0328 17:15:09.206399  1497 solver.cpp:237] Iteration 7100, loss = 0.42415
I0328 17:15:09.206423  1497 solver.cpp:253]     Train net output #0: loss = 0.42415 (* 1 = 0.42415 loss)
I0328 17:15:09.206428  1497 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0328 17:15:09.294374  1497 solver.cpp:237] Iteration 7200, loss = 0.0354117
I0328 17:15:09.294414  1497 solver.cpp:253]     Train net output #0: loss = 0.035412 (* 1 = 0.035412 loss)
I0328 17:15:09.294420  1497 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0328 17:15:10.203323  1497 solver.cpp:237] Iteration 7300, loss = 0.306968
I0328 17:15:10.203358  1497 solver.cpp:253]     Train net output #0: loss = 0.306968 (* 1 = 0.306968 loss)
I0328 17:15:10.203366  1497 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0328 17:15:10.647969  1497 solver.cpp:237] Iteration 7400, loss = 0.156507
I0328 17:15:10.648053  1497 solver.cpp:253]     Train net output #0: loss = 0.156507 (* 1 = 0.156507 loss)
I0328 17:15:10.648069  1497 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0328 17:15:10.735914  1497 solver.cpp:341] Iteration 7500, Testing net (#0)
I0328 17:15:10.814237  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9499
I0328 17:15:10.814323  1497 solver.cpp:409]     Test net output #1: loss = 0.16506 (* 1 = 0.16506 loss)
I0328 17:15:10.814944  1497 solver.cpp:237] Iteration 7500, loss = 0.118186
I0328 17:15:10.814985  1497 solver.cpp:253]     Train net output #0: loss = 0.118186 (* 1 = 0.118186 loss)
I0328 17:15:10.815014  1497 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0328 17:15:10.904639  1497 solver.cpp:237] Iteration 7600, loss = 0.173578
I0328 17:15:10.904682  1497 solver.cpp:253]     Train net output #0: loss = 0.173579 (* 1 = 0.173579 loss)
I0328 17:15:10.904691  1497 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0328 17:15:10.994719  1497 solver.cpp:237] Iteration 7700, loss = 0.0856952
I0328 17:15:10.994762  1497 solver.cpp:253]     Train net output #0: loss = 0.0856956 (* 1 = 0.0856956 loss)
I0328 17:15:10.994771  1497 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0328 17:15:11.085053  1497 solver.cpp:237] Iteration 7800, loss = 0.273024
I0328 17:15:11.085100  1497 solver.cpp:253]     Train net output #0: loss = 0.273024 (* 1 = 0.273024 loss)
I0328 17:15:11.085114  1497 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0328 17:15:11.175004  1497 solver.cpp:237] Iteration 7900, loss = 0.103381
I0328 17:15:11.175047  1497 solver.cpp:253]     Train net output #0: loss = 0.103381 (* 1 = 0.103381 loss)
I0328 17:15:11.175056  1497 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0328 17:15:11.261118  1497 solver.cpp:341] Iteration 8000, Testing net (#0)
I0328 17:15:11.333554  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9567
I0328 17:15:11.333593  1497 solver.cpp:409]     Test net output #1: loss = 0.139677 (* 1 = 0.139677 loss)
I0328 17:15:11.334192  1497 solver.cpp:237] Iteration 8000, loss = 0.0769246
I0328 17:15:11.334239  1497 solver.cpp:253]     Train net output #0: loss = 0.076925 (* 1 = 0.076925 loss)
I0328 17:15:11.334272  1497 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0328 17:15:11.420935  1497 solver.cpp:237] Iteration 8100, loss = 0.0459288
I0328 17:15:11.421021  1497 solver.cpp:253]     Train net output #0: loss = 0.0459292 (* 1 = 0.0459292 loss)
I0328 17:15:11.421051  1497 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0328 17:15:11.508054  1497 solver.cpp:237] Iteration 8200, loss = 0.200889
I0328 17:15:11.508097  1497 solver.cpp:253]     Train net output #0: loss = 0.20089 (* 1 = 0.20089 loss)
I0328 17:15:11.508107  1497 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0328 17:15:11.593982  1497 solver.cpp:237] Iteration 8300, loss = 0.192527
I0328 17:15:11.594018  1497 solver.cpp:253]     Train net output #0: loss = 0.192527 (* 1 = 0.192527 loss)
I0328 17:15:11.594027  1497 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0328 17:15:11.683236  1497 solver.cpp:237] Iteration 8400, loss = 0.130311
I0328 17:15:11.683266  1497 solver.cpp:253]     Train net output #0: loss = 0.130312 (* 1 = 0.130312 loss)
I0328 17:15:11.683275  1497 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0328 17:15:11.767874  1497 solver.cpp:341] Iteration 8500, Testing net (#0)
I0328 17:15:11.850457  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9587
I0328 17:15:11.850492  1497 solver.cpp:409]     Test net output #1: loss = 0.133649 (* 1 = 0.133649 loss)
I0328 17:15:11.851102  1497 solver.cpp:237] Iteration 8500, loss = 0.116607
I0328 17:15:11.851132  1497 solver.cpp:253]     Train net output #0: loss = 0.116607 (* 1 = 0.116607 loss)
I0328 17:15:11.851150  1497 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0328 17:15:11.935082  1497 solver.cpp:237] Iteration 8600, loss = 0.0399962
I0328 17:15:11.935106  1497 solver.cpp:253]     Train net output #0: loss = 0.0399965 (* 1 = 0.0399965 loss)
I0328 17:15:11.935117  1497 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0328 17:15:12.018414  1497 solver.cpp:237] Iteration 8700, loss = 0.0872411
I0328 17:15:12.018438  1497 solver.cpp:253]     Train net output #0: loss = 0.0872415 (* 1 = 0.0872415 loss)
I0328 17:15:12.018447  1497 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0328 17:15:12.101318  1497 solver.cpp:237] Iteration 8800, loss = 0.100211
I0328 17:15:12.101339  1497 solver.cpp:253]     Train net output #0: loss = 0.100211 (* 1 = 0.100211 loss)
I0328 17:15:12.101349  1497 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0328 17:15:12.184149  1497 solver.cpp:237] Iteration 8900, loss = 0.0602142
I0328 17:15:12.184170  1497 solver.cpp:253]     Train net output #0: loss = 0.0602146 (* 1 = 0.0602146 loss)
I0328 17:15:12.184180  1497 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0328 17:15:13.112433  1497 solver.cpp:341] Iteration 9000, Testing net (#0)
I0328 17:15:13.483867  1497 blocking_queue.cpp:50] Data layer prefetch queue empty
I0328 17:15:13.529176  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9561
I0328 17:15:13.529261  1497 solver.cpp:409]     Test net output #1: loss = 0.14066 (* 1 = 0.14066 loss)
I0328 17:15:13.529845  1497 solver.cpp:237] Iteration 9000, loss = 0.0833874
I0328 17:15:13.529863  1497 solver.cpp:253]     Train net output #0: loss = 0.0833878 (* 1 = 0.0833878 loss)
I0328 17:15:13.529870  1497 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0328 17:15:13.620450  1497 solver.cpp:237] Iteration 9100, loss = 0.217314
I0328 17:15:13.620507  1497 solver.cpp:253]     Train net output #0: loss = 0.217314 (* 1 = 0.217314 loss)
I0328 17:15:13.620523  1497 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0328 17:15:13.706068  1497 solver.cpp:237] Iteration 9200, loss = 0.0547325
I0328 17:15:13.706107  1497 solver.cpp:253]     Train net output #0: loss = 0.0547329 (* 1 = 0.0547329 loss)
I0328 17:15:13.706120  1497 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0328 17:15:13.789855  1497 solver.cpp:237] Iteration 9300, loss = 0.056033
I0328 17:15:13.789891  1497 solver.cpp:253]     Train net output #0: loss = 0.0560333 (* 1 = 0.0560333 loss)
I0328 17:15:13.789902  1497 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0328 17:15:13.872994  1497 solver.cpp:237] Iteration 9400, loss = 0.112075
I0328 17:15:13.873031  1497 solver.cpp:253]     Train net output #0: loss = 0.112076 (* 1 = 0.112076 loss)
I0328 17:15:13.873040  1497 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0328 17:15:13.955335  1497 solver.cpp:341] Iteration 9500, Testing net (#0)
I0328 17:15:14.029772  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9562
I0328 17:15:14.029815  1497 solver.cpp:409]     Test net output #1: loss = 0.137726 (* 1 = 0.137726 loss)
I0328 17:15:14.030422  1497 solver.cpp:237] Iteration 9500, loss = 0.0421853
I0328 17:15:14.030446  1497 solver.cpp:253]     Train net output #0: loss = 0.0421856 (* 1 = 0.0421856 loss)
I0328 17:15:14.030458  1497 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0328 17:15:14.113646  1497 solver.cpp:237] Iteration 9600, loss = 0.0370526
I0328 17:15:14.113680  1497 solver.cpp:253]     Train net output #0: loss = 0.0370529 (* 1 = 0.0370529 loss)
I0328 17:15:14.113773  1497 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0328 17:15:14.196800  1497 solver.cpp:237] Iteration 9700, loss = 0.181305
I0328 17:15:14.196836  1497 solver.cpp:253]     Train net output #0: loss = 0.181306 (* 1 = 0.181306 loss)
I0328 17:15:14.196846  1497 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0328 17:15:14.279968  1497 solver.cpp:237] Iteration 9800, loss = 0.275826
I0328 17:15:14.280004  1497 solver.cpp:253]     Train net output #0: loss = 0.275826 (* 1 = 0.275826 loss)
I0328 17:15:14.280015  1497 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0328 17:15:14.369371  1497 solver.cpp:237] Iteration 9900, loss = 0.0582275
I0328 17:15:14.369401  1497 solver.cpp:253]     Train net output #0: loss = 0.0582279 (* 1 = 0.0582279 loss)
I0328 17:15:14.369410  1497 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0328 17:15:14.451764  1497 solver.cpp:459] Snapshotting to binary proto file examples/mlp/mlp_iter_10000.caffemodel
I0328 17:15:14.454076  1497 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mlp/mlp_iter_10000.solverstate
I0328 17:15:14.455855  1497 solver.cpp:321] Iteration 10000, loss = 0.0607127
I0328 17:15:14.455874  1497 solver.cpp:341] Iteration 10000, Testing net (#0)
I0328 17:15:14.517654  1497 solver.cpp:409]     Test net output #0: accuracy = 0.9551
I0328 17:15:14.517685  1497 solver.cpp:409]     Test net output #1: loss = 0.13749 (* 1 = 0.13749 loss)
I0328 17:15:14.517693  1497 solver.cpp:326] Optimization Done.
I0328 17:15:14.517699  1497 caffe.cpp:215] Optimization Done.
