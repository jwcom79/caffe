I0416 20:56:35.940495 23299 caffe.cpp:184] Using GPUs 0
I0416 20:56:36.191298 23299 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 5000
base_lr: 0.001
display: 100
max_iter: 100000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/embeded/dart"
solver_mode: GPU
device_id: 0
net: "examples/embeded/dart_train_test.prototxt"
I0416 20:56:36.191426 23299 solver.cpp:91] Creating training net from net file: examples/embeded/dart_train_test.prototxt
I0416 20:56:36.191761 23299 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0416 20:56:36.191776 23299 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0416 20:56:36.191845 23299 net.cpp:49] Initializing net from parameters: 
name: "Embeded"
state {
  phase: TRAIN
}
layer {
  name: "dart"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/embeded/dart_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0416 20:56:36.191926 23299 layer_factory.hpp:77] Creating layer dart
I0416 20:56:36.192435 23299 net.cpp:106] Creating Layer dart
I0416 20:56:36.192448 23299 net.cpp:411] dart -> data
I0416 20:56:36.192477 23299 net.cpp:411] dart -> label
I0416 20:56:36.194054 23303 db_lmdb.cpp:38] Opened lmdb examples/embeded/dart_train_lmdb
I0416 20:56:36.200697 23299 data_layer.cpp:41] output data size: 100,3,24,24
I0416 20:56:36.202524 23299 net.cpp:150] Setting up dart
I0416 20:56:36.202544 23299 net.cpp:157] Top shape: 100 3 24 24 (172800)
I0416 20:56:36.202551 23299 net.cpp:157] Top shape: 100 (100)
I0416 20:56:36.202554 23299 net.cpp:165] Memory required for data: 691600
I0416 20:56:36.202564 23299 layer_factory.hpp:77] Creating layer conv1
I0416 20:56:36.202600 23299 net.cpp:106] Creating Layer conv1
I0416 20:56:36.202610 23299 net.cpp:454] conv1 <- data
I0416 20:56:36.202621 23299 net.cpp:411] conv1 -> conv1
I0416 20:56:36.317107 23299 net.cpp:150] Setting up conv1
I0416 20:56:36.317138 23299 net.cpp:157] Top shape: 100 20 20 20 (800000)
I0416 20:56:36.317143 23299 net.cpp:165] Memory required for data: 3891600
I0416 20:56:36.317162 23299 layer_factory.hpp:77] Creating layer pool1
I0416 20:56:36.317176 23299 net.cpp:106] Creating Layer pool1
I0416 20:56:36.317180 23299 net.cpp:454] pool1 <- conv1
I0416 20:56:36.317185 23299 net.cpp:411] pool1 -> pool1
I0416 20:56:36.317803 23299 net.cpp:150] Setting up pool1
I0416 20:56:36.317817 23299 net.cpp:157] Top shape: 100 20 10 10 (200000)
I0416 20:56:36.317821 23299 net.cpp:165] Memory required for data: 4691600
I0416 20:56:36.317824 23299 layer_factory.hpp:77] Creating layer conv2
I0416 20:56:36.317836 23299 net.cpp:106] Creating Layer conv2
I0416 20:56:36.317838 23299 net.cpp:454] conv2 <- pool1
I0416 20:56:36.317845 23299 net.cpp:411] conv2 -> conv2
I0416 20:56:36.320333 23299 net.cpp:150] Setting up conv2
I0416 20:56:36.320354 23299 net.cpp:157] Top shape: 100 50 6 6 (180000)
I0416 20:56:36.320359 23299 net.cpp:165] Memory required for data: 5411600
I0416 20:56:36.320374 23299 layer_factory.hpp:77] Creating layer pool2
I0416 20:56:36.320386 23299 net.cpp:106] Creating Layer pool2
I0416 20:56:36.320392 23299 net.cpp:454] pool2 <- conv2
I0416 20:56:36.320397 23299 net.cpp:411] pool2 -> pool2
I0416 20:56:36.321064 23299 net.cpp:150] Setting up pool2
I0416 20:56:36.321079 23299 net.cpp:157] Top shape: 100 50 3 3 (45000)
I0416 20:56:36.321082 23299 net.cpp:165] Memory required for data: 5591600
I0416 20:56:36.321085 23299 layer_factory.hpp:77] Creating layer ip1
I0416 20:56:36.321094 23299 net.cpp:106] Creating Layer ip1
I0416 20:56:36.321096 23299 net.cpp:454] ip1 <- pool2
I0416 20:56:36.321104 23299 net.cpp:411] ip1 -> ip1
I0416 20:56:36.321504 23299 net.cpp:150] Setting up ip1
I0416 20:56:36.321513 23299 net.cpp:157] Top shape: 100 128 (12800)
I0416 20:56:36.321516 23299 net.cpp:165] Memory required for data: 5642800
I0416 20:56:36.321524 23299 layer_factory.hpp:77] Creating layer relu1
I0416 20:56:36.321532 23299 net.cpp:106] Creating Layer relu1
I0416 20:56:36.321537 23299 net.cpp:454] relu1 <- ip1
I0416 20:56:36.321540 23299 net.cpp:397] relu1 -> ip1 (in-place)
I0416 20:56:36.322114 23299 net.cpp:150] Setting up relu1
I0416 20:56:36.322129 23299 net.cpp:157] Top shape: 100 128 (12800)
I0416 20:56:36.322131 23299 net.cpp:165] Memory required for data: 5694000
I0416 20:56:36.322134 23299 layer_factory.hpp:77] Creating layer ip2
I0416 20:56:36.322142 23299 net.cpp:106] Creating Layer ip2
I0416 20:56:36.322145 23299 net.cpp:454] ip2 <- ip1
I0416 20:56:36.322150 23299 net.cpp:411] ip2 -> ip2
I0416 20:56:36.322633 23299 net.cpp:150] Setting up ip2
I0416 20:56:36.322646 23299 net.cpp:157] Top shape: 100 48 (4800)
I0416 20:56:36.322649 23299 net.cpp:165] Memory required for data: 5713200
I0416 20:56:36.322655 23299 layer_factory.hpp:77] Creating layer loss
I0416 20:56:36.322662 23299 net.cpp:106] Creating Layer loss
I0416 20:56:36.322666 23299 net.cpp:454] loss <- ip2
I0416 20:56:36.322670 23299 net.cpp:454] loss <- label
I0416 20:56:36.322677 23299 net.cpp:411] loss -> loss
I0416 20:56:36.322695 23299 layer_factory.hpp:77] Creating layer loss
I0416 20:56:36.323354 23299 net.cpp:150] Setting up loss
I0416 20:56:36.323366 23299 net.cpp:157] Top shape: (1)
I0416 20:56:36.323369 23299 net.cpp:160]     with loss weight 1
I0416 20:56:36.323385 23299 net.cpp:165] Memory required for data: 5713204
I0416 20:56:36.323387 23299 net.cpp:226] loss needs backward computation.
I0416 20:56:36.323391 23299 net.cpp:226] ip2 needs backward computation.
I0416 20:56:36.323395 23299 net.cpp:226] relu1 needs backward computation.
I0416 20:56:36.323396 23299 net.cpp:226] ip1 needs backward computation.
I0416 20:56:36.323400 23299 net.cpp:226] pool2 needs backward computation.
I0416 20:56:36.323402 23299 net.cpp:226] conv2 needs backward computation.
I0416 20:56:36.323405 23299 net.cpp:226] pool1 needs backward computation.
I0416 20:56:36.323407 23299 net.cpp:226] conv1 needs backward computation.
I0416 20:56:36.323410 23299 net.cpp:228] dart does not need backward computation.
I0416 20:56:36.323413 23299 net.cpp:270] This network produces output loss
I0416 20:56:36.323423 23299 net.cpp:283] Network initialization done.
I0416 20:56:36.323724 23299 solver.cpp:181] Creating test net (#0) specified by net file: examples/embeded/dart_train_test.prototxt
I0416 20:56:36.323756 23299 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer dart
I0416 20:56:36.323851 23299 net.cpp:49] Initializing net from parameters: 
name: "Embeded"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/embeded/dart_val_lmdb"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0416 20:56:36.323918 23299 layer_factory.hpp:77] Creating layer mnist
I0416 20:56:36.323979 23299 net.cpp:106] Creating Layer mnist
I0416 20:56:36.323987 23299 net.cpp:411] mnist -> data
I0416 20:56:36.323995 23299 net.cpp:411] mnist -> label
I0416 20:56:36.325588 23305 db_lmdb.cpp:38] Opened lmdb examples/embeded/dart_val_lmdb
I0416 20:56:36.325716 23299 data_layer.cpp:41] output data size: 20,3,24,24
I0416 20:56:36.326093 23299 net.cpp:150] Setting up mnist
I0416 20:56:36.326107 23299 net.cpp:157] Top shape: 20 3 24 24 (34560)
I0416 20:56:36.326112 23299 net.cpp:157] Top shape: 20 (20)
I0416 20:56:36.326114 23299 net.cpp:165] Memory required for data: 138320
I0416 20:56:36.326117 23299 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0416 20:56:36.326125 23299 net.cpp:106] Creating Layer label_mnist_1_split
I0416 20:56:36.326128 23299 net.cpp:454] label_mnist_1_split <- label
I0416 20:56:36.326134 23299 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_0
I0416 20:56:36.326140 23299 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_1
I0416 20:56:36.326216 23299 net.cpp:150] Setting up label_mnist_1_split
I0416 20:56:36.326223 23299 net.cpp:157] Top shape: 20 (20)
I0416 20:56:36.326227 23299 net.cpp:157] Top shape: 20 (20)
I0416 20:56:36.326230 23299 net.cpp:165] Memory required for data: 138480
I0416 20:56:36.326232 23299 layer_factory.hpp:77] Creating layer conv1
I0416 20:56:36.326241 23299 net.cpp:106] Creating Layer conv1
I0416 20:56:36.326243 23299 net.cpp:454] conv1 <- data
I0416 20:56:36.326249 23299 net.cpp:411] conv1 -> conv1
I0416 20:56:36.328583 23299 net.cpp:150] Setting up conv1
I0416 20:56:36.328598 23299 net.cpp:157] Top shape: 20 20 20 20 (160000)
I0416 20:56:36.328603 23299 net.cpp:165] Memory required for data: 778480
I0416 20:56:36.328613 23299 layer_factory.hpp:77] Creating layer pool1
I0416 20:56:36.328619 23299 net.cpp:106] Creating Layer pool1
I0416 20:56:36.328622 23299 net.cpp:454] pool1 <- conv1
I0416 20:56:36.328639 23299 net.cpp:411] pool1 -> pool1
I0416 20:56:36.329394 23299 net.cpp:150] Setting up pool1
I0416 20:56:36.329408 23299 net.cpp:157] Top shape: 20 20 10 10 (40000)
I0416 20:56:36.329417 23299 net.cpp:165] Memory required for data: 938480
I0416 20:56:36.329421 23299 layer_factory.hpp:77] Creating layer conv2
I0416 20:56:36.329430 23299 net.cpp:106] Creating Layer conv2
I0416 20:56:36.329434 23299 net.cpp:454] conv2 <- pool1
I0416 20:56:36.329440 23299 net.cpp:411] conv2 -> conv2
I0416 20:56:36.331786 23299 net.cpp:150] Setting up conv2
I0416 20:56:36.331799 23299 net.cpp:157] Top shape: 20 50 6 6 (36000)
I0416 20:56:36.331804 23299 net.cpp:165] Memory required for data: 1082480
I0416 20:56:36.331811 23299 layer_factory.hpp:77] Creating layer pool2
I0416 20:56:36.331820 23299 net.cpp:106] Creating Layer pool2
I0416 20:56:36.331822 23299 net.cpp:454] pool2 <- conv2
I0416 20:56:36.331827 23299 net.cpp:411] pool2 -> pool2
I0416 20:56:36.332613 23299 net.cpp:150] Setting up pool2
I0416 20:56:36.332628 23299 net.cpp:157] Top shape: 20 50 3 3 (9000)
I0416 20:56:36.332631 23299 net.cpp:165] Memory required for data: 1118480
I0416 20:56:36.332634 23299 layer_factory.hpp:77] Creating layer ip1
I0416 20:56:36.332641 23299 net.cpp:106] Creating Layer ip1
I0416 20:56:36.332645 23299 net.cpp:454] ip1 <- pool2
I0416 20:56:36.332650 23299 net.cpp:411] ip1 -> ip1
I0416 20:56:36.333418 23299 net.cpp:150] Setting up ip1
I0416 20:56:36.333431 23299 net.cpp:157] Top shape: 20 128 (2560)
I0416 20:56:36.333436 23299 net.cpp:165] Memory required for data: 1128720
I0416 20:56:36.333443 23299 layer_factory.hpp:77] Creating layer relu1
I0416 20:56:36.333451 23299 net.cpp:106] Creating Layer relu1
I0416 20:56:36.333454 23299 net.cpp:454] relu1 <- ip1
I0416 20:56:36.333461 23299 net.cpp:397] relu1 -> ip1 (in-place)
I0416 20:56:36.334054 23299 net.cpp:150] Setting up relu1
I0416 20:56:36.334069 23299 net.cpp:157] Top shape: 20 128 (2560)
I0416 20:56:36.334072 23299 net.cpp:165] Memory required for data: 1138960
I0416 20:56:36.334075 23299 layer_factory.hpp:77] Creating layer ip2
I0416 20:56:36.334084 23299 net.cpp:106] Creating Layer ip2
I0416 20:56:36.334087 23299 net.cpp:454] ip2 <- ip1
I0416 20:56:36.334092 23299 net.cpp:411] ip2 -> ip2
I0416 20:56:36.334226 23299 net.cpp:150] Setting up ip2
I0416 20:56:36.334235 23299 net.cpp:157] Top shape: 20 48 (960)
I0416 20:56:36.334239 23299 net.cpp:165] Memory required for data: 1142800
I0416 20:56:36.334244 23299 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0416 20:56:36.334249 23299 net.cpp:106] Creating Layer ip2_ip2_0_split
I0416 20:56:36.334251 23299 net.cpp:454] ip2_ip2_0_split <- ip2
I0416 20:56:36.334257 23299 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0416 20:56:36.334262 23299 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0416 20:56:36.334295 23299 net.cpp:150] Setting up ip2_ip2_0_split
I0416 20:56:36.334300 23299 net.cpp:157] Top shape: 20 48 (960)
I0416 20:56:36.334305 23299 net.cpp:157] Top shape: 20 48 (960)
I0416 20:56:36.334306 23299 net.cpp:165] Memory required for data: 1150480
I0416 20:56:36.334309 23299 layer_factory.hpp:77] Creating layer accuracy
I0416 20:56:36.334314 23299 net.cpp:106] Creating Layer accuracy
I0416 20:56:36.334317 23299 net.cpp:454] accuracy <- ip2_ip2_0_split_0
I0416 20:56:36.334321 23299 net.cpp:454] accuracy <- label_mnist_1_split_0
I0416 20:56:36.334326 23299 net.cpp:411] accuracy -> accuracy
I0416 20:56:36.334332 23299 net.cpp:150] Setting up accuracy
I0416 20:56:36.334336 23299 net.cpp:157] Top shape: (1)
I0416 20:56:36.334339 23299 net.cpp:165] Memory required for data: 1150484
I0416 20:56:36.334342 23299 layer_factory.hpp:77] Creating layer loss
I0416 20:56:36.334345 23299 net.cpp:106] Creating Layer loss
I0416 20:56:36.334348 23299 net.cpp:454] loss <- ip2_ip2_0_split_1
I0416 20:56:36.334352 23299 net.cpp:454] loss <- label_mnist_1_split_1
I0416 20:56:36.334355 23299 net.cpp:411] loss -> loss
I0416 20:56:36.334362 23299 layer_factory.hpp:77] Creating layer loss
I0416 20:56:36.335027 23299 net.cpp:150] Setting up loss
I0416 20:56:36.335050 23299 net.cpp:157] Top shape: (1)
I0416 20:56:36.335054 23299 net.cpp:160]     with loss weight 1
I0416 20:56:36.335059 23299 net.cpp:165] Memory required for data: 1150488
I0416 20:56:36.335062 23299 net.cpp:226] loss needs backward computation.
I0416 20:56:36.335067 23299 net.cpp:228] accuracy does not need backward computation.
I0416 20:56:36.335069 23299 net.cpp:226] ip2_ip2_0_split needs backward computation.
I0416 20:56:36.335072 23299 net.cpp:226] ip2 needs backward computation.
I0416 20:56:36.335075 23299 net.cpp:226] relu1 needs backward computation.
I0416 20:56:36.335078 23299 net.cpp:226] ip1 needs backward computation.
I0416 20:56:36.335080 23299 net.cpp:226] pool2 needs backward computation.
I0416 20:56:36.335083 23299 net.cpp:226] conv2 needs backward computation.
I0416 20:56:36.335085 23299 net.cpp:226] pool1 needs backward computation.
I0416 20:56:36.335088 23299 net.cpp:226] conv1 needs backward computation.
I0416 20:56:36.335091 23299 net.cpp:228] label_mnist_1_split does not need backward computation.
I0416 20:56:36.335094 23299 net.cpp:228] mnist does not need backward computation.
I0416 20:56:36.335096 23299 net.cpp:270] This network produces output accuracy
I0416 20:56:36.335099 23299 net.cpp:270] This network produces output loss
I0416 20:56:36.335109 23299 net.cpp:283] Network initialization done.
I0416 20:56:36.335150 23299 solver.cpp:60] Solver scaffolding done.
I0416 20:56:36.335391 23299 caffe.cpp:212] Starting Optimization
I0416 20:56:36.335398 23299 solver.cpp:288] Solving Embeded
I0416 20:56:36.335402 23299 solver.cpp:289] Learning Rate Policy: fixed
I0416 20:56:36.335556 23299 solver.cpp:341] Iteration 0, Testing net (#0)
I0416 20:56:36.335566 23299 net.cpp:748] Ignoring source layer dart
I0416 20:56:36.347694 23299 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 20:56:36.385437 23299 solver.cpp:409]     Test net output #0: accuracy = 0.011
I0416 20:56:36.385462 23299 solver.cpp:409]     Test net output #1: loss = 4.00306 (* 1 = 4.00306 loss)
I0416 20:56:36.387496 23299 solver.cpp:237] Iteration 0, loss = 3.92405
I0416 20:56:36.387519 23299 solver.cpp:253]     Train net output #0: loss = 3.92405 (* 1 = 3.92405 loss)
I0416 20:56:36.387531 23299 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0416 20:56:36.581568 23299 solver.cpp:237] Iteration 100, loss = 2.87958
I0416 20:56:36.581600 23299 solver.cpp:253]     Train net output #0: loss = 2.87958 (* 1 = 2.87958 loss)
I0416 20:56:36.581606 23299 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0416 20:56:36.764503 23299 solver.cpp:237] Iteration 200, loss = 2.86835
I0416 20:56:36.764534 23299 solver.cpp:253]     Train net output #0: loss = 2.86835 (* 1 = 2.86835 loss)
I0416 20:56:36.764540 23299 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0416 20:56:36.944465 23299 solver.cpp:237] Iteration 300, loss = 2.85525
I0416 20:56:36.944496 23299 solver.cpp:253]     Train net output #0: loss = 2.85525 (* 1 = 2.85525 loss)
I0416 20:56:36.944509 23299 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0416 20:56:37.123529 23299 solver.cpp:237] Iteration 400, loss = 2.84624
I0416 20:56:37.123559 23299 solver.cpp:253]     Train net output #0: loss = 2.84624 (* 1 = 2.84624 loss)
I0416 20:56:37.123564 23299 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0416 20:56:37.302881 23299 solver.cpp:237] Iteration 500, loss = 2.83992
I0416 20:56:37.302911 23299 solver.cpp:253]     Train net output #0: loss = 2.83992 (* 1 = 2.83992 loss)
I0416 20:56:37.302917 23299 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0416 20:56:37.482508 23299 solver.cpp:237] Iteration 600, loss = 2.83563
I0416 20:56:37.482547 23299 solver.cpp:253]     Train net output #0: loss = 2.83563 (* 1 = 2.83563 loss)
I0416 20:56:37.482554 23299 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0416 20:56:37.659906 23299 solver.cpp:237] Iteration 700, loss = 2.83068
I0416 20:56:37.659955 23299 solver.cpp:253]     Train net output #0: loss = 2.83068 (* 1 = 2.83068 loss)
I0416 20:56:37.659968 23299 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0416 20:56:37.837455 23299 solver.cpp:237] Iteration 800, loss = 2.82665
I0416 20:56:37.837484 23299 solver.cpp:253]     Train net output #0: loss = 2.82665 (* 1 = 2.82665 loss)
I0416 20:56:37.837492 23299 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0416 20:56:38.015688 23299 solver.cpp:237] Iteration 900, loss = 2.82411
I0416 20:56:38.015714 23299 solver.cpp:253]     Train net output #0: loss = 2.82411 (* 1 = 2.82411 loss)
I0416 20:56:38.015719 23299 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0416 20:56:38.193658 23299 solver.cpp:237] Iteration 1000, loss = 2.8195
I0416 20:56:38.193686 23299 solver.cpp:253]     Train net output #0: loss = 2.8195 (* 1 = 2.8195 loss)
I0416 20:56:38.193691 23299 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0416 20:56:38.371822 23299 solver.cpp:237] Iteration 1100, loss = 2.81453
I0416 20:56:38.371850 23299 solver.cpp:253]     Train net output #0: loss = 2.81453 (* 1 = 2.81453 loss)
I0416 20:56:38.371855 23299 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0416 20:56:38.549907 23299 solver.cpp:237] Iteration 1200, loss = 2.80927
I0416 20:56:38.549939 23299 solver.cpp:253]     Train net output #0: loss = 2.80927 (* 1 = 2.80927 loss)
I0416 20:56:38.549945 23299 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0416 20:56:38.728369 23299 solver.cpp:237] Iteration 1300, loss = 2.80298
I0416 20:56:38.728397 23299 solver.cpp:253]     Train net output #0: loss = 2.80298 (* 1 = 2.80298 loss)
I0416 20:56:38.728402 23299 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0416 20:56:38.906150 23299 solver.cpp:237] Iteration 1400, loss = 2.79611
I0416 20:56:38.906177 23299 solver.cpp:253]     Train net output #0: loss = 2.79611 (* 1 = 2.79611 loss)
I0416 20:56:38.906183 23299 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0416 20:56:39.086452 23299 solver.cpp:237] Iteration 1500, loss = 2.78859
I0416 20:56:39.086488 23299 solver.cpp:253]     Train net output #0: loss = 2.78859 (* 1 = 2.78859 loss)
I0416 20:56:39.086498 23299 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0416 20:56:39.265300 23299 solver.cpp:237] Iteration 1600, loss = 2.77862
I0416 20:56:39.265347 23299 solver.cpp:253]     Train net output #0: loss = 2.77862 (* 1 = 2.77862 loss)
I0416 20:56:39.265357 23299 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0416 20:56:39.443460 23299 solver.cpp:237] Iteration 1700, loss = 2.76952
I0416 20:56:39.443490 23299 solver.cpp:253]     Train net output #0: loss = 2.76952 (* 1 = 2.76952 loss)
I0416 20:56:39.443496 23299 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0416 20:56:39.621115 23299 solver.cpp:237] Iteration 1800, loss = 2.75233
I0416 20:56:39.621145 23299 solver.cpp:253]     Train net output #0: loss = 2.75233 (* 1 = 2.75233 loss)
I0416 20:56:39.621150 23299 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0416 20:56:39.799455 23299 solver.cpp:237] Iteration 1900, loss = 2.73935
I0416 20:56:39.799485 23299 solver.cpp:253]     Train net output #0: loss = 2.73935 (* 1 = 2.73935 loss)
I0416 20:56:39.799491 23299 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0416 20:56:39.980510 23299 solver.cpp:237] Iteration 2000, loss = 2.72089
I0416 20:56:39.980548 23299 solver.cpp:253]     Train net output #0: loss = 2.72089 (* 1 = 2.72089 loss)
I0416 20:56:39.980558 23299 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0416 20:56:40.159143 23299 solver.cpp:237] Iteration 2100, loss = 2.69553
I0416 20:56:40.159181 23299 solver.cpp:253]     Train net output #0: loss = 2.69553 (* 1 = 2.69553 loss)
I0416 20:56:40.159190 23299 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0416 20:56:40.337985 23299 solver.cpp:237] Iteration 2200, loss = 2.654
I0416 20:56:40.338021 23299 solver.cpp:253]     Train net output #0: loss = 2.654 (* 1 = 2.654 loss)
I0416 20:56:40.338029 23299 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0416 20:56:40.517031 23299 solver.cpp:237] Iteration 2300, loss = 2.61543
I0416 20:56:40.517068 23299 solver.cpp:253]     Train net output #0: loss = 2.61543 (* 1 = 2.61543 loss)
I0416 20:56:40.517077 23299 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0416 20:56:40.695469 23299 solver.cpp:237] Iteration 2400, loss = 2.5724
I0416 20:56:40.695528 23299 solver.cpp:253]     Train net output #0: loss = 2.5724 (* 1 = 2.5724 loss)
I0416 20:56:40.695539 23299 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0416 20:56:40.873281 23299 solver.cpp:237] Iteration 2500, loss = 2.51966
I0416 20:56:40.873314 23299 solver.cpp:253]     Train net output #0: loss = 2.51966 (* 1 = 2.51966 loss)
I0416 20:56:40.873323 23299 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0416 20:56:41.052695 23299 solver.cpp:237] Iteration 2600, loss = 2.46611
I0416 20:56:41.052721 23299 solver.cpp:253]     Train net output #0: loss = 2.46611 (* 1 = 2.46611 loss)
I0416 20:56:41.052726 23299 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0416 20:56:41.230701 23299 solver.cpp:237] Iteration 2700, loss = 2.41417
I0416 20:56:41.230728 23299 solver.cpp:253]     Train net output #0: loss = 2.41417 (* 1 = 2.41417 loss)
I0416 20:56:41.230733 23299 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0416 20:56:41.421149 23299 solver.cpp:237] Iteration 2800, loss = 2.35931
I0416 20:56:41.421178 23299 solver.cpp:253]     Train net output #0: loss = 2.35931 (* 1 = 2.35931 loss)
I0416 20:56:41.421183 23299 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0416 20:56:41.601673 23299 solver.cpp:237] Iteration 2900, loss = 2.30554
I0416 20:56:41.601701 23299 solver.cpp:253]     Train net output #0: loss = 2.30554 (* 1 = 2.30554 loss)
I0416 20:56:41.601706 23299 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0416 20:56:41.779264 23299 solver.cpp:237] Iteration 3000, loss = 2.25308
I0416 20:56:41.779291 23299 solver.cpp:253]     Train net output #0: loss = 2.25308 (* 1 = 2.25308 loss)
I0416 20:56:41.779296 23299 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0416 20:56:41.957113 23299 solver.cpp:237] Iteration 3100, loss = 2.20502
I0416 20:56:41.957140 23299 solver.cpp:253]     Train net output #0: loss = 2.20502 (* 1 = 2.20502 loss)
I0416 20:56:41.957146 23299 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0416 20:56:42.134747 23299 solver.cpp:237] Iteration 3200, loss = 2.15825
I0416 20:56:42.134774 23299 solver.cpp:253]     Train net output #0: loss = 2.15825 (* 1 = 2.15825 loss)
I0416 20:56:42.134784 23299 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0416 20:56:42.312454 23299 solver.cpp:237] Iteration 3300, loss = 2.11609
I0416 20:56:42.312479 23299 solver.cpp:253]     Train net output #0: loss = 2.11609 (* 1 = 2.11609 loss)
I0416 20:56:42.312484 23299 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0416 20:56:42.490548 23299 solver.cpp:237] Iteration 3400, loss = 2.07785
I0416 20:56:42.490574 23299 solver.cpp:253]     Train net output #0: loss = 2.07785 (* 1 = 2.07785 loss)
I0416 20:56:42.490588 23299 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0416 20:56:42.668081 23299 solver.cpp:237] Iteration 3500, loss = 2.04071
I0416 20:56:42.668107 23299 solver.cpp:253]     Train net output #0: loss = 2.04071 (* 1 = 2.04071 loss)
I0416 20:56:42.668118 23299 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0416 20:56:42.845839 23299 solver.cpp:237] Iteration 3600, loss = 2.00708
I0416 20:56:42.845865 23299 solver.cpp:253]     Train net output #0: loss = 2.00708 (* 1 = 2.00708 loss)
I0416 20:56:42.845871 23299 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0416 20:56:43.023658 23299 solver.cpp:237] Iteration 3700, loss = 1.97508
I0416 20:56:43.023684 23299 solver.cpp:253]     Train net output #0: loss = 1.97508 (* 1 = 1.97508 loss)
I0416 20:56:43.023689 23299 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0416 20:56:43.201082 23299 solver.cpp:237] Iteration 3800, loss = 1.94346
I0416 20:56:43.201115 23299 solver.cpp:253]     Train net output #0: loss = 1.94346 (* 1 = 1.94346 loss)
I0416 20:56:43.201122 23299 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0416 20:56:43.378195 23299 solver.cpp:237] Iteration 3900, loss = 1.9158
I0416 20:56:43.378219 23299 solver.cpp:253]     Train net output #0: loss = 1.9158 (* 1 = 1.9158 loss)
I0416 20:56:43.378224 23299 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0416 20:56:43.556088 23299 solver.cpp:237] Iteration 4000, loss = 1.88765
I0416 20:56:43.556134 23299 solver.cpp:253]     Train net output #0: loss = 1.88765 (* 1 = 1.88765 loss)
I0416 20:56:43.556140 23299 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0416 20:56:43.733050 23299 solver.cpp:237] Iteration 4100, loss = 1.85932
I0416 20:56:43.733074 23299 solver.cpp:253]     Train net output #0: loss = 1.85932 (* 1 = 1.85932 loss)
I0416 20:56:43.733080 23299 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0416 20:56:43.911002 23299 solver.cpp:237] Iteration 4200, loss = 1.8348
I0416 20:56:43.911029 23299 solver.cpp:253]     Train net output #0: loss = 1.8348 (* 1 = 1.8348 loss)
I0416 20:56:43.911034 23299 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0416 20:56:44.089190 23299 solver.cpp:237] Iteration 4300, loss = 1.80829
I0416 20:56:44.089221 23299 solver.cpp:253]     Train net output #0: loss = 1.80829 (* 1 = 1.80829 loss)
I0416 20:56:44.089226 23299 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0416 20:56:44.269830 23299 solver.cpp:237] Iteration 4400, loss = 1.78503
I0416 20:56:44.269858 23299 solver.cpp:253]     Train net output #0: loss = 1.78503 (* 1 = 1.78503 loss)
I0416 20:56:44.269870 23299 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0416 20:56:44.448143 23299 solver.cpp:237] Iteration 4500, loss = 1.76127
I0416 20:56:44.448170 23299 solver.cpp:253]     Train net output #0: loss = 1.76127 (* 1 = 1.76127 loss)
I0416 20:56:44.448175 23299 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0416 20:56:44.626090 23299 solver.cpp:237] Iteration 4600, loss = 1.73909
I0416 20:56:44.626117 23299 solver.cpp:253]     Train net output #0: loss = 1.73909 (* 1 = 1.73909 loss)
I0416 20:56:44.626128 23299 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0416 20:56:44.803285 23299 solver.cpp:237] Iteration 4700, loss = 1.71621
I0416 20:56:44.803311 23299 solver.cpp:253]     Train net output #0: loss = 1.71621 (* 1 = 1.71621 loss)
I0416 20:56:44.803318 23299 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0416 20:56:44.981096 23299 solver.cpp:237] Iteration 4800, loss = 1.69637
I0416 20:56:44.981123 23299 solver.cpp:253]     Train net output #0: loss = 1.69637 (* 1 = 1.69637 loss)
I0416 20:56:44.981128 23299 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0416 20:56:45.159206 23299 solver.cpp:237] Iteration 4900, loss = 1.6777
I0416 20:56:45.159231 23299 solver.cpp:253]     Train net output #0: loss = 1.6777 (* 1 = 1.6777 loss)
I0416 20:56:45.159237 23299 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0416 20:56:45.334602 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_5000.caffemodel
I0416 20:56:45.337378 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_5000.solverstate
I0416 20:56:45.337959 23299 solver.cpp:341] Iteration 5000, Testing net (#0)
I0416 20:56:45.337970 23299 net.cpp:748] Ignoring source layer dart
I0416 20:56:45.380069 23299 solver.cpp:409]     Test net output #0: accuracy = 0.316
I0416 20:56:45.380089 23299 solver.cpp:409]     Test net output #1: loss = 1.75561 (* 1 = 1.75561 loss)
I0416 20:56:45.380870 23299 solver.cpp:237] Iteration 5000, loss = 1.65672
I0416 20:56:45.380888 23299 solver.cpp:253]     Train net output #0: loss = 1.65672 (* 1 = 1.65672 loss)
I0416 20:56:45.380913 23299 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0416 20:56:45.553660 23299 solver.cpp:237] Iteration 5100, loss = 1.63873
I0416 20:56:45.553689 23299 solver.cpp:253]     Train net output #0: loss = 1.63873 (* 1 = 1.63873 loss)
I0416 20:56:45.553694 23299 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
I0416 20:56:45.726773 23299 solver.cpp:237] Iteration 5200, loss = 1.61947
I0416 20:56:45.726799 23299 solver.cpp:253]     Train net output #0: loss = 1.61947 (* 1 = 1.61947 loss)
I0416 20:56:45.726804 23299 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0416 20:56:45.899678 23299 solver.cpp:237] Iteration 5300, loss = 1.60442
I0416 20:56:45.899704 23299 solver.cpp:253]     Train net output #0: loss = 1.60442 (* 1 = 1.60442 loss)
I0416 20:56:45.899710 23299 sgd_solver.cpp:106] Iteration 5300, lr = 0.001
I0416 20:56:46.072803 23299 solver.cpp:237] Iteration 5400, loss = 1.58868
I0416 20:56:46.072829 23299 solver.cpp:253]     Train net output #0: loss = 1.58868 (* 1 = 1.58868 loss)
I0416 20:56:46.072834 23299 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0416 20:56:46.245837 23299 solver.cpp:237] Iteration 5500, loss = 1.57685
I0416 20:56:46.245864 23299 solver.cpp:253]     Train net output #0: loss = 1.57685 (* 1 = 1.57685 loss)
I0416 20:56:46.245869 23299 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
I0416 20:56:46.418879 23299 solver.cpp:237] Iteration 5600, loss = 1.56134
I0416 20:56:46.418905 23299 solver.cpp:253]     Train net output #0: loss = 1.56134 (* 1 = 1.56134 loss)
I0416 20:56:46.418910 23299 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0416 20:56:46.591610 23299 solver.cpp:237] Iteration 5700, loss = 1.54806
I0416 20:56:46.591636 23299 solver.cpp:253]     Train net output #0: loss = 1.54806 (* 1 = 1.54806 loss)
I0416 20:56:46.591640 23299 sgd_solver.cpp:106] Iteration 5700, lr = 0.001
I0416 20:56:46.764272 23299 solver.cpp:237] Iteration 5800, loss = 1.53441
I0416 20:56:46.764299 23299 solver.cpp:253]     Train net output #0: loss = 1.53441 (* 1 = 1.53441 loss)
I0416 20:56:46.764304 23299 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0416 20:56:46.937340 23299 solver.cpp:237] Iteration 5900, loss = 1.52313
I0416 20:56:46.937366 23299 solver.cpp:253]     Train net output #0: loss = 1.52313 (* 1 = 1.52313 loss)
I0416 20:56:46.937371 23299 sgd_solver.cpp:106] Iteration 5900, lr = 0.001
I0416 20:56:47.110199 23299 solver.cpp:237] Iteration 6000, loss = 1.51177
I0416 20:56:47.110224 23299 solver.cpp:253]     Train net output #0: loss = 1.51177 (* 1 = 1.51177 loss)
I0416 20:56:47.110231 23299 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0416 20:56:47.283217 23299 solver.cpp:237] Iteration 6100, loss = 1.50196
I0416 20:56:47.283246 23299 solver.cpp:253]     Train net output #0: loss = 1.50196 (* 1 = 1.50196 loss)
I0416 20:56:47.283251 23299 sgd_solver.cpp:106] Iteration 6100, lr = 0.001
I0416 20:56:47.455981 23299 solver.cpp:237] Iteration 6200, loss = 1.48931
I0416 20:56:47.456008 23299 solver.cpp:253]     Train net output #0: loss = 1.48931 (* 1 = 1.48931 loss)
I0416 20:56:47.456013 23299 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I0416 20:56:47.629068 23299 solver.cpp:237] Iteration 6300, loss = 1.47686
I0416 20:56:47.629096 23299 solver.cpp:253]     Train net output #0: loss = 1.47686 (* 1 = 1.47686 loss)
I0416 20:56:47.629101 23299 sgd_solver.cpp:106] Iteration 6300, lr = 0.001
I0416 20:56:47.801568 23299 solver.cpp:237] Iteration 6400, loss = 1.46734
I0416 20:56:47.801594 23299 solver.cpp:253]     Train net output #0: loss = 1.46734 (* 1 = 1.46734 loss)
I0416 20:56:47.801599 23299 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I0416 20:56:47.976271 23299 solver.cpp:237] Iteration 6500, loss = 1.45763
I0416 20:56:47.976296 23299 solver.cpp:253]     Train net output #0: loss = 1.45763 (* 1 = 1.45763 loss)
I0416 20:56:47.976301 23299 sgd_solver.cpp:106] Iteration 6500, lr = 0.001
I0416 20:56:48.150475 23299 solver.cpp:237] Iteration 6600, loss = 1.44688
I0416 20:56:48.150501 23299 solver.cpp:253]     Train net output #0: loss = 1.44688 (* 1 = 1.44688 loss)
I0416 20:56:48.150506 23299 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0416 20:56:48.324200 23299 solver.cpp:237] Iteration 6700, loss = 1.43941
I0416 20:56:48.324225 23299 solver.cpp:253]     Train net output #0: loss = 1.43941 (* 1 = 1.43941 loss)
I0416 20:56:48.324230 23299 sgd_solver.cpp:106] Iteration 6700, lr = 0.001
I0416 20:56:48.497375 23299 solver.cpp:237] Iteration 6800, loss = 1.42847
I0416 20:56:48.497401 23299 solver.cpp:253]     Train net output #0: loss = 1.42847 (* 1 = 1.42847 loss)
I0416 20:56:48.497406 23299 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I0416 20:56:48.671066 23299 solver.cpp:237] Iteration 6900, loss = 1.42199
I0416 20:56:48.671092 23299 solver.cpp:253]     Train net output #0: loss = 1.42199 (* 1 = 1.42199 loss)
I0416 20:56:48.671097 23299 sgd_solver.cpp:106] Iteration 6900, lr = 0.001
I0416 20:56:48.844612 23299 solver.cpp:237] Iteration 7000, loss = 1.41381
I0416 20:56:48.844640 23299 solver.cpp:253]     Train net output #0: loss = 1.41381 (* 1 = 1.41381 loss)
I0416 20:56:48.844643 23299 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0416 20:56:49.018244 23299 solver.cpp:237] Iteration 7100, loss = 1.40477
I0416 20:56:49.018271 23299 solver.cpp:253]     Train net output #0: loss = 1.40477 (* 1 = 1.40477 loss)
I0416 20:56:49.018277 23299 sgd_solver.cpp:106] Iteration 7100, lr = 0.001
I0416 20:56:49.192473 23299 solver.cpp:237] Iteration 7200, loss = 1.39299
I0416 20:56:49.192500 23299 solver.cpp:253]     Train net output #0: loss = 1.39299 (* 1 = 1.39299 loss)
I0416 20:56:49.192505 23299 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0416 20:56:49.366417 23299 solver.cpp:237] Iteration 7300, loss = 1.37931
I0416 20:56:49.366443 23299 solver.cpp:253]     Train net output #0: loss = 1.37931 (* 1 = 1.37931 loss)
I0416 20:56:49.366449 23299 sgd_solver.cpp:106] Iteration 7300, lr = 0.001
I0416 20:56:49.540738 23299 solver.cpp:237] Iteration 7400, loss = 1.36529
I0416 20:56:49.540765 23299 solver.cpp:253]     Train net output #0: loss = 1.36529 (* 1 = 1.36529 loss)
I0416 20:56:49.540768 23299 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I0416 20:56:49.714812 23299 solver.cpp:237] Iteration 7500, loss = 1.35045
I0416 20:56:49.714836 23299 solver.cpp:253]     Train net output #0: loss = 1.35045 (* 1 = 1.35045 loss)
I0416 20:56:49.714841 23299 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I0416 20:56:49.889159 23299 solver.cpp:237] Iteration 7600, loss = 1.33578
I0416 20:56:49.889185 23299 solver.cpp:253]     Train net output #0: loss = 1.33578 (* 1 = 1.33578 loss)
I0416 20:56:49.889192 23299 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0416 20:56:50.063110 23299 solver.cpp:237] Iteration 7700, loss = 1.31989
I0416 20:56:50.063138 23299 solver.cpp:253]     Train net output #0: loss = 1.31989 (* 1 = 1.31989 loss)
I0416 20:56:50.063143 23299 sgd_solver.cpp:106] Iteration 7700, lr = 0.001
I0416 20:56:50.237359 23299 solver.cpp:237] Iteration 7800, loss = 1.30616
I0416 20:56:50.237385 23299 solver.cpp:253]     Train net output #0: loss = 1.30616 (* 1 = 1.30616 loss)
I0416 20:56:50.237390 23299 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0416 20:56:50.411501 23299 solver.cpp:237] Iteration 7900, loss = 1.2939
I0416 20:56:50.411528 23299 solver.cpp:253]     Train net output #0: loss = 1.2939 (* 1 = 1.2939 loss)
I0416 20:56:50.411533 23299 sgd_solver.cpp:106] Iteration 7900, lr = 0.001
I0416 20:56:50.584625 23299 solver.cpp:237] Iteration 8000, loss = 1.28059
I0416 20:56:50.584650 23299 solver.cpp:253]     Train net output #0: loss = 1.28059 (* 1 = 1.28059 loss)
I0416 20:56:50.584656 23299 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0416 20:56:50.758610 23299 solver.cpp:237] Iteration 8100, loss = 1.26793
I0416 20:56:50.758637 23299 solver.cpp:253]     Train net output #0: loss = 1.26793 (* 1 = 1.26793 loss)
I0416 20:56:50.758643 23299 sgd_solver.cpp:106] Iteration 8100, lr = 0.001
I0416 20:56:50.932911 23299 solver.cpp:237] Iteration 8200, loss = 1.2552
I0416 20:56:50.932937 23299 solver.cpp:253]     Train net output #0: loss = 1.2552 (* 1 = 1.2552 loss)
I0416 20:56:50.932942 23299 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0416 20:56:51.107362 23299 solver.cpp:237] Iteration 8300, loss = 1.24384
I0416 20:56:51.107388 23299 solver.cpp:253]     Train net output #0: loss = 1.24384 (* 1 = 1.24384 loss)
I0416 20:56:51.107393 23299 sgd_solver.cpp:106] Iteration 8300, lr = 0.001
I0416 20:56:51.281844 23299 solver.cpp:237] Iteration 8400, loss = 1.23186
I0416 20:56:51.281870 23299 solver.cpp:253]     Train net output #0: loss = 1.23186 (* 1 = 1.23186 loss)
I0416 20:56:51.281875 23299 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0416 20:56:51.455958 23299 solver.cpp:237] Iteration 8500, loss = 1.21978
I0416 20:56:51.455986 23299 solver.cpp:253]     Train net output #0: loss = 1.21978 (* 1 = 1.21978 loss)
I0416 20:56:51.455991 23299 sgd_solver.cpp:106] Iteration 8500, lr = 0.001
I0416 20:56:51.629878 23299 solver.cpp:237] Iteration 8600, loss = 1.20877
I0416 20:56:51.630264 23299 solver.cpp:253]     Train net output #0: loss = 1.20877 (* 1 = 1.20877 loss)
I0416 20:56:51.630312 23299 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0416 20:56:51.807960 23299 solver.cpp:237] Iteration 8700, loss = 1.19694
I0416 20:56:51.807997 23299 solver.cpp:253]     Train net output #0: loss = 1.19694 (* 1 = 1.19694 loss)
I0416 20:56:51.808008 23299 sgd_solver.cpp:106] Iteration 8700, lr = 0.001
I0416 20:56:51.981927 23299 solver.cpp:237] Iteration 8800, loss = 1.18438
I0416 20:56:51.981961 23299 solver.cpp:253]     Train net output #0: loss = 1.18438 (* 1 = 1.18438 loss)
I0416 20:56:51.981969 23299 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0416 20:56:52.155869 23299 solver.cpp:237] Iteration 8900, loss = 1.17341
I0416 20:56:52.155911 23299 solver.cpp:253]     Train net output #0: loss = 1.17341 (* 1 = 1.17341 loss)
I0416 20:56:52.155920 23299 sgd_solver.cpp:106] Iteration 8900, lr = 0.001
I0416 20:56:52.329746 23299 solver.cpp:237] Iteration 9000, loss = 1.16327
I0416 20:56:52.329777 23299 solver.cpp:253]     Train net output #0: loss = 1.16327 (* 1 = 1.16327 loss)
I0416 20:56:52.329785 23299 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0416 20:56:52.504190 23299 solver.cpp:237] Iteration 9100, loss = 1.15062
I0416 20:56:52.504226 23299 solver.cpp:253]     Train net output #0: loss = 1.15062 (* 1 = 1.15062 loss)
I0416 20:56:52.504240 23299 sgd_solver.cpp:106] Iteration 9100, lr = 0.001
I0416 20:56:52.678428 23299 solver.cpp:237] Iteration 9200, loss = 1.14001
I0416 20:56:52.678462 23299 solver.cpp:253]     Train net output #0: loss = 1.14001 (* 1 = 1.14001 loss)
I0416 20:56:52.678470 23299 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0416 20:56:52.852854 23299 solver.cpp:237] Iteration 9300, loss = 1.12883
I0416 20:56:52.852882 23299 solver.cpp:253]     Train net output #0: loss = 1.12883 (* 1 = 1.12883 loss)
I0416 20:56:52.852890 23299 sgd_solver.cpp:106] Iteration 9300, lr = 0.001
I0416 20:56:53.027572 23299 solver.cpp:237] Iteration 9400, loss = 1.11922
I0416 20:56:53.027601 23299 solver.cpp:253]     Train net output #0: loss = 1.11922 (* 1 = 1.11922 loss)
I0416 20:56:53.027611 23299 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0416 20:56:53.202055 23299 solver.cpp:237] Iteration 9500, loss = 1.10892
I0416 20:56:53.202085 23299 solver.cpp:253]     Train net output #0: loss = 1.10892 (* 1 = 1.10892 loss)
I0416 20:56:53.202092 23299 sgd_solver.cpp:106] Iteration 9500, lr = 0.001
I0416 20:56:53.376792 23299 solver.cpp:237] Iteration 9600, loss = 1.09893
I0416 20:56:53.376821 23299 solver.cpp:253]     Train net output #0: loss = 1.09893 (* 1 = 1.09893 loss)
I0416 20:56:53.376832 23299 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0416 20:56:53.551118 23299 solver.cpp:237] Iteration 9700, loss = 1.08821
I0416 20:56:53.551149 23299 solver.cpp:253]     Train net output #0: loss = 1.08821 (* 1 = 1.08821 loss)
I0416 20:56:53.551157 23299 sgd_solver.cpp:106] Iteration 9700, lr = 0.001
I0416 20:56:53.726766 23299 solver.cpp:237] Iteration 9800, loss = 1.07976
I0416 20:56:53.726796 23299 solver.cpp:253]     Train net output #0: loss = 1.07976 (* 1 = 1.07976 loss)
I0416 20:56:53.726805 23299 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0416 20:56:53.901196 23299 solver.cpp:237] Iteration 9900, loss = 1.0698
I0416 20:56:53.901224 23299 solver.cpp:253]     Train net output #0: loss = 1.0698 (* 1 = 1.0698 loss)
I0416 20:56:53.901235 23299 sgd_solver.cpp:106] Iteration 9900, lr = 0.001
I0416 20:56:54.073664 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_10000.caffemodel
I0416 20:56:54.075589 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_10000.solverstate
I0416 20:56:54.076134 23299 solver.cpp:341] Iteration 10000, Testing net (#0)
I0416 20:56:54.076146 23299 net.cpp:748] Ignoring source layer dart
I0416 20:56:54.131198 23299 solver.cpp:409]     Test net output #0: accuracy = 0.539
I0416 20:56:54.131240 23299 solver.cpp:409]     Test net output #1: loss = 1.18023 (* 1 = 1.18023 loss)
I0416 20:56:54.132294 23299 solver.cpp:237] Iteration 10000, loss = 1.05828
I0416 20:56:54.132328 23299 solver.cpp:253]     Train net output #0: loss = 1.05828 (* 1 = 1.05828 loss)
I0416 20:56:54.132346 23299 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0416 20:56:54.309191 23299 solver.cpp:237] Iteration 10100, loss = 1.04869
I0416 20:56:54.309226 23299 solver.cpp:253]     Train net output #0: loss = 1.04869 (* 1 = 1.04869 loss)
I0416 20:56:54.309232 23299 sgd_solver.cpp:106] Iteration 10100, lr = 0.001
I0416 20:56:54.492082 23299 solver.cpp:237] Iteration 10200, loss = 1.0385
I0416 20:56:54.492120 23299 solver.cpp:253]     Train net output #0: loss = 1.0385 (* 1 = 1.0385 loss)
I0416 20:56:54.492126 23299 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0416 20:56:54.678175 23299 solver.cpp:237] Iteration 10300, loss = 1.02894
I0416 20:56:54.678211 23299 solver.cpp:253]     Train net output #0: loss = 1.02894 (* 1 = 1.02894 loss)
I0416 20:56:54.678218 23299 sgd_solver.cpp:106] Iteration 10300, lr = 0.001
I0416 20:56:54.854961 23299 solver.cpp:237] Iteration 10400, loss = 1.0183
I0416 20:56:54.854992 23299 solver.cpp:253]     Train net output #0: loss = 1.0183 (* 1 = 1.0183 loss)
I0416 20:56:54.854997 23299 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I0416 20:56:55.033430 23299 solver.cpp:237] Iteration 10500, loss = 1.0089
I0416 20:56:55.033462 23299 solver.cpp:253]     Train net output #0: loss = 1.0089 (* 1 = 1.0089 loss)
I0416 20:56:55.033466 23299 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I0416 20:56:55.210583 23299 solver.cpp:237] Iteration 10600, loss = 0.999045
I0416 20:56:55.210613 23299 solver.cpp:253]     Train net output #0: loss = 0.999045 (* 1 = 0.999045 loss)
I0416 20:56:55.210618 23299 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I0416 20:56:55.386788 23299 solver.cpp:237] Iteration 10700, loss = 0.98978
I0416 20:56:55.386818 23299 solver.cpp:253]     Train net output #0: loss = 0.98978 (* 1 = 0.98978 loss)
I0416 20:56:55.386824 23299 sgd_solver.cpp:106] Iteration 10700, lr = 0.001
I0416 20:56:55.563235 23299 solver.cpp:237] Iteration 10800, loss = 0.981469
I0416 20:56:55.563266 23299 solver.cpp:253]     Train net output #0: loss = 0.981469 (* 1 = 0.981469 loss)
I0416 20:56:55.563277 23299 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0416 20:56:55.739639 23299 solver.cpp:237] Iteration 10900, loss = 0.971403
I0416 20:56:55.739667 23299 solver.cpp:253]     Train net output #0: loss = 0.971403 (* 1 = 0.971403 loss)
I0416 20:56:55.739672 23299 sgd_solver.cpp:106] Iteration 10900, lr = 0.001
I0416 20:56:55.914324 23299 solver.cpp:237] Iteration 11000, loss = 0.962741
I0416 20:56:55.914350 23299 solver.cpp:253]     Train net output #0: loss = 0.962741 (* 1 = 0.962741 loss)
I0416 20:56:55.914355 23299 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0416 20:56:56.088559 23299 solver.cpp:237] Iteration 11100, loss = 0.954838
I0416 20:56:56.088585 23299 solver.cpp:253]     Train net output #0: loss = 0.954838 (* 1 = 0.954838 loss)
I0416 20:56:56.088590 23299 sgd_solver.cpp:106] Iteration 11100, lr = 0.001
I0416 20:56:56.262840 23299 solver.cpp:237] Iteration 11200, loss = 0.946357
I0416 20:56:56.262866 23299 solver.cpp:253]     Train net output #0: loss = 0.946357 (* 1 = 0.946357 loss)
I0416 20:56:56.262871 23299 sgd_solver.cpp:106] Iteration 11200, lr = 0.001
I0416 20:56:56.437204 23299 solver.cpp:237] Iteration 11300, loss = 0.937278
I0416 20:56:56.437232 23299 solver.cpp:253]     Train net output #0: loss = 0.937278 (* 1 = 0.937278 loss)
I0416 20:56:56.437237 23299 sgd_solver.cpp:106] Iteration 11300, lr = 0.001
I0416 20:56:56.612257 23299 solver.cpp:237] Iteration 11400, loss = 0.928359
I0416 20:56:56.612283 23299 solver.cpp:253]     Train net output #0: loss = 0.928359 (* 1 = 0.928359 loss)
I0416 20:56:56.612288 23299 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I0416 20:56:56.786932 23299 solver.cpp:237] Iteration 11500, loss = 0.918331
I0416 20:56:56.786959 23299 solver.cpp:253]     Train net output #0: loss = 0.918331 (* 1 = 0.918331 loss)
I0416 20:56:56.786988 23299 sgd_solver.cpp:106] Iteration 11500, lr = 0.001
I0416 20:56:56.961714 23299 solver.cpp:237] Iteration 11600, loss = 0.909146
I0416 20:56:56.961741 23299 solver.cpp:253]     Train net output #0: loss = 0.909146 (* 1 = 0.909146 loss)
I0416 20:56:56.961751 23299 sgd_solver.cpp:106] Iteration 11600, lr = 0.001
I0416 20:56:57.136296 23299 solver.cpp:237] Iteration 11700, loss = 0.899993
I0416 20:56:57.136323 23299 solver.cpp:253]     Train net output #0: loss = 0.899993 (* 1 = 0.899993 loss)
I0416 20:56:57.136328 23299 sgd_solver.cpp:106] Iteration 11700, lr = 0.001
I0416 20:56:57.311300 23299 solver.cpp:237] Iteration 11800, loss = 0.891668
I0416 20:56:57.311327 23299 solver.cpp:253]     Train net output #0: loss = 0.891668 (* 1 = 0.891668 loss)
I0416 20:56:57.311332 23299 sgd_solver.cpp:106] Iteration 11800, lr = 0.001
I0416 20:56:57.486196 23299 solver.cpp:237] Iteration 11900, loss = 0.882052
I0416 20:56:57.486222 23299 solver.cpp:253]     Train net output #0: loss = 0.882052 (* 1 = 0.882052 loss)
I0416 20:56:57.486228 23299 sgd_solver.cpp:106] Iteration 11900, lr = 0.001
I0416 20:56:57.660799 23299 solver.cpp:237] Iteration 12000, loss = 0.87286
I0416 20:56:57.660825 23299 solver.cpp:253]     Train net output #0: loss = 0.87286 (* 1 = 0.87286 loss)
I0416 20:56:57.660831 23299 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0416 20:56:57.835790 23299 solver.cpp:237] Iteration 12100, loss = 0.863253
I0416 20:56:57.835818 23299 solver.cpp:253]     Train net output #0: loss = 0.863253 (* 1 = 0.863253 loss)
I0416 20:56:57.835822 23299 sgd_solver.cpp:106] Iteration 12100, lr = 0.001
I0416 20:56:58.010361 23299 solver.cpp:237] Iteration 12200, loss = 0.85382
I0416 20:56:58.010387 23299 solver.cpp:253]     Train net output #0: loss = 0.85382 (* 1 = 0.85382 loss)
I0416 20:56:58.010391 23299 sgd_solver.cpp:106] Iteration 12200, lr = 0.001
I0416 20:56:58.184847 23299 solver.cpp:237] Iteration 12300, loss = 0.84591
I0416 20:56:58.184873 23299 solver.cpp:253]     Train net output #0: loss = 0.84591 (* 1 = 0.84591 loss)
I0416 20:56:58.184878 23299 sgd_solver.cpp:106] Iteration 12300, lr = 0.001
I0416 20:56:58.359916 23299 solver.cpp:237] Iteration 12400, loss = 0.838261
I0416 20:56:58.359951 23299 solver.cpp:253]     Train net output #0: loss = 0.838261 (* 1 = 0.838261 loss)
I0416 20:56:58.359957 23299 sgd_solver.cpp:106] Iteration 12400, lr = 0.001
I0416 20:56:58.534893 23299 solver.cpp:237] Iteration 12500, loss = 0.83021
I0416 20:56:58.534920 23299 solver.cpp:253]     Train net output #0: loss = 0.83021 (* 1 = 0.83021 loss)
I0416 20:56:58.534926 23299 sgd_solver.cpp:106] Iteration 12500, lr = 0.001
I0416 20:56:58.709800 23299 solver.cpp:237] Iteration 12600, loss = 0.822382
I0416 20:56:58.709827 23299 solver.cpp:253]     Train net output #0: loss = 0.822382 (* 1 = 0.822382 loss)
I0416 20:56:58.709835 23299 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I0416 20:56:58.884794 23299 solver.cpp:237] Iteration 12700, loss = 0.813795
I0416 20:56:58.884821 23299 solver.cpp:253]     Train net output #0: loss = 0.813795 (* 1 = 0.813795 loss)
I0416 20:56:58.884826 23299 sgd_solver.cpp:106] Iteration 12700, lr = 0.001
I0416 20:56:59.060293 23299 solver.cpp:237] Iteration 12800, loss = 0.806624
I0416 20:56:59.060324 23299 solver.cpp:253]     Train net output #0: loss = 0.806624 (* 1 = 0.806624 loss)
I0416 20:56:59.060330 23299 sgd_solver.cpp:106] Iteration 12800, lr = 0.001
I0416 20:56:59.236066 23299 solver.cpp:237] Iteration 12900, loss = 0.80041
I0416 20:56:59.236102 23299 solver.cpp:253]     Train net output #0: loss = 0.80041 (* 1 = 0.80041 loss)
I0416 20:56:59.236109 23299 sgd_solver.cpp:106] Iteration 12900, lr = 0.001
I0416 20:56:59.411063 23299 solver.cpp:237] Iteration 13000, loss = 0.794492
I0416 20:56:59.411093 23299 solver.cpp:253]     Train net output #0: loss = 0.794492 (* 1 = 0.794492 loss)
I0416 20:56:59.411098 23299 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0416 20:56:59.586500 23299 solver.cpp:237] Iteration 13100, loss = 0.78867
I0416 20:56:59.586527 23299 solver.cpp:253]     Train net output #0: loss = 0.78867 (* 1 = 0.78867 loss)
I0416 20:56:59.586557 23299 sgd_solver.cpp:106] Iteration 13100, lr = 0.001
I0416 20:56:59.761570 23299 solver.cpp:237] Iteration 13200, loss = 0.780413
I0416 20:56:59.761600 23299 solver.cpp:253]     Train net output #0: loss = 0.780413 (* 1 = 0.780413 loss)
I0416 20:56:59.761610 23299 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I0416 20:56:59.937114 23299 solver.cpp:237] Iteration 13300, loss = 0.773376
I0416 20:56:59.937140 23299 solver.cpp:253]     Train net output #0: loss = 0.773376 (* 1 = 0.773376 loss)
I0416 20:56:59.937147 23299 sgd_solver.cpp:106] Iteration 13300, lr = 0.001
I0416 20:57:00.112057 23299 solver.cpp:237] Iteration 13400, loss = 0.767279
I0416 20:57:00.112085 23299 solver.cpp:253]     Train net output #0: loss = 0.767279 (* 1 = 0.767279 loss)
I0416 20:57:00.112090 23299 sgd_solver.cpp:106] Iteration 13400, lr = 0.001
I0416 20:57:00.287128 23299 solver.cpp:237] Iteration 13500, loss = 0.760016
I0416 20:57:00.287155 23299 solver.cpp:253]     Train net output #0: loss = 0.760016 (* 1 = 0.760016 loss)
I0416 20:57:00.287160 23299 sgd_solver.cpp:106] Iteration 13500, lr = 0.001
I0416 20:57:00.461724 23299 solver.cpp:237] Iteration 13600, loss = 0.752633
I0416 20:57:00.461750 23299 solver.cpp:253]     Train net output #0: loss = 0.752633 (* 1 = 0.752633 loss)
I0416 20:57:00.461755 23299 sgd_solver.cpp:106] Iteration 13600, lr = 0.001
I0416 20:57:00.636955 23299 solver.cpp:237] Iteration 13700, loss = 0.745594
I0416 20:57:00.636982 23299 solver.cpp:253]     Train net output #0: loss = 0.745594 (* 1 = 0.745594 loss)
I0416 20:57:00.636987 23299 sgd_solver.cpp:106] Iteration 13700, lr = 0.001
I0416 20:57:00.813397 23299 solver.cpp:237] Iteration 13800, loss = 0.73958
I0416 20:57:00.813426 23299 solver.cpp:253]     Train net output #0: loss = 0.73958 (* 1 = 0.73958 loss)
I0416 20:57:00.813432 23299 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I0416 20:57:00.988821 23299 solver.cpp:237] Iteration 13900, loss = 0.7329
I0416 20:57:00.988848 23299 solver.cpp:253]     Train net output #0: loss = 0.7329 (* 1 = 0.7329 loss)
I0416 20:57:00.988854 23299 sgd_solver.cpp:106] Iteration 13900, lr = 0.001
I0416 20:57:01.163594 23299 solver.cpp:237] Iteration 14000, loss = 0.726587
I0416 20:57:01.163621 23299 solver.cpp:253]     Train net output #0: loss = 0.726587 (* 1 = 0.726587 loss)
I0416 20:57:01.163626 23299 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0416 20:57:01.338732 23299 solver.cpp:237] Iteration 14100, loss = 0.722206
I0416 20:57:01.338758 23299 solver.cpp:253]     Train net output #0: loss = 0.722206 (* 1 = 0.722206 loss)
I0416 20:57:01.338763 23299 sgd_solver.cpp:106] Iteration 14100, lr = 0.001
I0416 20:57:01.513728 23299 solver.cpp:237] Iteration 14200, loss = 0.714356
I0416 20:57:01.513756 23299 solver.cpp:253]     Train net output #0: loss = 0.714356 (* 1 = 0.714356 loss)
I0416 20:57:01.513761 23299 sgd_solver.cpp:106] Iteration 14200, lr = 0.001
I0416 20:57:01.688889 23299 solver.cpp:237] Iteration 14300, loss = 0.70864
I0416 20:57:01.688921 23299 solver.cpp:253]     Train net output #0: loss = 0.70864 (* 1 = 0.70864 loss)
I0416 20:57:01.688928 23299 sgd_solver.cpp:106] Iteration 14300, lr = 0.001
I0416 20:57:01.863828 23299 solver.cpp:237] Iteration 14400, loss = 0.702433
I0416 20:57:01.863854 23299 solver.cpp:253]     Train net output #0: loss = 0.702433 (* 1 = 0.702433 loss)
I0416 20:57:01.863859 23299 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I0416 20:57:02.038907 23299 solver.cpp:237] Iteration 14500, loss = 0.694852
I0416 20:57:02.038933 23299 solver.cpp:253]     Train net output #0: loss = 0.694852 (* 1 = 0.694852 loss)
I0416 20:57:02.038939 23299 sgd_solver.cpp:106] Iteration 14500, lr = 0.001
I0416 20:57:02.213724 23299 solver.cpp:237] Iteration 14600, loss = 0.688199
I0416 20:57:02.213752 23299 solver.cpp:253]     Train net output #0: loss = 0.688199 (* 1 = 0.688199 loss)
I0416 20:57:02.213757 23299 sgd_solver.cpp:106] Iteration 14600, lr = 0.001
I0416 20:57:02.388447 23299 solver.cpp:237] Iteration 14700, loss = 0.682568
I0416 20:57:02.388473 23299 solver.cpp:253]     Train net output #0: loss = 0.682568 (* 1 = 0.682568 loss)
I0416 20:57:02.388499 23299 sgd_solver.cpp:106] Iteration 14700, lr = 0.001
I0416 20:57:02.564272 23299 solver.cpp:237] Iteration 14800, loss = 0.675295
I0416 20:57:02.564301 23299 solver.cpp:253]     Train net output #0: loss = 0.675295 (* 1 = 0.675295 loss)
I0416 20:57:02.564307 23299 sgd_solver.cpp:106] Iteration 14800, lr = 0.001
I0416 20:57:02.740340 23299 solver.cpp:237] Iteration 14900, loss = 0.667545
I0416 20:57:02.740366 23299 solver.cpp:253]     Train net output #0: loss = 0.667545 (* 1 = 0.667545 loss)
I0416 20:57:02.740371 23299 sgd_solver.cpp:106] Iteration 14900, lr = 0.001
I0416 20:57:02.914052 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_15000.caffemodel
I0416 20:57:02.915904 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_15000.solverstate
I0416 20:57:02.916448 23299 solver.cpp:341] Iteration 15000, Testing net (#0)
I0416 20:57:02.916458 23299 net.cpp:748] Ignoring source layer dart
I0416 20:57:02.961009 23299 solver.cpp:409]     Test net output #0: accuracy = 0.6635
I0416 20:57:02.961030 23299 solver.cpp:409]     Test net output #1: loss = 0.879556 (* 1 = 0.879556 loss)
I0416 20:57:02.961815 23299 solver.cpp:237] Iteration 15000, loss = 0.662341
I0416 20:57:02.961832 23299 solver.cpp:253]     Train net output #0: loss = 0.662341 (* 1 = 0.662341 loss)
I0416 20:57:02.961836 23299 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0416 20:57:03.135936 23299 solver.cpp:237] Iteration 15100, loss = 0.657819
I0416 20:57:03.135968 23299 solver.cpp:253]     Train net output #0: loss = 0.657819 (* 1 = 0.657819 loss)
I0416 20:57:03.135973 23299 sgd_solver.cpp:106] Iteration 15100, lr = 0.001
I0416 20:57:03.309826 23299 solver.cpp:237] Iteration 15200, loss = 0.651601
I0416 20:57:03.309854 23299 solver.cpp:253]     Train net output #0: loss = 0.651601 (* 1 = 0.651601 loss)
I0416 20:57:03.309860 23299 sgd_solver.cpp:106] Iteration 15200, lr = 0.001
I0416 20:57:03.483784 23299 solver.cpp:237] Iteration 15300, loss = 0.646993
I0416 20:57:03.483811 23299 solver.cpp:253]     Train net output #0: loss = 0.646993 (* 1 = 0.646993 loss)
I0416 20:57:03.483816 23299 sgd_solver.cpp:106] Iteration 15300, lr = 0.001
I0416 20:57:03.658193 23299 solver.cpp:237] Iteration 15400, loss = 0.641461
I0416 20:57:03.658220 23299 solver.cpp:253]     Train net output #0: loss = 0.641461 (* 1 = 0.641461 loss)
I0416 20:57:03.658224 23299 sgd_solver.cpp:106] Iteration 15400, lr = 0.001
I0416 20:57:03.832562 23299 solver.cpp:237] Iteration 15500, loss = 0.6368
I0416 20:57:03.832589 23299 solver.cpp:253]     Train net output #0: loss = 0.6368 (* 1 = 0.6368 loss)
I0416 20:57:03.832594 23299 sgd_solver.cpp:106] Iteration 15500, lr = 0.001
I0416 20:57:04.006850 23299 solver.cpp:237] Iteration 15600, loss = 0.629004
I0416 20:57:04.006875 23299 solver.cpp:253]     Train net output #0: loss = 0.629004 (* 1 = 0.629004 loss)
I0416 20:57:04.006882 23299 sgd_solver.cpp:106] Iteration 15600, lr = 0.001
I0416 20:57:04.180841 23299 solver.cpp:237] Iteration 15700, loss = 0.620958
I0416 20:57:04.180868 23299 solver.cpp:253]     Train net output #0: loss = 0.620958 (* 1 = 0.620958 loss)
I0416 20:57:04.180872 23299 sgd_solver.cpp:106] Iteration 15700, lr = 0.001
I0416 20:57:04.359836 23299 solver.cpp:237] Iteration 15800, loss = 0.613976
I0416 20:57:04.359875 23299 solver.cpp:253]     Train net output #0: loss = 0.613976 (* 1 = 0.613976 loss)
I0416 20:57:04.359884 23299 sgd_solver.cpp:106] Iteration 15800, lr = 0.001
I0416 20:57:04.537663 23299 solver.cpp:237] Iteration 15900, loss = 0.608425
I0416 20:57:04.537695 23299 solver.cpp:253]     Train net output #0: loss = 0.608425 (* 1 = 0.608425 loss)
I0416 20:57:04.537701 23299 sgd_solver.cpp:106] Iteration 15900, lr = 0.001
I0416 20:57:04.712326 23299 solver.cpp:237] Iteration 16000, loss = 0.602021
I0416 20:57:04.712359 23299 solver.cpp:253]     Train net output #0: loss = 0.602021 (* 1 = 0.602021 loss)
I0416 20:57:04.712365 23299 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I0416 20:57:04.891420 23299 solver.cpp:237] Iteration 16100, loss = 0.59526
I0416 20:57:04.891458 23299 solver.cpp:253]     Train net output #0: loss = 0.59526 (* 1 = 0.59526 loss)
I0416 20:57:04.891465 23299 sgd_solver.cpp:106] Iteration 16100, lr = 0.001
I0416 20:57:05.076256 23299 solver.cpp:237] Iteration 16200, loss = 0.587864
I0416 20:57:05.076287 23299 solver.cpp:253]     Train net output #0: loss = 0.587864 (* 1 = 0.587864 loss)
I0416 20:57:05.076292 23299 sgd_solver.cpp:106] Iteration 16200, lr = 0.001
I0416 20:57:05.257613 23299 solver.cpp:237] Iteration 16300, loss = 0.580343
I0416 20:57:05.257643 23299 solver.cpp:253]     Train net output #0: loss = 0.580343 (* 1 = 0.580343 loss)
I0416 20:57:05.257648 23299 sgd_solver.cpp:106] Iteration 16300, lr = 0.001
I0416 20:57:05.431279 23299 solver.cpp:237] Iteration 16400, loss = 0.574349
I0416 20:57:05.431308 23299 solver.cpp:253]     Train net output #0: loss = 0.574349 (* 1 = 0.574349 loss)
I0416 20:57:05.431315 23299 sgd_solver.cpp:106] Iteration 16400, lr = 0.001
I0416 20:57:05.606057 23299 solver.cpp:237] Iteration 16500, loss = 0.568614
I0416 20:57:05.606088 23299 solver.cpp:253]     Train net output #0: loss = 0.568614 (* 1 = 0.568614 loss)
I0416 20:57:05.606096 23299 sgd_solver.cpp:106] Iteration 16500, lr = 0.001
I0416 20:57:05.781085 23299 solver.cpp:237] Iteration 16600, loss = 0.561935
I0416 20:57:05.781114 23299 solver.cpp:253]     Train net output #0: loss = 0.561935 (* 1 = 0.561935 loss)
I0416 20:57:05.781121 23299 sgd_solver.cpp:106] Iteration 16600, lr = 0.001
I0416 20:57:05.956006 23299 solver.cpp:237] Iteration 16700, loss = 0.555457
I0416 20:57:05.956153 23299 solver.cpp:253]     Train net output #0: loss = 0.555457 (* 1 = 0.555457 loss)
I0416 20:57:05.956163 23299 sgd_solver.cpp:106] Iteration 16700, lr = 0.001
I0416 20:57:06.130542 23299 solver.cpp:237] Iteration 16800, loss = 0.549753
I0416 20:57:06.130569 23299 solver.cpp:253]     Train net output #0: loss = 0.549753 (* 1 = 0.549753 loss)
I0416 20:57:06.130574 23299 sgd_solver.cpp:106] Iteration 16800, lr = 0.001
I0416 20:57:06.304883 23299 solver.cpp:237] Iteration 16900, loss = 0.543034
I0416 20:57:06.304916 23299 solver.cpp:253]     Train net output #0: loss = 0.543034 (* 1 = 0.543034 loss)
I0416 20:57:06.304926 23299 sgd_solver.cpp:106] Iteration 16900, lr = 0.001
I0416 20:57:06.479205 23299 solver.cpp:237] Iteration 17000, loss = 0.536787
I0416 20:57:06.479230 23299 solver.cpp:253]     Train net output #0: loss = 0.536787 (* 1 = 0.536787 loss)
I0416 20:57:06.479238 23299 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I0416 20:57:06.653254 23299 solver.cpp:237] Iteration 17100, loss = 0.530225
I0416 20:57:06.653281 23299 solver.cpp:253]     Train net output #0: loss = 0.530225 (* 1 = 0.530225 loss)
I0416 20:57:06.653286 23299 sgd_solver.cpp:106] Iteration 17100, lr = 0.001
I0416 20:57:06.827287 23299 solver.cpp:237] Iteration 17200, loss = 0.52415
I0416 20:57:06.827314 23299 solver.cpp:253]     Train net output #0: loss = 0.52415 (* 1 = 0.52415 loss)
I0416 20:57:06.827319 23299 sgd_solver.cpp:106] Iteration 17200, lr = 0.001
I0416 20:57:07.005697 23299 solver.cpp:237] Iteration 17300, loss = 0.51661
I0416 20:57:07.005740 23299 solver.cpp:253]     Train net output #0: loss = 0.51661 (* 1 = 0.51661 loss)
I0416 20:57:07.005753 23299 sgd_solver.cpp:106] Iteration 17300, lr = 0.001
I0416 20:57:07.184775 23299 solver.cpp:237] Iteration 17400, loss = 0.509396
I0416 20:57:07.184808 23299 solver.cpp:253]     Train net output #0: loss = 0.509396 (* 1 = 0.509396 loss)
I0416 20:57:07.184815 23299 sgd_solver.cpp:106] Iteration 17400, lr = 0.001
I0416 20:57:07.360052 23299 solver.cpp:237] Iteration 17500, loss = 0.502911
I0416 20:57:07.360082 23299 solver.cpp:253]     Train net output #0: loss = 0.502911 (* 1 = 0.502911 loss)
I0416 20:57:07.360087 23299 sgd_solver.cpp:106] Iteration 17500, lr = 0.001
I0416 20:57:07.534438 23299 solver.cpp:237] Iteration 17600, loss = 0.495918
I0416 20:57:07.534468 23299 solver.cpp:253]     Train net output #0: loss = 0.495918 (* 1 = 0.495918 loss)
I0416 20:57:07.534474 23299 sgd_solver.cpp:106] Iteration 17600, lr = 0.001
I0416 20:57:07.709692 23299 solver.cpp:237] Iteration 17700, loss = 0.490233
I0416 20:57:07.709723 23299 solver.cpp:253]     Train net output #0: loss = 0.490233 (* 1 = 0.490233 loss)
I0416 20:57:07.709729 23299 sgd_solver.cpp:106] Iteration 17700, lr = 0.001
I0416 20:57:07.884269 23299 solver.cpp:237] Iteration 17800, loss = 0.482878
I0416 20:57:07.884299 23299 solver.cpp:253]     Train net output #0: loss = 0.482878 (* 1 = 0.482878 loss)
I0416 20:57:07.884305 23299 sgd_solver.cpp:106] Iteration 17800, lr = 0.001
I0416 20:57:08.060956 23299 solver.cpp:237] Iteration 17900, loss = 0.476706
I0416 20:57:08.060986 23299 solver.cpp:253]     Train net output #0: loss = 0.476706 (* 1 = 0.476706 loss)
I0416 20:57:08.060992 23299 sgd_solver.cpp:106] Iteration 17900, lr = 0.001
I0416 20:57:08.236570 23299 solver.cpp:237] Iteration 18000, loss = 0.470538
I0416 20:57:08.236599 23299 solver.cpp:253]     Train net output #0: loss = 0.470538 (* 1 = 0.470538 loss)
I0416 20:57:08.236605 23299 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0416 20:57:08.412492 23299 solver.cpp:237] Iteration 18100, loss = 0.463816
I0416 20:57:08.412523 23299 solver.cpp:253]     Train net output #0: loss = 0.463816 (* 1 = 0.463816 loss)
I0416 20:57:08.412528 23299 sgd_solver.cpp:106] Iteration 18100, lr = 0.001
I0416 20:57:08.586894 23299 solver.cpp:237] Iteration 18200, loss = 0.457996
I0416 20:57:08.586918 23299 solver.cpp:253]     Train net output #0: loss = 0.457996 (* 1 = 0.457996 loss)
I0416 20:57:08.586923 23299 sgd_solver.cpp:106] Iteration 18200, lr = 0.001
I0416 20:57:08.761056 23299 solver.cpp:237] Iteration 18300, loss = 0.453294
I0416 20:57:08.761106 23299 solver.cpp:253]     Train net output #0: loss = 0.453294 (* 1 = 0.453294 loss)
I0416 20:57:08.761117 23299 sgd_solver.cpp:106] Iteration 18300, lr = 0.001
I0416 20:57:08.935185 23299 solver.cpp:237] Iteration 18400, loss = 0.449309
I0416 20:57:08.935211 23299 solver.cpp:253]     Train net output #0: loss = 0.449309 (* 1 = 0.449309 loss)
I0416 20:57:08.935217 23299 sgd_solver.cpp:106] Iteration 18400, lr = 0.001
I0416 20:57:09.109566 23299 solver.cpp:237] Iteration 18500, loss = 0.444392
I0416 20:57:09.109592 23299 solver.cpp:253]     Train net output #0: loss = 0.444392 (* 1 = 0.444392 loss)
I0416 20:57:09.109597 23299 sgd_solver.cpp:106] Iteration 18500, lr = 0.001
I0416 20:57:09.284386 23299 solver.cpp:237] Iteration 18600, loss = 0.438131
I0416 20:57:09.284412 23299 solver.cpp:253]     Train net output #0: loss = 0.438131 (* 1 = 0.438131 loss)
I0416 20:57:09.284417 23299 sgd_solver.cpp:106] Iteration 18600, lr = 0.001
I0416 20:57:09.458883 23299 solver.cpp:237] Iteration 18700, loss = 0.432989
I0416 20:57:09.458909 23299 solver.cpp:253]     Train net output #0: loss = 0.432989 (* 1 = 0.432989 loss)
I0416 20:57:09.458915 23299 sgd_solver.cpp:106] Iteration 18700, lr = 0.001
I0416 20:57:09.633139 23299 solver.cpp:237] Iteration 18800, loss = 0.426502
I0416 20:57:09.633165 23299 solver.cpp:253]     Train net output #0: loss = 0.426502 (* 1 = 0.426502 loss)
I0416 20:57:09.633170 23299 sgd_solver.cpp:106] Iteration 18800, lr = 0.001
I0416 20:57:09.807437 23299 solver.cpp:237] Iteration 18900, loss = 0.422413
I0416 20:57:09.807463 23299 solver.cpp:253]     Train net output #0: loss = 0.422413 (* 1 = 0.422413 loss)
I0416 20:57:09.807471 23299 sgd_solver.cpp:106] Iteration 18900, lr = 0.001
I0416 20:57:09.982995 23299 solver.cpp:237] Iteration 19000, loss = 0.41771
I0416 20:57:09.983026 23299 solver.cpp:253]     Train net output #0: loss = 0.41771 (* 1 = 0.41771 loss)
I0416 20:57:09.983031 23299 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I0416 20:57:10.157143 23299 solver.cpp:237] Iteration 19100, loss = 0.413045
I0416 20:57:10.157172 23299 solver.cpp:253]     Train net output #0: loss = 0.413045 (* 1 = 0.413045 loss)
I0416 20:57:10.157178 23299 sgd_solver.cpp:106] Iteration 19100, lr = 0.001
I0416 20:57:10.331321 23299 solver.cpp:237] Iteration 19200, loss = 0.407318
I0416 20:57:10.331347 23299 solver.cpp:253]     Train net output #0: loss = 0.407318 (* 1 = 0.407318 loss)
I0416 20:57:10.331353 23299 sgd_solver.cpp:106] Iteration 19200, lr = 0.001
I0416 20:57:10.505336 23299 solver.cpp:237] Iteration 19300, loss = 0.402351
I0416 20:57:10.505364 23299 solver.cpp:253]     Train net output #0: loss = 0.402351 (* 1 = 0.402351 loss)
I0416 20:57:10.505378 23299 sgd_solver.cpp:106] Iteration 19300, lr = 0.001
I0416 20:57:10.678900 23299 solver.cpp:237] Iteration 19400, loss = 0.396643
I0416 20:57:10.678927 23299 solver.cpp:253]     Train net output #0: loss = 0.396643 (* 1 = 0.396643 loss)
I0416 20:57:10.678932 23299 sgd_solver.cpp:106] Iteration 19400, lr = 0.001
I0416 20:57:10.852459 23299 solver.cpp:237] Iteration 19500, loss = 0.391416
I0416 20:57:10.852486 23299 solver.cpp:253]     Train net output #0: loss = 0.391416 (* 1 = 0.391416 loss)
I0416 20:57:10.852493 23299 sgd_solver.cpp:106] Iteration 19500, lr = 0.001
I0416 20:57:11.026423 23299 solver.cpp:237] Iteration 19600, loss = 0.386544
I0416 20:57:11.026449 23299 solver.cpp:253]     Train net output #0: loss = 0.386544 (* 1 = 0.386544 loss)
I0416 20:57:11.026456 23299 sgd_solver.cpp:106] Iteration 19600, lr = 0.001
I0416 20:57:11.200651 23299 solver.cpp:237] Iteration 19700, loss = 0.381223
I0416 20:57:11.200677 23299 solver.cpp:253]     Train net output #0: loss = 0.381223 (* 1 = 0.381223 loss)
I0416 20:57:11.200682 23299 sgd_solver.cpp:106] Iteration 19700, lr = 0.001
I0416 20:57:11.375067 23299 solver.cpp:237] Iteration 19800, loss = 0.375826
I0416 20:57:11.375093 23299 solver.cpp:253]     Train net output #0: loss = 0.375826 (* 1 = 0.375826 loss)
I0416 20:57:11.375098 23299 sgd_solver.cpp:106] Iteration 19800, lr = 0.001
I0416 20:57:11.549686 23299 solver.cpp:237] Iteration 19900, loss = 0.369795
I0416 20:57:11.549715 23299 solver.cpp:253]     Train net output #0: loss = 0.369795 (* 1 = 0.369795 loss)
I0416 20:57:11.549721 23299 sgd_solver.cpp:106] Iteration 19900, lr = 0.001
I0416 20:57:11.722539 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_20000.caffemodel
I0416 20:57:11.724427 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_20000.solverstate
I0416 20:57:11.724988 23299 solver.cpp:341] Iteration 20000, Testing net (#0)
I0416 20:57:11.724999 23299 net.cpp:748] Ignoring source layer dart
I0416 20:57:11.766988 23299 solver.cpp:409]     Test net output #0: accuracy = 0.7525
I0416 20:57:11.767009 23299 solver.cpp:409]     Test net output #1: loss = 0.677711 (* 1 = 0.677711 loss)
I0416 20:57:11.767772 23299 solver.cpp:237] Iteration 20000, loss = 0.366423
I0416 20:57:11.767794 23299 solver.cpp:253]     Train net output #0: loss = 0.366423 (* 1 = 0.366423 loss)
I0416 20:57:11.767802 23299 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0416 20:57:11.941794 23299 solver.cpp:237] Iteration 20100, loss = 0.361478
I0416 20:57:11.941820 23299 solver.cpp:253]     Train net output #0: loss = 0.361478 (* 1 = 0.361478 loss)
I0416 20:57:11.941828 23299 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0416 20:57:12.115972 23299 solver.cpp:237] Iteration 20200, loss = 0.356863
I0416 20:57:12.115998 23299 solver.cpp:253]     Train net output #0: loss = 0.356863 (* 1 = 0.356863 loss)
I0416 20:57:12.116003 23299 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0416 20:57:12.289901 23299 solver.cpp:237] Iteration 20300, loss = 0.351889
I0416 20:57:12.289926 23299 solver.cpp:253]     Train net output #0: loss = 0.351889 (* 1 = 0.351889 loss)
I0416 20:57:12.289932 23299 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I0416 20:57:12.464040 23299 solver.cpp:237] Iteration 20400, loss = 0.347464
I0416 20:57:12.464067 23299 solver.cpp:253]     Train net output #0: loss = 0.347464 (* 1 = 0.347464 loss)
I0416 20:57:12.464073 23299 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0416 20:57:12.638003 23299 solver.cpp:237] Iteration 20500, loss = 0.342085
I0416 20:57:12.638030 23299 solver.cpp:253]     Train net output #0: loss = 0.342085 (* 1 = 0.342085 loss)
I0416 20:57:12.638034 23299 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0416 20:57:12.812216 23299 solver.cpp:237] Iteration 20600, loss = 0.339636
I0416 20:57:12.812243 23299 solver.cpp:253]     Train net output #0: loss = 0.339636 (* 1 = 0.339636 loss)
I0416 20:57:12.812249 23299 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0416 20:57:12.986491 23299 solver.cpp:237] Iteration 20700, loss = 0.335548
I0416 20:57:12.986516 23299 solver.cpp:253]     Train net output #0: loss = 0.335548 (* 1 = 0.335548 loss)
I0416 20:57:12.986522 23299 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0416 20:57:13.161425 23299 solver.cpp:237] Iteration 20800, loss = 0.332895
I0416 20:57:13.161454 23299 solver.cpp:253]     Train net output #0: loss = 0.332895 (* 1 = 0.332895 loss)
I0416 20:57:13.161459 23299 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0416 20:57:13.336035 23299 solver.cpp:237] Iteration 20900, loss = 0.329966
I0416 20:57:13.336061 23299 solver.cpp:253]     Train net output #0: loss = 0.329966 (* 1 = 0.329966 loss)
I0416 20:57:13.336066 23299 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I0416 20:57:13.510313 23299 solver.cpp:237] Iteration 21000, loss = 0.326076
I0416 20:57:13.510339 23299 solver.cpp:253]     Train net output #0: loss = 0.326076 (* 1 = 0.326076 loss)
I0416 20:57:13.510344 23299 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0416 20:57:13.684691 23299 solver.cpp:237] Iteration 21100, loss = 0.324843
I0416 20:57:13.684716 23299 solver.cpp:253]     Train net output #0: loss = 0.324843 (* 1 = 0.324843 loss)
I0416 20:57:13.684722 23299 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I0416 20:57:13.859275 23299 solver.cpp:237] Iteration 21200, loss = 0.322268
I0416 20:57:13.859324 23299 solver.cpp:253]     Train net output #0: loss = 0.322268 (* 1 = 0.322268 loss)
I0416 20:57:13.859330 23299 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0416 20:57:14.033650 23299 solver.cpp:237] Iteration 21300, loss = 0.317529
I0416 20:57:14.033677 23299 solver.cpp:253]     Train net output #0: loss = 0.317529 (* 1 = 0.317529 loss)
I0416 20:57:14.033684 23299 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0416 20:57:14.207850 23299 solver.cpp:237] Iteration 21400, loss = 0.314462
I0416 20:57:14.207877 23299 solver.cpp:253]     Train net output #0: loss = 0.314462 (* 1 = 0.314462 loss)
I0416 20:57:14.207882 23299 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0416 20:57:14.381868 23299 solver.cpp:237] Iteration 21500, loss = 0.310986
I0416 20:57:14.381899 23299 solver.cpp:253]     Train net output #0: loss = 0.310986 (* 1 = 0.310986 loss)
I0416 20:57:14.381906 23299 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0416 20:57:14.555872 23299 solver.cpp:237] Iteration 21600, loss = 0.308417
I0416 20:57:14.555901 23299 solver.cpp:253]     Train net output #0: loss = 0.308417 (* 1 = 0.308417 loss)
I0416 20:57:14.555908 23299 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0416 20:57:14.730118 23299 solver.cpp:237] Iteration 21700, loss = 0.303245
I0416 20:57:14.730145 23299 solver.cpp:253]     Train net output #0: loss = 0.303245 (* 1 = 0.303245 loss)
I0416 20:57:14.730150 23299 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I0416 20:57:14.904705 23299 solver.cpp:237] Iteration 21800, loss = 0.300329
I0416 20:57:14.904731 23299 solver.cpp:253]     Train net output #0: loss = 0.300329 (* 1 = 0.300329 loss)
I0416 20:57:14.904736 23299 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0416 20:57:15.079551 23299 solver.cpp:237] Iteration 21900, loss = 0.295084
I0416 20:57:15.079579 23299 solver.cpp:253]     Train net output #0: loss = 0.295084 (* 1 = 0.295084 loss)
I0416 20:57:15.079584 23299 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0416 20:57:15.255393 23299 solver.cpp:237] Iteration 22000, loss = 0.291724
I0416 20:57:15.255419 23299 solver.cpp:253]     Train net output #0: loss = 0.291724 (* 1 = 0.291724 loss)
I0416 20:57:15.255424 23299 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0416 20:57:15.431313 23299 solver.cpp:237] Iteration 22100, loss = 0.288976
I0416 20:57:15.431339 23299 solver.cpp:253]     Train net output #0: loss = 0.288976 (* 1 = 0.288976 loss)
I0416 20:57:15.431345 23299 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I0416 20:57:15.607156 23299 solver.cpp:237] Iteration 22200, loss = 0.284085
I0416 20:57:15.607182 23299 solver.cpp:253]     Train net output #0: loss = 0.284085 (* 1 = 0.284085 loss)
I0416 20:57:15.607195 23299 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0416 20:57:15.783565 23299 solver.cpp:237] Iteration 22300, loss = 0.279128
I0416 20:57:15.783591 23299 solver.cpp:253]     Train net output #0: loss = 0.279128 (* 1 = 0.279128 loss)
I0416 20:57:15.783596 23299 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I0416 20:57:15.959803 23299 solver.cpp:237] Iteration 22400, loss = 0.275089
I0416 20:57:15.959830 23299 solver.cpp:253]     Train net output #0: loss = 0.275089 (* 1 = 0.275089 loss)
I0416 20:57:15.959835 23299 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0416 20:57:16.135437 23299 solver.cpp:237] Iteration 22500, loss = 0.271777
I0416 20:57:16.135464 23299 solver.cpp:253]     Train net output #0: loss = 0.271777 (* 1 = 0.271777 loss)
I0416 20:57:16.135469 23299 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0416 20:57:16.311389 23299 solver.cpp:237] Iteration 22600, loss = 0.267257
I0416 20:57:16.311416 23299 solver.cpp:253]     Train net output #0: loss = 0.267257 (* 1 = 0.267257 loss)
I0416 20:57:16.311421 23299 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0416 20:57:16.487401 23299 solver.cpp:237] Iteration 22700, loss = 0.261945
I0416 20:57:16.487428 23299 solver.cpp:253]     Train net output #0: loss = 0.261945 (* 1 = 0.261945 loss)
I0416 20:57:16.487434 23299 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I0416 20:57:16.663803 23299 solver.cpp:237] Iteration 22800, loss = 0.258777
I0416 20:57:16.663854 23299 solver.cpp:253]     Train net output #0: loss = 0.258777 (* 1 = 0.258777 loss)
I0416 20:57:16.663861 23299 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0416 20:57:16.840029 23299 solver.cpp:237] Iteration 22900, loss = 0.255037
I0416 20:57:16.840055 23299 solver.cpp:253]     Train net output #0: loss = 0.255037 (* 1 = 0.255037 loss)
I0416 20:57:16.840070 23299 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I0416 20:57:17.015557 23299 solver.cpp:237] Iteration 23000, loss = 0.251962
I0416 20:57:17.015591 23299 solver.cpp:253]     Train net output #0: loss = 0.251962 (* 1 = 0.251962 loss)
I0416 20:57:17.015596 23299 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0416 20:57:17.191483 23299 solver.cpp:237] Iteration 23100, loss = 0.249584
I0416 20:57:17.191514 23299 solver.cpp:253]     Train net output #0: loss = 0.249584 (* 1 = 0.249584 loss)
I0416 20:57:17.191521 23299 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0416 20:57:17.367658 23299 solver.cpp:237] Iteration 23200, loss = 0.245746
I0416 20:57:17.367686 23299 solver.cpp:253]     Train net output #0: loss = 0.245746 (* 1 = 0.245746 loss)
I0416 20:57:17.367691 23299 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0416 20:57:17.543185 23299 solver.cpp:237] Iteration 23300, loss = 0.242849
I0416 20:57:17.543215 23299 solver.cpp:253]     Train net output #0: loss = 0.242849 (* 1 = 0.242849 loss)
I0416 20:57:17.543220 23299 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I0416 20:57:17.719527 23299 solver.cpp:237] Iteration 23400, loss = 0.239425
I0416 20:57:17.719553 23299 solver.cpp:253]     Train net output #0: loss = 0.239425 (* 1 = 0.239425 loss)
I0416 20:57:17.719558 23299 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0416 20:57:17.895674 23299 solver.cpp:237] Iteration 23500, loss = 0.236784
I0416 20:57:17.895701 23299 solver.cpp:253]     Train net output #0: loss = 0.236784 (* 1 = 0.236784 loss)
I0416 20:57:17.895707 23299 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0416 20:57:18.072290 23299 solver.cpp:237] Iteration 23600, loss = 0.234406
I0416 20:57:18.072316 23299 solver.cpp:253]     Train net output #0: loss = 0.234406 (* 1 = 0.234406 loss)
I0416 20:57:18.072321 23299 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0416 20:57:18.248039 23299 solver.cpp:237] Iteration 23700, loss = 0.231105
I0416 20:57:18.248064 23299 solver.cpp:253]     Train net output #0: loss = 0.231105 (* 1 = 0.231105 loss)
I0416 20:57:18.248070 23299 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0416 20:57:18.425798 23299 solver.cpp:237] Iteration 23800, loss = 0.228893
I0416 20:57:18.425827 23299 solver.cpp:253]     Train net output #0: loss = 0.228893 (* 1 = 0.228893 loss)
I0416 20:57:18.425832 23299 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0416 20:57:18.602053 23299 solver.cpp:237] Iteration 23900, loss = 0.22674
I0416 20:57:18.602082 23299 solver.cpp:253]     Train net output #0: loss = 0.22674 (* 1 = 0.22674 loss)
I0416 20:57:18.602087 23299 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I0416 20:57:18.778694 23299 solver.cpp:237] Iteration 24000, loss = 0.224109
I0416 20:57:18.778723 23299 solver.cpp:253]     Train net output #0: loss = 0.224109 (* 1 = 0.224109 loss)
I0416 20:57:18.778729 23299 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0416 20:57:18.955472 23299 solver.cpp:237] Iteration 24100, loss = 0.22172
I0416 20:57:18.955499 23299 solver.cpp:253]     Train net output #0: loss = 0.22172 (* 1 = 0.22172 loss)
I0416 20:57:18.955504 23299 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I0416 20:57:19.131183 23299 solver.cpp:237] Iteration 24200, loss = 0.219713
I0416 20:57:19.131211 23299 solver.cpp:253]     Train net output #0: loss = 0.219713 (* 1 = 0.219713 loss)
I0416 20:57:19.131217 23299 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0416 20:57:19.306697 23299 solver.cpp:237] Iteration 24300, loss = 0.21847
I0416 20:57:19.306725 23299 solver.cpp:253]     Train net output #0: loss = 0.21847 (* 1 = 0.21847 loss)
I0416 20:57:19.306730 23299 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0416 20:57:19.482739 23299 solver.cpp:237] Iteration 24400, loss = 0.216389
I0416 20:57:19.482765 23299 solver.cpp:253]     Train net output #0: loss = 0.216389 (* 1 = 0.216389 loss)
I0416 20:57:19.482770 23299 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0416 20:57:19.658804 23299 solver.cpp:237] Iteration 24500, loss = 0.214877
I0416 20:57:19.658831 23299 solver.cpp:253]     Train net output #0: loss = 0.214877 (* 1 = 0.214877 loss)
I0416 20:57:19.658836 23299 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0416 20:57:19.834522 23299 solver.cpp:237] Iteration 24600, loss = 0.213189
I0416 20:57:19.834547 23299 solver.cpp:253]     Train net output #0: loss = 0.213189 (* 1 = 0.213189 loss)
I0416 20:57:19.834553 23299 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0416 20:57:20.010395 23299 solver.cpp:237] Iteration 24700, loss = 0.211773
I0416 20:57:20.010421 23299 solver.cpp:253]     Train net output #0: loss = 0.211773 (* 1 = 0.211773 loss)
I0416 20:57:20.010427 23299 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I0416 20:57:20.185991 23299 solver.cpp:237] Iteration 24800, loss = 0.211487
I0416 20:57:20.186015 23299 solver.cpp:253]     Train net output #0: loss = 0.211487 (* 1 = 0.211487 loss)
I0416 20:57:20.186020 23299 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0416 20:57:20.361840 23299 solver.cpp:237] Iteration 24900, loss = 0.210164
I0416 20:57:20.361865 23299 solver.cpp:253]     Train net output #0: loss = 0.210164 (* 1 = 0.210164 loss)
I0416 20:57:20.361871 23299 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0416 20:57:20.536470 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_25000.caffemodel
I0416 20:57:20.538303 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_25000.solverstate
I0416 20:57:20.538844 23299 solver.cpp:341] Iteration 25000, Testing net (#0)
I0416 20:57:20.538856 23299 net.cpp:748] Ignoring source layer dart
I0416 20:57:20.581244 23299 solver.cpp:409]     Test net output #0: accuracy = 0.771
I0416 20:57:20.581265 23299 solver.cpp:409]     Test net output #1: loss = 0.628334 (* 1 = 0.628334 loss)
I0416 20:57:20.582049 23299 solver.cpp:237] Iteration 25000, loss = 0.208885
I0416 20:57:20.582067 23299 solver.cpp:253]     Train net output #0: loss = 0.208885 (* 1 = 0.208885 loss)
I0416 20:57:20.582072 23299 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0416 20:57:20.758208 23299 solver.cpp:237] Iteration 25100, loss = 0.206929
I0416 20:57:20.758234 23299 solver.cpp:253]     Train net output #0: loss = 0.206929 (* 1 = 0.206929 loss)
I0416 20:57:20.758239 23299 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I0416 20:57:20.934190 23299 solver.cpp:237] Iteration 25200, loss = 0.205109
I0416 20:57:20.934217 23299 solver.cpp:253]     Train net output #0: loss = 0.205109 (* 1 = 0.205109 loss)
I0416 20:57:20.934223 23299 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0416 20:57:21.110715 23299 solver.cpp:237] Iteration 25300, loss = 0.20298
I0416 20:57:21.110743 23299 solver.cpp:253]     Train net output #0: loss = 0.20298 (* 1 = 0.20298 loss)
I0416 20:57:21.110748 23299 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I0416 20:57:21.287000 23299 solver.cpp:237] Iteration 25400, loss = 0.20181
I0416 20:57:21.287026 23299 solver.cpp:253]     Train net output #0: loss = 0.20181 (* 1 = 0.20181 loss)
I0416 20:57:21.287032 23299 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0416 20:57:21.465386 23299 solver.cpp:237] Iteration 25500, loss = 0.20142
I0416 20:57:21.465430 23299 solver.cpp:253]     Train net output #0: loss = 0.20142 (* 1 = 0.20142 loss)
I0416 20:57:21.465446 23299 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0416 20:57:21.643465 23299 solver.cpp:237] Iteration 25600, loss = 0.199876
I0416 20:57:21.643498 23299 solver.cpp:253]     Train net output #0: loss = 0.199876 (* 1 = 0.199876 loss)
I0416 20:57:21.643504 23299 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0416 20:57:21.819672 23299 solver.cpp:237] Iteration 25700, loss = 0.197972
I0416 20:57:21.819702 23299 solver.cpp:253]     Train net output #0: loss = 0.197972 (* 1 = 0.197972 loss)
I0416 20:57:21.819737 23299 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I0416 20:57:21.995491 23299 solver.cpp:237] Iteration 25800, loss = 0.196567
I0416 20:57:21.995517 23299 solver.cpp:253]     Train net output #0: loss = 0.196567 (* 1 = 0.196567 loss)
I0416 20:57:21.995522 23299 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0416 20:57:22.171773 23299 solver.cpp:237] Iteration 25900, loss = 0.194598
I0416 20:57:22.171802 23299 solver.cpp:253]     Train net output #0: loss = 0.194598 (* 1 = 0.194598 loss)
I0416 20:57:22.171808 23299 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I0416 20:57:22.348701 23299 solver.cpp:237] Iteration 26000, loss = 0.192697
I0416 20:57:22.348733 23299 solver.cpp:253]     Train net output #0: loss = 0.192697 (* 1 = 0.192697 loss)
I0416 20:57:22.348738 23299 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0416 20:57:22.525653 23299 solver.cpp:237] Iteration 26100, loss = 0.191606
I0416 20:57:22.525681 23299 solver.cpp:253]     Train net output #0: loss = 0.191606 (* 1 = 0.191606 loss)
I0416 20:57:22.525687 23299 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0416 20:57:22.701539 23299 solver.cpp:237] Iteration 26200, loss = 0.189564
I0416 20:57:22.701565 23299 solver.cpp:253]     Train net output #0: loss = 0.189564 (* 1 = 0.189564 loss)
I0416 20:57:22.701570 23299 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0416 20:57:22.877272 23299 solver.cpp:237] Iteration 26300, loss = 0.188003
I0416 20:57:22.877298 23299 solver.cpp:253]     Train net output #0: loss = 0.188003 (* 1 = 0.188003 loss)
I0416 20:57:22.877303 23299 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I0416 20:57:23.053349 23299 solver.cpp:237] Iteration 26400, loss = 0.186259
I0416 20:57:23.053377 23299 solver.cpp:253]     Train net output #0: loss = 0.186259 (* 1 = 0.186259 loss)
I0416 20:57:23.053382 23299 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0416 20:57:23.229282 23299 solver.cpp:237] Iteration 26500, loss = 0.184927
I0416 20:57:23.229308 23299 solver.cpp:253]     Train net output #0: loss = 0.184927 (* 1 = 0.184927 loss)
I0416 20:57:23.229313 23299 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0416 20:57:23.404959 23299 solver.cpp:237] Iteration 26600, loss = 0.182544
I0416 20:57:23.404989 23299 solver.cpp:253]     Train net output #0: loss = 0.182544 (* 1 = 0.182544 loss)
I0416 20:57:23.404994 23299 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0416 20:57:23.581136 23299 solver.cpp:237] Iteration 26700, loss = 0.181417
I0416 20:57:23.581167 23299 solver.cpp:253]     Train net output #0: loss = 0.181417 (* 1 = 0.181417 loss)
I0416 20:57:23.581172 23299 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0416 20:57:23.757213 23299 solver.cpp:237] Iteration 26800, loss = 0.178743
I0416 20:57:23.757238 23299 solver.cpp:253]     Train net output #0: loss = 0.178743 (* 1 = 0.178743 loss)
I0416 20:57:23.757243 23299 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0416 20:57:23.933200 23299 solver.cpp:237] Iteration 26900, loss = 0.176109
I0416 20:57:23.933228 23299 solver.cpp:253]     Train net output #0: loss = 0.176109 (* 1 = 0.176109 loss)
I0416 20:57:23.933233 23299 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I0416 20:57:24.109205 23299 solver.cpp:237] Iteration 27000, loss = 0.174485
I0416 20:57:24.109231 23299 solver.cpp:253]     Train net output #0: loss = 0.174485 (* 1 = 0.174485 loss)
I0416 20:57:24.109236 23299 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0416 20:57:24.285270 23299 solver.cpp:237] Iteration 27100, loss = 0.171949
I0416 20:57:24.285297 23299 solver.cpp:253]     Train net output #0: loss = 0.171949 (* 1 = 0.171949 loss)
I0416 20:57:24.285302 23299 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I0416 20:57:24.461514 23299 solver.cpp:237] Iteration 27200, loss = 0.169504
I0416 20:57:24.461540 23299 solver.cpp:253]     Train net output #0: loss = 0.169504 (* 1 = 0.169504 loss)
I0416 20:57:24.461546 23299 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0416 20:57:24.637781 23299 solver.cpp:237] Iteration 27300, loss = 0.167308
I0416 20:57:24.638074 23299 solver.cpp:253]     Train net output #0: loss = 0.167308 (* 1 = 0.167308 loss)
I0416 20:57:24.638085 23299 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0416 20:57:24.814151 23299 solver.cpp:237] Iteration 27400, loss = 0.162457
I0416 20:57:24.814177 23299 solver.cpp:253]     Train net output #0: loss = 0.162457 (* 1 = 0.162457 loss)
I0416 20:57:24.814182 23299 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0416 20:57:24.990021 23299 solver.cpp:237] Iteration 27500, loss = 0.161305
I0416 20:57:24.990048 23299 solver.cpp:253]     Train net output #0: loss = 0.161305 (* 1 = 0.161305 loss)
I0416 20:57:24.990059 23299 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0416 20:57:25.165948 23299 solver.cpp:237] Iteration 27600, loss = 0.159197
I0416 20:57:25.165976 23299 solver.cpp:253]     Train net output #0: loss = 0.159197 (* 1 = 0.159197 loss)
I0416 20:57:25.165980 23299 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0416 20:57:25.341557 23299 solver.cpp:237] Iteration 27700, loss = 0.155957
I0416 20:57:25.341583 23299 solver.cpp:253]     Train net output #0: loss = 0.155957 (* 1 = 0.155957 loss)
I0416 20:57:25.341588 23299 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I0416 20:57:25.517496 23299 solver.cpp:237] Iteration 27800, loss = 0.153573
I0416 20:57:25.517524 23299 solver.cpp:253]     Train net output #0: loss = 0.153573 (* 1 = 0.153573 loss)
I0416 20:57:25.517529 23299 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0416 20:57:25.693794 23299 solver.cpp:237] Iteration 27900, loss = 0.150919
I0416 20:57:25.693821 23299 solver.cpp:253]     Train net output #0: loss = 0.150919 (* 1 = 0.150919 loss)
I0416 20:57:25.693826 23299 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0416 20:57:25.870182 23299 solver.cpp:237] Iteration 28000, loss = 0.149924
I0416 20:57:25.870209 23299 solver.cpp:253]     Train net output #0: loss = 0.149924 (* 1 = 0.149924 loss)
I0416 20:57:25.870214 23299 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0416 20:57:26.046087 23299 solver.cpp:237] Iteration 28100, loss = 0.146518
I0416 20:57:26.046113 23299 solver.cpp:253]     Train net output #0: loss = 0.146518 (* 1 = 0.146518 loss)
I0416 20:57:26.046118 23299 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I0416 20:57:26.225850 23299 solver.cpp:237] Iteration 28200, loss = 0.145268
I0416 20:57:26.225890 23299 solver.cpp:253]     Train net output #0: loss = 0.145268 (* 1 = 0.145268 loss)
I0416 20:57:26.225903 23299 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0416 20:57:26.402951 23299 solver.cpp:237] Iteration 28300, loss = 0.142477
I0416 20:57:26.402982 23299 solver.cpp:253]     Train net output #0: loss = 0.142477 (* 1 = 0.142477 loss)
I0416 20:57:26.402994 23299 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I0416 20:57:26.580341 23299 solver.cpp:237] Iteration 28400, loss = 0.140692
I0416 20:57:26.580374 23299 solver.cpp:253]     Train net output #0: loss = 0.140692 (* 1 = 0.140692 loss)
I0416 20:57:26.580382 23299 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0416 20:57:26.757696 23299 solver.cpp:237] Iteration 28500, loss = 0.138225
I0416 20:57:26.757728 23299 solver.cpp:253]     Train net output #0: loss = 0.138225 (* 1 = 0.138225 loss)
I0416 20:57:26.757740 23299 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0416 20:57:26.935433 23299 solver.cpp:237] Iteration 28600, loss = 0.13544
I0416 20:57:26.935467 23299 solver.cpp:253]     Train net output #0: loss = 0.13544 (* 1 = 0.13544 loss)
I0416 20:57:26.935474 23299 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0416 20:57:27.112470 23299 solver.cpp:237] Iteration 28700, loss = 0.135139
I0416 20:57:27.112500 23299 solver.cpp:253]     Train net output #0: loss = 0.135139 (* 1 = 0.135139 loss)
I0416 20:57:27.112509 23299 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I0416 20:57:27.289331 23299 solver.cpp:237] Iteration 28800, loss = 0.130737
I0416 20:57:27.289358 23299 solver.cpp:253]     Train net output #0: loss = 0.130737 (* 1 = 0.130737 loss)
I0416 20:57:27.289366 23299 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0416 20:57:27.465495 23299 solver.cpp:237] Iteration 28900, loss = 0.131211
I0416 20:57:27.465524 23299 solver.cpp:253]     Train net output #0: loss = 0.131211 (* 1 = 0.131211 loss)
I0416 20:57:27.465534 23299 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I0416 20:57:27.641625 23299 solver.cpp:237] Iteration 29000, loss = 0.128086
I0416 20:57:27.641652 23299 solver.cpp:253]     Train net output #0: loss = 0.128086 (* 1 = 0.128086 loss)
I0416 20:57:27.641664 23299 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0416 20:57:27.817704 23299 solver.cpp:237] Iteration 29100, loss = 0.126583
I0416 20:57:27.817734 23299 solver.cpp:253]     Train net output #0: loss = 0.126583 (* 1 = 0.126583 loss)
I0416 20:57:27.817744 23299 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0416 20:57:27.994043 23299 solver.cpp:237] Iteration 29200, loss = 0.125662
I0416 20:57:27.994071 23299 solver.cpp:253]     Train net output #0: loss = 0.125662 (* 1 = 0.125662 loss)
I0416 20:57:27.994079 23299 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0416 20:57:28.170403 23299 solver.cpp:237] Iteration 29300, loss = 0.122204
I0416 20:57:28.170431 23299 solver.cpp:253]     Train net output #0: loss = 0.122204 (* 1 = 0.122204 loss)
I0416 20:57:28.170439 23299 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I0416 20:57:28.346400 23299 solver.cpp:237] Iteration 29400, loss = 0.122708
I0416 20:57:28.346429 23299 solver.cpp:253]     Train net output #0: loss = 0.122708 (* 1 = 0.122708 loss)
I0416 20:57:28.346438 23299 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0416 20:57:28.522398 23299 solver.cpp:237] Iteration 29500, loss = 0.120211
I0416 20:57:28.522428 23299 solver.cpp:253]     Train net output #0: loss = 0.120211 (* 1 = 0.120211 loss)
I0416 20:57:28.522438 23299 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0416 20:57:28.698391 23299 solver.cpp:237] Iteration 29600, loss = 0.118689
I0416 20:57:28.698421 23299 solver.cpp:253]     Train net output #0: loss = 0.118689 (* 1 = 0.118689 loss)
I0416 20:57:28.698429 23299 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0416 20:57:28.874227 23299 solver.cpp:237] Iteration 29700, loss = 0.117341
I0416 20:57:28.874258 23299 solver.cpp:253]     Train net output #0: loss = 0.117341 (* 1 = 0.117341 loss)
I0416 20:57:28.874267 23299 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0416 20:57:29.050338 23299 solver.cpp:237] Iteration 29800, loss = 0.116783
I0416 20:57:29.050366 23299 solver.cpp:253]     Train net output #0: loss = 0.116783 (* 1 = 0.116783 loss)
I0416 20:57:29.050374 23299 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0416 20:57:29.226214 23299 solver.cpp:237] Iteration 29900, loss = 0.114795
I0416 20:57:29.226248 23299 solver.cpp:253]     Train net output #0: loss = 0.114795 (* 1 = 0.114795 loss)
I0416 20:57:29.226256 23299 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I0416 20:57:29.401455 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_30000.caffemodel
I0416 20:57:29.403359 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_30000.solverstate
I0416 20:57:29.403899 23299 solver.cpp:341] Iteration 30000, Testing net (#0)
I0416 20:57:29.403911 23299 net.cpp:748] Ignoring source layer dart
I0416 20:57:29.455883 23299 solver.cpp:409]     Test net output #0: accuracy = 0.801
I0416 20:57:29.455912 23299 solver.cpp:409]     Test net output #1: loss = 0.587002 (* 1 = 0.587002 loss)
I0416 20:57:29.456918 23299 solver.cpp:237] Iteration 30000, loss = 0.111648
I0416 20:57:29.456948 23299 solver.cpp:253]     Train net output #0: loss = 0.111648 (* 1 = 0.111648 loss)
I0416 20:57:29.456960 23299 sgd_solver.cpp:106] Iteration 30000, lr = 0.001
I0416 20:57:29.638962 23299 solver.cpp:237] Iteration 30100, loss = 0.112004
I0416 20:57:29.638990 23299 solver.cpp:253]     Train net output #0: loss = 0.112004 (* 1 = 0.112004 loss)
I0416 20:57:29.638995 23299 sgd_solver.cpp:106] Iteration 30100, lr = 0.001
I0416 20:57:29.820662 23299 solver.cpp:237] Iteration 30200, loss = 0.108811
I0416 20:57:29.820706 23299 solver.cpp:253]     Train net output #0: loss = 0.108811 (* 1 = 0.108811 loss)
I0416 20:57:29.820713 23299 sgd_solver.cpp:106] Iteration 30200, lr = 0.001
I0416 20:57:30.002073 23299 solver.cpp:237] Iteration 30300, loss = 0.108273
I0416 20:57:30.002099 23299 solver.cpp:253]     Train net output #0: loss = 0.108273 (* 1 = 0.108273 loss)
I0416 20:57:30.002104 23299 sgd_solver.cpp:106] Iteration 30300, lr = 0.001
I0416 20:57:30.184371 23299 solver.cpp:237] Iteration 30400, loss = 0.10748
I0416 20:57:30.184401 23299 solver.cpp:253]     Train net output #0: loss = 0.10748 (* 1 = 0.10748 loss)
I0416 20:57:30.184406 23299 sgd_solver.cpp:106] Iteration 30400, lr = 0.001
I0416 20:57:30.366026 23299 solver.cpp:237] Iteration 30500, loss = 0.105842
I0416 20:57:30.366052 23299 solver.cpp:253]     Train net output #0: loss = 0.105842 (* 1 = 0.105842 loss)
I0416 20:57:30.366057 23299 sgd_solver.cpp:106] Iteration 30500, lr = 0.001
I0416 20:57:30.547425 23299 solver.cpp:237] Iteration 30600, loss = 0.105149
I0416 20:57:30.547449 23299 solver.cpp:253]     Train net output #0: loss = 0.105149 (* 1 = 0.105149 loss)
I0416 20:57:30.547456 23299 sgd_solver.cpp:106] Iteration 30600, lr = 0.001
I0416 20:57:30.729431 23299 solver.cpp:237] Iteration 30700, loss = 0.10415
I0416 20:57:30.729470 23299 solver.cpp:253]     Train net output #0: loss = 0.10415 (* 1 = 0.10415 loss)
I0416 20:57:30.729482 23299 sgd_solver.cpp:106] Iteration 30700, lr = 0.001
I0416 20:57:30.909185 23299 solver.cpp:237] Iteration 30800, loss = 0.103885
I0416 20:57:30.909215 23299 solver.cpp:253]     Train net output #0: loss = 0.103885 (* 1 = 0.103885 loss)
I0416 20:57:30.909224 23299 sgd_solver.cpp:106] Iteration 30800, lr = 0.001
I0416 20:57:31.088973 23299 solver.cpp:237] Iteration 30900, loss = 0.102312
I0416 20:57:31.089009 23299 solver.cpp:253]     Train net output #0: loss = 0.102312 (* 1 = 0.102312 loss)
I0416 20:57:31.089017 23299 sgd_solver.cpp:106] Iteration 30900, lr = 0.001
I0416 20:57:31.271384 23299 solver.cpp:237] Iteration 31000, loss = 0.102453
I0416 20:57:31.271414 23299 solver.cpp:253]     Train net output #0: loss = 0.102453 (* 1 = 0.102453 loss)
I0416 20:57:31.271430 23299 sgd_solver.cpp:106] Iteration 31000, lr = 0.001
I0416 20:57:31.453093 23299 solver.cpp:237] Iteration 31100, loss = 0.103213
I0416 20:57:31.453121 23299 solver.cpp:253]     Train net output #0: loss = 0.103213 (* 1 = 0.103213 loss)
I0416 20:57:31.453130 23299 sgd_solver.cpp:106] Iteration 31100, lr = 0.001
I0416 20:57:31.634862 23299 solver.cpp:237] Iteration 31200, loss = 0.101445
I0416 20:57:31.634891 23299 solver.cpp:253]     Train net output #0: loss = 0.101445 (* 1 = 0.101445 loss)
I0416 20:57:31.634902 23299 sgd_solver.cpp:106] Iteration 31200, lr = 0.001
I0416 20:57:31.816766 23299 solver.cpp:237] Iteration 31300, loss = 0.100527
I0416 20:57:31.816797 23299 solver.cpp:253]     Train net output #0: loss = 0.100527 (* 1 = 0.100527 loss)
I0416 20:57:31.816807 23299 sgd_solver.cpp:106] Iteration 31300, lr = 0.001
I0416 20:57:31.998466 23299 solver.cpp:237] Iteration 31400, loss = 0.099995
I0416 20:57:31.998495 23299 solver.cpp:253]     Train net output #0: loss = 0.099995 (* 1 = 0.099995 loss)
I0416 20:57:31.998503 23299 sgd_solver.cpp:106] Iteration 31400, lr = 0.001
I0416 20:57:32.180181 23299 solver.cpp:237] Iteration 31500, loss = 0.0998229
I0416 20:57:32.180209 23299 solver.cpp:253]     Train net output #0: loss = 0.0998229 (* 1 = 0.0998229 loss)
I0416 20:57:32.180217 23299 sgd_solver.cpp:106] Iteration 31500, lr = 0.001
I0416 20:57:32.361680 23299 solver.cpp:237] Iteration 31600, loss = 0.0976995
I0416 20:57:32.361711 23299 solver.cpp:253]     Train net output #0: loss = 0.0976995 (* 1 = 0.0976995 loss)
I0416 20:57:32.361721 23299 sgd_solver.cpp:106] Iteration 31600, lr = 0.001
I0416 20:57:32.543326 23299 solver.cpp:237] Iteration 31700, loss = 0.0964132
I0416 20:57:32.543357 23299 solver.cpp:253]     Train net output #0: loss = 0.0964132 (* 1 = 0.0964132 loss)
I0416 20:57:32.543366 23299 sgd_solver.cpp:106] Iteration 31700, lr = 0.001
I0416 20:57:32.725127 23299 solver.cpp:237] Iteration 31800, loss = 0.095433
I0416 20:57:32.725177 23299 solver.cpp:253]     Train net output #0: loss = 0.095433 (* 1 = 0.095433 loss)
I0416 20:57:32.725185 23299 sgd_solver.cpp:106] Iteration 31800, lr = 0.001
I0416 20:57:32.906915 23299 solver.cpp:237] Iteration 31900, loss = 0.0935835
I0416 20:57:32.906945 23299 solver.cpp:253]     Train net output #0: loss = 0.0935835 (* 1 = 0.0935835 loss)
I0416 20:57:32.906955 23299 sgd_solver.cpp:106] Iteration 31900, lr = 0.001
I0416 20:57:33.089253 23299 solver.cpp:237] Iteration 32000, loss = 0.0938273
I0416 20:57:33.089282 23299 solver.cpp:253]     Train net output #0: loss = 0.0938273 (* 1 = 0.0938273 loss)
I0416 20:57:33.089293 23299 sgd_solver.cpp:106] Iteration 32000, lr = 0.001
I0416 20:57:33.270880 23299 solver.cpp:237] Iteration 32100, loss = 0.0922377
I0416 20:57:33.270910 23299 solver.cpp:253]     Train net output #0: loss = 0.0922377 (* 1 = 0.0922377 loss)
I0416 20:57:33.270918 23299 sgd_solver.cpp:106] Iteration 32100, lr = 0.001
I0416 20:57:33.460052 23299 solver.cpp:237] Iteration 32200, loss = 0.0917527
I0416 20:57:33.460085 23299 solver.cpp:253]     Train net output #0: loss = 0.0917527 (* 1 = 0.0917527 loss)
I0416 20:57:33.460094 23299 sgd_solver.cpp:106] Iteration 32200, lr = 0.001
I0416 20:57:33.641058 23299 solver.cpp:237] Iteration 32300, loss = 0.0914709
I0416 20:57:33.641089 23299 solver.cpp:253]     Train net output #0: loss = 0.0914709 (* 1 = 0.0914709 loss)
I0416 20:57:33.641098 23299 sgd_solver.cpp:106] Iteration 32300, lr = 0.001
I0416 20:57:33.822214 23299 solver.cpp:237] Iteration 32400, loss = 0.0920709
I0416 20:57:33.822244 23299 solver.cpp:253]     Train net output #0: loss = 0.0920709 (* 1 = 0.0920709 loss)
I0416 20:57:33.822252 23299 sgd_solver.cpp:106] Iteration 32400, lr = 0.001
I0416 20:57:34.003582 23299 solver.cpp:237] Iteration 32500, loss = 0.0926086
I0416 20:57:34.003610 23299 solver.cpp:253]     Train net output #0: loss = 0.0926086 (* 1 = 0.0926086 loss)
I0416 20:57:34.003618 23299 sgd_solver.cpp:106] Iteration 32500, lr = 0.001
I0416 20:57:34.184547 23299 solver.cpp:237] Iteration 32600, loss = 0.0932516
I0416 20:57:34.184576 23299 solver.cpp:253]     Train net output #0: loss = 0.0932516 (* 1 = 0.0932516 loss)
I0416 20:57:34.184584 23299 sgd_solver.cpp:106] Iteration 32600, lr = 0.001
I0416 20:57:34.366004 23299 solver.cpp:237] Iteration 32700, loss = 0.0950321
I0416 20:57:34.366034 23299 solver.cpp:253]     Train net output #0: loss = 0.0950321 (* 1 = 0.0950321 loss)
I0416 20:57:34.366042 23299 sgd_solver.cpp:106] Iteration 32700, lr = 0.001
I0416 20:57:34.547148 23299 solver.cpp:237] Iteration 32800, loss = 0.0957395
I0416 20:57:34.547176 23299 solver.cpp:253]     Train net output #0: loss = 0.0957395 (* 1 = 0.0957395 loss)
I0416 20:57:34.547184 23299 sgd_solver.cpp:106] Iteration 32800, lr = 0.001
I0416 20:57:34.728292 23299 solver.cpp:237] Iteration 32900, loss = 0.0969608
I0416 20:57:34.728320 23299 solver.cpp:253]     Train net output #0: loss = 0.0969608 (* 1 = 0.0969608 loss)
I0416 20:57:34.728328 23299 sgd_solver.cpp:106] Iteration 32900, lr = 0.001
I0416 20:57:34.908402 23299 solver.cpp:237] Iteration 33000, loss = 0.0986394
I0416 20:57:34.908432 23299 solver.cpp:253]     Train net output #0: loss = 0.0986394 (* 1 = 0.0986394 loss)
I0416 20:57:34.908438 23299 sgd_solver.cpp:106] Iteration 33000, lr = 0.001
I0416 20:57:35.089438 23299 solver.cpp:237] Iteration 33100, loss = 0.0998186
I0416 20:57:35.089467 23299 solver.cpp:253]     Train net output #0: loss = 0.0998186 (* 1 = 0.0998186 loss)
I0416 20:57:35.089474 23299 sgd_solver.cpp:106] Iteration 33100, lr = 0.001
I0416 20:57:35.269714 23299 solver.cpp:237] Iteration 33200, loss = 0.10116
I0416 20:57:35.269742 23299 solver.cpp:253]     Train net output #0: loss = 0.10116 (* 1 = 0.10116 loss)
I0416 20:57:35.269750 23299 sgd_solver.cpp:106] Iteration 33200, lr = 0.001
I0416 20:57:35.450774 23299 solver.cpp:237] Iteration 33300, loss = 0.101499
I0416 20:57:35.450805 23299 solver.cpp:253]     Train net output #0: loss = 0.101499 (* 1 = 0.101499 loss)
I0416 20:57:35.450842 23299 sgd_solver.cpp:106] Iteration 33300, lr = 0.001
I0416 20:57:35.631372 23299 solver.cpp:237] Iteration 33400, loss = 0.102976
I0416 20:57:35.631402 23299 solver.cpp:253]     Train net output #0: loss = 0.102976 (* 1 = 0.102976 loss)
I0416 20:57:35.631412 23299 sgd_solver.cpp:106] Iteration 33400, lr = 0.001
I0416 20:57:35.811028 23299 solver.cpp:237] Iteration 33500, loss = 0.102075
I0416 20:57:35.811056 23299 solver.cpp:253]     Train net output #0: loss = 0.102075 (* 1 = 0.102075 loss)
I0416 20:57:35.811064 23299 sgd_solver.cpp:106] Iteration 33500, lr = 0.001
I0416 20:57:35.991029 23299 solver.cpp:237] Iteration 33600, loss = 0.102416
I0416 20:57:35.991173 23299 solver.cpp:253]     Train net output #0: loss = 0.102416 (* 1 = 0.102416 loss)
I0416 20:57:35.991184 23299 sgd_solver.cpp:106] Iteration 33600, lr = 0.001
I0416 20:57:36.171703 23299 solver.cpp:237] Iteration 33700, loss = 0.101841
I0416 20:57:36.171731 23299 solver.cpp:253]     Train net output #0: loss = 0.101841 (* 1 = 0.101841 loss)
I0416 20:57:36.171739 23299 sgd_solver.cpp:106] Iteration 33700, lr = 0.001
I0416 20:57:36.351140 23299 solver.cpp:237] Iteration 33800, loss = 0.101782
I0416 20:57:36.351166 23299 solver.cpp:253]     Train net output #0: loss = 0.101782 (* 1 = 0.101782 loss)
I0416 20:57:36.351174 23299 sgd_solver.cpp:106] Iteration 33800, lr = 0.001
I0416 20:57:36.532209 23299 solver.cpp:237] Iteration 33900, loss = 0.101301
I0416 20:57:36.532238 23299 solver.cpp:253]     Train net output #0: loss = 0.101301 (* 1 = 0.101301 loss)
I0416 20:57:36.532246 23299 sgd_solver.cpp:106] Iteration 33900, lr = 0.001
I0416 20:57:36.712513 23299 solver.cpp:237] Iteration 34000, loss = 0.0989541
I0416 20:57:36.712543 23299 solver.cpp:253]     Train net output #0: loss = 0.0989541 (* 1 = 0.0989541 loss)
I0416 20:57:36.712553 23299 sgd_solver.cpp:106] Iteration 34000, lr = 0.001
I0416 20:57:36.892864 23299 solver.cpp:237] Iteration 34100, loss = 0.0978618
I0416 20:57:36.892894 23299 solver.cpp:253]     Train net output #0: loss = 0.0978618 (* 1 = 0.0978618 loss)
I0416 20:57:36.892909 23299 sgd_solver.cpp:106] Iteration 34100, lr = 0.001
I0416 20:57:37.074971 23299 solver.cpp:237] Iteration 34200, loss = 0.0962229
I0416 20:57:37.075007 23299 solver.cpp:253]     Train net output #0: loss = 0.0962229 (* 1 = 0.0962229 loss)
I0416 20:57:37.075016 23299 sgd_solver.cpp:106] Iteration 34200, lr = 0.001
I0416 20:57:37.257781 23299 solver.cpp:237] Iteration 34300, loss = 0.093003
I0416 20:57:37.257812 23299 solver.cpp:253]     Train net output #0: loss = 0.093003 (* 1 = 0.093003 loss)
I0416 20:57:37.257817 23299 sgd_solver.cpp:106] Iteration 34300, lr = 0.001
I0416 20:57:37.440438 23299 solver.cpp:237] Iteration 34400, loss = 0.0918258
I0416 20:57:37.440464 23299 solver.cpp:253]     Train net output #0: loss = 0.0918258 (* 1 = 0.0918258 loss)
I0416 20:57:37.440471 23299 sgd_solver.cpp:106] Iteration 34400, lr = 0.001
I0416 20:57:37.622720 23299 solver.cpp:237] Iteration 34500, loss = 0.0898663
I0416 20:57:37.622745 23299 solver.cpp:253]     Train net output #0: loss = 0.0898663 (* 1 = 0.0898663 loss)
I0416 20:57:37.622751 23299 sgd_solver.cpp:106] Iteration 34500, lr = 0.001
I0416 20:57:37.805039 23299 solver.cpp:237] Iteration 34600, loss = 0.0870697
I0416 20:57:37.805070 23299 solver.cpp:253]     Train net output #0: loss = 0.0870697 (* 1 = 0.0870697 loss)
I0416 20:57:37.805078 23299 sgd_solver.cpp:106] Iteration 34600, lr = 0.001
I0416 20:57:37.987512 23299 solver.cpp:237] Iteration 34700, loss = 0.0855598
I0416 20:57:37.987542 23299 solver.cpp:253]     Train net output #0: loss = 0.0855598 (* 1 = 0.0855598 loss)
I0416 20:57:37.987551 23299 sgd_solver.cpp:106] Iteration 34700, lr = 0.001
I0416 20:57:38.170059 23299 solver.cpp:237] Iteration 34800, loss = 0.0835636
I0416 20:57:38.170088 23299 solver.cpp:253]     Train net output #0: loss = 0.0835636 (* 1 = 0.0835636 loss)
I0416 20:57:38.170092 23299 sgd_solver.cpp:106] Iteration 34800, lr = 0.001
I0416 20:57:38.353330 23299 solver.cpp:237] Iteration 34900, loss = 0.0829544
I0416 20:57:38.353361 23299 solver.cpp:253]     Train net output #0: loss = 0.0829544 (* 1 = 0.0829544 loss)
I0416 20:57:38.353366 23299 sgd_solver.cpp:106] Iteration 34900, lr = 0.001
I0416 20:57:38.467360 23304 blocking_queue.cpp:50] Waiting for data
I0416 20:57:38.534781 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_35000.caffemodel
I0416 20:57:38.536767 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_35000.solverstate
I0416 20:57:38.537412 23299 solver.cpp:341] Iteration 35000, Testing net (#0)
I0416 20:57:38.537426 23299 net.cpp:748] Ignoring source layer dart
I0416 20:57:38.580055 23299 solver.cpp:409]     Test net output #0: accuracy = 0.788
I0416 20:57:38.580095 23299 solver.cpp:409]     Test net output #1: loss = 0.672582 (* 1 = 0.672582 loss)
I0416 20:57:38.580952 23299 solver.cpp:237] Iteration 35000, loss = 0.0816334
I0416 20:57:38.580972 23299 solver.cpp:253]     Train net output #0: loss = 0.0816334 (* 1 = 0.0816334 loss)
I0416 20:57:38.580978 23299 sgd_solver.cpp:106] Iteration 35000, lr = 0.001
I0416 20:57:38.759889 23299 solver.cpp:237] Iteration 35100, loss = 0.0809536
I0416 20:57:38.759932 23299 solver.cpp:253]     Train net output #0: loss = 0.0809536 (* 1 = 0.0809536 loss)
I0416 20:57:38.759940 23299 sgd_solver.cpp:106] Iteration 35100, lr = 0.001
I0416 20:57:38.939193 23299 solver.cpp:237] Iteration 35200, loss = 0.0794084
I0416 20:57:38.939231 23299 solver.cpp:253]     Train net output #0: loss = 0.0794084 (* 1 = 0.0794084 loss)
I0416 20:57:38.939244 23299 sgd_solver.cpp:106] Iteration 35200, lr = 0.001
I0416 20:57:39.005800 23299 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 20:57:39.122910 23299 solver.cpp:237] Iteration 35300, loss = 0.079252
I0416 20:57:39.122943 23299 solver.cpp:253]     Train net output #0: loss = 0.079252 (* 1 = 0.079252 loss)
I0416 20:57:39.122952 23299 sgd_solver.cpp:106] Iteration 35300, lr = 0.001
I0416 20:57:39.299029 23299 solver.cpp:237] Iteration 35400, loss = 0.079311
I0416 20:57:39.299062 23299 solver.cpp:253]     Train net output #0: loss = 0.079311 (* 1 = 0.079311 loss)
I0416 20:57:39.299067 23299 sgd_solver.cpp:106] Iteration 35400, lr = 0.001
I0416 20:57:39.476598 23299 solver.cpp:237] Iteration 35500, loss = 0.0787078
I0416 20:57:39.476652 23299 solver.cpp:253]     Train net output #0: loss = 0.0787078 (* 1 = 0.0787078 loss)
I0416 20:57:39.476670 23299 sgd_solver.cpp:106] Iteration 35500, lr = 0.001
I0416 20:57:39.657068 23299 solver.cpp:237] Iteration 35600, loss = 0.0779798
I0416 20:57:39.657107 23299 solver.cpp:253]     Train net output #0: loss = 0.0779798 (* 1 = 0.0779798 loss)
I0416 20:57:39.657117 23299 sgd_solver.cpp:106] Iteration 35600, lr = 0.001
I0416 20:57:39.832800 23299 solver.cpp:237] Iteration 35700, loss = 0.077922
I0416 20:57:39.832839 23299 solver.cpp:253]     Train net output #0: loss = 0.077922 (* 1 = 0.077922 loss)
I0416 20:57:39.832847 23299 sgd_solver.cpp:106] Iteration 35700, lr = 0.001
I0416 20:57:40.010866 23299 solver.cpp:237] Iteration 35800, loss = 0.0778319
I0416 20:57:40.010905 23299 solver.cpp:253]     Train net output #0: loss = 0.0778319 (* 1 = 0.0778319 loss)
I0416 20:57:40.010923 23299 sgd_solver.cpp:106] Iteration 35800, lr = 0.001
I0416 20:57:40.187049 23299 solver.cpp:237] Iteration 35900, loss = 0.077067
I0416 20:57:40.187083 23299 solver.cpp:253]     Train net output #0: loss = 0.077067 (* 1 = 0.077067 loss)
I0416 20:57:40.187091 23299 sgd_solver.cpp:106] Iteration 35900, lr = 0.001
I0416 20:57:40.362782 23299 solver.cpp:237] Iteration 36000, loss = 0.0763126
I0416 20:57:40.362818 23299 solver.cpp:253]     Train net output #0: loss = 0.0763126 (* 1 = 0.0763126 loss)
I0416 20:57:40.362826 23299 sgd_solver.cpp:106] Iteration 36000, lr = 0.001
I0416 20:57:40.539124 23299 solver.cpp:237] Iteration 36100, loss = 0.0765744
I0416 20:57:40.539160 23299 solver.cpp:253]     Train net output #0: loss = 0.0765744 (* 1 = 0.0765744 loss)
I0416 20:57:40.539170 23299 sgd_solver.cpp:106] Iteration 36100, lr = 0.001
I0416 20:57:40.714743 23299 solver.cpp:237] Iteration 36200, loss = 0.0759644
I0416 20:57:40.714778 23299 solver.cpp:253]     Train net output #0: loss = 0.0759644 (* 1 = 0.0759644 loss)
I0416 20:57:40.714786 23299 sgd_solver.cpp:106] Iteration 36200, lr = 0.001
I0416 20:57:40.890794 23299 solver.cpp:237] Iteration 36300, loss = 0.075906
I0416 20:57:40.890821 23299 solver.cpp:253]     Train net output #0: loss = 0.075906 (* 1 = 0.075906 loss)
I0416 20:57:40.890830 23299 sgd_solver.cpp:106] Iteration 36300, lr = 0.001
I0416 20:57:41.067159 23299 solver.cpp:237] Iteration 36400, loss = 0.0745025
I0416 20:57:41.067188 23299 solver.cpp:253]     Train net output #0: loss = 0.0745025 (* 1 = 0.0745025 loss)
I0416 20:57:41.067229 23299 sgd_solver.cpp:106] Iteration 36400, lr = 0.001
I0416 20:57:41.246980 23299 solver.cpp:237] Iteration 36500, loss = 0.0747009
I0416 20:57:41.247017 23299 solver.cpp:253]     Train net output #0: loss = 0.0747009 (* 1 = 0.0747009 loss)
I0416 20:57:41.247025 23299 sgd_solver.cpp:106] Iteration 36500, lr = 0.001
I0416 20:57:41.423229 23299 solver.cpp:237] Iteration 36600, loss = 0.0732151
I0416 20:57:41.423262 23299 solver.cpp:253]     Train net output #0: loss = 0.0732151 (* 1 = 0.0732151 loss)
I0416 20:57:41.423269 23299 sgd_solver.cpp:106] Iteration 36600, lr = 0.001
I0416 20:57:41.599133 23299 solver.cpp:237] Iteration 36700, loss = 0.0726576
I0416 20:57:41.599170 23299 solver.cpp:253]     Train net output #0: loss = 0.0726576 (* 1 = 0.0726576 loss)
I0416 20:57:41.599176 23299 sgd_solver.cpp:106] Iteration 36700, lr = 0.001
I0416 20:57:41.775028 23299 solver.cpp:237] Iteration 36800, loss = 0.0712649
I0416 20:57:41.775063 23299 solver.cpp:253]     Train net output #0: loss = 0.0712649 (* 1 = 0.0712649 loss)
I0416 20:57:41.775069 23299 sgd_solver.cpp:106] Iteration 36800, lr = 0.001
I0416 20:57:41.950650 23299 solver.cpp:237] Iteration 36900, loss = 0.0705479
I0416 20:57:41.950678 23299 solver.cpp:253]     Train net output #0: loss = 0.0705479 (* 1 = 0.0705479 loss)
I0416 20:57:41.950683 23299 sgd_solver.cpp:106] Iteration 36900, lr = 0.001
I0416 20:57:42.126081 23299 solver.cpp:237] Iteration 37000, loss = 0.0696858
I0416 20:57:42.126113 23299 solver.cpp:253]     Train net output #0: loss = 0.0696858 (* 1 = 0.0696858 loss)
I0416 20:57:42.126126 23299 sgd_solver.cpp:106] Iteration 37000, lr = 0.001
I0416 20:57:42.301447 23299 solver.cpp:237] Iteration 37100, loss = 0.0682709
I0416 20:57:42.301475 23299 solver.cpp:253]     Train net output #0: loss = 0.0682709 (* 1 = 0.0682709 loss)
I0416 20:57:42.301479 23299 sgd_solver.cpp:106] Iteration 37100, lr = 0.001
I0416 20:57:42.478260 23299 solver.cpp:237] Iteration 37200, loss = 0.0669467
I0416 20:57:42.478291 23299 solver.cpp:253]     Train net output #0: loss = 0.0669467 (* 1 = 0.0669467 loss)
I0416 20:57:42.478296 23299 sgd_solver.cpp:106] Iteration 37200, lr = 0.001
I0416 20:57:42.654817 23299 solver.cpp:237] Iteration 37300, loss = 0.0652333
I0416 20:57:42.654846 23299 solver.cpp:253]     Train net output #0: loss = 0.0652333 (* 1 = 0.0652333 loss)
I0416 20:57:42.654857 23299 sgd_solver.cpp:106] Iteration 37300, lr = 0.001
I0416 20:57:42.831646 23299 solver.cpp:237] Iteration 37400, loss = 0.064088
I0416 20:57:42.831675 23299 solver.cpp:253]     Train net output #0: loss = 0.064088 (* 1 = 0.064088 loss)
I0416 20:57:42.831679 23299 sgd_solver.cpp:106] Iteration 37400, lr = 0.001
I0416 20:57:43.008064 23299 solver.cpp:237] Iteration 37500, loss = 0.0622537
I0416 20:57:43.008091 23299 solver.cpp:253]     Train net output #0: loss = 0.0622537 (* 1 = 0.0622537 loss)
I0416 20:57:43.008096 23299 sgd_solver.cpp:106] Iteration 37500, lr = 0.001
I0416 20:57:43.184434 23299 solver.cpp:237] Iteration 37600, loss = 0.0607371
I0416 20:57:43.184461 23299 solver.cpp:253]     Train net output #0: loss = 0.0607371 (* 1 = 0.0607371 loss)
I0416 20:57:43.184466 23299 sgd_solver.cpp:106] Iteration 37600, lr = 0.001
I0416 20:57:43.361009 23299 solver.cpp:237] Iteration 37700, loss = 0.0595648
I0416 20:57:43.361037 23299 solver.cpp:253]     Train net output #0: loss = 0.0595648 (* 1 = 0.0595648 loss)
I0416 20:57:43.361042 23299 sgd_solver.cpp:106] Iteration 37700, lr = 0.001
I0416 20:57:43.537633 23299 solver.cpp:237] Iteration 37800, loss = 0.0584399
I0416 20:57:43.537660 23299 solver.cpp:253]     Train net output #0: loss = 0.0584399 (* 1 = 0.0584399 loss)
I0416 20:57:43.537665 23299 sgd_solver.cpp:106] Iteration 37800, lr = 0.001
I0416 20:57:43.714143 23299 solver.cpp:237] Iteration 37900, loss = 0.0574675
I0416 20:57:43.714169 23299 solver.cpp:253]     Train net output #0: loss = 0.0574675 (* 1 = 0.0574675 loss)
I0416 20:57:43.714174 23299 sgd_solver.cpp:106] Iteration 37900, lr = 0.001
I0416 20:57:43.890652 23299 solver.cpp:237] Iteration 38000, loss = 0.0560356
I0416 20:57:43.890700 23299 solver.cpp:253]     Train net output #0: loss = 0.0560356 (* 1 = 0.0560356 loss)
I0416 20:57:43.890707 23299 sgd_solver.cpp:106] Iteration 38000, lr = 0.001
I0416 20:57:44.067281 23299 solver.cpp:237] Iteration 38100, loss = 0.0547025
I0416 20:57:44.067309 23299 solver.cpp:253]     Train net output #0: loss = 0.0547025 (* 1 = 0.0547025 loss)
I0416 20:57:44.067314 23299 sgd_solver.cpp:106] Iteration 38100, lr = 0.001
I0416 20:57:44.243495 23299 solver.cpp:237] Iteration 38200, loss = 0.0541366
I0416 20:57:44.243522 23299 solver.cpp:253]     Train net output #0: loss = 0.0541366 (* 1 = 0.0541366 loss)
I0416 20:57:44.243527 23299 sgd_solver.cpp:106] Iteration 38200, lr = 0.001
I0416 20:57:44.419806 23299 solver.cpp:237] Iteration 38300, loss = 0.0530144
I0416 20:57:44.419834 23299 solver.cpp:253]     Train net output #0: loss = 0.0530144 (* 1 = 0.0530144 loss)
I0416 20:57:44.419839 23299 sgd_solver.cpp:106] Iteration 38300, lr = 0.001
I0416 20:57:44.596359 23299 solver.cpp:237] Iteration 38400, loss = 0.0520106
I0416 20:57:44.596387 23299 solver.cpp:253]     Train net output #0: loss = 0.0520106 (* 1 = 0.0520106 loss)
I0416 20:57:44.596392 23299 sgd_solver.cpp:106] Iteration 38400, lr = 0.001
I0416 20:57:44.773123 23299 solver.cpp:237] Iteration 38500, loss = 0.0511973
I0416 20:57:44.773149 23299 solver.cpp:253]     Train net output #0: loss = 0.0511973 (* 1 = 0.0511973 loss)
I0416 20:57:44.773154 23299 sgd_solver.cpp:106] Iteration 38500, lr = 0.001
I0416 20:57:44.951167 23299 solver.cpp:237] Iteration 38600, loss = 0.0507875
I0416 20:57:44.951195 23299 solver.cpp:253]     Train net output #0: loss = 0.0507875 (* 1 = 0.0507875 loss)
I0416 20:57:44.951200 23299 sgd_solver.cpp:106] Iteration 38600, lr = 0.001
I0416 20:57:45.127738 23299 solver.cpp:237] Iteration 38700, loss = 0.0497929
I0416 20:57:45.127768 23299 solver.cpp:253]     Train net output #0: loss = 0.0497929 (* 1 = 0.0497929 loss)
I0416 20:57:45.127774 23299 sgd_solver.cpp:106] Iteration 38700, lr = 0.001
I0416 20:57:45.304457 23299 solver.cpp:237] Iteration 38800, loss = 0.0491238
I0416 20:57:45.304483 23299 solver.cpp:253]     Train net output #0: loss = 0.0491238 (* 1 = 0.0491238 loss)
I0416 20:57:45.304488 23299 sgd_solver.cpp:106] Iteration 38800, lr = 0.001
I0416 20:57:45.481021 23299 solver.cpp:237] Iteration 38900, loss = 0.0487321
I0416 20:57:45.481048 23299 solver.cpp:253]     Train net output #0: loss = 0.0487321 (* 1 = 0.0487321 loss)
I0416 20:57:45.481053 23299 sgd_solver.cpp:106] Iteration 38900, lr = 0.001
I0416 20:57:45.657464 23299 solver.cpp:237] Iteration 39000, loss = 0.0482381
I0416 20:57:45.657488 23299 solver.cpp:253]     Train net output #0: loss = 0.0482381 (* 1 = 0.0482381 loss)
I0416 20:57:45.657493 23299 sgd_solver.cpp:106] Iteration 39000, lr = 0.001
I0416 20:57:45.833787 23299 solver.cpp:237] Iteration 39100, loss = 0.0478096
I0416 20:57:45.833813 23299 solver.cpp:253]     Train net output #0: loss = 0.0478096 (* 1 = 0.0478096 loss)
I0416 20:57:45.833819 23299 sgd_solver.cpp:106] Iteration 39100, lr = 0.001
I0416 20:57:46.010468 23299 solver.cpp:237] Iteration 39200, loss = 0.0471998
I0416 20:57:46.010495 23299 solver.cpp:253]     Train net output #0: loss = 0.0471998 (* 1 = 0.0471998 loss)
I0416 20:57:46.010501 23299 sgd_solver.cpp:106] Iteration 39200, lr = 0.001
I0416 20:57:46.188982 23299 solver.cpp:237] Iteration 39300, loss = 0.0468933
I0416 20:57:46.189023 23299 solver.cpp:253]     Train net output #0: loss = 0.0468933 (* 1 = 0.0468933 loss)
I0416 20:57:46.189033 23299 sgd_solver.cpp:106] Iteration 39300, lr = 0.001
I0416 20:57:46.365300 23299 solver.cpp:237] Iteration 39400, loss = 0.0464023
I0416 20:57:46.365329 23299 solver.cpp:253]     Train net output #0: loss = 0.0464023 (* 1 = 0.0464023 loss)
I0416 20:57:46.365334 23299 sgd_solver.cpp:106] Iteration 39400, lr = 0.001
I0416 20:57:46.543658 23299 solver.cpp:237] Iteration 39500, loss = 0.04618
I0416 20:57:46.543694 23299 solver.cpp:253]     Train net output #0: loss = 0.04618 (* 1 = 0.04618 loss)
I0416 20:57:46.543702 23299 sgd_solver.cpp:106] Iteration 39500, lr = 0.001
I0416 20:57:46.723235 23299 solver.cpp:237] Iteration 39600, loss = 0.045967
I0416 20:57:46.723266 23299 solver.cpp:253]     Train net output #0: loss = 0.045967 (* 1 = 0.045967 loss)
I0416 20:57:46.723273 23299 sgd_solver.cpp:106] Iteration 39600, lr = 0.001
I0416 20:57:46.899744 23299 solver.cpp:237] Iteration 39700, loss = 0.0457083
I0416 20:57:46.899773 23299 solver.cpp:253]     Train net output #0: loss = 0.0457083 (* 1 = 0.0457083 loss)
I0416 20:57:46.899780 23299 sgd_solver.cpp:106] Iteration 39700, lr = 0.001
I0416 20:57:47.076325 23299 solver.cpp:237] Iteration 39800, loss = 0.0455286
I0416 20:57:47.076357 23299 solver.cpp:253]     Train net output #0: loss = 0.0455286 (* 1 = 0.0455286 loss)
I0416 20:57:47.076364 23299 sgd_solver.cpp:106] Iteration 39800, lr = 0.001
I0416 20:57:47.252807 23299 solver.cpp:237] Iteration 39900, loss = 0.0450777
I0416 20:57:47.252843 23299 solver.cpp:253]     Train net output #0: loss = 0.0450777 (* 1 = 0.0450777 loss)
I0416 20:57:47.252849 23299 sgd_solver.cpp:106] Iteration 39900, lr = 0.001
I0416 20:57:47.427777 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_40000.caffemodel
I0416 20:57:47.429698 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_40000.solverstate
I0416 20:57:47.430269 23299 solver.cpp:341] Iteration 40000, Testing net (#0)
I0416 20:57:47.430279 23299 net.cpp:748] Ignoring source layer dart
I0416 20:57:47.472731 23299 solver.cpp:409]     Test net output #0: accuracy = 0.8015
I0416 20:57:47.472753 23299 solver.cpp:409]     Test net output #1: loss = 0.652223 (* 1 = 0.652223 loss)
I0416 20:57:47.473562 23299 solver.cpp:237] Iteration 40000, loss = 0.0451428
I0416 20:57:47.473578 23299 solver.cpp:253]     Train net output #0: loss = 0.0451428 (* 1 = 0.0451428 loss)
I0416 20:57:47.473587 23299 sgd_solver.cpp:106] Iteration 40000, lr = 0.001
I0416 20:57:47.650318 23299 solver.cpp:237] Iteration 40100, loss = 0.0447198
I0416 20:57:47.650351 23299 solver.cpp:253]     Train net output #0: loss = 0.0447198 (* 1 = 0.0447198 loss)
I0416 20:57:47.650357 23299 sgd_solver.cpp:106] Iteration 40100, lr = 0.001
I0416 20:57:47.827204 23299 solver.cpp:237] Iteration 40200, loss = 0.0447644
I0416 20:57:47.827231 23299 solver.cpp:253]     Train net output #0: loss = 0.0447644 (* 1 = 0.0447644 loss)
I0416 20:57:47.827239 23299 sgd_solver.cpp:106] Iteration 40200, lr = 0.001
I0416 20:57:48.003911 23299 solver.cpp:237] Iteration 40300, loss = 0.0443601
I0416 20:57:48.003937 23299 solver.cpp:253]     Train net output #0: loss = 0.0443601 (* 1 = 0.0443601 loss)
I0416 20:57:48.003942 23299 sgd_solver.cpp:106] Iteration 40300, lr = 0.001
I0416 20:57:48.180564 23299 solver.cpp:237] Iteration 40400, loss = 0.0442295
I0416 20:57:48.180591 23299 solver.cpp:253]     Train net output #0: loss = 0.0442295 (* 1 = 0.0442295 loss)
I0416 20:57:48.180598 23299 sgd_solver.cpp:106] Iteration 40400, lr = 0.001
I0416 20:57:48.357010 23299 solver.cpp:237] Iteration 40500, loss = 0.04403
I0416 20:57:48.357036 23299 solver.cpp:253]     Train net output #0: loss = 0.04403 (* 1 = 0.04403 loss)
I0416 20:57:48.357041 23299 sgd_solver.cpp:106] Iteration 40500, lr = 0.001
I0416 20:57:48.533392 23299 solver.cpp:237] Iteration 40600, loss = 0.0439222
I0416 20:57:48.533417 23299 solver.cpp:253]     Train net output #0: loss = 0.0439222 (* 1 = 0.0439222 loss)
I0416 20:57:48.533422 23299 sgd_solver.cpp:106] Iteration 40600, lr = 0.001
I0416 20:57:48.710263 23299 solver.cpp:237] Iteration 40700, loss = 0.0434229
I0416 20:57:48.710289 23299 solver.cpp:253]     Train net output #0: loss = 0.0434229 (* 1 = 0.0434229 loss)
I0416 20:57:48.710294 23299 sgd_solver.cpp:106] Iteration 40700, lr = 0.001
I0416 20:57:48.886853 23299 solver.cpp:237] Iteration 40800, loss = 0.0431917
I0416 20:57:48.886884 23299 solver.cpp:253]     Train net output #0: loss = 0.0431917 (* 1 = 0.0431917 loss)
I0416 20:57:48.886894 23299 sgd_solver.cpp:106] Iteration 40800, lr = 0.001
I0416 20:57:49.063535 23299 solver.cpp:237] Iteration 40900, loss = 0.042991
I0416 20:57:49.063580 23299 solver.cpp:253]     Train net output #0: loss = 0.042991 (* 1 = 0.042991 loss)
I0416 20:57:49.063586 23299 sgd_solver.cpp:106] Iteration 40900, lr = 0.001
I0416 20:57:49.240418 23299 solver.cpp:237] Iteration 41000, loss = 0.0426432
I0416 20:57:49.240445 23299 solver.cpp:253]     Train net output #0: loss = 0.0426432 (* 1 = 0.0426432 loss)
I0416 20:57:49.240450 23299 sgd_solver.cpp:106] Iteration 41000, lr = 0.001
I0416 20:57:49.417681 23299 solver.cpp:237] Iteration 41100, loss = 0.0423291
I0416 20:57:49.417708 23299 solver.cpp:253]     Train net output #0: loss = 0.0423291 (* 1 = 0.0423291 loss)
I0416 20:57:49.417713 23299 sgd_solver.cpp:106] Iteration 41100, lr = 0.001
I0416 20:57:49.594504 23299 solver.cpp:237] Iteration 41200, loss = 0.0420627
I0416 20:57:49.594530 23299 solver.cpp:253]     Train net output #0: loss = 0.0420627 (* 1 = 0.0420627 loss)
I0416 20:57:49.594535 23299 sgd_solver.cpp:106] Iteration 41200, lr = 0.001
I0416 20:57:49.771606 23299 solver.cpp:237] Iteration 41300, loss = 0.0416906
I0416 20:57:49.771633 23299 solver.cpp:253]     Train net output #0: loss = 0.0416906 (* 1 = 0.0416906 loss)
I0416 20:57:49.771638 23299 sgd_solver.cpp:106] Iteration 41300, lr = 0.001
I0416 20:57:49.948617 23299 solver.cpp:237] Iteration 41400, loss = 0.0415313
I0416 20:57:49.948642 23299 solver.cpp:253]     Train net output #0: loss = 0.0415313 (* 1 = 0.0415313 loss)
I0416 20:57:49.948648 23299 sgd_solver.cpp:106] Iteration 41400, lr = 0.001
I0416 20:57:50.125605 23299 solver.cpp:237] Iteration 41500, loss = 0.0411963
I0416 20:57:50.125633 23299 solver.cpp:253]     Train net output #0: loss = 0.0411963 (* 1 = 0.0411963 loss)
I0416 20:57:50.125638 23299 sgd_solver.cpp:106] Iteration 41500, lr = 0.001
I0416 20:57:50.302487 23299 solver.cpp:237] Iteration 41600, loss = 0.0406731
I0416 20:57:50.302515 23299 solver.cpp:253]     Train net output #0: loss = 0.0406731 (* 1 = 0.0406731 loss)
I0416 20:57:50.302520 23299 sgd_solver.cpp:106] Iteration 41600, lr = 0.001
I0416 20:57:50.479074 23299 solver.cpp:237] Iteration 41700, loss = 0.0403151
I0416 20:57:50.479102 23299 solver.cpp:253]     Train net output #0: loss = 0.0403151 (* 1 = 0.0403151 loss)
I0416 20:57:50.479107 23299 sgd_solver.cpp:106] Iteration 41700, lr = 0.001
I0416 20:57:50.656263 23299 solver.cpp:237] Iteration 41800, loss = 0.0402075
I0416 20:57:50.656291 23299 solver.cpp:253]     Train net output #0: loss = 0.0402075 (* 1 = 0.0402075 loss)
I0416 20:57:50.656297 23299 sgd_solver.cpp:106] Iteration 41800, lr = 0.001
I0416 20:57:50.833971 23299 solver.cpp:237] Iteration 41900, loss = 0.039776
I0416 20:57:50.833998 23299 solver.cpp:253]     Train net output #0: loss = 0.039776 (* 1 = 0.039776 loss)
I0416 20:57:50.834004 23299 sgd_solver.cpp:106] Iteration 41900, lr = 0.001
I0416 20:57:51.011574 23299 solver.cpp:237] Iteration 42000, loss = 0.0398879
I0416 20:57:51.011600 23299 solver.cpp:253]     Train net output #0: loss = 0.0398879 (* 1 = 0.0398879 loss)
I0416 20:57:51.011606 23299 sgd_solver.cpp:106] Iteration 42000, lr = 0.001
I0416 20:57:51.188056 23299 solver.cpp:237] Iteration 42100, loss = 0.0391484
I0416 20:57:51.188083 23299 solver.cpp:253]     Train net output #0: loss = 0.0391484 (* 1 = 0.0391484 loss)
I0416 20:57:51.188088 23299 sgd_solver.cpp:106] Iteration 42100, lr = 0.001
I0416 20:57:51.364524 23299 solver.cpp:237] Iteration 42200, loss = 0.0391677
I0416 20:57:51.364550 23299 solver.cpp:253]     Train net output #0: loss = 0.0391677 (* 1 = 0.0391677 loss)
I0416 20:57:51.364555 23299 sgd_solver.cpp:106] Iteration 42200, lr = 0.001
I0416 20:57:51.540964 23299 solver.cpp:237] Iteration 42300, loss = 0.0387151
I0416 20:57:51.540992 23299 solver.cpp:253]     Train net output #0: loss = 0.0387151 (* 1 = 0.0387151 loss)
I0416 20:57:51.540997 23299 sgd_solver.cpp:106] Iteration 42300, lr = 0.001
I0416 20:57:51.717494 23299 solver.cpp:237] Iteration 42400, loss = 0.03841
I0416 20:57:51.717521 23299 solver.cpp:253]     Train net output #0: loss = 0.03841 (* 1 = 0.03841 loss)
I0416 20:57:51.717526 23299 sgd_solver.cpp:106] Iteration 42400, lr = 0.001
I0416 20:57:51.894641 23299 solver.cpp:237] Iteration 42500, loss = 0.0382354
I0416 20:57:51.894668 23299 solver.cpp:253]     Train net output #0: loss = 0.0382354 (* 1 = 0.0382354 loss)
I0416 20:57:51.894673 23299 sgd_solver.cpp:106] Iteration 42500, lr = 0.001
I0416 20:57:52.071471 23299 solver.cpp:237] Iteration 42600, loss = 0.0380564
I0416 20:57:52.071499 23299 solver.cpp:253]     Train net output #0: loss = 0.0380564 (* 1 = 0.0380564 loss)
I0416 20:57:52.071504 23299 sgd_solver.cpp:106] Iteration 42600, lr = 0.001
I0416 20:57:52.248340 23299 solver.cpp:237] Iteration 42700, loss = 0.0378002
I0416 20:57:52.248368 23299 solver.cpp:253]     Train net output #0: loss = 0.0378002 (* 1 = 0.0378002 loss)
I0416 20:57:52.248374 23299 sgd_solver.cpp:106] Iteration 42700, lr = 0.001
I0416 20:57:52.425024 23299 solver.cpp:237] Iteration 42800, loss = 0.0375605
I0416 20:57:52.425050 23299 solver.cpp:253]     Train net output #0: loss = 0.0375605 (* 1 = 0.0375605 loss)
I0416 20:57:52.425055 23299 sgd_solver.cpp:106] Iteration 42800, lr = 0.001
I0416 20:57:52.601938 23299 solver.cpp:237] Iteration 42900, loss = 0.0373545
I0416 20:57:52.601966 23299 solver.cpp:253]     Train net output #0: loss = 0.0373545 (* 1 = 0.0373545 loss)
I0416 20:57:52.601971 23299 sgd_solver.cpp:106] Iteration 42900, lr = 0.001
I0416 20:57:52.778524 23299 solver.cpp:237] Iteration 43000, loss = 0.0371317
I0416 20:57:52.778551 23299 solver.cpp:253]     Train net output #0: loss = 0.0371317 (* 1 = 0.0371317 loss)
I0416 20:57:52.778556 23299 sgd_solver.cpp:106] Iteration 43000, lr = 0.001
I0416 20:57:52.955009 23299 solver.cpp:237] Iteration 43100, loss = 0.0369522
I0416 20:57:52.955037 23299 solver.cpp:253]     Train net output #0: loss = 0.0369522 (* 1 = 0.0369522 loss)
I0416 20:57:52.955042 23299 sgd_solver.cpp:106] Iteration 43100, lr = 0.001
I0416 20:57:53.132273 23299 solver.cpp:237] Iteration 43200, loss = 0.0370196
I0416 20:57:53.132300 23299 solver.cpp:253]     Train net output #0: loss = 0.0370196 (* 1 = 0.0370196 loss)
I0416 20:57:53.132307 23299 sgd_solver.cpp:106] Iteration 43200, lr = 0.001
I0416 20:57:53.312119 23299 solver.cpp:237] Iteration 43300, loss = 0.0369422
I0416 20:57:53.312158 23299 solver.cpp:253]     Train net output #0: loss = 0.0369422 (* 1 = 0.0369422 loss)
I0416 20:57:53.312166 23299 sgd_solver.cpp:106] Iteration 43300, lr = 0.001
I0416 20:57:53.490010 23299 solver.cpp:237] Iteration 43400, loss = 0.0364943
I0416 20:57:53.490041 23299 solver.cpp:253]     Train net output #0: loss = 0.0364943 (* 1 = 0.0364943 loss)
I0416 20:57:53.490046 23299 sgd_solver.cpp:106] Iteration 43400, lr = 0.001
I0416 20:57:53.667827 23299 solver.cpp:237] Iteration 43500, loss = 0.0363067
I0416 20:57:53.667860 23299 solver.cpp:253]     Train net output #0: loss = 0.0363067 (* 1 = 0.0363067 loss)
I0416 20:57:53.667870 23299 sgd_solver.cpp:106] Iteration 43500, lr = 0.001
I0416 20:57:53.846012 23299 solver.cpp:237] Iteration 43600, loss = 0.0364789
I0416 20:57:53.846042 23299 solver.cpp:253]     Train net output #0: loss = 0.0364789 (* 1 = 0.0364789 loss)
I0416 20:57:53.846047 23299 sgd_solver.cpp:106] Iteration 43600, lr = 0.001
I0416 20:57:54.023556 23299 solver.cpp:237] Iteration 43700, loss = 0.0362203
I0416 20:57:54.023586 23299 solver.cpp:253]     Train net output #0: loss = 0.0362203 (* 1 = 0.0362203 loss)
I0416 20:57:54.023592 23299 sgd_solver.cpp:106] Iteration 43700, lr = 0.001
I0416 20:57:54.213670 23299 solver.cpp:237] Iteration 43800, loss = 0.0360123
I0416 20:57:54.213699 23299 solver.cpp:253]     Train net output #0: loss = 0.0360123 (* 1 = 0.0360123 loss)
I0416 20:57:54.213704 23299 sgd_solver.cpp:106] Iteration 43800, lr = 0.001
I0416 20:57:54.392324 23299 solver.cpp:237] Iteration 43900, loss = 0.0360293
I0416 20:57:54.392356 23299 solver.cpp:253]     Train net output #0: loss = 0.0360293 (* 1 = 0.0360293 loss)
I0416 20:57:54.392364 23299 sgd_solver.cpp:106] Iteration 43900, lr = 0.001
I0416 20:57:54.570581 23299 solver.cpp:237] Iteration 44000, loss = 0.0357357
I0416 20:57:54.570611 23299 solver.cpp:253]     Train net output #0: loss = 0.0357357 (* 1 = 0.0357357 loss)
I0416 20:57:54.570642 23299 sgd_solver.cpp:106] Iteration 44000, lr = 0.001
I0416 20:57:54.748248 23299 solver.cpp:237] Iteration 44100, loss = 0.0358528
I0416 20:57:54.748276 23299 solver.cpp:253]     Train net output #0: loss = 0.0358528 (* 1 = 0.0358528 loss)
I0416 20:57:54.748283 23299 sgd_solver.cpp:106] Iteration 44100, lr = 0.001
I0416 20:57:54.926125 23299 solver.cpp:237] Iteration 44200, loss = 0.0357464
I0416 20:57:54.926151 23299 solver.cpp:253]     Train net output #0: loss = 0.0357464 (* 1 = 0.0357464 loss)
I0416 20:57:54.926157 23299 sgd_solver.cpp:106] Iteration 44200, lr = 0.001
I0416 20:57:55.103102 23299 solver.cpp:237] Iteration 44300, loss = 0.035748
I0416 20:57:55.103129 23299 solver.cpp:253]     Train net output #0: loss = 0.035748 (* 1 = 0.035748 loss)
I0416 20:57:55.103137 23299 sgd_solver.cpp:106] Iteration 44300, lr = 0.001
I0416 20:57:55.280154 23299 solver.cpp:237] Iteration 44400, loss = 0.0356482
I0416 20:57:55.280181 23299 solver.cpp:253]     Train net output #0: loss = 0.0356482 (* 1 = 0.0356482 loss)
I0416 20:57:55.280186 23299 sgd_solver.cpp:106] Iteration 44400, lr = 0.001
I0416 20:57:55.457329 23299 solver.cpp:237] Iteration 44500, loss = 0.0354929
I0416 20:57:55.457360 23299 solver.cpp:253]     Train net output #0: loss = 0.0354929 (* 1 = 0.0354929 loss)
I0416 20:57:55.457365 23299 sgd_solver.cpp:106] Iteration 44500, lr = 0.001
I0416 20:57:55.636286 23299 solver.cpp:237] Iteration 44600, loss = 0.0353722
I0416 20:57:55.636315 23299 solver.cpp:253]     Train net output #0: loss = 0.0353722 (* 1 = 0.0353722 loss)
I0416 20:57:55.636320 23299 sgd_solver.cpp:106] Iteration 44600, lr = 0.001
I0416 20:57:55.813926 23299 solver.cpp:237] Iteration 44700, loss = 0.0356391
I0416 20:57:55.813954 23299 solver.cpp:253]     Train net output #0: loss = 0.0356391 (* 1 = 0.0356391 loss)
I0416 20:57:55.813961 23299 sgd_solver.cpp:106] Iteration 44700, lr = 0.001
I0416 20:57:55.991032 23299 solver.cpp:237] Iteration 44800, loss = 0.0354633
I0416 20:57:55.991060 23299 solver.cpp:253]     Train net output #0: loss = 0.0354633 (* 1 = 0.0354633 loss)
I0416 20:57:55.991065 23299 sgd_solver.cpp:106] Iteration 44800, lr = 0.001
I0416 20:57:56.168189 23299 solver.cpp:237] Iteration 44900, loss = 0.0354885
I0416 20:57:56.168215 23299 solver.cpp:253]     Train net output #0: loss = 0.0354885 (* 1 = 0.0354885 loss)
I0416 20:57:56.168220 23299 sgd_solver.cpp:106] Iteration 44900, lr = 0.001
I0416 20:57:56.343505 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_45000.caffemodel
I0416 20:57:56.345408 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_45000.solverstate
I0416 20:57:56.345939 23299 solver.cpp:341] Iteration 45000, Testing net (#0)
I0416 20:57:56.345949 23299 net.cpp:748] Ignoring source layer dart
I0416 20:57:56.388495 23299 solver.cpp:409]     Test net output #0: accuracy = 0.8135
I0416 20:57:56.388516 23299 solver.cpp:409]     Test net output #1: loss = 0.62613 (* 1 = 0.62613 loss)
I0416 20:57:56.389305 23299 solver.cpp:237] Iteration 45000, loss = 0.0352682
I0416 20:57:56.389320 23299 solver.cpp:253]     Train net output #0: loss = 0.0352682 (* 1 = 0.0352682 loss)
I0416 20:57:56.389325 23299 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I0416 20:57:56.565765 23299 solver.cpp:237] Iteration 45100, loss = 0.0352055
I0416 20:57:56.565793 23299 solver.cpp:253]     Train net output #0: loss = 0.0352055 (* 1 = 0.0352055 loss)
I0416 20:57:56.565799 23299 sgd_solver.cpp:106] Iteration 45100, lr = 0.001
I0416 20:57:56.742254 23299 solver.cpp:237] Iteration 45200, loss = 0.0353043
I0416 20:57:56.742280 23299 solver.cpp:253]     Train net output #0: loss = 0.0353043 (* 1 = 0.0353043 loss)
I0416 20:57:56.742285 23299 sgd_solver.cpp:106] Iteration 45200, lr = 0.001
I0416 20:57:56.919456 23299 solver.cpp:237] Iteration 45300, loss = 0.0351885
I0416 20:57:56.919482 23299 solver.cpp:253]     Train net output #0: loss = 0.0351885 (* 1 = 0.0351885 loss)
I0416 20:57:56.919488 23299 sgd_solver.cpp:106] Iteration 45300, lr = 0.001
I0416 20:57:57.095927 23299 solver.cpp:237] Iteration 45400, loss = 0.0350461
I0416 20:57:57.095955 23299 solver.cpp:253]     Train net output #0: loss = 0.0350461 (* 1 = 0.0350461 loss)
I0416 20:57:57.095962 23299 sgd_solver.cpp:106] Iteration 45400, lr = 0.001
I0416 20:57:57.272465 23299 solver.cpp:237] Iteration 45500, loss = 0.0349002
I0416 20:57:57.272492 23299 solver.cpp:253]     Train net output #0: loss = 0.0349002 (* 1 = 0.0349002 loss)
I0416 20:57:57.272497 23299 sgd_solver.cpp:106] Iteration 45500, lr = 0.001
I0416 20:57:57.448797 23299 solver.cpp:237] Iteration 45600, loss = 0.0348484
I0416 20:57:57.448824 23299 solver.cpp:253]     Train net output #0: loss = 0.0348484 (* 1 = 0.0348484 loss)
I0416 20:57:57.448829 23299 sgd_solver.cpp:106] Iteration 45600, lr = 0.001
I0416 20:57:57.624603 23299 solver.cpp:237] Iteration 45700, loss = 0.0346588
I0416 20:57:57.624629 23299 solver.cpp:253]     Train net output #0: loss = 0.0346588 (* 1 = 0.0346588 loss)
I0416 20:57:57.624634 23299 sgd_solver.cpp:106] Iteration 45700, lr = 0.001
I0416 20:57:57.800747 23299 solver.cpp:237] Iteration 45800, loss = 0.0345863
I0416 20:57:57.800775 23299 solver.cpp:253]     Train net output #0: loss = 0.0345863 (* 1 = 0.0345863 loss)
I0416 20:57:57.800779 23299 sgd_solver.cpp:106] Iteration 45800, lr = 0.001
I0416 20:57:57.977819 23299 solver.cpp:237] Iteration 45900, loss = 0.0342401
I0416 20:57:57.977845 23299 solver.cpp:253]     Train net output #0: loss = 0.0342401 (* 1 = 0.0342401 loss)
I0416 20:57:57.977850 23299 sgd_solver.cpp:106] Iteration 45900, lr = 0.001
I0416 20:57:58.156499 23299 solver.cpp:237] Iteration 46000, loss = 0.0341012
I0416 20:57:58.156527 23299 solver.cpp:253]     Train net output #0: loss = 0.0341012 (* 1 = 0.0341012 loss)
I0416 20:57:58.156533 23299 sgd_solver.cpp:106] Iteration 46000, lr = 0.001
I0416 20:57:58.336556 23299 solver.cpp:237] Iteration 46100, loss = 0.0339142
I0416 20:57:58.336583 23299 solver.cpp:253]     Train net output #0: loss = 0.0339142 (* 1 = 0.0339142 loss)
I0416 20:57:58.336588 23299 sgd_solver.cpp:106] Iteration 46100, lr = 0.001
I0416 20:57:58.517850 23299 solver.cpp:237] Iteration 46200, loss = 0.0335954
I0416 20:57:58.517877 23299 solver.cpp:253]     Train net output #0: loss = 0.0335954 (* 1 = 0.0335954 loss)
I0416 20:57:58.517882 23299 sgd_solver.cpp:106] Iteration 46200, lr = 0.001
I0416 20:57:58.700844 23299 solver.cpp:237] Iteration 46300, loss = 0.0335524
I0416 20:57:58.700870 23299 solver.cpp:253]     Train net output #0: loss = 0.0335524 (* 1 = 0.0335524 loss)
I0416 20:57:58.700875 23299 sgd_solver.cpp:106] Iteration 46300, lr = 0.001
I0416 20:57:58.885525 23299 solver.cpp:237] Iteration 46400, loss = 0.0330926
I0416 20:57:58.885550 23299 solver.cpp:253]     Train net output #0: loss = 0.0330926 (* 1 = 0.0330926 loss)
I0416 20:57:58.885555 23299 sgd_solver.cpp:106] Iteration 46400, lr = 0.001
I0416 20:57:59.072432 23299 solver.cpp:237] Iteration 46500, loss = 0.0329975
I0416 20:57:59.072458 23299 solver.cpp:253]     Train net output #0: loss = 0.0329975 (* 1 = 0.0329975 loss)
I0416 20:57:59.072463 23299 sgd_solver.cpp:106] Iteration 46500, lr = 0.001
I0416 20:57:59.260124 23299 solver.cpp:237] Iteration 46600, loss = 0.0326295
I0416 20:57:59.260151 23299 solver.cpp:253]     Train net output #0: loss = 0.0326295 (* 1 = 0.0326295 loss)
I0416 20:57:59.260157 23299 sgd_solver.cpp:106] Iteration 46600, lr = 0.001
I0416 20:57:59.454192 23299 solver.cpp:237] Iteration 46700, loss = 0.0325294
I0416 20:57:59.454232 23299 solver.cpp:253]     Train net output #0: loss = 0.0325294 (* 1 = 0.0325294 loss)
I0416 20:57:59.454241 23299 sgd_solver.cpp:106] Iteration 46700, lr = 0.001
I0416 20:57:59.648866 23299 solver.cpp:237] Iteration 46800, loss = 0.0322803
I0416 20:57:59.648906 23299 solver.cpp:253]     Train net output #0: loss = 0.0322803 (* 1 = 0.0322803 loss)
I0416 20:57:59.648913 23299 sgd_solver.cpp:106] Iteration 46800, lr = 0.001
I0416 20:57:59.842183 23299 solver.cpp:237] Iteration 46900, loss = 0.032042
I0416 20:57:59.842214 23299 solver.cpp:253]     Train net output #0: loss = 0.032042 (* 1 = 0.032042 loss)
I0416 20:57:59.842252 23299 sgd_solver.cpp:106] Iteration 46900, lr = 0.001
I0416 20:58:00.036770 23299 solver.cpp:237] Iteration 47000, loss = 0.03185
I0416 20:58:00.036800 23299 solver.cpp:253]     Train net output #0: loss = 0.03185 (* 1 = 0.03185 loss)
I0416 20:58:00.036808 23299 sgd_solver.cpp:106] Iteration 47000, lr = 0.001
I0416 20:58:00.233544 23299 solver.cpp:237] Iteration 47100, loss = 0.0315149
I0416 20:58:00.233577 23299 solver.cpp:253]     Train net output #0: loss = 0.0315149 (* 1 = 0.0315149 loss)
I0416 20:58:00.233589 23299 sgd_solver.cpp:106] Iteration 47100, lr = 0.001
I0416 20:58:00.429863 23299 solver.cpp:237] Iteration 47200, loss = 0.031284
I0416 20:58:00.429893 23299 solver.cpp:253]     Train net output #0: loss = 0.031284 (* 1 = 0.031284 loss)
I0416 20:58:00.429901 23299 sgd_solver.cpp:106] Iteration 47200, lr = 0.001
I0416 20:58:00.626251 23299 solver.cpp:237] Iteration 47300, loss = 0.031174
I0416 20:58:00.626284 23299 solver.cpp:253]     Train net output #0: loss = 0.031174 (* 1 = 0.031174 loss)
I0416 20:58:00.626291 23299 sgd_solver.cpp:106] Iteration 47300, lr = 0.001
I0416 20:58:00.821887 23299 solver.cpp:237] Iteration 47400, loss = 0.0307419
I0416 20:58:00.821915 23299 solver.cpp:253]     Train net output #0: loss = 0.0307419 (* 1 = 0.0307419 loss)
I0416 20:58:00.821923 23299 sgd_solver.cpp:106] Iteration 47400, lr = 0.001
I0416 20:58:01.018585 23299 solver.cpp:237] Iteration 47500, loss = 0.0307218
I0416 20:58:01.018620 23299 solver.cpp:253]     Train net output #0: loss = 0.0307218 (* 1 = 0.0307218 loss)
I0416 20:58:01.018641 23299 sgd_solver.cpp:106] Iteration 47500, lr = 0.001
I0416 20:58:01.220837 23299 solver.cpp:237] Iteration 47600, loss = 0.0305084
I0416 20:58:01.220878 23299 solver.cpp:253]     Train net output #0: loss = 0.0305084 (* 1 = 0.0305084 loss)
I0416 20:58:01.220886 23299 sgd_solver.cpp:106] Iteration 47600, lr = 0.001
I0416 20:58:01.418335 23299 solver.cpp:237] Iteration 47700, loss = 0.0302759
I0416 20:58:01.418367 23299 solver.cpp:253]     Train net output #0: loss = 0.0302759 (* 1 = 0.0302759 loss)
I0416 20:58:01.418375 23299 sgd_solver.cpp:106] Iteration 47700, lr = 0.001
I0416 20:58:01.614598 23299 solver.cpp:237] Iteration 47800, loss = 0.0300516
I0416 20:58:01.614629 23299 solver.cpp:253]     Train net output #0: loss = 0.0300516 (* 1 = 0.0300516 loss)
I0416 20:58:01.614634 23299 sgd_solver.cpp:106] Iteration 47800, lr = 0.001
I0416 20:58:01.810348 23299 solver.cpp:237] Iteration 47900, loss = 0.0298146
I0416 20:58:01.810379 23299 solver.cpp:253]     Train net output #0: loss = 0.0298146 (* 1 = 0.0298146 loss)
I0416 20:58:01.810384 23299 sgd_solver.cpp:106] Iteration 47900, lr = 0.001
I0416 20:58:02.007266 23299 solver.cpp:237] Iteration 48000, loss = 0.0296381
I0416 20:58:02.007297 23299 solver.cpp:253]     Train net output #0: loss = 0.0296381 (* 1 = 0.0296381 loss)
I0416 20:58:02.007303 23299 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I0416 20:58:02.203788 23299 solver.cpp:237] Iteration 48100, loss = 0.0295123
I0416 20:58:02.203820 23299 solver.cpp:253]     Train net output #0: loss = 0.0295123 (* 1 = 0.0295123 loss)
I0416 20:58:02.203826 23299 sgd_solver.cpp:106] Iteration 48100, lr = 0.001
I0416 20:58:02.399531 23299 solver.cpp:237] Iteration 48200, loss = 0.029369
I0416 20:58:02.399561 23299 solver.cpp:253]     Train net output #0: loss = 0.029369 (* 1 = 0.029369 loss)
I0416 20:58:02.399569 23299 sgd_solver.cpp:106] Iteration 48200, lr = 0.001
I0416 20:58:02.594820 23299 solver.cpp:237] Iteration 48300, loss = 0.0292397
I0416 20:58:02.594847 23299 solver.cpp:253]     Train net output #0: loss = 0.0292397 (* 1 = 0.0292397 loss)
I0416 20:58:02.594859 23299 sgd_solver.cpp:106] Iteration 48300, lr = 0.001
I0416 20:58:02.790909 23299 solver.cpp:237] Iteration 48400, loss = 0.0289593
I0416 20:58:02.790936 23299 solver.cpp:253]     Train net output #0: loss = 0.0289593 (* 1 = 0.0289593 loss)
I0416 20:58:02.790941 23299 sgd_solver.cpp:106] Iteration 48400, lr = 0.001
I0416 20:58:02.986480 23299 solver.cpp:237] Iteration 48500, loss = 0.0288633
I0416 20:58:02.986508 23299 solver.cpp:253]     Train net output #0: loss = 0.0288633 (* 1 = 0.0288633 loss)
I0416 20:58:02.986515 23299 sgd_solver.cpp:106] Iteration 48500, lr = 0.001
I0416 20:58:03.182332 23299 solver.cpp:237] Iteration 48600, loss = 0.0287015
I0416 20:58:03.182359 23299 solver.cpp:253]     Train net output #0: loss = 0.0287015 (* 1 = 0.0287015 loss)
I0416 20:58:03.182365 23299 sgd_solver.cpp:106] Iteration 48600, lr = 0.001
I0416 20:58:03.377816 23299 solver.cpp:237] Iteration 48700, loss = 0.0287076
I0416 20:58:03.377846 23299 solver.cpp:253]     Train net output #0: loss = 0.0287076 (* 1 = 0.0287076 loss)
I0416 20:58:03.377851 23299 sgd_solver.cpp:106] Iteration 48700, lr = 0.001
I0416 20:58:03.573037 23299 solver.cpp:237] Iteration 48800, loss = 0.0284043
I0416 20:58:03.573065 23299 solver.cpp:253]     Train net output #0: loss = 0.0284043 (* 1 = 0.0284043 loss)
I0416 20:58:03.573070 23299 sgd_solver.cpp:106] Iteration 48800, lr = 0.001
I0416 20:58:03.768421 23299 solver.cpp:237] Iteration 48900, loss = 0.0283353
I0416 20:58:03.768450 23299 solver.cpp:253]     Train net output #0: loss = 0.0283353 (* 1 = 0.0283353 loss)
I0416 20:58:03.768455 23299 sgd_solver.cpp:106] Iteration 48900, lr = 0.001
I0416 20:58:03.963996 23299 solver.cpp:237] Iteration 49000, loss = 0.0283085
I0416 20:58:03.964025 23299 solver.cpp:253]     Train net output #0: loss = 0.0283085 (* 1 = 0.0283085 loss)
I0416 20:58:03.964030 23299 sgd_solver.cpp:106] Iteration 49000, lr = 0.001
I0416 20:58:04.159217 23299 solver.cpp:237] Iteration 49100, loss = 0.0281373
I0416 20:58:04.159246 23299 solver.cpp:253]     Train net output #0: loss = 0.0281373 (* 1 = 0.0281373 loss)
I0416 20:58:04.159252 23299 sgd_solver.cpp:106] Iteration 49100, lr = 0.001
I0416 20:58:04.354962 23299 solver.cpp:237] Iteration 49200, loss = 0.0279135
I0416 20:58:04.354990 23299 solver.cpp:253]     Train net output #0: loss = 0.0279135 (* 1 = 0.0279135 loss)
I0416 20:58:04.354996 23299 sgd_solver.cpp:106] Iteration 49200, lr = 0.001
I0416 20:58:04.550065 23299 solver.cpp:237] Iteration 49300, loss = 0.0279358
I0416 20:58:04.550092 23299 solver.cpp:253]     Train net output #0: loss = 0.0279358 (* 1 = 0.0279358 loss)
I0416 20:58:04.550097 23299 sgd_solver.cpp:106] Iteration 49300, lr = 0.001
I0416 20:58:04.746207 23299 solver.cpp:237] Iteration 49400, loss = 0.0277162
I0416 20:58:04.746235 23299 solver.cpp:253]     Train net output #0: loss = 0.0277162 (* 1 = 0.0277162 loss)
I0416 20:58:04.746242 23299 sgd_solver.cpp:106] Iteration 49400, lr = 0.001
I0416 20:58:04.943229 23299 solver.cpp:237] Iteration 49500, loss = 0.0276055
I0416 20:58:04.943256 23299 solver.cpp:253]     Train net output #0: loss = 0.0276055 (* 1 = 0.0276055 loss)
I0416 20:58:04.943261 23299 sgd_solver.cpp:106] Iteration 49500, lr = 0.001
I0416 20:58:05.139080 23299 solver.cpp:237] Iteration 49600, loss = 0.027453
I0416 20:58:05.139107 23299 solver.cpp:253]     Train net output #0: loss = 0.027453 (* 1 = 0.027453 loss)
I0416 20:58:05.139112 23299 sgd_solver.cpp:106] Iteration 49600, lr = 0.001
I0416 20:58:05.334882 23299 solver.cpp:237] Iteration 49700, loss = 0.0274054
I0416 20:58:05.334913 23299 solver.cpp:253]     Train net output #0: loss = 0.0274054 (* 1 = 0.0274054 loss)
I0416 20:58:05.334921 23299 sgd_solver.cpp:106] Iteration 49700, lr = 0.001
I0416 20:58:05.532821 23299 solver.cpp:237] Iteration 49800, loss = 0.0270797
I0416 20:58:05.532876 23299 solver.cpp:253]     Train net output #0: loss = 0.0270797 (* 1 = 0.0270797 loss)
I0416 20:58:05.532889 23299 sgd_solver.cpp:106] Iteration 49800, lr = 0.001
I0416 20:58:05.733144 23299 solver.cpp:237] Iteration 49900, loss = 0.0269678
I0416 20:58:05.733178 23299 solver.cpp:253]     Train net output #0: loss = 0.0269678 (* 1 = 0.0269678 loss)
I0416 20:58:05.733185 23299 sgd_solver.cpp:106] Iteration 49900, lr = 0.001
I0416 20:58:05.927012 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_50000.caffemodel
I0416 20:58:05.929119 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_50000.solverstate
I0416 20:58:05.929736 23299 solver.cpp:341] Iteration 50000, Testing net (#0)
I0416 20:58:05.929749 23299 net.cpp:748] Ignoring source layer dart
I0416 20:58:05.976246 23299 solver.cpp:409]     Test net output #0: accuracy = 0.8145
I0416 20:58:05.976269 23299 solver.cpp:409]     Test net output #1: loss = 0.639281 (* 1 = 0.639281 loss)
I0416 20:58:05.977138 23299 solver.cpp:237] Iteration 50000, loss = 0.0270398
I0416 20:58:05.977154 23299 solver.cpp:253]     Train net output #0: loss = 0.0270398 (* 1 = 0.0270398 loss)
I0416 20:58:05.977164 23299 sgd_solver.cpp:106] Iteration 50000, lr = 0.001
I0416 20:58:06.172755 23299 solver.cpp:237] Iteration 50100, loss = 0.0268118
I0416 20:58:06.172904 23299 solver.cpp:253]     Train net output #0: loss = 0.0268118 (* 1 = 0.0268118 loss)
I0416 20:58:06.172912 23299 sgd_solver.cpp:106] Iteration 50100, lr = 0.001
I0416 20:58:06.368283 23299 solver.cpp:237] Iteration 50200, loss = 0.0268085
I0416 20:58:06.368314 23299 solver.cpp:253]     Train net output #0: loss = 0.0268085 (* 1 = 0.0268085 loss)
I0416 20:58:06.368324 23299 sgd_solver.cpp:106] Iteration 50200, lr = 0.001
I0416 20:58:06.564944 23299 solver.cpp:237] Iteration 50300, loss = 0.0266772
I0416 20:58:06.564980 23299 solver.cpp:253]     Train net output #0: loss = 0.0266772 (* 1 = 0.0266772 loss)
I0416 20:58:06.564986 23299 sgd_solver.cpp:106] Iteration 50300, lr = 0.001
I0416 20:58:06.761283 23299 solver.cpp:237] Iteration 50400, loss = 0.0264801
I0416 20:58:06.761315 23299 solver.cpp:253]     Train net output #0: loss = 0.0264801 (* 1 = 0.0264801 loss)
I0416 20:58:06.761322 23299 sgd_solver.cpp:106] Iteration 50400, lr = 0.001
I0416 20:58:06.957425 23299 solver.cpp:237] Iteration 50500, loss = 0.0265248
I0416 20:58:06.957455 23299 solver.cpp:253]     Train net output #0: loss = 0.0265248 (* 1 = 0.0265248 loss)
I0416 20:58:06.957464 23299 sgd_solver.cpp:106] Iteration 50500, lr = 0.001
I0416 20:58:07.153743 23299 solver.cpp:237] Iteration 50600, loss = 0.0262873
I0416 20:58:07.153774 23299 solver.cpp:253]     Train net output #0: loss = 0.0262873 (* 1 = 0.0262873 loss)
I0416 20:58:07.153779 23299 sgd_solver.cpp:106] Iteration 50600, lr = 0.001
I0416 20:58:07.348963 23299 solver.cpp:237] Iteration 50700, loss = 0.0262124
I0416 20:58:07.348994 23299 solver.cpp:253]     Train net output #0: loss = 0.0262124 (* 1 = 0.0262124 loss)
I0416 20:58:07.349000 23299 sgd_solver.cpp:106] Iteration 50700, lr = 0.001
I0416 20:58:07.544397 23299 solver.cpp:237] Iteration 50800, loss = 0.0261353
I0416 20:58:07.544428 23299 solver.cpp:253]     Train net output #0: loss = 0.0261353 (* 1 = 0.0261353 loss)
I0416 20:58:07.544440 23299 sgd_solver.cpp:106] Iteration 50800, lr = 0.001
I0416 20:58:07.740316 23299 solver.cpp:237] Iteration 50900, loss = 0.0260024
I0416 20:58:07.740348 23299 solver.cpp:253]     Train net output #0: loss = 0.0260024 (* 1 = 0.0260024 loss)
I0416 20:58:07.740362 23299 sgd_solver.cpp:106] Iteration 50900, lr = 0.001
I0416 20:58:07.937965 23299 solver.cpp:237] Iteration 51000, loss = 0.0259608
I0416 20:58:07.938019 23299 solver.cpp:253]     Train net output #0: loss = 0.0259608 (* 1 = 0.0259608 loss)
I0416 20:58:07.938031 23299 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I0416 20:58:08.134670 23299 solver.cpp:237] Iteration 51100, loss = 0.0259035
I0416 20:58:08.134702 23299 solver.cpp:253]     Train net output #0: loss = 0.0259035 (* 1 = 0.0259035 loss)
I0416 20:58:08.134709 23299 sgd_solver.cpp:106] Iteration 51100, lr = 0.001
I0416 20:58:08.329686 23299 solver.cpp:237] Iteration 51200, loss = 0.0257249
I0416 20:58:08.329712 23299 solver.cpp:253]     Train net output #0: loss = 0.0257249 (* 1 = 0.0257249 loss)
I0416 20:58:08.329717 23299 sgd_solver.cpp:106] Iteration 51200, lr = 0.001
I0416 20:58:08.524919 23299 solver.cpp:237] Iteration 51300, loss = 0.0256813
I0416 20:58:08.524950 23299 solver.cpp:253]     Train net output #0: loss = 0.0256813 (* 1 = 0.0256813 loss)
I0416 20:58:08.524955 23299 sgd_solver.cpp:106] Iteration 51300, lr = 0.001
I0416 20:58:08.722090 23299 solver.cpp:237] Iteration 51400, loss = 0.0254741
I0416 20:58:08.722157 23299 solver.cpp:253]     Train net output #0: loss = 0.0254741 (* 1 = 0.0254741 loss)
I0416 20:58:08.722174 23299 sgd_solver.cpp:106] Iteration 51400, lr = 0.001
I0416 20:58:08.922117 23299 solver.cpp:237] Iteration 51500, loss = 0.0254647
I0416 20:58:08.922150 23299 solver.cpp:253]     Train net output #0: loss = 0.0254647 (* 1 = 0.0254647 loss)
I0416 20:58:08.922157 23299 sgd_solver.cpp:106] Iteration 51500, lr = 0.001
I0416 20:58:09.119251 23299 solver.cpp:237] Iteration 51600, loss = 0.0253203
I0416 20:58:09.119283 23299 solver.cpp:253]     Train net output #0: loss = 0.0253203 (* 1 = 0.0253203 loss)
I0416 20:58:09.119290 23299 sgd_solver.cpp:106] Iteration 51600, lr = 0.001
I0416 20:58:09.314954 23299 solver.cpp:237] Iteration 51700, loss = 0.0251729
I0416 20:58:09.314983 23299 solver.cpp:253]     Train net output #0: loss = 0.0251729 (* 1 = 0.0251729 loss)
I0416 20:58:09.314988 23299 sgd_solver.cpp:106] Iteration 51700, lr = 0.001
I0416 20:58:09.511188 23299 solver.cpp:237] Iteration 51800, loss = 0.0251501
I0416 20:58:09.511221 23299 solver.cpp:253]     Train net output #0: loss = 0.0251501 (* 1 = 0.0251501 loss)
I0416 20:58:09.511230 23299 sgd_solver.cpp:106] Iteration 51800, lr = 0.001
I0416 20:58:09.706915 23299 solver.cpp:237] Iteration 51900, loss = 0.0249654
I0416 20:58:09.706945 23299 solver.cpp:253]     Train net output #0: loss = 0.0249654 (* 1 = 0.0249654 loss)
I0416 20:58:09.706954 23299 sgd_solver.cpp:106] Iteration 51900, lr = 0.001
I0416 20:58:09.903993 23299 solver.cpp:237] Iteration 52000, loss = 0.02493
I0416 20:58:09.904026 23299 solver.cpp:253]     Train net output #0: loss = 0.02493 (* 1 = 0.02493 loss)
I0416 20:58:09.904039 23299 sgd_solver.cpp:106] Iteration 52000, lr = 0.001
I0416 20:58:10.102377 23299 solver.cpp:237] Iteration 52100, loss = 0.0248407
I0416 20:58:10.102412 23299 solver.cpp:253]     Train net output #0: loss = 0.0248407 (* 1 = 0.0248407 loss)
I0416 20:58:10.102421 23299 sgd_solver.cpp:106] Iteration 52100, lr = 0.001
I0416 20:58:10.298324 23299 solver.cpp:237] Iteration 52200, loss = 0.0248148
I0416 20:58:10.298355 23299 solver.cpp:253]     Train net output #0: loss = 0.0248148 (* 1 = 0.0248148 loss)
I0416 20:58:10.298362 23299 sgd_solver.cpp:106] Iteration 52200, lr = 0.001
I0416 20:58:10.494557 23299 solver.cpp:237] Iteration 52300, loss = 0.024593
I0416 20:58:10.494590 23299 solver.cpp:253]     Train net output #0: loss = 0.024593 (* 1 = 0.024593 loss)
I0416 20:58:10.494596 23299 sgd_solver.cpp:106] Iteration 52300, lr = 0.001
I0416 20:58:10.690685 23299 solver.cpp:237] Iteration 52400, loss = 0.024555
I0416 20:58:10.690717 23299 solver.cpp:253]     Train net output #0: loss = 0.024555 (* 1 = 0.024555 loss)
I0416 20:58:10.690723 23299 sgd_solver.cpp:106] Iteration 52400, lr = 0.001
I0416 20:58:10.886670 23299 solver.cpp:237] Iteration 52500, loss = 0.024525
I0416 20:58:10.886701 23299 solver.cpp:253]     Train net output #0: loss = 0.024525 (* 1 = 0.024525 loss)
I0416 20:58:10.886713 23299 sgd_solver.cpp:106] Iteration 52500, lr = 0.001
I0416 20:58:11.083514 23299 solver.cpp:237] Iteration 52600, loss = 0.0244606
I0416 20:58:11.083583 23299 solver.cpp:253]     Train net output #0: loss = 0.0244606 (* 1 = 0.0244606 loss)
I0416 20:58:11.083600 23299 sgd_solver.cpp:106] Iteration 52600, lr = 0.001
I0416 20:58:11.280458 23299 solver.cpp:237] Iteration 52700, loss = 0.0243574
I0416 20:58:11.280488 23299 solver.cpp:253]     Train net output #0: loss = 0.0243574 (* 1 = 0.0243574 loss)
I0416 20:58:11.280498 23299 sgd_solver.cpp:106] Iteration 52700, lr = 0.001
I0416 20:58:11.474915 23299 solver.cpp:237] Iteration 52800, loss = 0.0243729
I0416 20:58:11.474942 23299 solver.cpp:253]     Train net output #0: loss = 0.0243729 (* 1 = 0.0243729 loss)
I0416 20:58:11.474951 23299 sgd_solver.cpp:106] Iteration 52800, lr = 0.001
I0416 20:58:11.669752 23299 solver.cpp:237] Iteration 52900, loss = 0.0242402
I0416 20:58:11.669780 23299 solver.cpp:253]     Train net output #0: loss = 0.0242402 (* 1 = 0.0242402 loss)
I0416 20:58:11.669788 23299 sgd_solver.cpp:106] Iteration 52900, lr = 0.001
I0416 20:58:11.691274 23299 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 20:58:11.865140 23299 solver.cpp:237] Iteration 53000, loss = 0.0241309
I0416 20:58:11.865170 23299 solver.cpp:253]     Train net output #0: loss = 0.0241309 (* 1 = 0.0241309 loss)
I0416 20:58:11.865175 23299 sgd_solver.cpp:106] Iteration 53000, lr = 0.001
I0416 20:58:12.061185 23299 solver.cpp:237] Iteration 53100, loss = 0.0240636
I0416 20:58:12.061218 23299 solver.cpp:253]     Train net output #0: loss = 0.0240636 (* 1 = 0.0240636 loss)
I0416 20:58:12.061225 23299 sgd_solver.cpp:106] Iteration 53100, lr = 0.001
I0416 20:58:12.257019 23299 solver.cpp:237] Iteration 53200, loss = 0.0240197
I0416 20:58:12.257071 23299 solver.cpp:253]     Train net output #0: loss = 0.0240197 (* 1 = 0.0240197 loss)
I0416 20:58:12.257078 23299 sgd_solver.cpp:106] Iteration 53200, lr = 0.001
I0416 20:58:12.452317 23299 solver.cpp:237] Iteration 53300, loss = 0.0239617
I0416 20:58:12.452347 23299 solver.cpp:253]     Train net output #0: loss = 0.0239617 (* 1 = 0.0239617 loss)
I0416 20:58:12.452355 23299 sgd_solver.cpp:106] Iteration 53300, lr = 0.001
I0416 20:58:12.647976 23299 solver.cpp:237] Iteration 53400, loss = 0.0238547
I0416 20:58:12.648008 23299 solver.cpp:253]     Train net output #0: loss = 0.0238547 (* 1 = 0.0238547 loss)
I0416 20:58:12.648015 23299 sgd_solver.cpp:106] Iteration 53400, lr = 0.001
I0416 20:58:12.844161 23299 solver.cpp:237] Iteration 53500, loss = 0.0238639
I0416 20:58:12.844188 23299 solver.cpp:253]     Train net output #0: loss = 0.0238639 (* 1 = 0.0238639 loss)
I0416 20:58:12.844193 23299 sgd_solver.cpp:106] Iteration 53500, lr = 0.001
I0416 20:58:13.040101 23299 solver.cpp:237] Iteration 53600, loss = 0.0237538
I0416 20:58:13.040128 23299 solver.cpp:253]     Train net output #0: loss = 0.0237538 (* 1 = 0.0237538 loss)
I0416 20:58:13.040139 23299 sgd_solver.cpp:106] Iteration 53600, lr = 0.001
I0416 20:58:13.235816 23299 solver.cpp:237] Iteration 53700, loss = 0.0236873
I0416 20:58:13.235849 23299 solver.cpp:253]     Train net output #0: loss = 0.0236873 (* 1 = 0.0236873 loss)
I0416 20:58:13.235863 23299 sgd_solver.cpp:106] Iteration 53700, lr = 0.001
I0416 20:58:13.431591 23299 solver.cpp:237] Iteration 53800, loss = 0.0236329
I0416 20:58:13.431617 23299 solver.cpp:253]     Train net output #0: loss = 0.0236329 (* 1 = 0.0236329 loss)
I0416 20:58:13.431623 23299 sgd_solver.cpp:106] Iteration 53800, lr = 0.001
I0416 20:58:13.627245 23299 solver.cpp:237] Iteration 53900, loss = 0.0235467
I0416 20:58:13.627272 23299 solver.cpp:253]     Train net output #0: loss = 0.0235467 (* 1 = 0.0235467 loss)
I0416 20:58:13.627277 23299 sgd_solver.cpp:106] Iteration 53900, lr = 0.001
I0416 20:58:13.822871 23299 solver.cpp:237] Iteration 54000, loss = 0.0235752
I0416 20:58:13.822897 23299 solver.cpp:253]     Train net output #0: loss = 0.0235752 (* 1 = 0.0235752 loss)
I0416 20:58:13.822902 23299 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I0416 20:58:14.026468 23299 solver.cpp:237] Iteration 54100, loss = 0.0234641
I0416 20:58:14.026520 23299 solver.cpp:253]     Train net output #0: loss = 0.0234641 (* 1 = 0.0234641 loss)
I0416 20:58:14.026530 23299 sgd_solver.cpp:106] Iteration 54100, lr = 0.001
I0416 20:58:14.226057 23299 solver.cpp:237] Iteration 54200, loss = 0.0234216
I0416 20:58:14.226092 23299 solver.cpp:253]     Train net output #0: loss = 0.0234216 (* 1 = 0.0234216 loss)
I0416 20:58:14.226099 23299 sgd_solver.cpp:106] Iteration 54200, lr = 0.001
I0416 20:58:14.427960 23299 solver.cpp:237] Iteration 54300, loss = 0.0233982
I0416 20:58:14.428017 23299 solver.cpp:253]     Train net output #0: loss = 0.0233982 (* 1 = 0.0233982 loss)
I0416 20:58:14.428025 23299 sgd_solver.cpp:106] Iteration 54300, lr = 0.001
I0416 20:58:14.627686 23299 solver.cpp:237] Iteration 54400, loss = 0.0233226
I0416 20:58:14.627727 23299 solver.cpp:253]     Train net output #0: loss = 0.0233226 (* 1 = 0.0233226 loss)
I0416 20:58:14.627734 23299 sgd_solver.cpp:106] Iteration 54400, lr = 0.001
I0416 20:58:14.824657 23299 solver.cpp:237] Iteration 54500, loss = 0.0231839
I0416 20:58:14.824688 23299 solver.cpp:253]     Train net output #0: loss = 0.0231839 (* 1 = 0.0231839 loss)
I0416 20:58:14.824693 23299 sgd_solver.cpp:106] Iteration 54500, lr = 0.001
I0416 20:58:15.021896 23299 solver.cpp:237] Iteration 54600, loss = 0.0231758
I0416 20:58:15.021929 23299 solver.cpp:253]     Train net output #0: loss = 0.0231758 (* 1 = 0.0231758 loss)
I0416 20:58:15.021934 23299 sgd_solver.cpp:106] Iteration 54600, lr = 0.001
I0416 20:58:15.217994 23299 solver.cpp:237] Iteration 54700, loss = 0.0231261
I0416 20:58:15.218024 23299 solver.cpp:253]     Train net output #0: loss = 0.0231261 (* 1 = 0.0231261 loss)
I0416 20:58:15.218030 23299 sgd_solver.cpp:106] Iteration 54700, lr = 0.001
I0416 20:58:15.413866 23299 solver.cpp:237] Iteration 54800, loss = 0.0230239
I0416 20:58:15.413897 23299 solver.cpp:253]     Train net output #0: loss = 0.0230239 (* 1 = 0.0230239 loss)
I0416 20:58:15.413903 23299 sgd_solver.cpp:106] Iteration 54800, lr = 0.001
I0416 20:58:15.610214 23299 solver.cpp:237] Iteration 54900, loss = 0.023002
I0416 20:58:15.610245 23299 solver.cpp:253]     Train net output #0: loss = 0.023002 (* 1 = 0.023002 loss)
I0416 20:58:15.610255 23299 sgd_solver.cpp:106] Iteration 54900, lr = 0.001
I0416 20:58:15.805280 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_55000.caffemodel
I0416 20:58:15.807369 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_55000.solverstate
I0416 20:58:15.807950 23299 solver.cpp:341] Iteration 55000, Testing net (#0)
I0416 20:58:15.807962 23299 net.cpp:748] Ignoring source layer dart
I0416 20:58:15.855005 23299 solver.cpp:409]     Test net output #0: accuracy = 0.8115
I0416 20:58:15.855031 23299 solver.cpp:409]     Test net output #1: loss = 0.657633 (* 1 = 0.657633 loss)
I0416 20:58:15.855891 23299 solver.cpp:237] Iteration 55000, loss = 0.022933
I0416 20:58:15.855911 23299 solver.cpp:253]     Train net output #0: loss = 0.022933 (* 1 = 0.022933 loss)
I0416 20:58:15.855919 23299 sgd_solver.cpp:106] Iteration 55000, lr = 0.001
I0416 20:58:16.052369 23299 solver.cpp:237] Iteration 55100, loss = 0.0229831
I0416 20:58:16.052402 23299 solver.cpp:253]     Train net output #0: loss = 0.0229831 (* 1 = 0.0229831 loss)
I0416 20:58:16.052407 23299 sgd_solver.cpp:106] Iteration 55100, lr = 0.001
I0416 20:58:16.248402 23299 solver.cpp:237] Iteration 55200, loss = 0.022852
I0416 20:58:16.248428 23299 solver.cpp:253]     Train net output #0: loss = 0.022852 (* 1 = 0.022852 loss)
I0416 20:58:16.248435 23299 sgd_solver.cpp:106] Iteration 55200, lr = 0.001
I0416 20:58:16.443356 23299 solver.cpp:237] Iteration 55300, loss = 0.0227218
I0416 20:58:16.443382 23299 solver.cpp:253]     Train net output #0: loss = 0.0227218 (* 1 = 0.0227218 loss)
I0416 20:58:16.443387 23299 sgd_solver.cpp:106] Iteration 55300, lr = 0.001
I0416 20:58:16.638742 23299 solver.cpp:237] Iteration 55400, loss = 0.02284
I0416 20:58:16.638772 23299 solver.cpp:253]     Train net output #0: loss = 0.02284 (* 1 = 0.02284 loss)
I0416 20:58:16.638777 23299 sgd_solver.cpp:106] Iteration 55400, lr = 0.001
I0416 20:58:16.833885 23299 solver.cpp:237] Iteration 55500, loss = 0.0226891
I0416 20:58:16.833911 23299 solver.cpp:253]     Train net output #0: loss = 0.0226891 (* 1 = 0.0226891 loss)
I0416 20:58:16.833916 23299 sgd_solver.cpp:106] Iteration 55500, lr = 0.001
I0416 20:58:17.029994 23299 solver.cpp:237] Iteration 55600, loss = 0.0226176
I0416 20:58:17.030021 23299 solver.cpp:253]     Train net output #0: loss = 0.0226176 (* 1 = 0.0226176 loss)
I0416 20:58:17.030027 23299 sgd_solver.cpp:106] Iteration 55600, lr = 0.001
I0416 20:58:17.225062 23299 solver.cpp:237] Iteration 55700, loss = 0.0226056
I0416 20:58:17.225088 23299 solver.cpp:253]     Train net output #0: loss = 0.0226056 (* 1 = 0.0226056 loss)
I0416 20:58:17.225095 23299 sgd_solver.cpp:106] Iteration 55700, lr = 0.001
I0416 20:58:17.420056 23299 solver.cpp:237] Iteration 55800, loss = 0.0225155
I0416 20:58:17.420089 23299 solver.cpp:253]     Train net output #0: loss = 0.0225155 (* 1 = 0.0225155 loss)
I0416 20:58:17.420094 23299 sgd_solver.cpp:106] Iteration 55800, lr = 0.001
I0416 20:58:17.624528 23299 solver.cpp:237] Iteration 55900, loss = 0.0224724
I0416 20:58:17.624557 23299 solver.cpp:253]     Train net output #0: loss = 0.0224724 (* 1 = 0.0224724 loss)
I0416 20:58:17.624562 23299 sgd_solver.cpp:106] Iteration 55900, lr = 0.001
I0416 20:58:17.819658 23299 solver.cpp:237] Iteration 56000, loss = 0.0225177
I0416 20:58:17.819684 23299 solver.cpp:253]     Train net output #0: loss = 0.0225177 (* 1 = 0.0225177 loss)
I0416 20:58:17.819690 23299 sgd_solver.cpp:106] Iteration 56000, lr = 0.001
I0416 20:58:18.014178 23299 solver.cpp:237] Iteration 56100, loss = 0.0223833
I0416 20:58:18.014226 23299 solver.cpp:253]     Train net output #0: loss = 0.0223833 (* 1 = 0.0223833 loss)
I0416 20:58:18.014233 23299 sgd_solver.cpp:106] Iteration 56100, lr = 0.001
I0416 20:58:18.209379 23299 solver.cpp:237] Iteration 56200, loss = 0.022353
I0416 20:58:18.209411 23299 solver.cpp:253]     Train net output #0: loss = 0.022353 (* 1 = 0.022353 loss)
I0416 20:58:18.209419 23299 sgd_solver.cpp:106] Iteration 56200, lr = 0.001
I0416 20:58:18.404458 23299 solver.cpp:237] Iteration 56300, loss = 0.0222778
I0416 20:58:18.404484 23299 solver.cpp:253]     Train net output #0: loss = 0.0222778 (* 1 = 0.0222778 loss)
I0416 20:58:18.404489 23299 sgd_solver.cpp:106] Iteration 56300, lr = 0.001
I0416 20:58:18.600106 23299 solver.cpp:237] Iteration 56400, loss = 0.0222376
I0416 20:58:18.600132 23299 solver.cpp:253]     Train net output #0: loss = 0.0222376 (* 1 = 0.0222376 loss)
I0416 20:58:18.600137 23299 sgd_solver.cpp:106] Iteration 56400, lr = 0.001
I0416 20:58:18.795403 23299 solver.cpp:237] Iteration 56500, loss = 0.0222296
I0416 20:58:18.795430 23299 solver.cpp:253]     Train net output #0: loss = 0.0222296 (* 1 = 0.0222296 loss)
I0416 20:58:18.795441 23299 sgd_solver.cpp:106] Iteration 56500, lr = 0.001
I0416 20:58:18.990890 23299 solver.cpp:237] Iteration 56600, loss = 0.0221527
I0416 20:58:18.990917 23299 solver.cpp:253]     Train net output #0: loss = 0.0221527 (* 1 = 0.0221527 loss)
I0416 20:58:18.990922 23299 sgd_solver.cpp:106] Iteration 56600, lr = 0.001
I0416 20:58:19.186719 23299 solver.cpp:237] Iteration 56700, loss = 0.0221646
I0416 20:58:19.186748 23299 solver.cpp:253]     Train net output #0: loss = 0.0221646 (* 1 = 0.0221646 loss)
I0416 20:58:19.186753 23299 sgd_solver.cpp:106] Iteration 56700, lr = 0.001
I0416 20:58:19.382447 23299 solver.cpp:237] Iteration 56800, loss = 0.0220898
I0416 20:58:19.382474 23299 solver.cpp:253]     Train net output #0: loss = 0.0220898 (* 1 = 0.0220898 loss)
I0416 20:58:19.382479 23299 sgd_solver.cpp:106] Iteration 56800, lr = 0.001
I0416 20:58:19.585548 23299 solver.cpp:237] Iteration 56900, loss = 0.022051
I0416 20:58:19.585598 23299 solver.cpp:253]     Train net output #0: loss = 0.022051 (* 1 = 0.022051 loss)
I0416 20:58:19.585611 23299 sgd_solver.cpp:106] Iteration 56900, lr = 0.001
I0416 20:58:19.782627 23299 solver.cpp:237] Iteration 57000, loss = 0.0219634
I0416 20:58:19.782661 23299 solver.cpp:253]     Train net output #0: loss = 0.0219634 (* 1 = 0.0219634 loss)
I0416 20:58:19.782670 23299 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I0416 20:58:19.977810 23299 solver.cpp:237] Iteration 57100, loss = 0.0219532
I0416 20:58:19.977839 23299 solver.cpp:253]     Train net output #0: loss = 0.0219532 (* 1 = 0.0219532 loss)
I0416 20:58:19.977844 23299 sgd_solver.cpp:106] Iteration 57100, lr = 0.001
I0416 20:58:20.173353 23299 solver.cpp:237] Iteration 57200, loss = 0.0219168
I0416 20:58:20.173382 23299 solver.cpp:253]     Train net output #0: loss = 0.0219168 (* 1 = 0.0219168 loss)
I0416 20:58:20.173388 23299 sgd_solver.cpp:106] Iteration 57200, lr = 0.001
I0416 20:58:20.368826 23299 solver.cpp:237] Iteration 57300, loss = 0.0219483
I0416 20:58:20.368859 23299 solver.cpp:253]     Train net output #0: loss = 0.0219483 (* 1 = 0.0219483 loss)
I0416 20:58:20.368865 23299 sgd_solver.cpp:106] Iteration 57300, lr = 0.001
I0416 20:58:20.564436 23299 solver.cpp:237] Iteration 57400, loss = 0.0218758
I0416 20:58:20.564466 23299 solver.cpp:253]     Train net output #0: loss = 0.0218758 (* 1 = 0.0218758 loss)
I0416 20:58:20.564472 23299 sgd_solver.cpp:106] Iteration 57400, lr = 0.001
I0416 20:58:20.760589 23299 solver.cpp:237] Iteration 57500, loss = 0.021812
I0416 20:58:20.760617 23299 solver.cpp:253]     Train net output #0: loss = 0.021812 (* 1 = 0.021812 loss)
I0416 20:58:20.760622 23299 sgd_solver.cpp:106] Iteration 57500, lr = 0.001
I0416 20:58:20.955831 23299 solver.cpp:237] Iteration 57600, loss = 0.0217927
I0416 20:58:20.955857 23299 solver.cpp:253]     Train net output #0: loss = 0.0217927 (* 1 = 0.0217927 loss)
I0416 20:58:20.955863 23299 sgd_solver.cpp:106] Iteration 57600, lr = 0.001
I0416 20:58:21.152464 23299 solver.cpp:237] Iteration 57700, loss = 0.0217424
I0416 20:58:21.152509 23299 solver.cpp:253]     Train net output #0: loss = 0.0217424 (* 1 = 0.0217424 loss)
I0416 20:58:21.152520 23299 sgd_solver.cpp:106] Iteration 57700, lr = 0.001
I0416 20:58:21.350132 23299 solver.cpp:237] Iteration 57800, loss = 0.021709
I0416 20:58:21.350162 23299 solver.cpp:253]     Train net output #0: loss = 0.021709 (* 1 = 0.021709 loss)
I0416 20:58:21.350169 23299 sgd_solver.cpp:106] Iteration 57800, lr = 0.001
I0416 20:58:21.546166 23299 solver.cpp:237] Iteration 57900, loss = 0.0216948
I0416 20:58:21.546195 23299 solver.cpp:253]     Train net output #0: loss = 0.0216948 (* 1 = 0.0216948 loss)
I0416 20:58:21.546201 23299 sgd_solver.cpp:106] Iteration 57900, lr = 0.001
I0416 20:58:21.742317 23299 solver.cpp:237] Iteration 58000, loss = 0.0216649
I0416 20:58:21.742347 23299 solver.cpp:253]     Train net output #0: loss = 0.0216649 (* 1 = 0.0216649 loss)
I0416 20:58:21.742354 23299 sgd_solver.cpp:106] Iteration 58000, lr = 0.001
I0416 20:58:21.938942 23299 solver.cpp:237] Iteration 58100, loss = 0.0216609
I0416 20:58:21.938973 23299 solver.cpp:253]     Train net output #0: loss = 0.0216609 (* 1 = 0.0216609 loss)
I0416 20:58:21.938979 23299 sgd_solver.cpp:106] Iteration 58100, lr = 0.001
I0416 20:58:22.136943 23299 solver.cpp:237] Iteration 58200, loss = 0.0215878
I0416 20:58:22.136981 23299 solver.cpp:253]     Train net output #0: loss = 0.0215878 (* 1 = 0.0215878 loss)
I0416 20:58:22.136992 23299 sgd_solver.cpp:106] Iteration 58200, lr = 0.001
I0416 20:58:22.334027 23299 solver.cpp:237] Iteration 58300, loss = 0.021563
I0416 20:58:22.334056 23299 solver.cpp:253]     Train net output #0: loss = 0.021563 (* 1 = 0.021563 loss)
I0416 20:58:22.334062 23299 sgd_solver.cpp:106] Iteration 58300, lr = 0.001
I0416 20:58:22.530215 23299 solver.cpp:237] Iteration 58400, loss = 0.0216035
I0416 20:58:22.530246 23299 solver.cpp:253]     Train net output #0: loss = 0.0216035 (* 1 = 0.0216035 loss)
I0416 20:58:22.530251 23299 sgd_solver.cpp:106] Iteration 58400, lr = 0.001
I0416 20:58:22.726922 23299 solver.cpp:237] Iteration 58500, loss = 0.0215808
I0416 20:58:22.726954 23299 solver.cpp:253]     Train net output #0: loss = 0.0215808 (* 1 = 0.0215808 loss)
I0416 20:58:22.726960 23299 sgd_solver.cpp:106] Iteration 58500, lr = 0.001
I0416 20:58:22.923919 23299 solver.cpp:237] Iteration 58600, loss = 0.0215642
I0416 20:58:22.923954 23299 solver.cpp:253]     Train net output #0: loss = 0.0215642 (* 1 = 0.0215642 loss)
I0416 20:58:22.923960 23299 sgd_solver.cpp:106] Iteration 58600, lr = 0.001
I0416 20:58:23.120669 23299 solver.cpp:237] Iteration 58700, loss = 0.0214614
I0416 20:58:23.120700 23299 solver.cpp:253]     Train net output #0: loss = 0.0214614 (* 1 = 0.0214614 loss)
I0416 20:58:23.120708 23299 sgd_solver.cpp:106] Iteration 58700, lr = 0.001
I0416 20:58:23.317131 23299 solver.cpp:237] Iteration 58800, loss = 0.0214572
I0416 20:58:23.317160 23299 solver.cpp:253]     Train net output #0: loss = 0.0214572 (* 1 = 0.0214572 loss)
I0416 20:58:23.317167 23299 sgd_solver.cpp:106] Iteration 58800, lr = 0.001
I0416 20:58:23.513878 23299 solver.cpp:237] Iteration 58900, loss = 0.0214481
I0416 20:58:23.513909 23299 solver.cpp:253]     Train net output #0: loss = 0.0214481 (* 1 = 0.0214481 loss)
I0416 20:58:23.513914 23299 sgd_solver.cpp:106] Iteration 58900, lr = 0.001
I0416 20:58:23.709662 23299 solver.cpp:237] Iteration 59000, loss = 0.0214348
I0416 20:58:23.709689 23299 solver.cpp:253]     Train net output #0: loss = 0.0214348 (* 1 = 0.0214348 loss)
I0416 20:58:23.709695 23299 sgd_solver.cpp:106] Iteration 59000, lr = 0.001
I0416 20:58:23.904942 23299 solver.cpp:237] Iteration 59100, loss = 0.0213395
I0416 20:58:23.904969 23299 solver.cpp:253]     Train net output #0: loss = 0.0213395 (* 1 = 0.0213395 loss)
I0416 20:58:23.904974 23299 sgd_solver.cpp:106] Iteration 59100, lr = 0.001
I0416 20:58:24.099625 23299 solver.cpp:237] Iteration 59200, loss = 0.0212891
I0416 20:58:24.099653 23299 solver.cpp:253]     Train net output #0: loss = 0.0212891 (* 1 = 0.0212891 loss)
I0416 20:58:24.099681 23299 sgd_solver.cpp:106] Iteration 59200, lr = 0.001
I0416 20:58:24.295375 23299 solver.cpp:237] Iteration 59300, loss = 0.021387
I0416 20:58:24.295403 23299 solver.cpp:253]     Train net output #0: loss = 0.021387 (* 1 = 0.021387 loss)
I0416 20:58:24.295408 23299 sgd_solver.cpp:106] Iteration 59300, lr = 0.001
I0416 20:58:24.491127 23299 solver.cpp:237] Iteration 59400, loss = 0.0212527
I0416 20:58:24.491154 23299 solver.cpp:253]     Train net output #0: loss = 0.0212527 (* 1 = 0.0212527 loss)
I0416 20:58:24.491159 23299 sgd_solver.cpp:106] Iteration 59400, lr = 0.001
I0416 20:58:24.686970 23299 solver.cpp:237] Iteration 59500, loss = 0.0212587
I0416 20:58:24.686996 23299 solver.cpp:253]     Train net output #0: loss = 0.0212587 (* 1 = 0.0212587 loss)
I0416 20:58:24.687001 23299 sgd_solver.cpp:106] Iteration 59500, lr = 0.001
I0416 20:58:24.885290 23299 solver.cpp:237] Iteration 59600, loss = 0.021166
I0416 20:58:24.885331 23299 solver.cpp:253]     Train net output #0: loss = 0.021166 (* 1 = 0.021166 loss)
I0416 20:58:24.885339 23299 sgd_solver.cpp:106] Iteration 59600, lr = 0.001
I0416 20:58:25.081099 23299 solver.cpp:237] Iteration 59700, loss = 0.0212457
I0416 20:58:25.081128 23299 solver.cpp:253]     Train net output #0: loss = 0.0212457 (* 1 = 0.0212457 loss)
I0416 20:58:25.081133 23299 sgd_solver.cpp:106] Iteration 59700, lr = 0.001
I0416 20:58:25.276969 23299 solver.cpp:237] Iteration 59800, loss = 0.0211756
I0416 20:58:25.276998 23299 solver.cpp:253]     Train net output #0: loss = 0.0211756 (* 1 = 0.0211756 loss)
I0416 20:58:25.277003 23299 sgd_solver.cpp:106] Iteration 59800, lr = 0.001
I0416 20:58:25.473284 23299 solver.cpp:237] Iteration 59900, loss = 0.0211797
I0416 20:58:25.473315 23299 solver.cpp:253]     Train net output #0: loss = 0.0211797 (* 1 = 0.0211797 loss)
I0416 20:58:25.473320 23299 sgd_solver.cpp:106] Iteration 59900, lr = 0.001
I0416 20:58:25.667997 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_60000.caffemodel
I0416 20:58:25.670007 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_60000.solverstate
I0416 20:58:25.670577 23299 solver.cpp:341] Iteration 60000, Testing net (#0)
I0416 20:58:25.670589 23299 net.cpp:748] Ignoring source layer dart
I0416 20:58:25.719416 23299 solver.cpp:409]     Test net output #0: accuracy = 0.8055
I0416 20:58:25.719442 23299 solver.cpp:409]     Test net output #1: loss = 0.673627 (* 1 = 0.673627 loss)
I0416 20:58:25.720371 23299 solver.cpp:237] Iteration 60000, loss = 0.0211714
I0416 20:58:25.720389 23299 solver.cpp:253]     Train net output #0: loss = 0.0211714 (* 1 = 0.0211714 loss)
I0416 20:58:25.720396 23299 sgd_solver.cpp:106] Iteration 60000, lr = 0.001
I0416 20:58:25.919860 23299 solver.cpp:237] Iteration 60100, loss = 0.0211518
I0416 20:58:25.919888 23299 solver.cpp:253]     Train net output #0: loss = 0.0211518 (* 1 = 0.0211518 loss)
I0416 20:58:25.919894 23299 sgd_solver.cpp:106] Iteration 60100, lr = 0.001
I0416 20:58:26.120978 23299 solver.cpp:237] Iteration 60200, loss = 0.0211617
I0416 20:58:26.121006 23299 solver.cpp:253]     Train net output #0: loss = 0.0211617 (* 1 = 0.0211617 loss)
I0416 20:58:26.121011 23299 sgd_solver.cpp:106] Iteration 60200, lr = 0.001
I0416 20:58:26.321581 23299 solver.cpp:237] Iteration 60300, loss = 0.0210901
I0416 20:58:26.321609 23299 solver.cpp:253]     Train net output #0: loss = 0.0210901 (* 1 = 0.0210901 loss)
I0416 20:58:26.321614 23299 sgd_solver.cpp:106] Iteration 60300, lr = 0.001
I0416 20:58:26.522755 23299 solver.cpp:237] Iteration 60400, loss = 0.021102
I0416 20:58:26.522784 23299 solver.cpp:253]     Train net output #0: loss = 0.021102 (* 1 = 0.021102 loss)
I0416 20:58:26.522789 23299 sgd_solver.cpp:106] Iteration 60400, lr = 0.001
I0416 20:58:26.724422 23299 solver.cpp:237] Iteration 60500, loss = 0.0210095
I0416 20:58:26.724470 23299 solver.cpp:253]     Train net output #0: loss = 0.0210095 (* 1 = 0.0210095 loss)
I0416 20:58:26.724509 23299 sgd_solver.cpp:106] Iteration 60500, lr = 0.001
I0416 20:58:26.923830 23299 solver.cpp:237] Iteration 60600, loss = 0.020993
I0416 20:58:26.923856 23299 solver.cpp:253]     Train net output #0: loss = 0.020993 (* 1 = 0.020993 loss)
I0416 20:58:26.923864 23299 sgd_solver.cpp:106] Iteration 60600, lr = 0.001
I0416 20:58:27.124481 23299 solver.cpp:237] Iteration 60700, loss = 0.0210315
I0416 20:58:27.124507 23299 solver.cpp:253]     Train net output #0: loss = 0.0210315 (* 1 = 0.0210315 loss)
I0416 20:58:27.124512 23299 sgd_solver.cpp:106] Iteration 60700, lr = 0.001
I0416 20:58:27.325134 23299 solver.cpp:237] Iteration 60800, loss = 0.0209138
I0416 20:58:27.325160 23299 solver.cpp:253]     Train net output #0: loss = 0.0209138 (* 1 = 0.0209138 loss)
I0416 20:58:27.325165 23299 sgd_solver.cpp:106] Iteration 60800, lr = 0.001
I0416 20:58:27.525068 23299 solver.cpp:237] Iteration 60900, loss = 0.0209365
I0416 20:58:27.525094 23299 solver.cpp:253]     Train net output #0: loss = 0.0209365 (* 1 = 0.0209365 loss)
I0416 20:58:27.525101 23299 sgd_solver.cpp:106] Iteration 60900, lr = 0.001
I0416 20:58:27.725338 23299 solver.cpp:237] Iteration 61000, loss = 0.020865
I0416 20:58:27.725365 23299 solver.cpp:253]     Train net output #0: loss = 0.020865 (* 1 = 0.020865 loss)
I0416 20:58:27.725370 23299 sgd_solver.cpp:106] Iteration 61000, lr = 0.001
I0416 20:58:27.926821 23299 solver.cpp:237] Iteration 61100, loss = 0.0208658
I0416 20:58:27.926847 23299 solver.cpp:253]     Train net output #0: loss = 0.0208658 (* 1 = 0.0208658 loss)
I0416 20:58:27.926852 23299 sgd_solver.cpp:106] Iteration 61100, lr = 0.001
I0416 20:58:28.126157 23299 solver.cpp:237] Iteration 61200, loss = 0.020831
I0416 20:58:28.126183 23299 solver.cpp:253]     Train net output #0: loss = 0.020831 (* 1 = 0.020831 loss)
I0416 20:58:28.126188 23299 sgd_solver.cpp:106] Iteration 61200, lr = 0.001
I0416 20:58:28.326297 23299 solver.cpp:237] Iteration 61300, loss = 0.0208427
I0416 20:58:28.326323 23299 solver.cpp:253]     Train net output #0: loss = 0.0208427 (* 1 = 0.0208427 loss)
I0416 20:58:28.326328 23299 sgd_solver.cpp:106] Iteration 61300, lr = 0.001
I0416 20:58:28.528167 23299 solver.cpp:237] Iteration 61400, loss = 0.0207833
I0416 20:58:28.528211 23299 solver.cpp:253]     Train net output #0: loss = 0.0207833 (* 1 = 0.0207833 loss)
I0416 20:58:28.528223 23299 sgd_solver.cpp:106] Iteration 61400, lr = 0.001
I0416 20:58:28.730494 23299 solver.cpp:237] Iteration 61500, loss = 0.0207649
I0416 20:58:28.730528 23299 solver.cpp:253]     Train net output #0: loss = 0.0207649 (* 1 = 0.0207649 loss)
I0416 20:58:28.730535 23299 sgd_solver.cpp:106] Iteration 61500, lr = 0.001
I0416 20:58:28.931597 23299 solver.cpp:237] Iteration 61600, loss = 0.0207677
I0416 20:58:28.931623 23299 solver.cpp:253]     Train net output #0: loss = 0.0207677 (* 1 = 0.0207677 loss)
I0416 20:58:28.931630 23299 sgd_solver.cpp:106] Iteration 61600, lr = 0.001
I0416 20:58:29.133107 23299 solver.cpp:237] Iteration 61700, loss = 0.0206653
I0416 20:58:29.133141 23299 solver.cpp:253]     Train net output #0: loss = 0.0206653 (* 1 = 0.0206653 loss)
I0416 20:58:29.133147 23299 sgd_solver.cpp:106] Iteration 61700, lr = 0.001
I0416 20:58:29.334643 23299 solver.cpp:237] Iteration 61800, loss = 0.0206986
I0416 20:58:29.334674 23299 solver.cpp:253]     Train net output #0: loss = 0.0206986 (* 1 = 0.0206986 loss)
I0416 20:58:29.334679 23299 sgd_solver.cpp:106] Iteration 61800, lr = 0.001
I0416 20:58:29.536591 23299 solver.cpp:237] Iteration 61900, loss = 0.0206553
I0416 20:58:29.536623 23299 solver.cpp:253]     Train net output #0: loss = 0.0206553 (* 1 = 0.0206553 loss)
I0416 20:58:29.536629 23299 sgd_solver.cpp:106] Iteration 61900, lr = 0.001
I0416 20:58:29.739259 23299 solver.cpp:237] Iteration 62000, loss = 0.0205994
I0416 20:58:29.739311 23299 solver.cpp:253]     Train net output #0: loss = 0.0205994 (* 1 = 0.0205994 loss)
I0416 20:58:29.739323 23299 sgd_solver.cpp:106] Iteration 62000, lr = 0.001
I0416 20:58:29.941330 23299 solver.cpp:237] Iteration 62100, loss = 0.0205935
I0416 20:58:29.941391 23299 solver.cpp:253]     Train net output #0: loss = 0.0205935 (* 1 = 0.0205935 loss)
I0416 20:58:29.941400 23299 sgd_solver.cpp:106] Iteration 62100, lr = 0.001
I0416 20:58:30.142592 23299 solver.cpp:237] Iteration 62200, loss = 0.0205552
I0416 20:58:30.142626 23299 solver.cpp:253]     Train net output #0: loss = 0.0205552 (* 1 = 0.0205552 loss)
I0416 20:58:30.142632 23299 sgd_solver.cpp:106] Iteration 62200, lr = 0.001
I0416 20:58:30.343895 23299 solver.cpp:237] Iteration 62300, loss = 0.0205063
I0416 20:58:30.343926 23299 solver.cpp:253]     Train net output #0: loss = 0.0205063 (* 1 = 0.0205063 loss)
I0416 20:58:30.343932 23299 sgd_solver.cpp:106] Iteration 62300, lr = 0.001
I0416 20:58:30.545397 23299 solver.cpp:237] Iteration 62400, loss = 0.0205039
I0416 20:58:30.545425 23299 solver.cpp:253]     Train net output #0: loss = 0.0205039 (* 1 = 0.0205039 loss)
I0416 20:58:30.545431 23299 sgd_solver.cpp:106] Iteration 62400, lr = 0.001
I0416 20:58:30.746906 23299 solver.cpp:237] Iteration 62500, loss = 0.0203873
I0416 20:58:30.746950 23299 solver.cpp:253]     Train net output #0: loss = 0.0203873 (* 1 = 0.0203873 loss)
I0416 20:58:30.746955 23299 sgd_solver.cpp:106] Iteration 62500, lr = 0.001
I0416 20:58:30.948297 23299 solver.cpp:237] Iteration 62600, loss = 0.0204144
I0416 20:58:30.948328 23299 solver.cpp:253]     Train net output #0: loss = 0.0204144 (* 1 = 0.0204144 loss)
I0416 20:58:30.948344 23299 sgd_solver.cpp:106] Iteration 62600, lr = 0.001
I0416 20:58:31.150327 23299 solver.cpp:237] Iteration 62700, loss = 0.0203933
I0416 20:58:31.150359 23299 solver.cpp:253]     Train net output #0: loss = 0.0203933 (* 1 = 0.0203933 loss)
I0416 20:58:31.150367 23299 sgd_solver.cpp:106] Iteration 62700, lr = 0.001
I0416 20:58:31.352200 23299 solver.cpp:237] Iteration 62800, loss = 0.0203223
I0416 20:58:31.352231 23299 solver.cpp:253]     Train net output #0: loss = 0.0203223 (* 1 = 0.0203223 loss)
I0416 20:58:31.352236 23299 sgd_solver.cpp:106] Iteration 62800, lr = 0.001
I0416 20:58:31.552949 23299 solver.cpp:237] Iteration 62900, loss = 0.0202986
I0416 20:58:31.552986 23299 solver.cpp:253]     Train net output #0: loss = 0.0202986 (* 1 = 0.0202986 loss)
I0416 20:58:31.552994 23299 sgd_solver.cpp:106] Iteration 62900, lr = 0.001
I0416 20:58:31.754031 23299 solver.cpp:237] Iteration 63000, loss = 0.0202789
I0416 20:58:31.754060 23299 solver.cpp:253]     Train net output #0: loss = 0.0202789 (* 1 = 0.0202789 loss)
I0416 20:58:31.754065 23299 sgd_solver.cpp:106] Iteration 63000, lr = 0.001
I0416 20:58:31.955260 23299 solver.cpp:237] Iteration 63100, loss = 0.0202587
I0416 20:58:31.955286 23299 solver.cpp:253]     Train net output #0: loss = 0.0202587 (* 1 = 0.0202587 loss)
I0416 20:58:31.955302 23299 sgd_solver.cpp:106] Iteration 63100, lr = 0.001
I0416 20:58:32.157292 23299 solver.cpp:237] Iteration 63200, loss = 0.0202261
I0416 20:58:32.157321 23299 solver.cpp:253]     Train net output #0: loss = 0.0202261 (* 1 = 0.0202261 loss)
I0416 20:58:32.157328 23299 sgd_solver.cpp:106] Iteration 63200, lr = 0.001
I0416 20:58:32.358449 23299 solver.cpp:237] Iteration 63300, loss = 0.0201781
I0416 20:58:32.358476 23299 solver.cpp:253]     Train net output #0: loss = 0.0201781 (* 1 = 0.0201781 loss)
I0416 20:58:32.358490 23299 sgd_solver.cpp:106] Iteration 63300, lr = 0.001
I0416 20:58:32.559540 23299 solver.cpp:237] Iteration 63400, loss = 0.0202163
I0416 20:58:32.559568 23299 solver.cpp:253]     Train net output #0: loss = 0.0202163 (* 1 = 0.0202163 loss)
I0416 20:58:32.559576 23299 sgd_solver.cpp:106] Iteration 63400, lr = 0.001
I0416 20:58:32.760946 23299 solver.cpp:237] Iteration 63500, loss = 0.0201257
I0416 20:58:32.760977 23299 solver.cpp:253]     Train net output #0: loss = 0.0201257 (* 1 = 0.0201257 loss)
I0416 20:58:32.760982 23299 sgd_solver.cpp:106] Iteration 63500, lr = 0.001
I0416 20:58:32.902057 23299 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 20:58:32.962371 23299 solver.cpp:237] Iteration 63600, loss = 0.0201079
I0416 20:58:32.962396 23299 solver.cpp:253]     Train net output #0: loss = 0.0201079 (* 1 = 0.0201079 loss)
I0416 20:58:32.962421 23299 sgd_solver.cpp:106] Iteration 63600, lr = 0.001
I0416 20:58:33.164079 23299 solver.cpp:237] Iteration 63700, loss = 0.0200634
I0416 20:58:33.164106 23299 solver.cpp:253]     Train net output #0: loss = 0.0200634 (* 1 = 0.0200634 loss)
I0416 20:58:33.164111 23299 sgd_solver.cpp:106] Iteration 63700, lr = 0.001
I0416 20:58:33.365535 23299 solver.cpp:237] Iteration 63800, loss = 0.0200325
I0416 20:58:33.365563 23299 solver.cpp:253]     Train net output #0: loss = 0.0200325 (* 1 = 0.0200325 loss)
I0416 20:58:33.365568 23299 sgd_solver.cpp:106] Iteration 63800, lr = 0.001
I0416 20:58:33.566661 23299 solver.cpp:237] Iteration 63900, loss = 0.0200393
I0416 20:58:33.566689 23299 solver.cpp:253]     Train net output #0: loss = 0.0200393 (* 1 = 0.0200393 loss)
I0416 20:58:33.566695 23299 sgd_solver.cpp:106] Iteration 63900, lr = 0.001
I0416 20:58:33.767246 23299 solver.cpp:237] Iteration 64000, loss = 0.01995
I0416 20:58:33.767274 23299 solver.cpp:253]     Train net output #0: loss = 0.01995 (* 1 = 0.01995 loss)
I0416 20:58:33.767284 23299 sgd_solver.cpp:106] Iteration 64000, lr = 0.001
I0416 20:58:33.968243 23299 solver.cpp:237] Iteration 64100, loss = 0.0199306
I0416 20:58:33.968271 23299 solver.cpp:253]     Train net output #0: loss = 0.0199306 (* 1 = 0.0199306 loss)
I0416 20:58:33.968281 23299 sgd_solver.cpp:106] Iteration 64100, lr = 0.001
I0416 20:58:34.169781 23299 solver.cpp:237] Iteration 64200, loss = 0.0199233
I0416 20:58:34.169836 23299 solver.cpp:253]     Train net output #0: loss = 0.0199233 (* 1 = 0.0199233 loss)
I0416 20:58:34.169850 23299 sgd_solver.cpp:106] Iteration 64200, lr = 0.001
I0416 20:58:34.372772 23299 solver.cpp:237] Iteration 64300, loss = 0.0198233
I0416 20:58:34.372805 23299 solver.cpp:253]     Train net output #0: loss = 0.0198233 (* 1 = 0.0198233 loss)
I0416 20:58:34.372822 23299 sgd_solver.cpp:106] Iteration 64300, lr = 0.001
I0416 20:58:34.574645 23299 solver.cpp:237] Iteration 64400, loss = 0.0197867
I0416 20:58:34.574676 23299 solver.cpp:253]     Train net output #0: loss = 0.0197867 (* 1 = 0.0197867 loss)
I0416 20:58:34.574681 23299 sgd_solver.cpp:106] Iteration 64400, lr = 0.001
I0416 20:58:34.776584 23299 solver.cpp:237] Iteration 64500, loss = 0.0198763
I0416 20:58:34.776618 23299 solver.cpp:253]     Train net output #0: loss = 0.0198763 (* 1 = 0.0198763 loss)
I0416 20:58:34.776623 23299 sgd_solver.cpp:106] Iteration 64500, lr = 0.001
I0416 20:58:34.978582 23299 solver.cpp:237] Iteration 64600, loss = 0.0198196
I0416 20:58:34.978612 23299 solver.cpp:253]     Train net output #0: loss = 0.0198196 (* 1 = 0.0198196 loss)
I0416 20:58:34.978620 23299 sgd_solver.cpp:106] Iteration 64600, lr = 0.001
I0416 20:58:35.180357 23299 solver.cpp:237] Iteration 64700, loss = 0.0197607
I0416 20:58:35.180388 23299 solver.cpp:253]     Train net output #0: loss = 0.0197607 (* 1 = 0.0197607 loss)
I0416 20:58:35.180394 23299 sgd_solver.cpp:106] Iteration 64700, lr = 0.001
I0416 20:58:35.381830 23299 solver.cpp:237] Iteration 64800, loss = 0.0197335
I0416 20:58:35.381860 23299 solver.cpp:253]     Train net output #0: loss = 0.0197335 (* 1 = 0.0197335 loss)
I0416 20:58:35.381865 23299 sgd_solver.cpp:106] Iteration 64800, lr = 0.001
I0416 20:58:35.584121 23299 solver.cpp:237] Iteration 64900, loss = 0.0197421
I0416 20:58:35.584156 23299 solver.cpp:253]     Train net output #0: loss = 0.0197421 (* 1 = 0.0197421 loss)
I0416 20:58:35.584162 23299 sgd_solver.cpp:106] Iteration 64900, lr = 0.001
I0416 20:58:35.784044 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_65000.caffemodel
I0416 20:58:35.786196 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_65000.solverstate
I0416 20:58:35.786766 23299 solver.cpp:341] Iteration 65000, Testing net (#0)
I0416 20:58:35.786777 23299 net.cpp:748] Ignoring source layer dart
I0416 20:58:35.836096 23299 solver.cpp:409]     Test net output #0: accuracy = 0.8095
I0416 20:58:35.836122 23299 solver.cpp:409]     Test net output #1: loss = 0.677119 (* 1 = 0.677119 loss)
I0416 20:58:35.837028 23299 solver.cpp:237] Iteration 65000, loss = 0.0196185
I0416 20:58:35.837056 23299 solver.cpp:253]     Train net output #0: loss = 0.0196185 (* 1 = 0.0196185 loss)
I0416 20:58:35.837069 23299 sgd_solver.cpp:106] Iteration 65000, lr = 0.001
I0416 20:58:36.032070 23299 solver.cpp:237] Iteration 65100, loss = 0.0196681
I0416 20:58:36.032101 23299 solver.cpp:253]     Train net output #0: loss = 0.0196681 (* 1 = 0.0196681 loss)
I0416 20:58:36.032110 23299 sgd_solver.cpp:106] Iteration 65100, lr = 0.001
I0416 20:58:36.227367 23299 solver.cpp:237] Iteration 65200, loss = 0.0196494
I0416 20:58:36.227491 23299 solver.cpp:253]     Train net output #0: loss = 0.0196494 (* 1 = 0.0196494 loss)
I0416 20:58:36.227505 23299 sgd_solver.cpp:106] Iteration 65200, lr = 0.001
I0416 20:58:36.424442 23299 solver.cpp:237] Iteration 65300, loss = 0.0195091
I0416 20:58:36.424481 23299 solver.cpp:253]     Train net output #0: loss = 0.0195091 (* 1 = 0.0195091 loss)
I0416 20:58:36.424490 23299 sgd_solver.cpp:106] Iteration 65300, lr = 0.001
I0416 20:58:36.621721 23299 solver.cpp:237] Iteration 65400, loss = 0.0195256
I0416 20:58:36.621786 23299 solver.cpp:253]     Train net output #0: loss = 0.0195256 (* 1 = 0.0195256 loss)
I0416 20:58:36.621810 23299 sgd_solver.cpp:106] Iteration 65400, lr = 0.001
I0416 20:58:36.818997 23299 solver.cpp:237] Iteration 65500, loss = 0.0195296
I0416 20:58:36.819036 23299 solver.cpp:253]     Train net output #0: loss = 0.0195296 (* 1 = 0.0195296 loss)
I0416 20:58:36.819046 23299 sgd_solver.cpp:106] Iteration 65500, lr = 0.001
I0416 20:58:37.017993 23299 solver.cpp:237] Iteration 65600, loss = 0.0194698
I0416 20:58:37.018043 23299 solver.cpp:253]     Train net output #0: loss = 0.0194698 (* 1 = 0.0194698 loss)
I0416 20:58:37.018054 23299 sgd_solver.cpp:106] Iteration 65600, lr = 0.001
I0416 20:58:37.215613 23299 solver.cpp:237] Iteration 65700, loss = 0.0193913
I0416 20:58:37.215646 23299 solver.cpp:253]     Train net output #0: loss = 0.0193913 (* 1 = 0.0193913 loss)
I0416 20:58:37.215651 23299 sgd_solver.cpp:106] Iteration 65700, lr = 0.001
I0416 20:58:37.412587 23299 solver.cpp:237] Iteration 65800, loss = 0.0193919
I0416 20:58:37.412617 23299 solver.cpp:253]     Train net output #0: loss = 0.0193919 (* 1 = 0.0193919 loss)
I0416 20:58:37.412622 23299 sgd_solver.cpp:106] Iteration 65800, lr = 0.001
I0416 20:58:37.609035 23299 solver.cpp:237] Iteration 65900, loss = 0.019343
I0416 20:58:37.609066 23299 solver.cpp:253]     Train net output #0: loss = 0.019343 (* 1 = 0.019343 loss)
I0416 20:58:37.609074 23299 sgd_solver.cpp:106] Iteration 65900, lr = 0.001
I0416 20:58:37.806361 23299 solver.cpp:237] Iteration 66000, loss = 0.0193048
I0416 20:58:37.806407 23299 solver.cpp:253]     Train net output #0: loss = 0.0193048 (* 1 = 0.0193048 loss)
I0416 20:58:37.806417 23299 sgd_solver.cpp:106] Iteration 66000, lr = 0.001
I0416 20:58:38.003108 23299 solver.cpp:237] Iteration 66100, loss = 0.0193481
I0416 20:58:38.003139 23299 solver.cpp:253]     Train net output #0: loss = 0.0193481 (* 1 = 0.0193481 loss)
I0416 20:58:38.003147 23299 sgd_solver.cpp:106] Iteration 66100, lr = 0.001
I0416 20:58:38.199249 23299 solver.cpp:237] Iteration 66200, loss = 0.0192451
I0416 20:58:38.199277 23299 solver.cpp:253]     Train net output #0: loss = 0.0192451 (* 1 = 0.0192451 loss)
I0416 20:58:38.199283 23299 sgd_solver.cpp:106] Iteration 66200, lr = 0.001
I0416 20:58:38.395655 23299 solver.cpp:237] Iteration 66300, loss = 0.0192805
I0416 20:58:38.395687 23299 solver.cpp:253]     Train net output #0: loss = 0.0192805 (* 1 = 0.0192805 loss)
I0416 20:58:38.395694 23299 sgd_solver.cpp:106] Iteration 66300, lr = 0.001
I0416 20:58:38.591680 23299 solver.cpp:237] Iteration 66400, loss = 0.0192278
I0416 20:58:38.591711 23299 solver.cpp:253]     Train net output #0: loss = 0.0192278 (* 1 = 0.0192278 loss)
I0416 20:58:38.591717 23299 sgd_solver.cpp:106] Iteration 66400, lr = 0.001
I0416 20:58:38.788125 23299 solver.cpp:237] Iteration 66500, loss = 0.0192127
I0416 20:58:38.788153 23299 solver.cpp:253]     Train net output #0: loss = 0.0192127 (* 1 = 0.0192127 loss)
I0416 20:58:38.788159 23299 sgd_solver.cpp:106] Iteration 66500, lr = 0.001
I0416 20:58:38.990838 23299 solver.cpp:237] Iteration 66600, loss = 0.0190962
I0416 20:58:38.990869 23299 solver.cpp:253]     Train net output #0: loss = 0.0190962 (* 1 = 0.0190962 loss)
I0416 20:58:38.990875 23299 sgd_solver.cpp:106] Iteration 66600, lr = 0.001
I0416 20:58:39.189705 23299 solver.cpp:237] Iteration 66700, loss = 0.0191454
I0416 20:58:39.189743 23299 solver.cpp:253]     Train net output #0: loss = 0.0191454 (* 1 = 0.0191454 loss)
I0416 20:58:39.189754 23299 sgd_solver.cpp:106] Iteration 66700, lr = 0.001
I0416 20:58:39.386090 23299 solver.cpp:237] Iteration 66800, loss = 0.0191744
I0416 20:58:39.386122 23299 solver.cpp:253]     Train net output #0: loss = 0.0191744 (* 1 = 0.0191744 loss)
I0416 20:58:39.386129 23299 sgd_solver.cpp:106] Iteration 66800, lr = 0.001
I0416 20:58:39.581645 23299 solver.cpp:237] Iteration 66900, loss = 0.0190263
I0416 20:58:39.581676 23299 solver.cpp:253]     Train net output #0: loss = 0.0190263 (* 1 = 0.0190263 loss)
I0416 20:58:39.581683 23299 sgd_solver.cpp:106] Iteration 66900, lr = 0.001
I0416 20:58:39.777312 23299 solver.cpp:237] Iteration 67000, loss = 0.019029
I0416 20:58:39.777343 23299 solver.cpp:253]     Train net output #0: loss = 0.019029 (* 1 = 0.019029 loss)
I0416 20:58:39.777348 23299 sgd_solver.cpp:106] Iteration 67000, lr = 0.001
I0416 20:58:39.973248 23299 solver.cpp:237] Iteration 67100, loss = 0.0189699
I0416 20:58:39.973276 23299 solver.cpp:253]     Train net output #0: loss = 0.0189699 (* 1 = 0.0189699 loss)
I0416 20:58:39.973284 23299 sgd_solver.cpp:106] Iteration 67100, lr = 0.001
I0416 20:58:40.168759 23299 solver.cpp:237] Iteration 67200, loss = 0.0189998
I0416 20:58:40.168787 23299 solver.cpp:253]     Train net output #0: loss = 0.0189998 (* 1 = 0.0189998 loss)
I0416 20:58:40.168792 23299 sgd_solver.cpp:106] Iteration 67200, lr = 0.001
I0416 20:58:40.364372 23299 solver.cpp:237] Iteration 67300, loss = 0.0189308
I0416 20:58:40.364398 23299 solver.cpp:253]     Train net output #0: loss = 0.0189308 (* 1 = 0.0189308 loss)
I0416 20:58:40.364403 23299 sgd_solver.cpp:106] Iteration 67300, lr = 0.001
I0416 20:58:40.559994 23299 solver.cpp:237] Iteration 67400, loss = 0.0188651
I0416 20:58:40.560021 23299 solver.cpp:253]     Train net output #0: loss = 0.0188651 (* 1 = 0.0188651 loss)
I0416 20:58:40.560027 23299 sgd_solver.cpp:106] Iteration 67400, lr = 0.001
I0416 20:58:40.755584 23299 solver.cpp:237] Iteration 67500, loss = 0.0189045
I0416 20:58:40.755611 23299 solver.cpp:253]     Train net output #0: loss = 0.0189045 (* 1 = 0.0189045 loss)
I0416 20:58:40.755622 23299 sgd_solver.cpp:106] Iteration 67500, lr = 0.001
I0416 20:58:40.951721 23299 solver.cpp:237] Iteration 67600, loss = 0.0187987
I0416 20:58:40.951746 23299 solver.cpp:253]     Train net output #0: loss = 0.0187987 (* 1 = 0.0187987 loss)
I0416 20:58:40.951752 23299 sgd_solver.cpp:106] Iteration 67600, lr = 0.001
I0416 20:58:41.149895 23299 solver.cpp:237] Iteration 67700, loss = 0.0188468
I0416 20:58:41.149930 23299 solver.cpp:253]     Train net output #0: loss = 0.0188468 (* 1 = 0.0188468 loss)
I0416 20:58:41.149938 23299 sgd_solver.cpp:106] Iteration 67700, lr = 0.001
I0416 20:58:41.346199 23299 solver.cpp:237] Iteration 67800, loss = 0.0187552
I0416 20:58:41.346228 23299 solver.cpp:253]     Train net output #0: loss = 0.0187552 (* 1 = 0.0187552 loss)
I0416 20:58:41.346235 23299 sgd_solver.cpp:106] Iteration 67800, lr = 0.001
I0416 20:58:41.541945 23299 solver.cpp:237] Iteration 67900, loss = 0.0187462
I0416 20:58:41.541973 23299 solver.cpp:253]     Train net output #0: loss = 0.0187462 (* 1 = 0.0187462 loss)
I0416 20:58:41.541978 23299 sgd_solver.cpp:106] Iteration 67900, lr = 0.001
I0416 20:58:41.738083 23299 solver.cpp:237] Iteration 68000, loss = 0.0187268
I0416 20:58:41.738111 23299 solver.cpp:253]     Train net output #0: loss = 0.0187268 (* 1 = 0.0187268 loss)
I0416 20:58:41.738116 23299 sgd_solver.cpp:106] Iteration 68000, lr = 0.001
I0416 20:58:41.933418 23299 solver.cpp:237] Iteration 68100, loss = 0.0187884
I0416 20:58:41.933444 23299 solver.cpp:253]     Train net output #0: loss = 0.0187884 (* 1 = 0.0187884 loss)
I0416 20:58:41.933454 23299 sgd_solver.cpp:106] Iteration 68100, lr = 0.001
I0416 20:58:42.128877 23299 solver.cpp:237] Iteration 68200, loss = 0.0186291
I0416 20:58:42.128918 23299 solver.cpp:253]     Train net output #0: loss = 0.0186291 (* 1 = 0.0186291 loss)
I0416 20:58:42.128928 23299 sgd_solver.cpp:106] Iteration 68200, lr = 0.001
I0416 20:58:42.324139 23299 solver.cpp:237] Iteration 68300, loss = 0.0186947
I0416 20:58:42.324169 23299 solver.cpp:253]     Train net output #0: loss = 0.0186947 (* 1 = 0.0186947 loss)
I0416 20:58:42.324208 23299 sgd_solver.cpp:106] Iteration 68300, lr = 0.001
I0416 20:58:42.520035 23299 solver.cpp:237] Iteration 68400, loss = 0.0186557
I0416 20:58:42.520071 23299 solver.cpp:253]     Train net output #0: loss = 0.0186557 (* 1 = 0.0186557 loss)
I0416 20:58:42.520078 23299 sgd_solver.cpp:106] Iteration 68400, lr = 0.001
I0416 20:58:42.715401 23299 solver.cpp:237] Iteration 68500, loss = 0.018592
I0416 20:58:42.715430 23299 solver.cpp:253]     Train net output #0: loss = 0.018592 (* 1 = 0.018592 loss)
I0416 20:58:42.715438 23299 sgd_solver.cpp:106] Iteration 68500, lr = 0.001
I0416 20:58:42.911434 23299 solver.cpp:237] Iteration 68600, loss = 0.0185825
I0416 20:58:42.911463 23299 solver.cpp:253]     Train net output #0: loss = 0.0185825 (* 1 = 0.0185825 loss)
I0416 20:58:42.911473 23299 sgd_solver.cpp:106] Iteration 68600, lr = 0.001
I0416 20:58:43.107208 23299 solver.cpp:237] Iteration 68700, loss = 0.0185887
I0416 20:58:43.107237 23299 solver.cpp:253]     Train net output #0: loss = 0.0185887 (* 1 = 0.0185887 loss)
I0416 20:58:43.107246 23299 sgd_solver.cpp:106] Iteration 68700, lr = 0.001
I0416 20:58:43.302934 23299 solver.cpp:237] Iteration 68800, loss = 0.0185222
I0416 20:58:43.302963 23299 solver.cpp:253]     Train net output #0: loss = 0.0185222 (* 1 = 0.0185222 loss)
I0416 20:58:43.302973 23299 sgd_solver.cpp:106] Iteration 68800, lr = 0.001
I0416 20:58:43.498248 23299 solver.cpp:237] Iteration 68900, loss = 0.0184837
I0416 20:58:43.498276 23299 solver.cpp:253]     Train net output #0: loss = 0.0184837 (* 1 = 0.0184837 loss)
I0416 20:58:43.498284 23299 sgd_solver.cpp:106] Iteration 68900, lr = 0.001
I0416 20:58:43.693559 23299 solver.cpp:237] Iteration 69000, loss = 0.0184738
I0416 20:58:43.693590 23299 solver.cpp:253]     Train net output #0: loss = 0.0184738 (* 1 = 0.0184738 loss)
I0416 20:58:43.693598 23299 sgd_solver.cpp:106] Iteration 69000, lr = 0.001
I0416 20:58:43.888763 23299 solver.cpp:237] Iteration 69100, loss = 0.01842
I0416 20:58:43.888792 23299 solver.cpp:253]     Train net output #0: loss = 0.01842 (* 1 = 0.01842 loss)
I0416 20:58:43.888800 23299 sgd_solver.cpp:106] Iteration 69100, lr = 0.001
I0416 20:58:44.084522 23299 solver.cpp:237] Iteration 69200, loss = 0.0184728
I0416 20:58:44.084553 23299 solver.cpp:253]     Train net output #0: loss = 0.0184728 (* 1 = 0.0184728 loss)
I0416 20:58:44.084563 23299 sgd_solver.cpp:106] Iteration 69200, lr = 0.001
I0416 20:58:44.280339 23299 solver.cpp:237] Iteration 69300, loss = 0.0184313
I0416 20:58:44.280369 23299 solver.cpp:253]     Train net output #0: loss = 0.0184313 (* 1 = 0.0184313 loss)
I0416 20:58:44.280380 23299 sgd_solver.cpp:106] Iteration 69300, lr = 0.001
I0416 20:58:44.476619 23299 solver.cpp:237] Iteration 69400, loss = 0.0182852
I0416 20:58:44.476649 23299 solver.cpp:253]     Train net output #0: loss = 0.0182852 (* 1 = 0.0182852 loss)
I0416 20:58:44.476655 23299 sgd_solver.cpp:106] Iteration 69400, lr = 0.001
I0416 20:58:44.672297 23299 solver.cpp:237] Iteration 69500, loss = 0.0183072
I0416 20:58:44.672323 23299 solver.cpp:253]     Train net output #0: loss = 0.0183072 (* 1 = 0.0183072 loss)
I0416 20:58:44.672339 23299 sgd_solver.cpp:106] Iteration 69500, lr = 0.001
I0416 20:58:44.867761 23299 solver.cpp:237] Iteration 69600, loss = 0.0182448
I0416 20:58:44.867789 23299 solver.cpp:253]     Train net output #0: loss = 0.0182448 (* 1 = 0.0182448 loss)
I0416 20:58:44.867799 23299 sgd_solver.cpp:106] Iteration 69600, lr = 0.001
I0416 20:58:45.068032 23299 solver.cpp:237] Iteration 69700, loss = 0.0181998
I0416 20:58:45.068061 23299 solver.cpp:253]     Train net output #0: loss = 0.0181998 (* 1 = 0.0181998 loss)
I0416 20:58:45.068068 23299 sgd_solver.cpp:106] Iteration 69700, lr = 0.001
I0416 20:58:45.263656 23299 solver.cpp:237] Iteration 69800, loss = 0.0182049
I0416 20:58:45.263684 23299 solver.cpp:253]     Train net output #0: loss = 0.0182049 (* 1 = 0.0182049 loss)
I0416 20:58:45.263695 23299 sgd_solver.cpp:106] Iteration 69800, lr = 0.001
I0416 20:58:45.459704 23299 solver.cpp:237] Iteration 69900, loss = 0.0181809
I0416 20:58:45.459753 23299 solver.cpp:253]     Train net output #0: loss = 0.0181809 (* 1 = 0.0181809 loss)
I0416 20:58:45.459761 23299 sgd_solver.cpp:106] Iteration 69900, lr = 0.001
I0416 20:58:45.653468 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_70000.caffemodel
I0416 20:58:45.655493 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_70000.solverstate
I0416 20:58:45.656060 23299 solver.cpp:341] Iteration 70000, Testing net (#0)
I0416 20:58:45.656070 23299 net.cpp:748] Ignoring source layer dart
I0416 20:58:45.701786 23299 solver.cpp:409]     Test net output #0: accuracy = 0.814
I0416 20:58:45.701807 23299 solver.cpp:409]     Test net output #1: loss = 0.669862 (* 1 = 0.669862 loss)
I0416 20:58:45.702651 23299 solver.cpp:237] Iteration 70000, loss = 0.0182142
I0416 20:58:45.702669 23299 solver.cpp:253]     Train net output #0: loss = 0.0182142 (* 1 = 0.0182142 loss)
I0416 20:58:45.702674 23299 sgd_solver.cpp:106] Iteration 70000, lr = 0.001
I0416 20:58:45.898494 23299 solver.cpp:237] Iteration 70100, loss = 0.0181625
I0416 20:58:45.898520 23299 solver.cpp:253]     Train net output #0: loss = 0.0181625 (* 1 = 0.0181625 loss)
I0416 20:58:45.898525 23299 sgd_solver.cpp:106] Iteration 70100, lr = 0.001
I0416 20:58:46.094010 23299 solver.cpp:237] Iteration 70200, loss = 0.0180521
I0416 20:58:46.094038 23299 solver.cpp:253]     Train net output #0: loss = 0.0180521 (* 1 = 0.0180521 loss)
I0416 20:58:46.094049 23299 sgd_solver.cpp:106] Iteration 70200, lr = 0.001
I0416 20:58:46.289199 23299 solver.cpp:237] Iteration 70300, loss = 0.0181081
I0416 20:58:46.289225 23299 solver.cpp:253]     Train net output #0: loss = 0.0181081 (* 1 = 0.0181081 loss)
I0416 20:58:46.289230 23299 sgd_solver.cpp:106] Iteration 70300, lr = 0.001
I0416 20:58:46.484935 23299 solver.cpp:237] Iteration 70400, loss = 0.0180392
I0416 20:58:46.484967 23299 solver.cpp:253]     Train net output #0: loss = 0.0180392 (* 1 = 0.0180392 loss)
I0416 20:58:46.484979 23299 sgd_solver.cpp:106] Iteration 70400, lr = 0.001
I0416 20:58:46.680973 23299 solver.cpp:237] Iteration 70500, loss = 0.0180114
I0416 20:58:46.681005 23299 solver.cpp:253]     Train net output #0: loss = 0.0180114 (* 1 = 0.0180114 loss)
I0416 20:58:46.681012 23299 sgd_solver.cpp:106] Iteration 70500, lr = 0.001
I0416 20:58:46.876827 23299 solver.cpp:237] Iteration 70600, loss = 0.0179573
I0416 20:58:46.876860 23299 solver.cpp:253]     Train net output #0: loss = 0.0179573 (* 1 = 0.0179573 loss)
I0416 20:58:46.876865 23299 sgd_solver.cpp:106] Iteration 70600, lr = 0.001
I0416 20:58:47.072592 23299 solver.cpp:237] Iteration 70700, loss = 0.0180076
I0416 20:58:47.072625 23299 solver.cpp:253]     Train net output #0: loss = 0.0180076 (* 1 = 0.0180076 loss)
I0416 20:58:47.072633 23299 sgd_solver.cpp:106] Iteration 70700, lr = 0.001
I0416 20:58:47.268169 23299 solver.cpp:237] Iteration 70800, loss = 0.0178868
I0416 20:58:47.268196 23299 solver.cpp:253]     Train net output #0: loss = 0.0178868 (* 1 = 0.0178868 loss)
I0416 20:58:47.268208 23299 sgd_solver.cpp:106] Iteration 70800, lr = 0.001
I0416 20:58:47.463531 23299 solver.cpp:237] Iteration 70900, loss = 0.0179205
I0416 20:58:47.463562 23299 solver.cpp:253]     Train net output #0: loss = 0.0179205 (* 1 = 0.0179205 loss)
I0416 20:58:47.463568 23299 sgd_solver.cpp:106] Iteration 70900, lr = 0.001
I0416 20:58:47.658850 23299 solver.cpp:237] Iteration 71000, loss = 0.0178643
I0416 20:58:47.658879 23299 solver.cpp:253]     Train net output #0: loss = 0.0178643 (* 1 = 0.0178643 loss)
I0416 20:58:47.658885 23299 sgd_solver.cpp:106] Iteration 71000, lr = 0.001
I0416 20:58:47.854645 23299 solver.cpp:237] Iteration 71100, loss = 0.0178775
I0416 20:58:47.854671 23299 solver.cpp:253]     Train net output #0: loss = 0.0178775 (* 1 = 0.0178775 loss)
I0416 20:58:47.854676 23299 sgd_solver.cpp:106] Iteration 71100, lr = 0.001
I0416 20:58:48.050557 23299 solver.cpp:237] Iteration 71200, loss = 0.0178213
I0416 20:58:48.050585 23299 solver.cpp:253]     Train net output #0: loss = 0.0178213 (* 1 = 0.0178213 loss)
I0416 20:58:48.050609 23299 sgd_solver.cpp:106] Iteration 71200, lr = 0.001
I0416 20:58:48.254650 23299 solver.cpp:237] Iteration 71300, loss = 0.0177565
I0416 20:58:48.254678 23299 solver.cpp:253]     Train net output #0: loss = 0.0177565 (* 1 = 0.0177565 loss)
I0416 20:58:48.254684 23299 sgd_solver.cpp:106] Iteration 71300, lr = 0.001
I0416 20:58:48.449040 23299 solver.cpp:237] Iteration 71400, loss = 0.0177891
I0416 20:58:48.449067 23299 solver.cpp:253]     Train net output #0: loss = 0.0177891 (* 1 = 0.0177891 loss)
I0416 20:58:48.449072 23299 sgd_solver.cpp:106] Iteration 71400, lr = 0.001
I0416 20:58:48.643674 23299 solver.cpp:237] Iteration 71500, loss = 0.0177058
I0416 20:58:48.643700 23299 solver.cpp:253]     Train net output #0: loss = 0.0177058 (* 1 = 0.0177058 loss)
I0416 20:58:48.643705 23299 sgd_solver.cpp:106] Iteration 71500, lr = 0.001
I0416 20:58:48.838508 23299 solver.cpp:237] Iteration 71600, loss = 0.017699
I0416 20:58:48.838536 23299 solver.cpp:253]     Train net output #0: loss = 0.017699 (* 1 = 0.017699 loss)
I0416 20:58:48.838547 23299 sgd_solver.cpp:106] Iteration 71600, lr = 0.001
I0416 20:58:49.033380 23299 solver.cpp:237] Iteration 71700, loss = 0.0176307
I0416 20:58:49.033406 23299 solver.cpp:253]     Train net output #0: loss = 0.0176307 (* 1 = 0.0176307 loss)
I0416 20:58:49.033411 23299 sgd_solver.cpp:106] Iteration 71700, lr = 0.001
I0416 20:58:49.229092 23299 solver.cpp:237] Iteration 71800, loss = 0.017722
I0416 20:58:49.229120 23299 solver.cpp:253]     Train net output #0: loss = 0.017722 (* 1 = 0.017722 loss)
I0416 20:58:49.229128 23299 sgd_solver.cpp:106] Iteration 71800, lr = 0.001
I0416 20:58:49.424938 23299 solver.cpp:237] Iteration 71900, loss = 0.0176328
I0416 20:58:49.424965 23299 solver.cpp:253]     Train net output #0: loss = 0.0176328 (* 1 = 0.0176328 loss)
I0416 20:58:49.424970 23299 sgd_solver.cpp:106] Iteration 71900, lr = 0.001
I0416 20:58:49.620569 23299 solver.cpp:237] Iteration 72000, loss = 0.0175632
I0416 20:58:49.620596 23299 solver.cpp:253]     Train net output #0: loss = 0.0175632 (* 1 = 0.0175632 loss)
I0416 20:58:49.620602 23299 sgd_solver.cpp:106] Iteration 72000, lr = 0.001
I0416 20:58:49.816051 23299 solver.cpp:237] Iteration 72100, loss = 0.0175892
I0416 20:58:49.816079 23299 solver.cpp:253]     Train net output #0: loss = 0.0175892 (* 1 = 0.0175892 loss)
I0416 20:58:49.816084 23299 sgd_solver.cpp:106] Iteration 72100, lr = 0.001
I0416 20:58:50.011232 23299 solver.cpp:237] Iteration 72200, loss = 0.017502
I0416 20:58:50.011257 23299 solver.cpp:253]     Train net output #0: loss = 0.017502 (* 1 = 0.017502 loss)
I0416 20:58:50.011265 23299 sgd_solver.cpp:106] Iteration 72200, lr = 0.001
I0416 20:58:50.207204 23299 solver.cpp:237] Iteration 72300, loss = 0.0175269
I0416 20:58:50.207233 23299 solver.cpp:253]     Train net output #0: loss = 0.0175269 (* 1 = 0.0175269 loss)
I0416 20:58:50.207238 23299 sgd_solver.cpp:106] Iteration 72300, lr = 0.001
I0416 20:58:50.402956 23299 solver.cpp:237] Iteration 72400, loss = 0.0175368
I0416 20:58:50.402984 23299 solver.cpp:253]     Train net output #0: loss = 0.0175368 (* 1 = 0.0175368 loss)
I0416 20:58:50.402989 23299 sgd_solver.cpp:106] Iteration 72400, lr = 0.001
I0416 20:58:50.598551 23299 solver.cpp:237] Iteration 72500, loss = 0.017446
I0416 20:58:50.598578 23299 solver.cpp:253]     Train net output #0: loss = 0.017446 (* 1 = 0.017446 loss)
I0416 20:58:50.598584 23299 sgd_solver.cpp:106] Iteration 72500, lr = 0.001
I0416 20:58:50.794832 23299 solver.cpp:237] Iteration 72600, loss = 0.0174647
I0416 20:58:50.794858 23299 solver.cpp:253]     Train net output #0: loss = 0.0174647 (* 1 = 0.0174647 loss)
I0416 20:58:50.794863 23299 sgd_solver.cpp:106] Iteration 72600, lr = 0.001
I0416 20:58:50.990945 23299 solver.cpp:237] Iteration 72700, loss = 0.0174584
I0416 20:58:50.990974 23299 solver.cpp:253]     Train net output #0: loss = 0.0174584 (* 1 = 0.0174584 loss)
I0416 20:58:50.990979 23299 sgd_solver.cpp:106] Iteration 72700, lr = 0.001
I0416 20:58:51.186702 23299 solver.cpp:237] Iteration 72800, loss = 0.0173963
I0416 20:58:51.186729 23299 solver.cpp:253]     Train net output #0: loss = 0.0173963 (* 1 = 0.0173963 loss)
I0416 20:58:51.186734 23299 sgd_solver.cpp:106] Iteration 72800, lr = 0.001
I0416 20:58:51.382710 23299 solver.cpp:237] Iteration 72900, loss = 0.0173933
I0416 20:58:51.382736 23299 solver.cpp:253]     Train net output #0: loss = 0.0173933 (* 1 = 0.0173933 loss)
I0416 20:58:51.382742 23299 sgd_solver.cpp:106] Iteration 72900, lr = 0.001
I0416 20:58:51.570193 23299 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 20:58:51.583950 23299 solver.cpp:237] Iteration 73000, loss = 0.0172885
I0416 20:58:51.583986 23299 solver.cpp:253]     Train net output #0: loss = 0.0172885 (* 1 = 0.0172885 loss)
I0416 20:58:51.583994 23299 sgd_solver.cpp:106] Iteration 73000, lr = 0.001
I0416 20:58:51.781193 23299 solver.cpp:237] Iteration 73100, loss = 0.0173809
I0416 20:58:51.781224 23299 solver.cpp:253]     Train net output #0: loss = 0.0173809 (* 1 = 0.0173809 loss)
I0416 20:58:51.781231 23299 sgd_solver.cpp:106] Iteration 73100, lr = 0.001
I0416 20:58:51.977517 23299 solver.cpp:237] Iteration 73200, loss = 0.0173564
I0416 20:58:51.977546 23299 solver.cpp:253]     Train net output #0: loss = 0.0173564 (* 1 = 0.0173564 loss)
I0416 20:58:51.977557 23299 sgd_solver.cpp:106] Iteration 73200, lr = 0.001
I0416 20:58:52.173496 23299 solver.cpp:237] Iteration 73300, loss = 0.0172836
I0416 20:58:52.173526 23299 solver.cpp:253]     Train net output #0: loss = 0.0172836 (* 1 = 0.0172836 loss)
I0416 20:58:52.173530 23299 sgd_solver.cpp:106] Iteration 73300, lr = 0.001
I0416 20:58:52.369055 23299 solver.cpp:237] Iteration 73400, loss = 0.0172545
I0416 20:58:52.369082 23299 solver.cpp:253]     Train net output #0: loss = 0.0172545 (* 1 = 0.0172545 loss)
I0416 20:58:52.369087 23299 sgd_solver.cpp:106] Iteration 73400, lr = 0.001
I0416 20:58:52.564853 23299 solver.cpp:237] Iteration 73500, loss = 0.0172713
I0416 20:58:52.564880 23299 solver.cpp:253]     Train net output #0: loss = 0.0172713 (* 1 = 0.0172713 loss)
I0416 20:58:52.564887 23299 sgd_solver.cpp:106] Iteration 73500, lr = 0.001
I0416 20:58:52.760756 23299 solver.cpp:237] Iteration 73600, loss = 0.017259
I0416 20:58:52.760783 23299 solver.cpp:253]     Train net output #0: loss = 0.017259 (* 1 = 0.017259 loss)
I0416 20:58:52.760789 23299 sgd_solver.cpp:106] Iteration 73600, lr = 0.001
I0416 20:58:52.957104 23299 solver.cpp:237] Iteration 73700, loss = 0.0171792
I0416 20:58:52.957131 23299 solver.cpp:253]     Train net output #0: loss = 0.0171792 (* 1 = 0.0171792 loss)
I0416 20:58:52.957136 23299 sgd_solver.cpp:106] Iteration 73700, lr = 0.001
I0416 20:58:53.152508 23299 solver.cpp:237] Iteration 73800, loss = 0.0171787
I0416 20:58:53.152534 23299 solver.cpp:253]     Train net output #0: loss = 0.0171787 (* 1 = 0.0171787 loss)
I0416 20:58:53.152539 23299 sgd_solver.cpp:106] Iteration 73800, lr = 0.001
I0416 20:58:53.348448 23299 solver.cpp:237] Iteration 73900, loss = 0.0171614
I0416 20:58:53.348474 23299 solver.cpp:253]     Train net output #0: loss = 0.0171614 (* 1 = 0.0171614 loss)
I0416 20:58:53.348479 23299 sgd_solver.cpp:106] Iteration 73900, lr = 0.001
I0416 20:58:53.544358 23299 solver.cpp:237] Iteration 74000, loss = 0.0171544
I0416 20:58:53.544389 23299 solver.cpp:253]     Train net output #0: loss = 0.0171544 (* 1 = 0.0171544 loss)
I0416 20:58:53.544395 23299 sgd_solver.cpp:106] Iteration 74000, lr = 0.001
I0416 20:58:53.739819 23299 solver.cpp:237] Iteration 74100, loss = 0.0171212
I0416 20:58:53.739850 23299 solver.cpp:253]     Train net output #0: loss = 0.0171212 (* 1 = 0.0171212 loss)
I0416 20:58:53.739856 23299 sgd_solver.cpp:106] Iteration 74100, lr = 0.001
I0416 20:58:53.935336 23299 solver.cpp:237] Iteration 74200, loss = 0.0170889
I0416 20:58:53.935362 23299 solver.cpp:253]     Train net output #0: loss = 0.0170889 (* 1 = 0.0170889 loss)
I0416 20:58:53.935369 23299 sgd_solver.cpp:106] Iteration 74200, lr = 0.001
I0416 20:58:54.130940 23299 solver.cpp:237] Iteration 74300, loss = 0.0170033
I0416 20:58:54.130988 23299 solver.cpp:253]     Train net output #0: loss = 0.0170033 (* 1 = 0.0170033 loss)
I0416 20:58:54.130995 23299 sgd_solver.cpp:106] Iteration 74300, lr = 0.001
I0416 20:58:54.326783 23299 solver.cpp:237] Iteration 74400, loss = 0.0170619
I0416 20:58:54.326810 23299 solver.cpp:253]     Train net output #0: loss = 0.0170619 (* 1 = 0.0170619 loss)
I0416 20:58:54.326815 23299 sgd_solver.cpp:106] Iteration 74400, lr = 0.001
I0416 20:58:54.523581 23299 solver.cpp:237] Iteration 74500, loss = 0.0170178
I0416 20:58:54.523609 23299 solver.cpp:253]     Train net output #0: loss = 0.0170178 (* 1 = 0.0170178 loss)
I0416 20:58:54.523615 23299 sgd_solver.cpp:106] Iteration 74500, lr = 0.001
I0416 20:58:54.719238 23299 solver.cpp:237] Iteration 74600, loss = 0.0170086
I0416 20:58:54.719264 23299 solver.cpp:253]     Train net output #0: loss = 0.0170086 (* 1 = 0.0170086 loss)
I0416 20:58:54.719269 23299 sgd_solver.cpp:106] Iteration 74600, lr = 0.001
I0416 20:58:54.914760 23299 solver.cpp:237] Iteration 74700, loss = 0.0169313
I0416 20:58:54.914793 23299 solver.cpp:253]     Train net output #0: loss = 0.0169313 (* 1 = 0.0169313 loss)
I0416 20:58:54.914801 23299 sgd_solver.cpp:106] Iteration 74700, lr = 0.001
I0416 20:58:55.111325 23299 solver.cpp:237] Iteration 74800, loss = 0.01703
I0416 20:58:55.111353 23299 solver.cpp:253]     Train net output #0: loss = 0.01703 (* 1 = 0.01703 loss)
I0416 20:58:55.111358 23299 sgd_solver.cpp:106] Iteration 74800, lr = 0.001
I0416 20:58:55.306864 23299 solver.cpp:237] Iteration 74900, loss = 0.0169044
I0416 20:58:55.306891 23299 solver.cpp:253]     Train net output #0: loss = 0.0169044 (* 1 = 0.0169044 loss)
I0416 20:58:55.306896 23299 sgd_solver.cpp:106] Iteration 74900, lr = 0.001
I0416 20:58:55.500705 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_75000.caffemodel
I0416 20:58:55.502710 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_75000.solverstate
I0416 20:58:55.503245 23299 solver.cpp:341] Iteration 75000, Testing net (#0)
I0416 20:58:55.503257 23299 net.cpp:748] Ignoring source layer dart
I0416 20:58:55.558698 23299 solver.cpp:409]     Test net output #0: accuracy = 0.813
I0416 20:58:55.558735 23299 solver.cpp:409]     Test net output #1: loss = 0.658892 (* 1 = 0.658892 loss)
I0416 20:58:55.559895 23299 solver.cpp:237] Iteration 75000, loss = 0.0169184
I0416 20:58:55.559922 23299 solver.cpp:253]     Train net output #0: loss = 0.0169184 (* 1 = 0.0169184 loss)
I0416 20:58:55.559933 23299 sgd_solver.cpp:106] Iteration 75000, lr = 0.001
I0416 20:58:55.764004 23299 solver.cpp:237] Iteration 75100, loss = 0.0168945
I0416 20:58:55.764047 23299 solver.cpp:253]     Train net output #0: loss = 0.0168945 (* 1 = 0.0168945 loss)
I0416 20:58:55.764058 23299 sgd_solver.cpp:106] Iteration 75100, lr = 0.001
I0416 20:58:55.966627 23299 solver.cpp:237] Iteration 75200, loss = 0.0168637
I0416 20:58:55.966677 23299 solver.cpp:253]     Train net output #0: loss = 0.0168637 (* 1 = 0.0168637 loss)
I0416 20:58:55.966693 23299 sgd_solver.cpp:106] Iteration 75200, lr = 0.001
I0416 20:58:56.166936 23299 solver.cpp:237] Iteration 75300, loss = 0.0168509
I0416 20:58:56.166971 23299 solver.cpp:253]     Train net output #0: loss = 0.0168509 (* 1 = 0.0168509 loss)
I0416 20:58:56.166987 23299 sgd_solver.cpp:106] Iteration 75300, lr = 0.001
I0416 20:58:56.362962 23299 solver.cpp:237] Iteration 75400, loss = 0.016816
I0416 20:58:56.362993 23299 solver.cpp:253]     Train net output #0: loss = 0.016816 (* 1 = 0.016816 loss)
I0416 20:58:56.363001 23299 sgd_solver.cpp:106] Iteration 75400, lr = 0.001
I0416 20:58:56.558873 23299 solver.cpp:237] Iteration 75500, loss = 0.016815
I0416 20:58:56.558908 23299 solver.cpp:253]     Train net output #0: loss = 0.016815 (* 1 = 0.016815 loss)
I0416 20:58:56.558913 23299 sgd_solver.cpp:106] Iteration 75500, lr = 0.001
I0416 20:58:56.754657 23299 solver.cpp:237] Iteration 75600, loss = 0.0168269
I0416 20:58:56.754688 23299 solver.cpp:253]     Train net output #0: loss = 0.0168269 (* 1 = 0.0168269 loss)
I0416 20:58:56.754725 23299 sgd_solver.cpp:106] Iteration 75600, lr = 0.001
I0416 20:58:56.951329 23299 solver.cpp:237] Iteration 75700, loss = 0.0167509
I0416 20:58:56.951362 23299 solver.cpp:253]     Train net output #0: loss = 0.0167509 (* 1 = 0.0167509 loss)
I0416 20:58:56.951369 23299 sgd_solver.cpp:106] Iteration 75700, lr = 0.001
I0416 20:58:57.147055 23299 solver.cpp:237] Iteration 75800, loss = 0.0167843
I0416 20:58:57.147085 23299 solver.cpp:253]     Train net output #0: loss = 0.0167843 (* 1 = 0.0167843 loss)
I0416 20:58:57.147092 23299 sgd_solver.cpp:106] Iteration 75800, lr = 0.001
I0416 20:58:57.343009 23299 solver.cpp:237] Iteration 75900, loss = 0.0167249
I0416 20:58:57.343037 23299 solver.cpp:253]     Train net output #0: loss = 0.0167249 (* 1 = 0.0167249 loss)
I0416 20:58:57.343042 23299 sgd_solver.cpp:106] Iteration 75900, lr = 0.001
I0416 20:58:57.538293 23299 solver.cpp:237] Iteration 76000, loss = 0.016647
I0416 20:58:57.538323 23299 solver.cpp:253]     Train net output #0: loss = 0.016647 (* 1 = 0.016647 loss)
I0416 20:58:57.538339 23299 sgd_solver.cpp:106] Iteration 76000, lr = 0.001
I0416 20:58:57.733605 23299 solver.cpp:237] Iteration 76100, loss = 0.0167142
I0416 20:58:57.733633 23299 solver.cpp:253]     Train net output #0: loss = 0.0167142 (* 1 = 0.0167142 loss)
I0416 20:58:57.733640 23299 sgd_solver.cpp:106] Iteration 76100, lr = 0.001
I0416 20:58:57.931545 23299 solver.cpp:237] Iteration 76200, loss = 0.0166596
I0416 20:58:57.931591 23299 solver.cpp:253]     Train net output #0: loss = 0.0166596 (* 1 = 0.0166596 loss)
I0416 20:58:57.931602 23299 sgd_solver.cpp:106] Iteration 76200, lr = 0.001
I0416 20:58:58.133339 23299 solver.cpp:237] Iteration 76300, loss = 0.0165934
I0416 20:58:58.133374 23299 solver.cpp:253]     Train net output #0: loss = 0.0165934 (* 1 = 0.0165934 loss)
I0416 20:58:58.133383 23299 sgd_solver.cpp:106] Iteration 76300, lr = 0.001
I0416 20:58:58.329486 23299 solver.cpp:237] Iteration 76400, loss = 0.0166452
I0416 20:58:58.329516 23299 solver.cpp:253]     Train net output #0: loss = 0.0166452 (* 1 = 0.0166452 loss)
I0416 20:58:58.329522 23299 sgd_solver.cpp:106] Iteration 76400, lr = 0.001
I0416 20:58:58.525450 23299 solver.cpp:237] Iteration 76500, loss = 0.0166315
I0416 20:58:58.525481 23299 solver.cpp:253]     Train net output #0: loss = 0.0166315 (* 1 = 0.0166315 loss)
I0416 20:58:58.525495 23299 sgd_solver.cpp:106] Iteration 76500, lr = 0.001
I0416 20:58:58.721853 23299 solver.cpp:237] Iteration 76600, loss = 0.016565
I0416 20:58:58.721882 23299 solver.cpp:253]     Train net output #0: loss = 0.016565 (* 1 = 0.016565 loss)
I0416 20:58:58.721889 23299 sgd_solver.cpp:106] Iteration 76600, lr = 0.001
I0416 20:58:58.919754 23299 solver.cpp:237] Iteration 76700, loss = 0.0165847
I0416 20:58:58.919785 23299 solver.cpp:253]     Train net output #0: loss = 0.0165847 (* 1 = 0.0165847 loss)
I0416 20:58:58.919791 23299 sgd_solver.cpp:106] Iteration 76700, lr = 0.001
I0416 20:58:59.115592 23299 solver.cpp:237] Iteration 76800, loss = 0.0165652
I0416 20:58:59.115620 23299 solver.cpp:253]     Train net output #0: loss = 0.0165652 (* 1 = 0.0165652 loss)
I0416 20:58:59.115627 23299 sgd_solver.cpp:106] Iteration 76800, lr = 0.001
I0416 20:58:59.311805 23299 solver.cpp:237] Iteration 76900, loss = 0.0164989
I0416 20:58:59.311836 23299 solver.cpp:253]     Train net output #0: loss = 0.0164989 (* 1 = 0.0164989 loss)
I0416 20:58:59.311841 23299 sgd_solver.cpp:106] Iteration 76900, lr = 0.001
I0416 20:58:59.507817 23299 solver.cpp:237] Iteration 77000, loss = 0.0164939
I0416 20:58:59.507848 23299 solver.cpp:253]     Train net output #0: loss = 0.0164939 (* 1 = 0.0164939 loss)
I0416 20:58:59.507853 23299 sgd_solver.cpp:106] Iteration 77000, lr = 0.001
I0416 20:58:59.704238 23299 solver.cpp:237] Iteration 77100, loss = 0.0165247
I0416 20:58:59.704267 23299 solver.cpp:253]     Train net output #0: loss = 0.0165247 (* 1 = 0.0165247 loss)
I0416 20:58:59.704273 23299 sgd_solver.cpp:106] Iteration 77100, lr = 0.001
I0416 20:58:59.899871 23299 solver.cpp:237] Iteration 77200, loss = 0.0164744
I0416 20:58:59.899919 23299 solver.cpp:253]     Train net output #0: loss = 0.0164744 (* 1 = 0.0164744 loss)
I0416 20:58:59.899925 23299 sgd_solver.cpp:106] Iteration 77200, lr = 0.001
I0416 20:59:00.095233 23299 solver.cpp:237] Iteration 77300, loss = 0.0164668
I0416 20:59:00.095259 23299 solver.cpp:253]     Train net output #0: loss = 0.0164668 (* 1 = 0.0164668 loss)
I0416 20:59:00.095264 23299 sgd_solver.cpp:106] Iteration 77300, lr = 0.001
I0416 20:59:00.291039 23299 solver.cpp:237] Iteration 77400, loss = 0.0163945
I0416 20:59:00.291065 23299 solver.cpp:253]     Train net output #0: loss = 0.0163945 (* 1 = 0.0163945 loss)
I0416 20:59:00.291071 23299 sgd_solver.cpp:106] Iteration 77400, lr = 0.001
I0416 20:59:00.486302 23299 solver.cpp:237] Iteration 77500, loss = 0.0164287
I0416 20:59:00.486330 23299 solver.cpp:253]     Train net output #0: loss = 0.0164287 (* 1 = 0.0164287 loss)
I0416 20:59:00.486335 23299 sgd_solver.cpp:106] Iteration 77500, lr = 0.001
I0416 20:59:00.682458 23299 solver.cpp:237] Iteration 77600, loss = 0.0164748
I0416 20:59:00.682487 23299 solver.cpp:253]     Train net output #0: loss = 0.0164748 (* 1 = 0.0164748 loss)
I0416 20:59:00.682492 23299 sgd_solver.cpp:106] Iteration 77600, lr = 0.001
I0416 20:59:00.877413 23299 solver.cpp:237] Iteration 77700, loss = 0.0163601
I0416 20:59:00.877441 23299 solver.cpp:253]     Train net output #0: loss = 0.0163601 (* 1 = 0.0163601 loss)
I0416 20:59:00.877449 23299 sgd_solver.cpp:106] Iteration 77700, lr = 0.001
I0416 20:59:01.072942 23299 solver.cpp:237] Iteration 77800, loss = 0.0163893
I0416 20:59:01.072968 23299 solver.cpp:253]     Train net output #0: loss = 0.0163893 (* 1 = 0.0163893 loss)
I0416 20:59:01.072973 23299 sgd_solver.cpp:106] Iteration 77800, lr = 0.001
I0416 20:59:01.268301 23299 solver.cpp:237] Iteration 77900, loss = 0.0163898
I0416 20:59:01.268328 23299 solver.cpp:253]     Train net output #0: loss = 0.0163898 (* 1 = 0.0163898 loss)
I0416 20:59:01.268335 23299 sgd_solver.cpp:106] Iteration 77900, lr = 0.001
I0416 20:59:01.464323 23299 solver.cpp:237] Iteration 78000, loss = 0.0163257
I0416 20:59:01.464349 23299 solver.cpp:253]     Train net output #0: loss = 0.0163257 (* 1 = 0.0163257 loss)
I0416 20:59:01.464357 23299 sgd_solver.cpp:106] Iteration 78000, lr = 0.001
I0416 20:59:01.660148 23299 solver.cpp:237] Iteration 78100, loss = 0.0163389
I0416 20:59:01.660176 23299 solver.cpp:253]     Train net output #0: loss = 0.0163389 (* 1 = 0.0163389 loss)
I0416 20:59:01.660181 23299 sgd_solver.cpp:106] Iteration 78100, lr = 0.001
I0416 20:59:01.855376 23299 solver.cpp:237] Iteration 78200, loss = 0.0163364
I0416 20:59:01.855402 23299 solver.cpp:253]     Train net output #0: loss = 0.0163364 (* 1 = 0.0163364 loss)
I0416 20:59:01.855407 23299 sgd_solver.cpp:106] Iteration 78200, lr = 0.001
I0416 20:59:02.050834 23299 solver.cpp:237] Iteration 78300, loss = 0.0163175
I0416 20:59:02.050861 23299 solver.cpp:253]     Train net output #0: loss = 0.0163175 (* 1 = 0.0163175 loss)
I0416 20:59:02.050868 23299 sgd_solver.cpp:106] Iteration 78300, lr = 0.001
I0416 20:59:02.246300 23299 solver.cpp:237] Iteration 78400, loss = 0.0163095
I0416 20:59:02.246330 23299 solver.cpp:253]     Train net output #0: loss = 0.0163095 (* 1 = 0.0163095 loss)
I0416 20:59:02.246341 23299 sgd_solver.cpp:106] Iteration 78400, lr = 0.001
I0416 20:59:02.441432 23299 solver.cpp:237] Iteration 78500, loss = 0.0162921
I0416 20:59:02.441459 23299 solver.cpp:253]     Train net output #0: loss = 0.0162921 (* 1 = 0.0162921 loss)
I0416 20:59:02.441464 23299 sgd_solver.cpp:106] Iteration 78500, lr = 0.001
I0416 20:59:02.636833 23299 solver.cpp:237] Iteration 78600, loss = 0.0162622
I0416 20:59:02.636859 23299 solver.cpp:253]     Train net output #0: loss = 0.0162622 (* 1 = 0.0162622 loss)
I0416 20:59:02.636864 23299 sgd_solver.cpp:106] Iteration 78600, lr = 0.001
I0416 20:59:02.832942 23299 solver.cpp:237] Iteration 78700, loss = 0.0163096
I0416 20:59:02.832968 23299 solver.cpp:253]     Train net output #0: loss = 0.0163096 (* 1 = 0.0163096 loss)
I0416 20:59:02.832973 23299 sgd_solver.cpp:106] Iteration 78700, lr = 0.001
I0416 20:59:03.028707 23299 solver.cpp:237] Iteration 78800, loss = 0.0162305
I0416 20:59:03.028735 23299 solver.cpp:253]     Train net output #0: loss = 0.0162305 (* 1 = 0.0162305 loss)
I0416 20:59:03.028740 23299 sgd_solver.cpp:106] Iteration 78800, lr = 0.001
I0416 20:59:03.223870 23299 solver.cpp:237] Iteration 78900, loss = 0.0162562
I0416 20:59:03.223897 23299 solver.cpp:253]     Train net output #0: loss = 0.0162562 (* 1 = 0.0162562 loss)
I0416 20:59:03.223904 23299 sgd_solver.cpp:106] Iteration 78900, lr = 0.001
I0416 20:59:03.419504 23299 solver.cpp:237] Iteration 79000, loss = 0.0162529
I0416 20:59:03.419530 23299 solver.cpp:253]     Train net output #0: loss = 0.0162529 (* 1 = 0.0162529 loss)
I0416 20:59:03.419535 23299 sgd_solver.cpp:106] Iteration 79000, lr = 0.001
I0416 20:59:03.614748 23299 solver.cpp:237] Iteration 79100, loss = 0.0161823
I0416 20:59:03.614773 23299 solver.cpp:253]     Train net output #0: loss = 0.0161823 (* 1 = 0.0161823 loss)
I0416 20:59:03.614778 23299 sgd_solver.cpp:106] Iteration 79100, lr = 0.001
I0416 20:59:03.809885 23299 solver.cpp:237] Iteration 79200, loss = 0.0161933
I0416 20:59:03.809912 23299 solver.cpp:253]     Train net output #0: loss = 0.0161933 (* 1 = 0.0161933 loss)
I0416 20:59:03.809917 23299 sgd_solver.cpp:106] Iteration 79200, lr = 0.001
I0416 20:59:04.004894 23299 solver.cpp:237] Iteration 79300, loss = 0.0161876
I0416 20:59:04.004932 23299 solver.cpp:253]     Train net output #0: loss = 0.0161876 (* 1 = 0.0161876 loss)
I0416 20:59:04.004940 23299 sgd_solver.cpp:106] Iteration 79300, lr = 0.001
I0416 20:59:04.200130 23299 solver.cpp:237] Iteration 79400, loss = 0.016212
I0416 20:59:04.200157 23299 solver.cpp:253]     Train net output #0: loss = 0.016212 (* 1 = 0.016212 loss)
I0416 20:59:04.200162 23299 sgd_solver.cpp:106] Iteration 79400, lr = 0.001
I0416 20:59:04.395169 23299 solver.cpp:237] Iteration 79500, loss = 0.0162372
I0416 20:59:04.395196 23299 solver.cpp:253]     Train net output #0: loss = 0.0162372 (* 1 = 0.0162372 loss)
I0416 20:59:04.395201 23299 sgd_solver.cpp:106] Iteration 79500, lr = 0.001
I0416 20:59:04.591105 23299 solver.cpp:237] Iteration 79600, loss = 0.0161764
I0416 20:59:04.591132 23299 solver.cpp:253]     Train net output #0: loss = 0.0161764 (* 1 = 0.0161764 loss)
I0416 20:59:04.591138 23299 sgd_solver.cpp:106] Iteration 79600, lr = 0.001
I0416 20:59:04.786425 23299 solver.cpp:237] Iteration 79700, loss = 0.0161481
I0416 20:59:04.786453 23299 solver.cpp:253]     Train net output #0: loss = 0.0161481 (* 1 = 0.0161481 loss)
I0416 20:59:04.786458 23299 sgd_solver.cpp:106] Iteration 79700, lr = 0.001
I0416 20:59:04.982060 23299 solver.cpp:237] Iteration 79800, loss = 0.0161902
I0416 20:59:04.982087 23299 solver.cpp:253]     Train net output #0: loss = 0.0161902 (* 1 = 0.0161902 loss)
I0416 20:59:04.982092 23299 sgd_solver.cpp:106] Iteration 79800, lr = 0.001
I0416 20:59:05.177376 23299 solver.cpp:237] Iteration 79900, loss = 0.0160973
I0416 20:59:05.177402 23299 solver.cpp:253]     Train net output #0: loss = 0.0160973 (* 1 = 0.0160973 loss)
I0416 20:59:05.177407 23299 sgd_solver.cpp:106] Iteration 79900, lr = 0.001
I0416 20:59:05.370820 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_80000.caffemodel
I0416 20:59:05.372823 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_80000.solverstate
I0416 20:59:05.373364 23299 solver.cpp:341] Iteration 80000, Testing net (#0)
I0416 20:59:05.373374 23299 net.cpp:748] Ignoring source layer dart
I0416 20:59:05.423903 23299 solver.cpp:409]     Test net output #0: accuracy = 0.818
I0416 20:59:05.423935 23299 solver.cpp:409]     Test net output #1: loss = 0.64618 (* 1 = 0.64618 loss)
I0416 20:59:05.424922 23299 solver.cpp:237] Iteration 80000, loss = 0.0161166
I0416 20:59:05.424945 23299 solver.cpp:253]     Train net output #0: loss = 0.0161166 (* 1 = 0.0161166 loss)
I0416 20:59:05.424954 23299 sgd_solver.cpp:106] Iteration 80000, lr = 0.001
I0416 20:59:05.620379 23299 solver.cpp:237] Iteration 80100, loss = 0.0161259
I0416 20:59:05.620431 23299 solver.cpp:253]     Train net output #0: loss = 0.0161259 (* 1 = 0.0161259 loss)
I0416 20:59:05.620439 23299 sgd_solver.cpp:106] Iteration 80100, lr = 0.001
I0416 20:59:05.815959 23299 solver.cpp:237] Iteration 80200, loss = 0.0161172
I0416 20:59:05.815994 23299 solver.cpp:253]     Train net output #0: loss = 0.0161172 (* 1 = 0.0161172 loss)
I0416 20:59:05.816004 23299 sgd_solver.cpp:106] Iteration 80200, lr = 0.001
I0416 20:59:06.011809 23299 solver.cpp:237] Iteration 80300, loss = 0.0160609
I0416 20:59:06.011837 23299 solver.cpp:253]     Train net output #0: loss = 0.0160609 (* 1 = 0.0160609 loss)
I0416 20:59:06.011842 23299 sgd_solver.cpp:106] Iteration 80300, lr = 0.001
I0416 20:59:06.207276 23299 solver.cpp:237] Iteration 80400, loss = 0.016082
I0416 20:59:06.207304 23299 solver.cpp:253]     Train net output #0: loss = 0.016082 (* 1 = 0.016082 loss)
I0416 20:59:06.207310 23299 sgd_solver.cpp:106] Iteration 80400, lr = 0.001
I0416 20:59:06.404309 23299 solver.cpp:237] Iteration 80500, loss = 0.0160156
I0416 20:59:06.404450 23299 solver.cpp:253]     Train net output #0: loss = 0.0160156 (* 1 = 0.0160156 loss)
I0416 20:59:06.404459 23299 sgd_solver.cpp:106] Iteration 80500, lr = 0.001
I0416 20:59:06.600039 23299 solver.cpp:237] Iteration 80600, loss = 0.016054
I0416 20:59:06.600069 23299 solver.cpp:253]     Train net output #0: loss = 0.016054 (* 1 = 0.016054 loss)
I0416 20:59:06.600076 23299 sgd_solver.cpp:106] Iteration 80600, lr = 0.001
I0416 20:59:06.801086 23299 solver.cpp:237] Iteration 80700, loss = 0.0160629
I0416 20:59:06.801120 23299 solver.cpp:253]     Train net output #0: loss = 0.0160629 (* 1 = 0.0160629 loss)
I0416 20:59:06.801146 23299 sgd_solver.cpp:106] Iteration 80700, lr = 0.001
I0416 20:59:06.998198 23299 solver.cpp:237] Iteration 80800, loss = 0.0160529
I0416 20:59:06.998230 23299 solver.cpp:253]     Train net output #0: loss = 0.0160529 (* 1 = 0.0160529 loss)
I0416 20:59:06.998235 23299 sgd_solver.cpp:106] Iteration 80800, lr = 0.001
I0416 20:59:07.202271 23299 solver.cpp:237] Iteration 80900, loss = 0.015998
I0416 20:59:07.202308 23299 solver.cpp:253]     Train net output #0: loss = 0.015998 (* 1 = 0.015998 loss)
I0416 20:59:07.202316 23299 sgd_solver.cpp:106] Iteration 80900, lr = 0.001
I0416 20:59:07.400115 23299 solver.cpp:237] Iteration 81000, loss = 0.01602
I0416 20:59:07.400146 23299 solver.cpp:253]     Train net output #0: loss = 0.01602 (* 1 = 0.01602 loss)
I0416 20:59:07.400159 23299 sgd_solver.cpp:106] Iteration 81000, lr = 0.001
I0416 20:59:07.596209 23299 solver.cpp:237] Iteration 81100, loss = 0.0160258
I0416 20:59:07.596240 23299 solver.cpp:253]     Train net output #0: loss = 0.0160258 (* 1 = 0.0160258 loss)
I0416 20:59:07.596246 23299 sgd_solver.cpp:106] Iteration 81100, lr = 0.001
I0416 20:59:07.792819 23299 solver.cpp:237] Iteration 81200, loss = 0.0159662
I0416 20:59:07.792848 23299 solver.cpp:253]     Train net output #0: loss = 0.0159662 (* 1 = 0.0159662 loss)
I0416 20:59:07.792855 23299 sgd_solver.cpp:106] Iteration 81200, lr = 0.001
I0416 20:59:07.988864 23299 solver.cpp:237] Iteration 81300, loss = 0.0159773
I0416 20:59:07.988903 23299 solver.cpp:253]     Train net output #0: loss = 0.0159773 (* 1 = 0.0159773 loss)
I0416 20:59:07.988914 23299 sgd_solver.cpp:106] Iteration 81300, lr = 0.001
I0416 20:59:08.184747 23299 solver.cpp:237] Iteration 81400, loss = 0.0159654
I0416 20:59:08.184777 23299 solver.cpp:253]     Train net output #0: loss = 0.0159654 (* 1 = 0.0159654 loss)
I0416 20:59:08.184782 23299 sgd_solver.cpp:106] Iteration 81400, lr = 0.001
I0416 20:59:08.379916 23299 solver.cpp:237] Iteration 81500, loss = 0.0159245
I0416 20:59:08.379945 23299 solver.cpp:253]     Train net output #0: loss = 0.0159245 (* 1 = 0.0159245 loss)
I0416 20:59:08.379951 23299 sgd_solver.cpp:106] Iteration 81500, lr = 0.001
I0416 20:59:08.575791 23299 solver.cpp:237] Iteration 81600, loss = 0.0159369
I0416 20:59:08.575825 23299 solver.cpp:253]     Train net output #0: loss = 0.0159369 (* 1 = 0.0159369 loss)
I0416 20:59:08.575832 23299 sgd_solver.cpp:106] Iteration 81600, lr = 0.001
I0416 20:59:08.771672 23299 solver.cpp:237] Iteration 81700, loss = 0.0159027
I0416 20:59:08.771699 23299 solver.cpp:253]     Train net output #0: loss = 0.0159027 (* 1 = 0.0159027 loss)
I0416 20:59:08.771705 23299 sgd_solver.cpp:106] Iteration 81700, lr = 0.001
I0416 20:59:08.968595 23299 solver.cpp:237] Iteration 81800, loss = 0.0158941
I0416 20:59:08.968621 23299 solver.cpp:253]     Train net output #0: loss = 0.0158941 (* 1 = 0.0158941 loss)
I0416 20:59:08.968626 23299 sgd_solver.cpp:106] Iteration 81800, lr = 0.001
I0416 20:59:09.164198 23299 solver.cpp:237] Iteration 81900, loss = 0.0158416
I0416 20:59:09.164225 23299 solver.cpp:253]     Train net output #0: loss = 0.0158416 (* 1 = 0.0158416 loss)
I0416 20:59:09.164232 23299 sgd_solver.cpp:106] Iteration 81900, lr = 0.001
I0416 20:59:09.362970 23299 solver.cpp:237] Iteration 82000, loss = 0.0158958
I0416 20:59:09.363013 23299 solver.cpp:253]     Train net output #0: loss = 0.0158958 (* 1 = 0.0158958 loss)
I0416 20:59:09.363024 23299 sgd_solver.cpp:106] Iteration 82000, lr = 0.001
I0416 20:59:09.559398 23299 solver.cpp:237] Iteration 82100, loss = 0.0158904
I0416 20:59:09.559432 23299 solver.cpp:253]     Train net output #0: loss = 0.0158904 (* 1 = 0.0158904 loss)
I0416 20:59:09.559445 23299 sgd_solver.cpp:106] Iteration 82100, lr = 0.001
I0416 20:59:09.755216 23299 solver.cpp:237] Iteration 82200, loss = 0.0158253
I0416 20:59:09.755244 23299 solver.cpp:253]     Train net output #0: loss = 0.0158253 (* 1 = 0.0158253 loss)
I0416 20:59:09.755249 23299 sgd_solver.cpp:106] Iteration 82200, lr = 0.001
I0416 20:59:09.950981 23299 solver.cpp:237] Iteration 82300, loss = 0.0158059
I0416 20:59:09.951011 23299 solver.cpp:253]     Train net output #0: loss = 0.0158059 (* 1 = 0.0158059 loss)
I0416 20:59:09.951017 23299 sgd_solver.cpp:106] Iteration 82300, lr = 0.001
I0416 20:59:10.146234 23299 solver.cpp:237] Iteration 82400, loss = 0.0157769
I0416 20:59:10.146265 23299 solver.cpp:253]     Train net output #0: loss = 0.0157769 (* 1 = 0.0157769 loss)
I0416 20:59:10.146273 23299 sgd_solver.cpp:106] Iteration 82400, lr = 0.001
I0416 20:59:10.342000 23299 solver.cpp:237] Iteration 82500, loss = 0.0158679
I0416 20:59:10.342031 23299 solver.cpp:253]     Train net output #0: loss = 0.0158679 (* 1 = 0.0158679 loss)
I0416 20:59:10.342043 23299 sgd_solver.cpp:106] Iteration 82500, lr = 0.001
I0416 20:59:10.537744 23299 solver.cpp:237] Iteration 82600, loss = 0.0157837
I0416 20:59:10.537775 23299 solver.cpp:253]     Train net output #0: loss = 0.0157837 (* 1 = 0.0157837 loss)
I0416 20:59:10.537780 23299 sgd_solver.cpp:106] Iteration 82600, lr = 0.001
I0416 20:59:10.733211 23299 solver.cpp:237] Iteration 82700, loss = 0.0157574
I0416 20:59:10.733240 23299 solver.cpp:253]     Train net output #0: loss = 0.0157574 (* 1 = 0.0157574 loss)
I0416 20:59:10.733253 23299 sgd_solver.cpp:106] Iteration 82700, lr = 0.001
I0416 20:59:10.930013 23299 solver.cpp:237] Iteration 82800, loss = 0.01578
I0416 20:59:10.930073 23299 solver.cpp:253]     Train net output #0: loss = 0.01578 (* 1 = 0.01578 loss)
I0416 20:59:10.930094 23299 sgd_solver.cpp:106] Iteration 82800, lr = 0.001
I0416 20:59:11.130213 23299 solver.cpp:237] Iteration 82900, loss = 0.0157677
I0416 20:59:11.130244 23299 solver.cpp:253]     Train net output #0: loss = 0.0157677 (* 1 = 0.0157677 loss)
I0416 20:59:11.130249 23299 sgd_solver.cpp:106] Iteration 82900, lr = 0.001
I0416 20:59:11.328079 23299 solver.cpp:237] Iteration 83000, loss = 0.0157487
I0416 20:59:11.328115 23299 solver.cpp:253]     Train net output #0: loss = 0.0157487 (* 1 = 0.0157487 loss)
I0416 20:59:11.328125 23299 sgd_solver.cpp:106] Iteration 83000, lr = 0.001
I0416 20:59:11.529265 23299 solver.cpp:237] Iteration 83100, loss = 0.0156896
I0416 20:59:11.529297 23299 solver.cpp:253]     Train net output #0: loss = 0.0156896 (* 1 = 0.0156896 loss)
I0416 20:59:11.529304 23299 sgd_solver.cpp:106] Iteration 83100, lr = 0.001
I0416 20:59:11.725127 23299 solver.cpp:237] Iteration 83200, loss = 0.0157202
I0416 20:59:11.725153 23299 solver.cpp:253]     Train net output #0: loss = 0.0157202 (* 1 = 0.0157202 loss)
I0416 20:59:11.725159 23299 sgd_solver.cpp:106] Iteration 83200, lr = 0.001
I0416 20:59:11.920305 23299 solver.cpp:237] Iteration 83300, loss = 0.0157078
I0416 20:59:11.920331 23299 solver.cpp:253]     Train net output #0: loss = 0.0157078 (* 1 = 0.0157078 loss)
I0416 20:59:11.920338 23299 sgd_solver.cpp:106] Iteration 83300, lr = 0.001
I0416 20:59:11.957665 23299 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 20:59:12.115911 23299 solver.cpp:237] Iteration 83400, loss = 0.0156815
I0416 20:59:12.115941 23299 solver.cpp:253]     Train net output #0: loss = 0.0156815 (* 1 = 0.0156815 loss)
I0416 20:59:12.115947 23299 sgd_solver.cpp:106] Iteration 83400, lr = 0.001
I0416 20:59:12.313973 23299 solver.cpp:237] Iteration 83500, loss = 0.0157091
I0416 20:59:12.314005 23299 solver.cpp:253]     Train net output #0: loss = 0.0157091 (* 1 = 0.0157091 loss)
I0416 20:59:12.314012 23299 sgd_solver.cpp:106] Iteration 83500, lr = 0.001
I0416 20:59:12.509469 23299 solver.cpp:237] Iteration 83600, loss = 0.0156887
I0416 20:59:12.509516 23299 solver.cpp:253]     Train net output #0: loss = 0.0156887 (* 1 = 0.0156887 loss)
I0416 20:59:12.509526 23299 sgd_solver.cpp:106] Iteration 83600, lr = 0.001
I0416 20:59:12.705130 23299 solver.cpp:237] Iteration 83700, loss = 0.0156553
I0416 20:59:12.705157 23299 solver.cpp:253]     Train net output #0: loss = 0.0156553 (* 1 = 0.0156553 loss)
I0416 20:59:12.705163 23299 sgd_solver.cpp:106] Iteration 83700, lr = 0.001
I0416 20:59:12.899919 23299 solver.cpp:237] Iteration 83800, loss = 0.0156497
I0416 20:59:12.899947 23299 solver.cpp:253]     Train net output #0: loss = 0.0156497 (* 1 = 0.0156497 loss)
I0416 20:59:12.899960 23299 sgd_solver.cpp:106] Iteration 83800, lr = 0.001
I0416 20:59:13.096329 23299 solver.cpp:237] Iteration 83900, loss = 0.015613
I0416 20:59:13.096364 23299 solver.cpp:253]     Train net output #0: loss = 0.015613 (* 1 = 0.015613 loss)
I0416 20:59:13.096377 23299 sgd_solver.cpp:106] Iteration 83900, lr = 0.001
I0416 20:59:13.292166 23299 solver.cpp:237] Iteration 84000, loss = 0.0156638
I0416 20:59:13.292197 23299 solver.cpp:253]     Train net output #0: loss = 0.0156638 (* 1 = 0.0156638 loss)
I0416 20:59:13.292209 23299 sgd_solver.cpp:106] Iteration 84000, lr = 0.001
I0416 20:59:13.488487 23299 solver.cpp:237] Iteration 84100, loss = 0.0156501
I0416 20:59:13.488517 23299 solver.cpp:253]     Train net output #0: loss = 0.0156501 (* 1 = 0.0156501 loss)
I0416 20:59:13.488524 23299 sgd_solver.cpp:106] Iteration 84100, lr = 0.001
I0416 20:59:13.684777 23299 solver.cpp:237] Iteration 84200, loss = 0.0156444
I0416 20:59:13.684803 23299 solver.cpp:253]     Train net output #0: loss = 0.0156444 (* 1 = 0.0156444 loss)
I0416 20:59:13.684808 23299 sgd_solver.cpp:106] Iteration 84200, lr = 0.001
I0416 20:59:13.880630 23299 solver.cpp:237] Iteration 84300, loss = 0.015585
I0416 20:59:13.880662 23299 solver.cpp:253]     Train net output #0: loss = 0.015585 (* 1 = 0.015585 loss)
I0416 20:59:13.880676 23299 sgd_solver.cpp:106] Iteration 84300, lr = 0.001
I0416 20:59:14.076052 23299 solver.cpp:237] Iteration 84400, loss = 0.015605
I0416 20:59:14.076078 23299 solver.cpp:253]     Train net output #0: loss = 0.015605 (* 1 = 0.015605 loss)
I0416 20:59:14.076083 23299 sgd_solver.cpp:106] Iteration 84400, lr = 0.001
I0416 20:59:14.271615 23299 solver.cpp:237] Iteration 84500, loss = 0.0155695
I0416 20:59:14.271641 23299 solver.cpp:253]     Train net output #0: loss = 0.0155695 (* 1 = 0.0155695 loss)
I0416 20:59:14.271646 23299 sgd_solver.cpp:106] Iteration 84500, lr = 0.001
I0416 20:59:14.467026 23299 solver.cpp:237] Iteration 84600, loss = 0.0155932
I0416 20:59:14.467056 23299 solver.cpp:253]     Train net output #0: loss = 0.0155932 (* 1 = 0.0155932 loss)
I0416 20:59:14.467067 23299 sgd_solver.cpp:106] Iteration 84600, lr = 0.001
I0416 20:59:14.664682 23299 solver.cpp:237] Iteration 84700, loss = 0.0155975
I0416 20:59:14.664712 23299 solver.cpp:253]     Train net output #0: loss = 0.0155975 (* 1 = 0.0155975 loss)
I0416 20:59:14.664717 23299 sgd_solver.cpp:106] Iteration 84700, lr = 0.001
I0416 20:59:14.871207 23299 solver.cpp:237] Iteration 84800, loss = 0.0155766
I0416 20:59:14.871248 23299 solver.cpp:253]     Train net output #0: loss = 0.0155766 (* 1 = 0.0155766 loss)
I0416 20:59:14.871256 23299 sgd_solver.cpp:106] Iteration 84800, lr = 0.001
I0416 20:59:15.066776 23299 solver.cpp:237] Iteration 84900, loss = 0.0155519
I0416 20:59:15.066805 23299 solver.cpp:253]     Train net output #0: loss = 0.0155519 (* 1 = 0.0155519 loss)
I0416 20:59:15.066812 23299 sgd_solver.cpp:106] Iteration 84900, lr = 0.001
I0416 20:59:15.259881 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_85000.caffemodel
I0416 20:59:15.261865 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_85000.solverstate
I0416 20:59:15.262406 23299 solver.cpp:341] Iteration 85000, Testing net (#0)
I0416 20:59:15.262416 23299 net.cpp:748] Ignoring source layer dart
I0416 20:59:15.320451 23299 solver.cpp:409]     Test net output #0: accuracy = 0.818
I0416 20:59:15.320515 23299 solver.cpp:409]     Test net output #1: loss = 0.635775 (* 1 = 0.635775 loss)
I0416 20:59:15.321665 23299 solver.cpp:237] Iteration 85000, loss = 0.0155656
I0416 20:59:15.321699 23299 solver.cpp:253]     Train net output #0: loss = 0.0155656 (* 1 = 0.0155656 loss)
I0416 20:59:15.321718 23299 sgd_solver.cpp:106] Iteration 85000, lr = 0.001
I0416 20:59:15.517617 23299 solver.cpp:237] Iteration 85100, loss = 0.0155757
I0416 20:59:15.517645 23299 solver.cpp:253]     Train net output #0: loss = 0.0155757 (* 1 = 0.0155757 loss)
I0416 20:59:15.517650 23299 sgd_solver.cpp:106] Iteration 85100, lr = 0.001
I0416 20:59:15.712689 23299 solver.cpp:237] Iteration 85200, loss = 0.0155289
I0416 20:59:15.712716 23299 solver.cpp:253]     Train net output #0: loss = 0.0155289 (* 1 = 0.0155289 loss)
I0416 20:59:15.712721 23299 sgd_solver.cpp:106] Iteration 85200, lr = 0.001
I0416 20:59:15.908404 23299 solver.cpp:237] Iteration 85300, loss = 0.0155147
I0416 20:59:15.908434 23299 solver.cpp:253]     Train net output #0: loss = 0.0155147 (* 1 = 0.0155147 loss)
I0416 20:59:15.908440 23299 sgd_solver.cpp:106] Iteration 85300, lr = 0.001
I0416 20:59:16.103932 23299 solver.cpp:237] Iteration 85400, loss = 0.0155572
I0416 20:59:16.103962 23299 solver.cpp:253]     Train net output #0: loss = 0.0155572 (* 1 = 0.0155572 loss)
I0416 20:59:16.103968 23299 sgd_solver.cpp:106] Iteration 85400, lr = 0.001
I0416 20:59:16.299355 23299 solver.cpp:237] Iteration 85500, loss = 0.0154844
I0416 20:59:16.299382 23299 solver.cpp:253]     Train net output #0: loss = 0.0154844 (* 1 = 0.0154844 loss)
I0416 20:59:16.299388 23299 sgd_solver.cpp:106] Iteration 85500, lr = 0.001
I0416 20:59:16.494421 23299 solver.cpp:237] Iteration 85600, loss = 0.0154912
I0416 20:59:16.494446 23299 solver.cpp:253]     Train net output #0: loss = 0.0154912 (* 1 = 0.0154912 loss)
I0416 20:59:16.494452 23299 sgd_solver.cpp:106] Iteration 85600, lr = 0.001
I0416 20:59:16.689298 23299 solver.cpp:237] Iteration 85700, loss = 0.0155118
I0416 20:59:16.689327 23299 solver.cpp:253]     Train net output #0: loss = 0.0155118 (* 1 = 0.0155118 loss)
I0416 20:59:16.689337 23299 sgd_solver.cpp:106] Iteration 85700, lr = 0.001
I0416 20:59:16.885870 23299 solver.cpp:237] Iteration 85800, loss = 0.0154841
I0416 20:59:16.885917 23299 solver.cpp:253]     Train net output #0: loss = 0.0154841 (* 1 = 0.0154841 loss)
I0416 20:59:16.885929 23299 sgd_solver.cpp:106] Iteration 85800, lr = 0.001
I0416 20:59:17.083042 23299 solver.cpp:237] Iteration 85900, loss = 0.0154972
I0416 20:59:17.083075 23299 solver.cpp:253]     Train net output #0: loss = 0.0154972 (* 1 = 0.0154972 loss)
I0416 20:59:17.083081 23299 sgd_solver.cpp:106] Iteration 85900, lr = 0.001
I0416 20:59:17.277868 23299 solver.cpp:237] Iteration 86000, loss = 0.0154692
I0416 20:59:17.277892 23299 solver.cpp:253]     Train net output #0: loss = 0.0154692 (* 1 = 0.0154692 loss)
I0416 20:59:17.277897 23299 sgd_solver.cpp:106] Iteration 86000, lr = 0.001
I0416 20:59:17.472568 23299 solver.cpp:237] Iteration 86100, loss = 0.0154539
I0416 20:59:17.472596 23299 solver.cpp:253]     Train net output #0: loss = 0.0154539 (* 1 = 0.0154539 loss)
I0416 20:59:17.472604 23299 sgd_solver.cpp:106] Iteration 86100, lr = 0.001
I0416 20:59:17.673923 23299 solver.cpp:237] Iteration 86200, loss = 0.0154407
I0416 20:59:17.673969 23299 solver.cpp:253]     Train net output #0: loss = 0.0154407 (* 1 = 0.0154407 loss)
I0416 20:59:17.673988 23299 sgd_solver.cpp:106] Iteration 86200, lr = 0.001
I0416 20:59:17.871354 23299 solver.cpp:237] Iteration 86300, loss = 0.0154365
I0416 20:59:17.871386 23299 solver.cpp:253]     Train net output #0: loss = 0.0154365 (* 1 = 0.0154365 loss)
I0416 20:59:17.871392 23299 sgd_solver.cpp:106] Iteration 86300, lr = 0.001
I0416 20:59:18.067188 23299 solver.cpp:237] Iteration 86400, loss = 0.015431
I0416 20:59:18.067219 23299 solver.cpp:253]     Train net output #0: loss = 0.015431 (* 1 = 0.015431 loss)
I0416 20:59:18.067225 23299 sgd_solver.cpp:106] Iteration 86400, lr = 0.001
I0416 20:59:18.263461 23299 solver.cpp:237] Iteration 86500, loss = 0.0154596
I0416 20:59:18.263519 23299 solver.cpp:253]     Train net output #0: loss = 0.0154596 (* 1 = 0.0154596 loss)
I0416 20:59:18.263525 23299 sgd_solver.cpp:106] Iteration 86500, lr = 0.001
I0416 20:59:18.459630 23299 solver.cpp:237] Iteration 86600, loss = 0.015428
I0416 20:59:18.459661 23299 solver.cpp:253]     Train net output #0: loss = 0.015428 (* 1 = 0.015428 loss)
I0416 20:59:18.459667 23299 sgd_solver.cpp:106] Iteration 86600, lr = 0.001
I0416 20:59:18.656218 23299 solver.cpp:237] Iteration 86700, loss = 0.0153744
I0416 20:59:18.656250 23299 solver.cpp:253]     Train net output #0: loss = 0.0153744 (* 1 = 0.0153744 loss)
I0416 20:59:18.656263 23299 sgd_solver.cpp:106] Iteration 86700, lr = 0.001
I0416 20:59:18.852756 23299 solver.cpp:237] Iteration 86800, loss = 0.0153952
I0416 20:59:18.852789 23299 solver.cpp:253]     Train net output #0: loss = 0.0153952 (* 1 = 0.0153952 loss)
I0416 20:59:18.852797 23299 sgd_solver.cpp:106] Iteration 86800, lr = 0.001
I0416 20:59:19.050401 23299 solver.cpp:237] Iteration 86900, loss = 0.015394
I0416 20:59:19.050437 23299 solver.cpp:253]     Train net output #0: loss = 0.015394 (* 1 = 0.015394 loss)
I0416 20:59:19.050446 23299 sgd_solver.cpp:106] Iteration 86900, lr = 0.001
I0416 20:59:19.246857 23299 solver.cpp:237] Iteration 87000, loss = 0.0154004
I0416 20:59:19.246903 23299 solver.cpp:253]     Train net output #0: loss = 0.0154004 (* 1 = 0.0154004 loss)
I0416 20:59:19.246912 23299 sgd_solver.cpp:106] Iteration 87000, lr = 0.001
I0416 20:59:19.443363 23299 solver.cpp:237] Iteration 87100, loss = 0.0153838
I0416 20:59:19.443393 23299 solver.cpp:253]     Train net output #0: loss = 0.0153838 (* 1 = 0.0153838 loss)
I0416 20:59:19.443413 23299 sgd_solver.cpp:106] Iteration 87100, lr = 0.001
I0416 20:59:19.639425 23299 solver.cpp:237] Iteration 87200, loss = 0.0153999
I0416 20:59:19.639456 23299 solver.cpp:253]     Train net output #0: loss = 0.0153999 (* 1 = 0.0153999 loss)
I0416 20:59:19.639463 23299 sgd_solver.cpp:106] Iteration 87200, lr = 0.001
I0416 20:59:19.834949 23299 solver.cpp:237] Iteration 87300, loss = 0.01533
I0416 20:59:19.834980 23299 solver.cpp:253]     Train net output #0: loss = 0.01533 (* 1 = 0.01533 loss)
I0416 20:59:19.834985 23299 sgd_solver.cpp:106] Iteration 87300, lr = 0.001
I0416 20:59:20.030887 23299 solver.cpp:237] Iteration 87400, loss = 0.0153224
I0416 20:59:20.030915 23299 solver.cpp:253]     Train net output #0: loss = 0.0153224 (* 1 = 0.0153224 loss)
I0416 20:59:20.030920 23299 sgd_solver.cpp:106] Iteration 87400, lr = 0.001
I0416 20:59:20.226420 23299 solver.cpp:237] Iteration 87500, loss = 0.0153398
I0416 20:59:20.226449 23299 solver.cpp:253]     Train net output #0: loss = 0.0153398 (* 1 = 0.0153398 loss)
I0416 20:59:20.226454 23299 sgd_solver.cpp:106] Iteration 87500, lr = 0.001
I0416 20:59:20.421576 23299 solver.cpp:237] Iteration 87600, loss = 0.0153719
I0416 20:59:20.421604 23299 solver.cpp:253]     Train net output #0: loss = 0.0153719 (* 1 = 0.0153719 loss)
I0416 20:59:20.421609 23299 sgd_solver.cpp:106] Iteration 87600, lr = 0.001
I0416 20:59:20.616819 23299 solver.cpp:237] Iteration 87700, loss = 0.0153195
I0416 20:59:20.616847 23299 solver.cpp:253]     Train net output #0: loss = 0.0153195 (* 1 = 0.0153195 loss)
I0416 20:59:20.616852 23299 sgd_solver.cpp:106] Iteration 87700, lr = 0.001
I0416 20:59:20.812130 23299 solver.cpp:237] Iteration 87800, loss = 0.0153551
I0416 20:59:20.812160 23299 solver.cpp:253]     Train net output #0: loss = 0.0153551 (* 1 = 0.0153551 loss)
I0416 20:59:20.812165 23299 sgd_solver.cpp:106] Iteration 87800, lr = 0.001
I0416 20:59:21.006964 23299 solver.cpp:237] Iteration 87900, loss = 0.0153491
I0416 20:59:21.006990 23299 solver.cpp:253]     Train net output #0: loss = 0.0153491 (* 1 = 0.0153491 loss)
I0416 20:59:21.006995 23299 sgd_solver.cpp:106] Iteration 87900, lr = 0.001
I0416 20:59:21.202445 23299 solver.cpp:237] Iteration 88000, loss = 0.0152699
I0416 20:59:21.202472 23299 solver.cpp:253]     Train net output #0: loss = 0.0152699 (* 1 = 0.0152699 loss)
I0416 20:59:21.202477 23299 sgd_solver.cpp:106] Iteration 88000, lr = 0.001
I0416 20:59:21.397850 23299 solver.cpp:237] Iteration 88100, loss = 0.0152678
I0416 20:59:21.397881 23299 solver.cpp:253]     Train net output #0: loss = 0.0152678 (* 1 = 0.0152678 loss)
I0416 20:59:21.397886 23299 sgd_solver.cpp:106] Iteration 88100, lr = 0.001
I0416 20:59:21.593169 23299 solver.cpp:237] Iteration 88200, loss = 0.0153128
I0416 20:59:21.593197 23299 solver.cpp:253]     Train net output #0: loss = 0.0153128 (* 1 = 0.0153128 loss)
I0416 20:59:21.593202 23299 sgd_solver.cpp:106] Iteration 88200, lr = 0.001
I0416 20:59:21.788534 23299 solver.cpp:237] Iteration 88300, loss = 0.0152911
I0416 20:59:21.788563 23299 solver.cpp:253]     Train net output #0: loss = 0.0152911 (* 1 = 0.0152911 loss)
I0416 20:59:21.788568 23299 sgd_solver.cpp:106] Iteration 88300, lr = 0.001
I0416 20:59:21.983737 23299 solver.cpp:237] Iteration 88400, loss = 0.0153154
I0416 20:59:21.983764 23299 solver.cpp:253]     Train net output #0: loss = 0.0153154 (* 1 = 0.0153154 loss)
I0416 20:59:21.983772 23299 sgd_solver.cpp:106] Iteration 88400, lr = 0.001
I0416 20:59:22.179095 23299 solver.cpp:237] Iteration 88500, loss = 0.015324
I0416 20:59:22.179122 23299 solver.cpp:253]     Train net output #0: loss = 0.015324 (* 1 = 0.015324 loss)
I0416 20:59:22.179131 23299 sgd_solver.cpp:106] Iteration 88500, lr = 0.001
I0416 20:59:22.374819 23299 solver.cpp:237] Iteration 88600, loss = 0.0152854
I0416 20:59:22.374846 23299 solver.cpp:253]     Train net output #0: loss = 0.0152854 (* 1 = 0.0152854 loss)
I0416 20:59:22.374852 23299 sgd_solver.cpp:106] Iteration 88600, lr = 0.001
I0416 20:59:22.570581 23299 solver.cpp:237] Iteration 88700, loss = 0.0152984
I0416 20:59:22.570608 23299 solver.cpp:253]     Train net output #0: loss = 0.0152984 (* 1 = 0.0152984 loss)
I0416 20:59:22.570613 23299 sgd_solver.cpp:106] Iteration 88700, lr = 0.001
I0416 20:59:22.765647 23299 solver.cpp:237] Iteration 88800, loss = 0.0152764
I0416 20:59:22.765674 23299 solver.cpp:253]     Train net output #0: loss = 0.0152764 (* 1 = 0.0152764 loss)
I0416 20:59:22.765679 23299 sgd_solver.cpp:106] Iteration 88800, lr = 0.001
I0416 20:59:22.963883 23299 solver.cpp:237] Iteration 88900, loss = 0.0152651
I0416 20:59:22.963925 23299 solver.cpp:253]     Train net output #0: loss = 0.0152651 (* 1 = 0.0152651 loss)
I0416 20:59:22.963934 23299 sgd_solver.cpp:106] Iteration 88900, lr = 0.001
I0416 20:59:23.159322 23299 solver.cpp:237] Iteration 89000, loss = 0.015267
I0416 20:59:23.159348 23299 solver.cpp:253]     Train net output #0: loss = 0.015267 (* 1 = 0.015267 loss)
I0416 20:59:23.159353 23299 sgd_solver.cpp:106] Iteration 89000, lr = 0.001
I0416 20:59:23.354420 23299 solver.cpp:237] Iteration 89100, loss = 0.0152197
I0416 20:59:23.354451 23299 solver.cpp:253]     Train net output #0: loss = 0.0152197 (* 1 = 0.0152197 loss)
I0416 20:59:23.354456 23299 sgd_solver.cpp:106] Iteration 89100, lr = 0.001
I0416 20:59:23.555510 23299 solver.cpp:237] Iteration 89200, loss = 0.015283
I0416 20:59:23.555548 23299 solver.cpp:253]     Train net output #0: loss = 0.015283 (* 1 = 0.015283 loss)
I0416 20:59:23.555557 23299 sgd_solver.cpp:106] Iteration 89200, lr = 0.001
I0416 20:59:23.753216 23299 solver.cpp:237] Iteration 89300, loss = 0.015207
I0416 20:59:23.753252 23299 solver.cpp:253]     Train net output #0: loss = 0.015207 (* 1 = 0.015207 loss)
I0416 20:59:23.753259 23299 sgd_solver.cpp:106] Iteration 89300, lr = 0.001
I0416 20:59:23.950201 23299 solver.cpp:237] Iteration 89400, loss = 0.0152669
I0416 20:59:23.950235 23299 solver.cpp:253]     Train net output #0: loss = 0.0152669 (* 1 = 0.0152669 loss)
I0416 20:59:23.950244 23299 sgd_solver.cpp:106] Iteration 89400, lr = 0.001
I0416 20:59:24.147163 23299 solver.cpp:237] Iteration 89500, loss = 0.0153103
I0416 20:59:24.147195 23299 solver.cpp:253]     Train net output #0: loss = 0.0153103 (* 1 = 0.0153103 loss)
I0416 20:59:24.147200 23299 sgd_solver.cpp:106] Iteration 89500, lr = 0.001
I0416 20:59:24.343284 23299 solver.cpp:237] Iteration 89600, loss = 0.0152408
I0416 20:59:24.343317 23299 solver.cpp:253]     Train net output #0: loss = 0.0152408 (* 1 = 0.0152408 loss)
I0416 20:59:24.343350 23299 sgd_solver.cpp:106] Iteration 89600, lr = 0.001
I0416 20:59:24.539109 23299 solver.cpp:237] Iteration 89700, loss = 0.0152011
I0416 20:59:24.539135 23299 solver.cpp:253]     Train net output #0: loss = 0.0152011 (* 1 = 0.0152011 loss)
I0416 20:59:24.539144 23299 sgd_solver.cpp:106] Iteration 89700, lr = 0.001
I0416 20:59:24.733824 23299 solver.cpp:237] Iteration 89800, loss = 0.0152073
I0416 20:59:24.733850 23299 solver.cpp:253]     Train net output #0: loss = 0.0152073 (* 1 = 0.0152073 loss)
I0416 20:59:24.733857 23299 sgd_solver.cpp:106] Iteration 89800, lr = 0.001
I0416 20:59:24.929457 23299 solver.cpp:237] Iteration 89900, loss = 0.0152357
I0416 20:59:24.929483 23299 solver.cpp:253]     Train net output #0: loss = 0.0152357 (* 1 = 0.0152357 loss)
I0416 20:59:24.929491 23299 sgd_solver.cpp:106] Iteration 89900, lr = 0.001
I0416 20:59:25.122941 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_90000.caffemodel
I0416 20:59:25.124999 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_90000.solverstate
I0416 20:59:25.125562 23299 solver.cpp:341] Iteration 90000, Testing net (#0)
I0416 20:59:25.125572 23299 net.cpp:748] Ignoring source layer dart
I0416 20:59:25.173948 23299 solver.cpp:409]     Test net output #0: accuracy = 0.818
I0416 20:59:25.173970 23299 solver.cpp:409]     Test net output #1: loss = 0.627979 (* 1 = 0.627979 loss)
I0416 20:59:25.174842 23299 solver.cpp:237] Iteration 90000, loss = 0.0152095
I0416 20:59:25.174860 23299 solver.cpp:253]     Train net output #0: loss = 0.0152095 (* 1 = 0.0152095 loss)
I0416 20:59:25.174873 23299 sgd_solver.cpp:106] Iteration 90000, lr = 0.001
I0416 20:59:25.376032 23299 solver.cpp:237] Iteration 90100, loss = 0.015266
I0416 20:59:25.376060 23299 solver.cpp:253]     Train net output #0: loss = 0.015266 (* 1 = 0.015266 loss)
I0416 20:59:25.376065 23299 sgd_solver.cpp:106] Iteration 90100, lr = 0.001
I0416 20:59:25.576992 23299 solver.cpp:237] Iteration 90200, loss = 0.0152382
I0416 20:59:25.577025 23299 solver.cpp:253]     Train net output #0: loss = 0.0152382 (* 1 = 0.0152382 loss)
I0416 20:59:25.577030 23299 sgd_solver.cpp:106] Iteration 90200, lr = 0.001
I0416 20:59:25.777962 23299 solver.cpp:237] Iteration 90300, loss = 0.015155
I0416 20:59:25.777989 23299 solver.cpp:253]     Train net output #0: loss = 0.015155 (* 1 = 0.015155 loss)
I0416 20:59:25.777995 23299 sgd_solver.cpp:106] Iteration 90300, lr = 0.001
I0416 20:59:25.979274 23299 solver.cpp:237] Iteration 90400, loss = 0.015205
I0416 20:59:25.979300 23299 solver.cpp:253]     Train net output #0: loss = 0.015205 (* 1 = 0.015205 loss)
I0416 20:59:25.979305 23299 sgd_solver.cpp:106] Iteration 90400, lr = 0.001
I0416 20:59:26.180132 23299 solver.cpp:237] Iteration 90500, loss = 0.0151975
I0416 20:59:26.180160 23299 solver.cpp:253]     Train net output #0: loss = 0.0151975 (* 1 = 0.0151975 loss)
I0416 20:59:26.180166 23299 sgd_solver.cpp:106] Iteration 90500, lr = 0.001
I0416 20:59:26.381216 23299 solver.cpp:237] Iteration 90600, loss = 0.0152152
I0416 20:59:26.381242 23299 solver.cpp:253]     Train net output #0: loss = 0.0152152 (* 1 = 0.0152152 loss)
I0416 20:59:26.381247 23299 sgd_solver.cpp:106] Iteration 90600, lr = 0.001
I0416 20:59:26.582221 23299 solver.cpp:237] Iteration 90700, loss = 0.0151902
I0416 20:59:26.582249 23299 solver.cpp:253]     Train net output #0: loss = 0.0151902 (* 1 = 0.0151902 loss)
I0416 20:59:26.582255 23299 sgd_solver.cpp:106] Iteration 90700, lr = 0.001
I0416 20:59:26.783359 23299 solver.cpp:237] Iteration 90800, loss = 0.0151773
I0416 20:59:26.783385 23299 solver.cpp:253]     Train net output #0: loss = 0.0151773 (* 1 = 0.0151773 loss)
I0416 20:59:26.783398 23299 sgd_solver.cpp:106] Iteration 90800, lr = 0.001
I0416 20:59:26.984550 23299 solver.cpp:237] Iteration 90900, loss = 0.0152223
I0416 20:59:26.984577 23299 solver.cpp:253]     Train net output #0: loss = 0.0152223 (* 1 = 0.0152223 loss)
I0416 20:59:26.984604 23299 sgd_solver.cpp:106] Iteration 90900, lr = 0.001
I0416 20:59:27.184792 23299 solver.cpp:237] Iteration 91000, loss = 0.0151549
I0416 20:59:27.184819 23299 solver.cpp:253]     Train net output #0: loss = 0.0151549 (* 1 = 0.0151549 loss)
I0416 20:59:27.184830 23299 sgd_solver.cpp:106] Iteration 91000, lr = 0.001
I0416 20:59:27.384814 23299 solver.cpp:237] Iteration 91100, loss = 0.0151699
I0416 20:59:27.384838 23299 solver.cpp:253]     Train net output #0: loss = 0.0151699 (* 1 = 0.0151699 loss)
I0416 20:59:27.384845 23299 sgd_solver.cpp:106] Iteration 91100, lr = 0.001
I0416 20:59:27.585088 23299 solver.cpp:237] Iteration 91200, loss = 0.0151516
I0416 20:59:27.585114 23299 solver.cpp:253]     Train net output #0: loss = 0.0151516 (* 1 = 0.0151516 loss)
I0416 20:59:27.585120 23299 sgd_solver.cpp:106] Iteration 91200, lr = 0.001
I0416 20:59:27.785244 23299 solver.cpp:237] Iteration 91300, loss = 0.0151985
I0416 20:59:27.785269 23299 solver.cpp:253]     Train net output #0: loss = 0.0151985 (* 1 = 0.0151985 loss)
I0416 20:59:27.785274 23299 sgd_solver.cpp:106] Iteration 91300, lr = 0.001
I0416 20:59:27.985460 23299 solver.cpp:237] Iteration 91400, loss = 0.0152028
I0416 20:59:27.985483 23299 solver.cpp:253]     Train net output #0: loss = 0.0152028 (* 1 = 0.0152028 loss)
I0416 20:59:27.985488 23299 sgd_solver.cpp:106] Iteration 91400, lr = 0.001
I0416 20:59:28.186022 23299 solver.cpp:237] Iteration 91500, loss = 0.0151691
I0416 20:59:28.186048 23299 solver.cpp:253]     Train net output #0: loss = 0.0151691 (* 1 = 0.0151691 loss)
I0416 20:59:28.186053 23299 sgd_solver.cpp:106] Iteration 91500, lr = 0.001
I0416 20:59:28.386636 23299 solver.cpp:237] Iteration 91600, loss = 0.0151842
I0416 20:59:28.386661 23299 solver.cpp:253]     Train net output #0: loss = 0.0151842 (* 1 = 0.0151842 loss)
I0416 20:59:28.386665 23299 sgd_solver.cpp:106] Iteration 91600, lr = 0.001
I0416 20:59:28.586980 23299 solver.cpp:237] Iteration 91700, loss = 0.0151345
I0416 20:59:28.587005 23299 solver.cpp:253]     Train net output #0: loss = 0.0151345 (* 1 = 0.0151345 loss)
I0416 20:59:28.587010 23299 sgd_solver.cpp:106] Iteration 91700, lr = 0.001
I0416 20:59:28.787041 23299 solver.cpp:237] Iteration 91800, loss = 0.0152017
I0416 20:59:28.787067 23299 solver.cpp:253]     Train net output #0: loss = 0.0152017 (* 1 = 0.0152017 loss)
I0416 20:59:28.787072 23299 sgd_solver.cpp:106] Iteration 91800, lr = 0.001
I0416 20:59:28.987458 23299 solver.cpp:237] Iteration 91900, loss = 0.0151637
I0416 20:59:28.987483 23299 solver.cpp:253]     Train net output #0: loss = 0.0151637 (* 1 = 0.0151637 loss)
I0416 20:59:28.987488 23299 sgd_solver.cpp:106] Iteration 91900, lr = 0.001
I0416 20:59:29.188042 23299 solver.cpp:237] Iteration 92000, loss = 0.0151691
I0416 20:59:29.188071 23299 solver.cpp:253]     Train net output #0: loss = 0.0151691 (* 1 = 0.0151691 loss)
I0416 20:59:29.188077 23299 sgd_solver.cpp:106] Iteration 92000, lr = 0.001
I0416 20:59:29.388813 23299 solver.cpp:237] Iteration 92100, loss = 0.0151368
I0416 20:59:29.388839 23299 solver.cpp:253]     Train net output #0: loss = 0.0151368 (* 1 = 0.0151368 loss)
I0416 20:59:29.388846 23299 sgd_solver.cpp:106] Iteration 92100, lr = 0.001
I0416 20:59:29.589110 23299 solver.cpp:237] Iteration 92200, loss = 0.0150771
I0416 20:59:29.589138 23299 solver.cpp:253]     Train net output #0: loss = 0.0150771 (* 1 = 0.0150771 loss)
I0416 20:59:29.589144 23299 sgd_solver.cpp:106] Iteration 92200, lr = 0.001
I0416 20:59:29.791138 23299 solver.cpp:237] Iteration 92300, loss = 0.0151733
I0416 20:59:29.791188 23299 solver.cpp:253]     Train net output #0: loss = 0.0151733 (* 1 = 0.0151733 loss)
I0416 20:59:29.791201 23299 sgd_solver.cpp:106] Iteration 92300, lr = 0.001
I0416 20:59:29.998420 23299 solver.cpp:237] Iteration 92400, loss = 0.0151437
I0416 20:59:29.998450 23299 solver.cpp:253]     Train net output #0: loss = 0.0151437 (* 1 = 0.0151437 loss)
I0416 20:59:29.998456 23299 sgd_solver.cpp:106] Iteration 92400, lr = 0.001
I0416 20:59:30.199965 23299 solver.cpp:237] Iteration 92500, loss = 0.0151026
I0416 20:59:30.200031 23299 solver.cpp:253]     Train net output #0: loss = 0.0151026 (* 1 = 0.0151026 loss)
I0416 20:59:30.200040 23299 sgd_solver.cpp:106] Iteration 92500, lr = 0.001
I0416 20:59:30.403064 23299 solver.cpp:237] Iteration 92600, loss = 0.0151189
I0416 20:59:30.403100 23299 solver.cpp:253]     Train net output #0: loss = 0.0151189 (* 1 = 0.0151189 loss)
I0416 20:59:30.403106 23299 sgd_solver.cpp:106] Iteration 92600, lr = 0.001
I0416 20:59:30.603641 23299 solver.cpp:237] Iteration 92700, loss = 0.0151507
I0416 20:59:30.603667 23299 solver.cpp:253]     Train net output #0: loss = 0.0151507 (* 1 = 0.0151507 loss)
I0416 20:59:30.603672 23299 sgd_solver.cpp:106] Iteration 92700, lr = 0.001
I0416 20:59:30.805249 23299 solver.cpp:237] Iteration 92800, loss = 0.0151299
I0416 20:59:30.805275 23299 solver.cpp:253]     Train net output #0: loss = 0.0151299 (* 1 = 0.0151299 loss)
I0416 20:59:30.805281 23299 sgd_solver.cpp:106] Iteration 92800, lr = 0.001
I0416 20:59:31.006189 23299 solver.cpp:237] Iteration 92900, loss = 0.0150957
I0416 20:59:31.006217 23299 solver.cpp:253]     Train net output #0: loss = 0.0150957 (* 1 = 0.0150957 loss)
I0416 20:59:31.006224 23299 sgd_solver.cpp:106] Iteration 92900, lr = 0.001
I0416 20:59:31.207188 23299 solver.cpp:237] Iteration 93000, loss = 0.015125
I0416 20:59:31.207216 23299 solver.cpp:253]     Train net output #0: loss = 0.015125 (* 1 = 0.015125 loss)
I0416 20:59:31.207221 23299 sgd_solver.cpp:106] Iteration 93000, lr = 0.001
I0416 20:59:31.408087 23299 solver.cpp:237] Iteration 93100, loss = 0.0150571
I0416 20:59:31.408116 23299 solver.cpp:253]     Train net output #0: loss = 0.0150571 (* 1 = 0.0150571 loss)
I0416 20:59:31.408123 23299 sgd_solver.cpp:106] Iteration 93100, lr = 0.001
I0416 20:59:31.608934 23299 solver.cpp:237] Iteration 93200, loss = 0.0150983
I0416 20:59:31.608966 23299 solver.cpp:253]     Train net output #0: loss = 0.0150983 (* 1 = 0.0150983 loss)
I0416 20:59:31.608980 23299 sgd_solver.cpp:106] Iteration 93200, lr = 0.001
I0416 20:59:31.809785 23299 solver.cpp:237] Iteration 93300, loss = 0.0151149
I0416 20:59:31.809813 23299 solver.cpp:253]     Train net output #0: loss = 0.0151149 (* 1 = 0.0151149 loss)
I0416 20:59:31.809818 23299 sgd_solver.cpp:106] Iteration 93300, lr = 0.001
I0416 20:59:32.010709 23299 solver.cpp:237] Iteration 93400, loss = 0.0151247
I0416 20:59:32.010740 23299 solver.cpp:253]     Train net output #0: loss = 0.0151247 (* 1 = 0.0151247 loss)
I0416 20:59:32.010746 23299 sgd_solver.cpp:106] Iteration 93400, lr = 0.001
I0416 20:59:32.211341 23299 solver.cpp:237] Iteration 93500, loss = 0.0151377
I0416 20:59:32.211367 23299 solver.cpp:253]     Train net output #0: loss = 0.0151377 (* 1 = 0.0151377 loss)
I0416 20:59:32.211374 23299 sgd_solver.cpp:106] Iteration 93500, lr = 0.001
I0416 20:59:32.411936 23299 solver.cpp:237] Iteration 93600, loss = 0.0151021
I0416 20:59:32.411962 23299 solver.cpp:253]     Train net output #0: loss = 0.0151021 (* 1 = 0.0151021 loss)
I0416 20:59:32.411967 23299 sgd_solver.cpp:106] Iteration 93600, lr = 0.001
I0416 20:59:32.613379 23299 solver.cpp:237] Iteration 93700, loss = 0.0150785
I0416 20:59:32.613411 23299 solver.cpp:253]     Train net output #0: loss = 0.0150785 (* 1 = 0.0150785 loss)
I0416 20:59:32.613417 23299 sgd_solver.cpp:106] Iteration 93700, lr = 0.001
I0416 20:59:32.814877 23299 solver.cpp:237] Iteration 93800, loss = 0.0150952
I0416 20:59:32.814903 23299 solver.cpp:253]     Train net output #0: loss = 0.0150952 (* 1 = 0.0150952 loss)
I0416 20:59:32.814909 23299 sgd_solver.cpp:106] Iteration 93800, lr = 0.001
I0416 20:59:33.016837 23299 solver.cpp:237] Iteration 93900, loss = 0.0150753
I0416 20:59:33.016865 23299 solver.cpp:253]     Train net output #0: loss = 0.0150753 (* 1 = 0.0150753 loss)
I0416 20:59:33.016870 23299 sgd_solver.cpp:106] Iteration 93900, lr = 0.001
I0416 20:59:33.217777 23299 solver.cpp:237] Iteration 94000, loss = 0.0151111
I0416 20:59:33.217805 23299 solver.cpp:253]     Train net output #0: loss = 0.0151111 (* 1 = 0.0151111 loss)
I0416 20:59:33.217811 23299 sgd_solver.cpp:106] Iteration 94000, lr = 0.001
I0416 20:59:33.418598 23299 solver.cpp:237] Iteration 94100, loss = 0.0151386
I0416 20:59:33.418627 23299 solver.cpp:253]     Train net output #0: loss = 0.0151386 (* 1 = 0.0151386 loss)
I0416 20:59:33.418633 23299 sgd_solver.cpp:106] Iteration 94100, lr = 0.001
I0416 20:59:33.619649 23299 solver.cpp:237] Iteration 94200, loss = 0.0151036
I0416 20:59:33.619675 23299 solver.cpp:253]     Train net output #0: loss = 0.0151036 (* 1 = 0.0151036 loss)
I0416 20:59:33.619680 23299 sgd_solver.cpp:106] Iteration 94200, lr = 0.001
I0416 20:59:33.820513 23299 solver.cpp:237] Iteration 94300, loss = 0.0151067
I0416 20:59:33.820543 23299 solver.cpp:253]     Train net output #0: loss = 0.0151067 (* 1 = 0.0151067 loss)
I0416 20:59:33.820554 23299 sgd_solver.cpp:106] Iteration 94300, lr = 0.001
I0416 20:59:34.021275 23299 solver.cpp:237] Iteration 94400, loss = 0.015115
I0416 20:59:34.021303 23299 solver.cpp:253]     Train net output #0: loss = 0.015115 (* 1 = 0.015115 loss)
I0416 20:59:34.021311 23299 sgd_solver.cpp:106] Iteration 94400, lr = 0.001
I0416 20:59:34.221954 23299 solver.cpp:237] Iteration 94500, loss = 0.0150885
I0416 20:59:34.221985 23299 solver.cpp:253]     Train net output #0: loss = 0.0150885 (* 1 = 0.0150885 loss)
I0416 20:59:34.221997 23299 sgd_solver.cpp:106] Iteration 94500, lr = 0.001
I0416 20:59:34.422909 23299 solver.cpp:237] Iteration 94600, loss = 0.0150731
I0416 20:59:34.422940 23299 solver.cpp:253]     Train net output #0: loss = 0.0150731 (* 1 = 0.0150731 loss)
I0416 20:59:34.422947 23299 sgd_solver.cpp:106] Iteration 94600, lr = 0.001
I0416 20:59:34.624255 23299 solver.cpp:237] Iteration 94700, loss = 0.0150911
I0416 20:59:34.624285 23299 solver.cpp:253]     Train net output #0: loss = 0.0150911 (* 1 = 0.0150911 loss)
I0416 20:59:34.624296 23299 sgd_solver.cpp:106] Iteration 94700, lr = 0.001
I0416 20:59:34.825104 23299 solver.cpp:237] Iteration 94800, loss = 0.0151239
I0416 20:59:34.825132 23299 solver.cpp:253]     Train net output #0: loss = 0.0151239 (* 1 = 0.0151239 loss)
I0416 20:59:34.825141 23299 sgd_solver.cpp:106] Iteration 94800, lr = 0.001
I0416 20:59:35.032358 23299 solver.cpp:237] Iteration 94900, loss = 0.0150994
I0416 20:59:35.032392 23299 solver.cpp:253]     Train net output #0: loss = 0.0150994 (* 1 = 0.0150994 loss)
I0416 20:59:35.032400 23299 sgd_solver.cpp:106] Iteration 94900, lr = 0.001
I0416 20:59:35.231595 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_95000.caffemodel
I0416 20:59:35.233711 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_95000.solverstate
I0416 20:59:35.234268 23299 solver.cpp:341] Iteration 95000, Testing net (#0)
I0416 20:59:35.234282 23299 net.cpp:748] Ignoring source layer dart
I0416 20:59:35.280772 23299 solver.cpp:409]     Test net output #0: accuracy = 0.8205
I0416 20:59:35.280797 23299 solver.cpp:409]     Test net output #1: loss = 0.62118 (* 1 = 0.62118 loss)
I0416 20:59:35.281649 23299 solver.cpp:237] Iteration 95000, loss = 0.0150749
I0416 20:59:35.281669 23299 solver.cpp:253]     Train net output #0: loss = 0.0150749 (* 1 = 0.0150749 loss)
I0416 20:59:35.281678 23299 sgd_solver.cpp:106] Iteration 95000, lr = 0.001
I0416 20:59:35.477694 23299 solver.cpp:237] Iteration 95100, loss = 0.0150427
I0416 20:59:35.477725 23299 solver.cpp:253]     Train net output #0: loss = 0.0150427 (* 1 = 0.0150427 loss)
I0416 20:59:35.477743 23299 sgd_solver.cpp:106] Iteration 95100, lr = 0.001
I0416 20:59:35.673593 23299 solver.cpp:237] Iteration 95200, loss = 0.0150753
I0416 20:59:35.673622 23299 solver.cpp:253]     Train net output #0: loss = 0.0150753 (* 1 = 0.0150753 loss)
I0416 20:59:35.673629 23299 sgd_solver.cpp:106] Iteration 95200, lr = 0.001
I0416 20:59:35.869109 23299 solver.cpp:237] Iteration 95300, loss = 0.0151183
I0416 20:59:35.869138 23299 solver.cpp:253]     Train net output #0: loss = 0.0151183 (* 1 = 0.0151183 loss)
I0416 20:59:35.869143 23299 sgd_solver.cpp:106] Iteration 95300, lr = 0.001
I0416 20:59:36.064275 23299 solver.cpp:237] Iteration 95400, loss = 0.0151011
I0416 20:59:36.064323 23299 solver.cpp:253]     Train net output #0: loss = 0.0151011 (* 1 = 0.0151011 loss)
I0416 20:59:36.064332 23299 sgd_solver.cpp:106] Iteration 95400, lr = 0.001
I0416 20:59:36.259743 23299 solver.cpp:237] Iteration 95500, loss = 0.0150423
I0416 20:59:36.259769 23299 solver.cpp:253]     Train net output #0: loss = 0.0150423 (* 1 = 0.0150423 loss)
I0416 20:59:36.259774 23299 sgd_solver.cpp:106] Iteration 95500, lr = 0.001
I0416 20:59:36.455420 23299 solver.cpp:237] Iteration 95600, loss = 0.0150854
I0416 20:59:36.455593 23299 solver.cpp:253]     Train net output #0: loss = 0.0150854 (* 1 = 0.0150854 loss)
I0416 20:59:36.455634 23299 sgd_solver.cpp:106] Iteration 95600, lr = 0.001
I0416 20:59:36.660219 23299 solver.cpp:237] Iteration 95700, loss = 0.0150861
I0416 20:59:36.660257 23299 solver.cpp:253]     Train net output #0: loss = 0.0150861 (* 1 = 0.0150861 loss)
I0416 20:59:36.660265 23299 sgd_solver.cpp:106] Iteration 95700, lr = 0.001
I0416 20:59:36.857002 23299 solver.cpp:237] Iteration 95800, loss = 0.015058
I0416 20:59:36.857029 23299 solver.cpp:253]     Train net output #0: loss = 0.015058 (* 1 = 0.015058 loss)
I0416 20:59:36.857034 23299 sgd_solver.cpp:106] Iteration 95800, lr = 0.001
I0416 20:59:37.053288 23299 solver.cpp:237] Iteration 95900, loss = 0.0150644
I0416 20:59:37.053319 23299 solver.cpp:253]     Train net output #0: loss = 0.0150644 (* 1 = 0.0150644 loss)
I0416 20:59:37.053328 23299 sgd_solver.cpp:106] Iteration 95900, lr = 0.001
I0416 20:59:37.249217 23299 solver.cpp:237] Iteration 96000, loss = 0.0150818
I0416 20:59:37.249248 23299 solver.cpp:253]     Train net output #0: loss = 0.0150818 (* 1 = 0.0150818 loss)
I0416 20:59:37.249253 23299 sgd_solver.cpp:106] Iteration 96000, lr = 0.001
I0416 20:59:37.445747 23299 solver.cpp:237] Iteration 96100, loss = 0.0150703
I0416 20:59:37.445777 23299 solver.cpp:253]     Train net output #0: loss = 0.0150703 (* 1 = 0.0150703 loss)
I0416 20:59:37.445783 23299 sgd_solver.cpp:106] Iteration 96100, lr = 0.001
I0416 20:59:37.642402 23299 solver.cpp:237] Iteration 96200, loss = 0.0150533
I0416 20:59:37.642434 23299 solver.cpp:253]     Train net output #0: loss = 0.0150533 (* 1 = 0.0150533 loss)
I0416 20:59:37.642441 23299 sgd_solver.cpp:106] Iteration 96200, lr = 0.001
I0416 20:59:37.839176 23299 solver.cpp:237] Iteration 96300, loss = 0.0150527
I0416 20:59:37.839207 23299 solver.cpp:253]     Train net output #0: loss = 0.0150527 (* 1 = 0.0150527 loss)
I0416 20:59:37.839213 23299 sgd_solver.cpp:106] Iteration 96300, lr = 0.001
I0416 20:59:38.037262 23299 solver.cpp:237] Iteration 96400, loss = 0.0150562
I0416 20:59:38.037304 23299 solver.cpp:253]     Train net output #0: loss = 0.0150562 (* 1 = 0.0150562 loss)
I0416 20:59:38.037313 23299 sgd_solver.cpp:106] Iteration 96400, lr = 0.001
I0416 20:59:38.233669 23299 solver.cpp:237] Iteration 96500, loss = 0.0150328
I0416 20:59:38.233700 23299 solver.cpp:253]     Train net output #0: loss = 0.0150328 (* 1 = 0.0150328 loss)
I0416 20:59:38.233712 23299 sgd_solver.cpp:106] Iteration 96500, lr = 0.001
I0416 20:59:38.270953 23299 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 20:59:38.430388 23299 solver.cpp:237] Iteration 96600, loss = 0.0150778
I0416 20:59:38.430419 23299 solver.cpp:253]     Train net output #0: loss = 0.0150778 (* 1 = 0.0150778 loss)
I0416 20:59:38.430425 23299 sgd_solver.cpp:106] Iteration 96600, lr = 0.001
I0416 20:59:38.626786 23299 solver.cpp:237] Iteration 96700, loss = 0.0150697
I0416 20:59:38.626818 23299 solver.cpp:253]     Train net output #0: loss = 0.0150697 (* 1 = 0.0150697 loss)
I0416 20:59:38.626824 23299 sgd_solver.cpp:106] Iteration 96700, lr = 0.001
I0416 20:59:38.822968 23299 solver.cpp:237] Iteration 96800, loss = 0.0149971
I0416 20:59:38.822998 23299 solver.cpp:253]     Train net output #0: loss = 0.0149971 (* 1 = 0.0149971 loss)
I0416 20:59:38.823004 23299 sgd_solver.cpp:106] Iteration 96800, lr = 0.001
I0416 20:59:39.019214 23299 solver.cpp:237] Iteration 96900, loss = 0.0150754
I0416 20:59:39.019253 23299 solver.cpp:253]     Train net output #0: loss = 0.0150754 (* 1 = 0.0150754 loss)
I0416 20:59:39.019261 23299 sgd_solver.cpp:106] Iteration 96900, lr = 0.001
I0416 20:59:39.215085 23299 solver.cpp:237] Iteration 97000, loss = 0.0150465
I0416 20:59:39.215116 23299 solver.cpp:253]     Train net output #0: loss = 0.0150465 (* 1 = 0.0150465 loss)
I0416 20:59:39.215122 23299 sgd_solver.cpp:106] Iteration 97000, lr = 0.001
I0416 20:59:39.411057 23299 solver.cpp:237] Iteration 97100, loss = 0.0150561
I0416 20:59:39.411087 23299 solver.cpp:253]     Train net output #0: loss = 0.0150561 (* 1 = 0.0150561 loss)
I0416 20:59:39.411123 23299 sgd_solver.cpp:106] Iteration 97100, lr = 0.001
I0416 20:59:39.607588 23299 solver.cpp:237] Iteration 97200, loss = 0.0150556
I0416 20:59:39.607617 23299 solver.cpp:253]     Train net output #0: loss = 0.0150556 (* 1 = 0.0150556 loss)
I0416 20:59:39.607623 23299 sgd_solver.cpp:106] Iteration 97200, lr = 0.001
I0416 20:59:39.803556 23299 solver.cpp:237] Iteration 97300, loss = 0.0150174
I0416 20:59:39.803586 23299 solver.cpp:253]     Train net output #0: loss = 0.0150174 (* 1 = 0.0150174 loss)
I0416 20:59:39.803593 23299 sgd_solver.cpp:106] Iteration 97300, lr = 0.001
I0416 20:59:39.999380 23299 solver.cpp:237] Iteration 97400, loss = 0.0150079
I0416 20:59:39.999411 23299 solver.cpp:253]     Train net output #0: loss = 0.0150079 (* 1 = 0.0150079 loss)
I0416 20:59:39.999423 23299 sgd_solver.cpp:106] Iteration 97400, lr = 0.001
I0416 20:59:40.196027 23299 solver.cpp:237] Iteration 97500, loss = 0.0150162
I0416 20:59:40.196058 23299 solver.cpp:253]     Train net output #0: loss = 0.0150162 (* 1 = 0.0150162 loss)
I0416 20:59:40.196064 23299 sgd_solver.cpp:106] Iteration 97500, lr = 0.001
I0416 20:59:40.391984 23299 solver.cpp:237] Iteration 97600, loss = 0.0150533
I0416 20:59:40.392011 23299 solver.cpp:253]     Train net output #0: loss = 0.0150533 (* 1 = 0.0150533 loss)
I0416 20:59:40.392017 23299 sgd_solver.cpp:106] Iteration 97600, lr = 0.001
I0416 20:59:40.587517 23299 solver.cpp:237] Iteration 97700, loss = 0.0150702
I0416 20:59:40.587544 23299 solver.cpp:253]     Train net output #0: loss = 0.0150702 (* 1 = 0.0150702 loss)
I0416 20:59:40.587549 23299 sgd_solver.cpp:106] Iteration 97700, lr = 0.001
I0416 20:59:40.783917 23299 solver.cpp:237] Iteration 97800, loss = 0.0150614
I0416 20:59:40.783943 23299 solver.cpp:253]     Train net output #0: loss = 0.0150614 (* 1 = 0.0150614 loss)
I0416 20:59:40.783948 23299 sgd_solver.cpp:106] Iteration 97800, lr = 0.001
I0416 20:59:40.980487 23299 solver.cpp:237] Iteration 97900, loss = 0.0149936
I0416 20:59:40.980512 23299 solver.cpp:253]     Train net output #0: loss = 0.0149936 (* 1 = 0.0149936 loss)
I0416 20:59:40.980518 23299 sgd_solver.cpp:106] Iteration 97900, lr = 0.001
I0416 20:59:41.176362 23299 solver.cpp:237] Iteration 98000, loss = 0.0149927
I0416 20:59:41.176389 23299 solver.cpp:253]     Train net output #0: loss = 0.0149927 (* 1 = 0.0149927 loss)
I0416 20:59:41.176396 23299 sgd_solver.cpp:106] Iteration 98000, lr = 0.001
I0416 20:59:41.371845 23299 solver.cpp:237] Iteration 98100, loss = 0.0149767
I0416 20:59:41.371870 23299 solver.cpp:253]     Train net output #0: loss = 0.0149767 (* 1 = 0.0149767 loss)
I0416 20:59:41.371876 23299 sgd_solver.cpp:106] Iteration 98100, lr = 0.001
I0416 20:59:41.568552 23299 solver.cpp:237] Iteration 98200, loss = 0.0150092
I0416 20:59:41.568581 23299 solver.cpp:253]     Train net output #0: loss = 0.0150092 (* 1 = 0.0150092 loss)
I0416 20:59:41.568586 23299 sgd_solver.cpp:106] Iteration 98200, lr = 0.001
I0416 20:59:41.763432 23299 solver.cpp:237] Iteration 98300, loss = 0.0150144
I0416 20:59:41.763458 23299 solver.cpp:253]     Train net output #0: loss = 0.0150144 (* 1 = 0.0150144 loss)
I0416 20:59:41.763464 23299 sgd_solver.cpp:106] Iteration 98300, lr = 0.001
I0416 20:59:41.958179 23299 solver.cpp:237] Iteration 98400, loss = 0.0150335
I0416 20:59:41.958205 23299 solver.cpp:253]     Train net output #0: loss = 0.0150335 (* 1 = 0.0150335 loss)
I0416 20:59:41.958210 23299 sgd_solver.cpp:106] Iteration 98400, lr = 0.001
I0416 20:59:42.154497 23299 solver.cpp:237] Iteration 98500, loss = 0.0150331
I0416 20:59:42.154525 23299 solver.cpp:253]     Train net output #0: loss = 0.0150331 (* 1 = 0.0150331 loss)
I0416 20:59:42.154531 23299 sgd_solver.cpp:106] Iteration 98500, lr = 0.001
I0416 20:59:42.350682 23299 solver.cpp:237] Iteration 98600, loss = 0.0150563
I0416 20:59:42.350718 23299 solver.cpp:253]     Train net output #0: loss = 0.0150563 (* 1 = 0.0150563 loss)
I0416 20:59:42.350728 23299 sgd_solver.cpp:106] Iteration 98600, lr = 0.001
I0416 20:59:42.547750 23299 solver.cpp:237] Iteration 98700, loss = 0.0149729
I0416 20:59:42.547813 23299 solver.cpp:253]     Train net output #0: loss = 0.0149729 (* 1 = 0.0149729 loss)
I0416 20:59:42.547827 23299 sgd_solver.cpp:106] Iteration 98700, lr = 0.001
I0416 20:59:42.743914 23299 solver.cpp:237] Iteration 98800, loss = 0.0149946
I0416 20:59:42.743943 23299 solver.cpp:253]     Train net output #0: loss = 0.0149946 (* 1 = 0.0149946 loss)
I0416 20:59:42.743953 23299 sgd_solver.cpp:106] Iteration 98800, lr = 0.001
I0416 20:59:42.939694 23299 solver.cpp:237] Iteration 98900, loss = 0.0150178
I0416 20:59:42.939721 23299 solver.cpp:253]     Train net output #0: loss = 0.0150178 (* 1 = 0.0150178 loss)
I0416 20:59:42.939726 23299 sgd_solver.cpp:106] Iteration 98900, lr = 0.001
I0416 20:59:43.135648 23299 solver.cpp:237] Iteration 99000, loss = 0.0149971
I0416 20:59:43.135673 23299 solver.cpp:253]     Train net output #0: loss = 0.0149971 (* 1 = 0.0149971 loss)
I0416 20:59:43.135681 23299 sgd_solver.cpp:106] Iteration 99000, lr = 0.001
I0416 20:59:43.331735 23299 solver.cpp:237] Iteration 99100, loss = 0.0149626
I0416 20:59:43.331760 23299 solver.cpp:253]     Train net output #0: loss = 0.0149626 (* 1 = 0.0149626 loss)
I0416 20:59:43.331765 23299 sgd_solver.cpp:106] Iteration 99100, lr = 0.001
I0416 20:59:43.527809 23299 solver.cpp:237] Iteration 99200, loss = 0.0150393
I0416 20:59:43.527837 23299 solver.cpp:253]     Train net output #0: loss = 0.0150393 (* 1 = 0.0150393 loss)
I0416 20:59:43.527842 23299 sgd_solver.cpp:106] Iteration 99200, lr = 0.001
I0416 20:59:43.724153 23299 solver.cpp:237] Iteration 99300, loss = 0.0149914
I0416 20:59:43.724179 23299 solver.cpp:253]     Train net output #0: loss = 0.0149914 (* 1 = 0.0149914 loss)
I0416 20:59:43.724185 23299 sgd_solver.cpp:106] Iteration 99300, lr = 0.001
I0416 20:59:43.922948 23299 solver.cpp:237] Iteration 99400, loss = 0.0149939
I0416 20:59:43.922992 23299 solver.cpp:253]     Train net output #0: loss = 0.0149939 (* 1 = 0.0149939 loss)
I0416 20:59:43.923002 23299 sgd_solver.cpp:106] Iteration 99400, lr = 0.001
I0416 20:59:44.119523 23299 solver.cpp:237] Iteration 99500, loss = 0.0149918
I0416 20:59:44.119554 23299 solver.cpp:253]     Train net output #0: loss = 0.0149918 (* 1 = 0.0149918 loss)
I0416 20:59:44.119567 23299 sgd_solver.cpp:106] Iteration 99500, lr = 0.001
I0416 20:59:44.315546 23299 solver.cpp:237] Iteration 99600, loss = 0.0149682
I0416 20:59:44.315574 23299 solver.cpp:253]     Train net output #0: loss = 0.0149682 (* 1 = 0.0149682 loss)
I0416 20:59:44.315587 23299 sgd_solver.cpp:106] Iteration 99600, lr = 0.001
I0416 20:59:44.511520 23299 solver.cpp:237] Iteration 99700, loss = 0.0149703
I0416 20:59:44.511551 23299 solver.cpp:253]     Train net output #0: loss = 0.0149703 (* 1 = 0.0149703 loss)
I0416 20:59:44.511559 23299 sgd_solver.cpp:106] Iteration 99700, lr = 0.001
I0416 20:59:44.707280 23299 solver.cpp:237] Iteration 99800, loss = 0.0149134
I0416 20:59:44.707316 23299 solver.cpp:253]     Train net output #0: loss = 0.0149134 (* 1 = 0.0149134 loss)
I0416 20:59:44.707322 23299 sgd_solver.cpp:106] Iteration 99800, lr = 0.001
I0416 20:59:44.903165 23299 solver.cpp:237] Iteration 99900, loss = 0.0149704
I0416 20:59:44.903193 23299 solver.cpp:253]     Train net output #0: loss = 0.0149704 (* 1 = 0.0149704 loss)
I0416 20:59:44.903199 23299 sgd_solver.cpp:106] Iteration 99900, lr = 0.001
I0416 20:59:45.096724 23299 solver.cpp:459] Snapshotting to binary proto file examples/embeded/dart_iter_100000.caffemodel
I0416 20:59:45.098723 23299 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/embeded/dart_iter_100000.solverstate
I0416 20:59:45.099913 23299 solver.cpp:321] Iteration 100000, loss = 0.0149493
I0416 20:59:45.099931 23299 solver.cpp:341] Iteration 100000, Testing net (#0)
I0416 20:59:45.099941 23299 net.cpp:748] Ignoring source layer dart
I0416 20:59:45.145906 23299 solver.cpp:409]     Test net output #0: accuracy = 0.8205
I0416 20:59:45.145927 23299 solver.cpp:409]     Test net output #1: loss = 0.614754 (* 1 = 0.614754 loss)
I0416 20:59:45.145932 23299 solver.cpp:326] Optimization Done.
I0416 20:59:45.145951 23299 caffe.cpp:215] Optimization Done.
